{
  "video_id": "cMscNuSUy0I",
  "title": "Noam Chomsky: Language, Cognition, and Deep Learning | Lex Fridman Podcast #53",
  "date": "2019-11-29",
  "transcript": [
    {
      "timestamp": "0:00",
      "section": "Full Transcript",
      "text": "- The following is a\nconversation with Noam Chomsky. He's truly one of the\ngreat minds of our time and is one of the most cited scholars in the history of our civilization. He has spent over 60 years at MIT and recently also joined\nthe University of Arizona where we met for this conversation, but it was at MIT about\nfour and 1/2 years ago when I first met Noam. My first few days there I remember getting into an elevator at Stata Center, pressing the button for\nwhatever floor, looking up and realizing it was\njust me and Noam Chomsky riding the elevator, just me\nand one of the seminal figures of linguistics, cognitive\nscience, philosophy, and political thought in the\npast century if not ever. I tell that silly story\nbecause I think life is made up of funny\nlittle defining moments that you never forget for\nreasons that may be too poetic to try and explain, that was one of mine. Noam has been an inspiration\nto me and millions of others. It was truly an honor for me to sit down with him in Arizona. I traveled there just\nfor this conversation, and in a rare, heartbreaking moment after everything was set up and tested the camera was moved and accidentally the recording button was\npressed stopping the recording. So I have good audio of both\nof us but no video of Noam, just a video of me and my\nsleep deprived but excited face that I get to keep as a\nreminder of my failures. Most people just listen\nto this audio version for the podcast as opposed\nto watching it on YouTube, but still it's heartbreaking for me. I hope you understand and still enjoy this\nconversation as much as I did. The depth of intellect that Noam showed and his willingness to truly listen to me, a silly looking Russian\nin a suit was humbling and something I'm deeply grateful for. As some of you know, this\npodcast is a side project for me where my main journey and dream is to build AI systems that\ndo some good for the world. This latter effort\ntakes up most of my time but for the moment has\nbeen mostly private, but the former, the podcast\nis something I put my heart and soul into and I hope you feel that even when I screw things up. I recently started doing ads at the end of the introduction. I'll do one or two minutes\nafter introducing the episode and never any ads in the middle that break the flow of the conversation. I hope that works for you and doesn't hurt the listening experience. This is the Artificial\nIntelligence podcast. If you enjoy it, subscribe on YouTube, give it five stars on Apple Podcast, support it on Patreon, or simply\ncontact with me on Twitter @lexfridman spelled F-R-I-D-M-A-N. This show is presented by Cash App, the number one finance\napp on the App Store. I personally use cash app\nto send money to friends, but you can also use it to buy, sell, and deposit Bitcoin in just seconds. Cash App also has a new investing feature. You can buy fractions of a stock, say $1 worth, no matter\nwhat the stock price is. Broker services are provided\nby Cash App Investing, a subsidiary of Square and member SIPC. I'm excited to be working with Cash App to support one of my favorite\norganizations called the FIRST best known for their FIRST\nrobotics and LEGO competitions. They educate and inspire\nhundreds of thousands of students in over 110 countries\nand have a perfect rating on Charity Navigator which\nmeans the donated money is used to maximum effectiveness. When you get Cash App in\nthe App Store or Google Play and use code LexPodcast you'll get $10 and Cash App will also\ndonate $10 to FIRST, which again is an organization that I've personally seen\ninspire girls and boys to dream of engineering a better world. And now here's my conversation\nwith Noam Chomsky. I apologize for the absurd\nphilosophical question, but if an alien species\nwere to visit Earth, do you think we would be able\nto find a common language or protocol of communication with them? - [Noam] There are arguments\nto the effect that we could. In fact, one of them was Marv Minsky's. Back about 20 or 30 years ago he performed a brief experiment with a\nstudent of his, Daniel Bobrow they essentially ran the\nsimplest possible Turing machines just free to see what would happen. And most of them crashed,\neither got into an infinite loop or were stopped, the few that persisted essentially gave\nsomething like arithmetic. And his conclusion from that was that if some alien species\ndeveloped higher intelligence they would at least have arithmetic. They would at least have what\nthe simplest computer would do and in fact he didn't\nknow that at the time, but the core principles\nof natural language are based on operations\nwhich yield something like arithmetic in the limiting\ncase, in the minimal case. So it's conceivable that\na mode of communication could be established based\non the core properties of human language and the\ncore properties of arithmetic which maybe are universally\nshared so it's conceivable. - [Lex] What is the\nstructure of that language, of language as an internal\nsystem inside our mind versus an external\nsystem as it's expressed? - [Noam] It's not an alternative. It's two different concepts of language. - [Lex] Different. - [Noam] It's a simple fact that there's something\nabout you, a trait of yours, part of the organism you that determines that you're talking English\nand not Tagalog, let's say. So there is an inner system. It determines the sound and meaning of the infinite number of\nexpressions of your language. It's localized, it's not in your foot obviously it's in your brain. If you look more closely it's\nin specific configurations of your brain and that's essentially like the internal\nstructure of your laptop. Whatever programs it has are in there. Now, one of the things\nyou can do with language, it's a marginal thing in\nfact is use it to externalize what's in your head. I think most of your use\nof language is thought, internal thought, but can do\nwhat you and I are now doing. We can externalize it. Well, the set of things\nthat we're externalizing are an external system, they're\nnoises in the atmosphere, and you can call that language in some other sense of the word, but it's not a set of alternatives. These are just different concepts. - [Lex] So how deep do the roots of language go in our brain? - Well--\n- Our mind, is it yet another feature like vision? Or is it something more fundamental from which everything else\nsprings in the human mind? - [Noam] Well in a way it's like vision. There's something about\nour genetic endowment that determines that we have a mammalian rather than an insect visual system. And there's something\nin our genetic endowment that determines that we have\na human language faculty. No other organism has\nanything remotely similar. So in that sense it's internal. Now, there is a long tradition\nwhich I think is valid going back centuries to the\nearly scientific revolution at least that holds that language is the sort of the core of\nhuman cognitive nature. It's the source, it's the\nmode for constructing thoughts and expressing them and\nthat is what forms thought and it's got fundamental\ncreative capacities. It's free, independent,\nunbounded and so on. And undoubtedly I think the basis for our creative capacities\nand the other remarkable human capacities that lead\nto the unique achievements and not so great\nachievements of the species. - [Lex] The capacity to think and reason. Do you think that's deeply\nlinked with language? Do you think the internal\nlanguage system is essentially the mechanism by which we\nalso reason internally? - [Noam] It is undoubtedly the\nmechanism by which we reason. There may also be other,\nthere are undoubtedly other faculties involved in reasoning. We have a kind of scientific faculty. Nobody knows what it\nis, but whatever it is that enables us to pursue\ncertain lines of endeavor and inquiry and to decide what makes sense and doesn't make sense and\nto achieve a certain degree of understanding in the\nworld that uses language but goes beyond it just as using\nour capacity for arithmetic is not the same as having the capacity. - [Lex] The idea of capacity,\nour biology, evolution, you've talked about it defining\nessentially our capacity, our limit and our scope. Can you try to define\nwhat limit and scope are, and the bigger question,\ndo you think it's possible to find the limit of human cognition? - [Noam] Well that's an\ninteresting question. It's commonly believed,\nmost scientists believe that human intelligence can answer any question in principle. I think that's a very strange belief. If we're biological organisms\nwhich are not angels then our capacities ought\nto have scope and limits which are interrelated. - [Lex] Can you define those two terms? - [Noam] Well, let's\ntake a concrete example. Your genetic endowment, it determines that you can have a\nmammalian visual system and arms and legs and so on and therefore become a\nrich, complex organism, but if you look at that\nsame genetic endowment it prevents you from\ndeveloping in other directions. There's no kind of experience\nwhich would yield the embryo to develop an insect visual system or to develop wings instead of arms. So the very endowment that\nconfers richness and complexity also sets bounds on what can be attained. Now I assume that our cognitive capacities are part of the organic world therefore they should\nhave the same properties. If they had no built-in\ncapacity to develop a rich and complex structure we\nwould understand nothing just as if your genetic endowment did not compel you to\ndevelop arms and legs you would just be some kind\nof a random ameboid creature with no structure at all\nso I think it's plausible to assume that there are limits, and I think we even have some\nevidence as to what they are. So for example there's a classic moment in the history of science\nat the time of Newton. There was from Galileo to\nNewton modern science developed on a fundamental assumption\nwhich Newton also accepted, namely that the world, the entire universe is a mechanical object and\nby mechanical they meant something like the kinds of artifacts that were being developed\nby skilled artisans all over Europe, the\ngears, levers, and so on. And their belief was, well the world is just a more complex variant of this. Newton to his astonishment\nand distress proved that there are no machines, that there's\ninteraction without contact. His contemporaries like\nLeibniz and Huygens just dismissed this as\nreturning to the mysticism of the Neo-Scholastics and Newton agreed. He said, \"It is totally absurd. \"No person of any scientific intelligence \"could ever accept this for a moment.\" In fact, he spent the rest of his life trying to get around it somehow as did many other scientists. That was the very criterion\nof intelligibility for say Galileo or Newton. Theory did not produce\nan intelligible world unless you could duplicate it in a machine and he showed you can't,\nthere are no machines, any. Finally after a long\nstruggle, took a long time scientists just accepted\nthis as common sense, but that's a significant moment. That means they abandoned the search for an intelligible world\nand the great philosophers of the time understood that very well. So for example, David Hume\nin his encomium to Newton wrote that, who was the\ngreatest thinker ever and so on. He said that he unveiled\nmany of the secrets of nature but by showing the imperfections of the mechanical philosophy,\nmechanical science he left us with, he showed\nthat there are mysteries which ever will remain, and\nscience just changed its goals. It abandoned the mysteries. It can't solve it, they'll put it aside. We only look for intelligible theories. Newton's theories were intelligible it's just what they described wasn't. Well, Locke said the same thing. I think they're basically right and if so that showed something about\nthe limits of human cognition. We cannot attain the goal\nof understanding the world, of finding an intelligible world. This mechanical philosophy,\nGalileo to Newton, there's a good case that can be made that that's our instinctive\nconception of how things work. So if say infants are tested with things that if this moves and then this moves they kind of invent something\nthat must be invisible that's in between them that's\nmaking them move and so on. - [Lex] Yeah, we like physical contact. Something about our brain seeks-- - [Noam] Makes us want a world like then just like it wants a world that has regular geometric figures\nso for example Descartes pointed this out that\nif you have an infant who's never seen a triangle\nbefore and you draw a triangle the infant will see a distorted triangle not whatever crazy figure\nit actually is, you know, three lines not coming quite together or one of them a little\nbit curved and so on. We just impose a conception of the world in terms of perfect geometric objects. It's now been shown that\nit goes way beyond that, that if you show on a\ntachistoscope, let's say, a couple of lights\nshining, you do it three or four times in a row\nwhat people actually see is a rigid object in motion\nnot whatever's there. We all know that from a\ntelevision set basically. - [Lex] So that gives us\nhints of potential limits to our cognition?\n- I think it does, but it's a very contested view. If you do a poll among scientists\nthey'll say impossible. We can understand anything. - [Lex] Let me ask and\ngive me a chance with this. So I just spent a day at a\ncompany called Neuralink, and what they do is try\nto design what's called a brain machine, a brain\ncomputer interface. So they try to just do thousands\nof readings in the brain, be able to read what\nthe neurons are firing and then stimulate back, so two-way. Do you think their dream\nis to expand the capacity of the brain to attain information, sort of increase the bandwidth at which we can search\nGoogle kind of thing? Do you think our cognitive\ncapacity might be expanded, our linguistic capacity,\nour ability to reason might be expanded by adding\na machine into the picture? - [Noam] It can be expanded\nin a certain sense, but a sense that was known\nthousands of years ago. A book expands your\ncognitive capacity, okay, so this could expand it, too. - [Lex] But it's not a\nfundamental expansion. It's not totally new\nthings could be understood. - [Noam] Well, nothing that goes beyond our native cognitive capacities just like you can't turn the visual system into an insect system. - [Lex] Well, I mean\nthe thought is perhaps you can't directly but you can map. - [Noam] You could be we know\nthat without this experiment you could map what a\nbee sees and present it in a form so that we could follow it. In fact every bee scientist does that. - [Lex] Uh-huh, but you\ndon't think there's something greater than bees that we can map and then all of a sudden\ndiscover something, be able to understand a quantum\nworld, quantum mechanics, be able to start to be able to make sense. - [Noam] You can, students at MIT study and understand quantum mechanics. - [Lex] (laughs) But they\nalways reduce it to the infant, the physical, I mean they\ndon't really understand-- - [Noam] Not physical,\nthat may be another area where there's just a\nlimit to understanding. We understand the theories, but the world that it describes\ndoesn't make any sense. So you know the experiment,\nthe Schrodinger's cat for example, can understand the theory but as Schrodinger pointed out it's not an intelligible world. One of the reasons why Einstein\nwas always very skeptical about quantum theory, he described himself as a classical realist\nand wants intelligibility. - [Lex] He has something in\ncommon with infants in that way. So back to linguistics,\nif you could humor me, what are the most beautiful\nor fascinating aspects of language or ideas in linguistics or cognitive science that you've seen in a lifetime of studying language and studying the human mind? - [Noam] Well, I think the\ndeepest property of language and puzzling property\nthat's been discovered is what is sometimes called\nstructure dependence. We now understand it pretty well, but it was puzzling for a long time. I'll give you a concrete example. So suppose you say, the\nguy who fixed the car carefully packed his tools. That's ambiguous, he could\nfix the car carefully or carefully pack his tools. Now suppose you put carefully in front. Carefully the guy who fixed\nthe car packed his tools. Then it's carefully packed,\nnot carefully fixed. And in fact you do that\neven if it makes no sense. So suppose you say, carefully the guy who fixed the car is tall. You have to interpret it\nas carefully he's tall even though that doesn't make any sense. And notice that that's\na very puzzling fact because you're relating carefully not to the linearly closest verb but to the linearly more remote verb. Linear closeness is a easy computation, but here you're doing a much more, what looks like a more\ncomplex computation. You're doing something that's taking you essentially to the more remote thing, it's now if you look at the\nactual structure of the sentence where the phrases are and so on turns out you're picking out the\nstructurally closest thing, but the linearly more remote thing. But notice that what's linear\nis 100% of what you hear. You never hear of structure. So what you're doing is and\ninstantly this is universal. All constructions, all languages and what we're compelled\nto do is carry out what looks like the\nmore complex computation on material that we never\nhear and we ignore 100% of what we hear on the\nsimplest computation. And by now there's even\na neural basis for this that's somewhat understood,\nand there's good theories but none that explain why it's true. That's a deep insight\ninto the surprising nature of language with many consequences. - [Lex] Let me ask you about\na field of machine learning and deep learning, there's\nbeen a lot of progress in neural network-based machine learning in the recent decade. Of course, neural network\nresearch goes back many decades. - [Noam] Yeah. - [Lex] What do you think are\nthe limits of deep learning, of neural network-based machine learning? - [Noam] Well, to give\na real answer to that you'd have to understand\nthe exact processes that are taking place, and\nthose are pretty opaque so it's pretty hard to prove a theorem about what can be done\nand what can't be done. But I think it's reasonably clear, I mean, putting technicalities aside what deep learning is doing\nis taking huge numbers of examples and finding some patterns. Okay, that could be interesting\nand in some areas it is but we have to ask here\na certain question. Is it engineering or is it science? Engineering in the sense of\njust trying to build something that's useful or science in the sense that it's trying to understand\nsomething about elements of the world so it takes a Google parser. We can ask that question, is it useful? Yeah, it's pretty useful. I use Google Translator\nso on engineering grounds it's kinda worth having like a bulldozer. Does it tell you anything\nabout human language? Zero, nothing, and in\nfact it's very striking. From the very beginning it's just totally remote from science so what is a Google parser doing? It's taking an enormous text, let's say The Wall Street\nJournal corpus and asking, how close can we come to\ngetting the right description of every sentence in the corpus? Well, ever sentence in the corpus is essentially an experiment. Each sentence that you produce\nis an experiment which is, am I a grammatical sentence? Now the answer is usually\nyes so most of the stuff in the corpus is grammatical sentences, but now ask yourself, is there any science which takes random experiments\nwhich are carried out for no reason whatsoever and tries to find out something from them? Like if you're, say, a\nchemistry PhD student you want to get a thesis can you say, well I'm just gonna do a\nlot of, mix a lot of things together, no purpose, and\nmaybe I'll find something. You'd be laughed out of the department. Science tries to find\ncritical experiments, ones that answer some\ntheoretical question. Doesn't care about coverage\nof millions of experiments. So it just begins by being\nvery remote from science and it continues like\nthat so the usual question that's asked about, say, a Google parser is how well does it do, or some parser, how well does it do on a corpus? But there's another\nquestion that's never asked. How well does it do on something that violates all the rules of language? So for example, take the\nstructure dependence case that I mentioned, suppose\nthere was a language in which you used linear\nproximity as the mode of interpretation, these deep learning would work very easily on that. In fact, much more easily\nthan on an actual language. Is that a success? No, that's a failure. From a scientific point\nof view that's a failure. It shows that we're not discovering the nature of the system at all 'cause it does just as well or even better on things that violate the\nstructure of the system, and it goes on from there. It's not an argument against doing it. It is useful to have devices like this. - [Lex] So yes, neural networks\nare kind of approximators that look, there's echoes of\nthe behavioral debates right, behavioralism.\n- More than echoes. Many of the people in deep learning say they vindicated.\n- (laughs) Yeah. - [Noam] Terry Sejnowski for\nexample in his recent book says this vindicates Skinnerian behaviors and it doesn't have\nanything to do with it. - [Lex] Yes, but I think there's something actually fundamentally different\nwhen the data set is huge, but your point is extremely well taken. But do you think we can learn, approximate that interesting, complex\nstructure of language with neural networks that will somehow help us understand the science? - [Noam] It's possible,\nI mean, you find patterns that you hadn't noticed, let's say. Could be, in fact it's very\nmuch like a kind of linguistics that's done, what's called\ncorpus linguistics when you, suppose you have some language\nwhere all the speakers have died out but you have records. So you just look at the records and see what you can figure out from that. It's much better to have actual speakers where you can do critical experiments, but if they're all dead you can't do them so you have to try to\nsee what you can find out from just looking at\nthe data that's around. You can learn things. Anthropology is very much like that. You can't do a critical experiment on what happened two million years ago so you're kinda forced to\ntake what data's around and see what you can figure out from it. Okay, it's a serious study. - [Lex] So let me venture into\nanother whole body of work and philosophical question. You've said that evil in society\narises from institutions, not inherently from our nature. Do you think most human beings are good, they have good intent or\ndo most have the capacity for intentional evil that\ndepends on their upbringing, depends on their environment, on context? - [Noam] I wouldn't say that they don't arise from our nature. Anything we do arises from our nature. And the fact that we\nhave certain institutions and not others is one mode in which human nature\nhas expressed itself. But as far as we know, human nature could yield many different\nkinds of institutions. The particular ones that have developed have to do with historical contingency, who conquered whom and that sort of thing, then they're not rooted in our nature in the sense that they're\nessential to our nature so it's commonly argued that\nthese days that something like market systems is\njust part of our nature, but we know from a huge amount of evidence that that's not true, there's\nall kinds of other structures. That's a particular fact of\na moment of modern history. Others have argued that the\nroots of classical liberalism actually argue that\nwhat's called sometimes an instinct for freedom, an instinct to be free of domination\nby illegitimate authority is the core of our nature. That would be the opposite of this. And we don't know, we just\nknow that human nature can accommodate both kinds. - [Lex] If you look back at your life, is there a moment in\nyour intellectual life or life in general that jumps from memory that brought you happiness that you would love to relive again? - [Noam] Sure, falling\nin love, having children. - [Lex] What about, so\nyou have put forward into the world a lot of\nincredible ideas in linguistics, in cognitive science, in terms of ideas that just excites you\nwhen it first came to you that you love to relive those moments. - [Noam] Well, I mean,\nwhen you make a discovery about something it's exciting like say even the observation\nof structure dependence and on from that the explanation for it, but the major things just\nseem like common sense. So if you go back to, take your question about external and internal language. You go back to, say, the 1950s almost entirely language is\nregarded as an external object, something outside the mind. It just seemed obvious\nthat that can't be true. Like I said, there's something\nabout you that determines you're talking English\nnot Swahili or something. But that's not really a discovery. That's just an observation\nof what's transparent. You might say it's kind of like the 17th century, the\nbeginnings of modern science 17th century, they came from being willing to be puzzled about things\nthat seemed obvious. So it seems obvious that a heavy\nball of lead'll fall faster than a light ball of lead,\nbut Galileo was not impressed by the fact that it seemed obvious. so he wanted to know if it's true He carried out experiments,\nactually thought experiments never actually carried\nthem out which showed that it can't be true, you know. And out of things like that,\nobservations of that kind, you know, why does a\nball fall to the ground instead of rising, let's say? It seems obvious till you\nstart thinking about it 'cause why does steam rise, let's say. And I think the beginnings\nof modern linguistics roughly in the 50s are kind of like that, just being willing to be\npuzzled about phenomena that looked from some\npoint of view obvious. And for example a kind of doctrine, almost official doctrine\nof structural linguistics in the 50s was that languages\ncan differ from one another in arbitrary ways and\neach one has to be studied on its own without any presuppositions and in fact there were\nsimilar views among biologists about the nature of\norganisms that each one's, they're so different when you look at them that you could be almost anything. Well in both domains it's been learned that it's very far from true. There are very narrow constraints on what could be an organism\nor what could be a language. But these are, you know, that's\njust the nature of inquiry. - [Lex] Science in general, yeah, inquiry. So one of the peculiar things about us human beings is our mortality. Ernest Becker explored it. In general do you ponder\nthe value of mortality? Do you think about your own mortality? - [Noam] I used to when\nI was about 12 years old. I wondered, I didn't care\nmuch about my own mortality, but I was worried about the\nfact that if my consciousness disappeared would the\nentire universe disappear. That was frightening. - [Lex] Did you ever find\nan answer to that question? - [Noam] No, nobody's\never found an answer, but I stopped being bothered by it. It's kind of like Woody\nAllen in one of his films. You may recall he goes to\na shrink when he's a child and the shrink asks him,\n\"What's your problem?\" He says, \"I just learned that\nthe universe is expanding. \"I can't handle that.\" - [Lex] (laughs) And\nanother absurd question is, what do you think is the\nmeaning of our existence here, our life on Earth, our\nbrief little moment in time? - [Noam] That's something we\nanswer by our own activities. There's no general answer. We determine what the meaning of it is. - [Lex] The action determine the meaning. - [Noam] Meaning in the\nsense of significance not meaning in the sense that\nchair means this, you know, but the significance of your\nlife is something you create. - Noam, thank you so\nmuch for talking today. It was a huge honor, thank you so much. Thanks for listening to this\nconversation with Noam Chomsky, and thank you to our\npresenting sponsor Cash App. Download it, use code LexPodcast. You'll get $10 and $10 will go to FIRST, a STEM education nonprofit\nthat inspires hundreds of thousands of young minds to learn and to dream of engineering our future. If you enjoy this podcast\nsubscribe on YouTube. Give us five stars on Apple Podcast, support on Patreon, or\nconnect with me on Twitter. Thank you for listening and\nhope to see you next time."
    }
  ],
  "full_text": "- The following is a\nconversation with Noam Chomsky. He's truly one of the\ngreat minds of our time and is one of the most cited scholars in the history of our civilization. He has spent over 60 years at MIT and recently also joined\nthe University of Arizona where we met for this conversation, but it was at MIT about\nfour and 1/2 years ago when I first met Noam. My first few days there I remember getting into an elevator at Stata Center, pressing the button for\nwhatever floor, looking up and realizing it was\njust me and Noam Chomsky riding the elevator, just me\nand one of the seminal figures of linguistics, cognitive\nscience, philosophy, and political thought in the\npast century if not ever. I tell that silly story\nbecause I think life is made up of funny\nlittle defining moments that you never forget for\nreasons that may be too poetic to try and explain, that was one of mine. Noam has been an inspiration\nto me and millions of others. It was truly an honor for me to sit down with him in Arizona. I traveled there just\nfor this conversation, and in a rare, heartbreaking moment after everything was set up and tested the camera was moved and accidentally the recording button was\npressed stopping the recording. So I have good audio of both\nof us but no video of Noam, just a video of me and my\nsleep deprived but excited face that I get to keep as a\nreminder of my failures. Most people just listen\nto this audio version for the podcast as opposed\nto watching it on YouTube, but still it's heartbreaking for me. I hope you understand and still enjoy this\nconversation as much as I did. The depth of intellect that Noam showed and his willingness to truly listen to me, a silly looking Russian\nin a suit was humbling and something I'm deeply grateful for. As some of you know, this\npodcast is a side project for me where my main journey and dream is to build AI systems that\ndo some good for the world. This latter effort\ntakes up most of my time but for the moment has\nbeen mostly private, but the former, the podcast\nis something I put my heart and soul into and I hope you feel that even when I screw things up. I recently started doing ads at the end of the introduction. I'll do one or two minutes\nafter introducing the episode and never any ads in the middle that break the flow of the conversation. I hope that works for you and doesn't hurt the listening experience. This is the Artificial\nIntelligence podcast. If you enjoy it, subscribe on YouTube, give it five stars on Apple Podcast, support it on Patreon, or simply\ncontact with me on Twitter @lexfridman spelled F-R-I-D-M-A-N. This show is presented by Cash App, the number one finance\napp on the App Store. I personally use cash app\nto send money to friends, but you can also use it to buy, sell, and deposit Bitcoin in just seconds. Cash App also has a new investing feature. You can buy fractions of a stock, say $1 worth, no matter\nwhat the stock price is. Broker services are provided\nby Cash App Investing, a subsidiary of Square and member SIPC. I'm excited to be working with Cash App to support one of my favorite\norganizations called the FIRST best known for their FIRST\nrobotics and LEGO competitions. They educate and inspire\nhundreds of thousands of students in over 110 countries\nand have a perfect rating on Charity Navigator which\nmeans the donated money is used to maximum effectiveness. When you get Cash App in\nthe App Store or Google Play and use code LexPodcast you'll get $10 and Cash App will also\ndonate $10 to FIRST, which again is an organization that I've personally seen\ninspire girls and boys to dream of engineering a better world. And now here's my conversation\nwith Noam Chomsky. I apologize for the absurd\nphilosophical question, but if an alien species\nwere to visit Earth, do you think we would be able\nto find a common language or protocol of communication with them? - [Noam] There are arguments\nto the effect that we could. In fact, one of them was Marv Minsky's. Back about 20 or 30 years ago he performed a brief experiment with a\nstudent of his, Daniel Bobrow they essentially ran the\nsimplest possible Turing machines just free to see what would happen. And most of them crashed,\neither got into an infinite loop or were stopped, the few that persisted essentially gave\nsomething like arithmetic. And his conclusion from that was that if some alien species\ndeveloped higher intelligence they would at least have arithmetic. They would at least have what\nthe simplest computer would do and in fact he didn't\nknow that at the time, but the core principles\nof natural language are based on operations\nwhich yield something like arithmetic in the limiting\ncase, in the minimal case. So it's conceivable that\na mode of communication could be established based\non the core properties of human language and the\ncore properties of arithmetic which maybe are universally\nshared so it's conceivable. - [Lex] What is the\nstructure of that language, of language as an internal\nsystem inside our mind versus an external\nsystem as it's expressed? - [Noam] It's not an alternative. It's two different concepts of language. - [Lex] Different. - [Noam] It's a simple fact that there's something\nabout you, a trait of yours, part of the organism you that determines that you're talking English\nand not Tagalog, let's say. So there is an inner system. It determines the sound and meaning of the infinite number of\nexpressions of your language. It's localized, it's not in your foot obviously it's in your brain. If you look more closely it's\nin specific configurations of your brain and that's essentially like the internal\nstructure of your laptop. Whatever programs it has are in there. Now, one of the things\nyou can do with language, it's a marginal thing in\nfact is use it to externalize what's in your head. I think most of your use\nof language is thought, internal thought, but can do\nwhat you and I are now doing. We can externalize it. Well, the set of things\nthat we're externalizing are an external system, they're\nnoises in the atmosphere, and you can call that language in some other sense of the word, but it's not a set of alternatives. These are just different concepts. - [Lex] So how deep do the roots of language go in our brain? - Well--\n- Our mind, is it yet another feature like vision? Or is it something more fundamental from which everything else\nsprings in the human mind? - [Noam] Well in a way it's like vision. There's something about\nour genetic endowment that determines that we have a mammalian rather than an insect visual system. And there's something\nin our genetic endowment that determines that we have\na human language faculty. No other organism has\nanything remotely similar. So in that sense it's internal. Now, there is a long tradition\nwhich I think is valid going back centuries to the\nearly scientific revolution at least that holds that language is the sort of the core of\nhuman cognitive nature. It's the source, it's the\nmode for constructing thoughts and expressing them and\nthat is what forms thought and it's got fundamental\ncreative capacities. It's free, independent,\nunbounded and so on. And undoubtedly I think the basis for our creative capacities\nand the other remarkable human capacities that lead\nto the unique achievements and not so great\nachievements of the species. - [Lex] The capacity to think and reason. Do you think that's deeply\nlinked with language? Do you think the internal\nlanguage system is essentially the mechanism by which we\nalso reason internally? - [Noam] It is undoubtedly the\nmechanism by which we reason. There may also be other,\nthere are undoubtedly other faculties involved in reasoning. We have a kind of scientific faculty. Nobody knows what it\nis, but whatever it is that enables us to pursue\ncertain lines of endeavor and inquiry and to decide what makes sense and doesn't make sense and\nto achieve a certain degree of understanding in the\nworld that uses language but goes beyond it just as using\nour capacity for arithmetic is not the same as having the capacity. - [Lex] The idea of capacity,\nour biology, evolution, you've talked about it defining\nessentially our capacity, our limit and our scope. Can you try to define\nwhat limit and scope are, and the bigger question,\ndo you think it's possible to find the limit of human cognition? - [Noam] Well that's an\ninteresting question. It's commonly believed,\nmost scientists believe that human intelligence can answer any question in principle. I think that's a very strange belief. If we're biological organisms\nwhich are not angels then our capacities ought\nto have scope and limits which are interrelated. - [Lex] Can you define those two terms? - [Noam] Well, let's\ntake a concrete example. Your genetic endowment, it determines that you can have a\nmammalian visual system and arms and legs and so on and therefore become a\nrich, complex organism, but if you look at that\nsame genetic endowment it prevents you from\ndeveloping in other directions. There's no kind of experience\nwhich would yield the embryo to develop an insect visual system or to develop wings instead of arms. So the very endowment that\nconfers richness and complexity also sets bounds on what can be attained. Now I assume that our cognitive capacities are part of the organic world therefore they should\nhave the same properties. If they had no built-in\ncapacity to develop a rich and complex structure we\nwould understand nothing just as if your genetic endowment did not compel you to\ndevelop arms and legs you would just be some kind\nof a random ameboid creature with no structure at all\nso I think it's plausible to assume that there are limits, and I think we even have some\nevidence as to what they are. So for example there's a classic moment in the history of science\nat the time of Newton. There was from Galileo to\nNewton modern science developed on a fundamental assumption\nwhich Newton also accepted, namely that the world, the entire universe is a mechanical object and\nby mechanical they meant something like the kinds of artifacts that were being developed\nby skilled artisans all over Europe, the\ngears, levers, and so on. And their belief was, well the world is just a more complex variant of this. Newton to his astonishment\nand distress proved that there are no machines, that there's\ninteraction without contact. His contemporaries like\nLeibniz and Huygens just dismissed this as\nreturning to the mysticism of the Neo-Scholastics and Newton agreed. He said, \"It is totally absurd. \"No person of any scientific intelligence \"could ever accept this for a moment.\" In fact, he spent the rest of his life trying to get around it somehow as did many other scientists. That was the very criterion\nof intelligibility for say Galileo or Newton. Theory did not produce\nan intelligible world unless you could duplicate it in a machine and he showed you can't,\nthere are no machines, any. Finally after a long\nstruggle, took a long time scientists just accepted\nthis as common sense, but that's a significant moment. That means they abandoned the search for an intelligible world\nand the great philosophers of the time understood that very well. So for example, David Hume\nin his encomium to Newton wrote that, who was the\ngreatest thinker ever and so on. He said that he unveiled\nmany of the secrets of nature but by showing the imperfections of the mechanical philosophy,\nmechanical science he left us with, he showed\nthat there are mysteries which ever will remain, and\nscience just changed its goals. It abandoned the mysteries. It can't solve it, they'll put it aside. We only look for intelligible theories. Newton's theories were intelligible it's just what they described wasn't. Well, Locke said the same thing. I think they're basically right and if so that showed something about\nthe limits of human cognition. We cannot attain the goal\nof understanding the world, of finding an intelligible world. This mechanical philosophy,\nGalileo to Newton, there's a good case that can be made that that's our instinctive\nconception of how things work. So if say infants are tested with things that if this moves and then this moves they kind of invent something\nthat must be invisible that's in between them that's\nmaking them move and so on. - [Lex] Yeah, we like physical contact. Something about our brain seeks-- - [Noam] Makes us want a world like then just like it wants a world that has regular geometric figures\nso for example Descartes pointed this out that\nif you have an infant who's never seen a triangle\nbefore and you draw a triangle the infant will see a distorted triangle not whatever crazy figure\nit actually is, you know, three lines not coming quite together or one of them a little\nbit curved and so on. We just impose a conception of the world in terms of perfect geometric objects. It's now been shown that\nit goes way beyond that, that if you show on a\ntachistoscope, let's say, a couple of lights\nshining, you do it three or four times in a row\nwhat people actually see is a rigid object in motion\nnot whatever's there. We all know that from a\ntelevision set basically. - [Lex] So that gives us\nhints of potential limits to our cognition?\n- I think it does, but it's a very contested view. If you do a poll among scientists\nthey'll say impossible. We can understand anything. - [Lex] Let me ask and\ngive me a chance with this. So I just spent a day at a\ncompany called Neuralink, and what they do is try\nto design what's called a brain machine, a brain\ncomputer interface. So they try to just do thousands\nof readings in the brain, be able to read what\nthe neurons are firing and then stimulate back, so two-way. Do you think their dream\nis to expand the capacity of the brain to attain information, sort of increase the bandwidth at which we can search\nGoogle kind of thing? Do you think our cognitive\ncapacity might be expanded, our linguistic capacity,\nour ability to reason might be expanded by adding\na machine into the picture? - [Noam] It can be expanded\nin a certain sense, but a sense that was known\nthousands of years ago. A book expands your\ncognitive capacity, okay, so this could expand it, too. - [Lex] But it's not a\nfundamental expansion. It's not totally new\nthings could be understood. - [Noam] Well, nothing that goes beyond our native cognitive capacities just like you can't turn the visual system into an insect system. - [Lex] Well, I mean\nthe thought is perhaps you can't directly but you can map. - [Noam] You could be we know\nthat without this experiment you could map what a\nbee sees and present it in a form so that we could follow it. In fact every bee scientist does that. - [Lex] Uh-huh, but you\ndon't think there's something greater than bees that we can map and then all of a sudden\ndiscover something, be able to understand a quantum\nworld, quantum mechanics, be able to start to be able to make sense. - [Noam] You can, students at MIT study and understand quantum mechanics. - [Lex] (laughs) But they\nalways reduce it to the infant, the physical, I mean they\ndon't really understand-- - [Noam] Not physical,\nthat may be another area where there's just a\nlimit to understanding. We understand the theories, but the world that it describes\ndoesn't make any sense. So you know the experiment,\nthe Schrodinger's cat for example, can understand the theory but as Schrodinger pointed out it's not an intelligible world. One of the reasons why Einstein\nwas always very skeptical about quantum theory, he described himself as a classical realist\nand wants intelligibility. - [Lex] He has something in\ncommon with infants in that way. So back to linguistics,\nif you could humor me, what are the most beautiful\nor fascinating aspects of language or ideas in linguistics or cognitive science that you've seen in a lifetime of studying language and studying the human mind? - [Noam] Well, I think the\ndeepest property of language and puzzling property\nthat's been discovered is what is sometimes called\nstructure dependence. We now understand it pretty well, but it was puzzling for a long time. I'll give you a concrete example. So suppose you say, the\nguy who fixed the car carefully packed his tools. That's ambiguous, he could\nfix the car carefully or carefully pack his tools. Now suppose you put carefully in front. Carefully the guy who fixed\nthe car packed his tools. Then it's carefully packed,\nnot carefully fixed. And in fact you do that\neven if it makes no sense. So suppose you say, carefully the guy who fixed the car is tall. You have to interpret it\nas carefully he's tall even though that doesn't make any sense. And notice that that's\na very puzzling fact because you're relating carefully not to the linearly closest verb but to the linearly more remote verb. Linear closeness is a easy computation, but here you're doing a much more, what looks like a more\ncomplex computation. You're doing something that's taking you essentially to the more remote thing, it's now if you look at the\nactual structure of the sentence where the phrases are and so on turns out you're picking out the\nstructurally closest thing, but the linearly more remote thing. But notice that what's linear\nis 100% of what you hear. You never hear of structure. So what you're doing is and\ninstantly this is universal. All constructions, all languages and what we're compelled\nto do is carry out what looks like the\nmore complex computation on material that we never\nhear and we ignore 100% of what we hear on the\nsimplest computation. And by now there's even\na neural basis for this that's somewhat understood,\nand there's good theories but none that explain why it's true. That's a deep insight\ninto the surprising nature of language with many consequences. - [Lex] Let me ask you about\na field of machine learning and deep learning, there's\nbeen a lot of progress in neural network-based machine learning in the recent decade. Of course, neural network\nresearch goes back many decades. - [Noam] Yeah. - [Lex] What do you think are\nthe limits of deep learning, of neural network-based machine learning? - [Noam] Well, to give\na real answer to that you'd have to understand\nthe exact processes that are taking place, and\nthose are pretty opaque so it's pretty hard to prove a theorem about what can be done\nand what can't be done. But I think it's reasonably clear, I mean, putting technicalities aside what deep learning is doing\nis taking huge numbers of examples and finding some patterns. Okay, that could be interesting\nand in some areas it is but we have to ask here\na certain question. Is it engineering or is it science? Engineering in the sense of\njust trying to build something that's useful or science in the sense that it's trying to understand\nsomething about elements of the world so it takes a Google parser. We can ask that question, is it useful? Yeah, it's pretty useful. I use Google Translator\nso on engineering grounds it's kinda worth having like a bulldozer. Does it tell you anything\nabout human language? Zero, nothing, and in\nfact it's very striking. From the very beginning it's just totally remote from science so what is a Google parser doing? It's taking an enormous text, let's say The Wall Street\nJournal corpus and asking, how close can we come to\ngetting the right description of every sentence in the corpus? Well, ever sentence in the corpus is essentially an experiment. Each sentence that you produce\nis an experiment which is, am I a grammatical sentence? Now the answer is usually\nyes so most of the stuff in the corpus is grammatical sentences, but now ask yourself, is there any science which takes random experiments\nwhich are carried out for no reason whatsoever and tries to find out something from them? Like if you're, say, a\nchemistry PhD student you want to get a thesis can you say, well I'm just gonna do a\nlot of, mix a lot of things together, no purpose, and\nmaybe I'll find something. You'd be laughed out of the department. Science tries to find\ncritical experiments, ones that answer some\ntheoretical question. Doesn't care about coverage\nof millions of experiments. So it just begins by being\nvery remote from science and it continues like\nthat so the usual question that's asked about, say, a Google parser is how well does it do, or some parser, how well does it do on a corpus? But there's another\nquestion that's never asked. How well does it do on something that violates all the rules of language? So for example, take the\nstructure dependence case that I mentioned, suppose\nthere was a language in which you used linear\nproximity as the mode of interpretation, these deep learning would work very easily on that. In fact, much more easily\nthan on an actual language. Is that a success? No, that's a failure. From a scientific point\nof view that's a failure. It shows that we're not discovering the nature of the system at all 'cause it does just as well or even better on things that violate the\nstructure of the system, and it goes on from there. It's not an argument against doing it. It is useful to have devices like this. - [Lex] So yes, neural networks\nare kind of approximators that look, there's echoes of\nthe behavioral debates right, behavioralism.\n- More than echoes. Many of the people in deep learning say they vindicated.\n- (laughs) Yeah. - [Noam] Terry Sejnowski for\nexample in his recent book says this vindicates Skinnerian behaviors and it doesn't have\nanything to do with it. - [Lex] Yes, but I think there's something actually fundamentally different\nwhen the data set is huge, but your point is extremely well taken. But do you think we can learn, approximate that interesting, complex\nstructure of language with neural networks that will somehow help us understand the science? - [Noam] It's possible,\nI mean, you find patterns that you hadn't noticed, let's say. Could be, in fact it's very\nmuch like a kind of linguistics that's done, what's called\ncorpus linguistics when you, suppose you have some language\nwhere all the speakers have died out but you have records. So you just look at the records and see what you can figure out from that. It's much better to have actual speakers where you can do critical experiments, but if they're all dead you can't do them so you have to try to\nsee what you can find out from just looking at\nthe data that's around. You can learn things. Anthropology is very much like that. You can't do a critical experiment on what happened two million years ago so you're kinda forced to\ntake what data's around and see what you can figure out from it. Okay, it's a serious study. - [Lex] So let me venture into\nanother whole body of work and philosophical question. You've said that evil in society\narises from institutions, not inherently from our nature. Do you think most human beings are good, they have good intent or\ndo most have the capacity for intentional evil that\ndepends on their upbringing, depends on their environment, on context? - [Noam] I wouldn't say that they don't arise from our nature. Anything we do arises from our nature. And the fact that we\nhave certain institutions and not others is one mode in which human nature\nhas expressed itself. But as far as we know, human nature could yield many different\nkinds of institutions. The particular ones that have developed have to do with historical contingency, who conquered whom and that sort of thing, then they're not rooted in our nature in the sense that they're\nessential to our nature so it's commonly argued that\nthese days that something like market systems is\njust part of our nature, but we know from a huge amount of evidence that that's not true, there's\nall kinds of other structures. That's a particular fact of\na moment of modern history. Others have argued that the\nroots of classical liberalism actually argue that\nwhat's called sometimes an instinct for freedom, an instinct to be free of domination\nby illegitimate authority is the core of our nature. That would be the opposite of this. And we don't know, we just\nknow that human nature can accommodate both kinds. - [Lex] If you look back at your life, is there a moment in\nyour intellectual life or life in general that jumps from memory that brought you happiness that you would love to relive again? - [Noam] Sure, falling\nin love, having children. - [Lex] What about, so\nyou have put forward into the world a lot of\nincredible ideas in linguistics, in cognitive science, in terms of ideas that just excites you\nwhen it first came to you that you love to relive those moments. - [Noam] Well, I mean,\nwhen you make a discovery about something it's exciting like say even the observation\nof structure dependence and on from that the explanation for it, but the major things just\nseem like common sense. So if you go back to, take your question about external and internal language. You go back to, say, the 1950s almost entirely language is\nregarded as an external object, something outside the mind. It just seemed obvious\nthat that can't be true. Like I said, there's something\nabout you that determines you're talking English\nnot Swahili or something. But that's not really a discovery. That's just an observation\nof what's transparent. You might say it's kind of like the 17th century, the\nbeginnings of modern science 17th century, they came from being willing to be puzzled about things\nthat seemed obvious. So it seems obvious that a heavy\nball of lead'll fall faster than a light ball of lead,\nbut Galileo was not impressed by the fact that it seemed obvious. so he wanted to know if it's true He carried out experiments,\nactually thought experiments never actually carried\nthem out which showed that it can't be true, you know. And out of things like that,\nobservations of that kind, you know, why does a\nball fall to the ground instead of rising, let's say? It seems obvious till you\nstart thinking about it 'cause why does steam rise, let's say. And I think the beginnings\nof modern linguistics roughly in the 50s are kind of like that, just being willing to be\npuzzled about phenomena that looked from some\npoint of view obvious. And for example a kind of doctrine, almost official doctrine\nof structural linguistics in the 50s was that languages\ncan differ from one another in arbitrary ways and\neach one has to be studied on its own without any presuppositions and in fact there were\nsimilar views among biologists about the nature of\norganisms that each one's, they're so different when you look at them that you could be almost anything. Well in both domains it's been learned that it's very far from true. There are very narrow constraints on what could be an organism\nor what could be a language. But these are, you know, that's\njust the nature of inquiry. - [Lex] Science in general, yeah, inquiry. So one of the peculiar things about us human beings is our mortality. Ernest Becker explored it. In general do you ponder\nthe value of mortality? Do you think about your own mortality? - [Noam] I used to when\nI was about 12 years old. I wondered, I didn't care\nmuch about my own mortality, but I was worried about the\nfact that if my consciousness disappeared would the\nentire universe disappear. That was frightening. - [Lex] Did you ever find\nan answer to that question? - [Noam] No, nobody's\never found an answer, but I stopped being bothered by it. It's kind of like Woody\nAllen in one of his films. You may recall he goes to\na shrink when he's a child and the shrink asks him,\n\"What's your problem?\" He says, \"I just learned that\nthe universe is expanding. \"I can't handle that.\" - [Lex] (laughs) And\nanother absurd question is, what do you think is the\nmeaning of our existence here, our life on Earth, our\nbrief little moment in time? - [Noam] That's something we\nanswer by our own activities. There's no general answer. We determine what the meaning of it is. - [Lex] The action determine the meaning. - [Noam] Meaning in the\nsense of significance not meaning in the sense that\nchair means this, you know, but the significance of your\nlife is something you create. - Noam, thank you so\nmuch for talking today. It was a huge honor, thank you so much. Thanks for listening to this\nconversation with Noam Chomsky, and thank you to our\npresenting sponsor Cash App. Download it, use code LexPodcast. You'll get $10 and $10 will go to FIRST, a STEM education nonprofit\nthat inspires hundreds of thousands of young minds to learn and to dream of engineering our future. If you enjoy this podcast\nsubscribe on YouTube. Give us five stars on Apple Podcast, support on Patreon, or\nconnect with me on Twitter. Thank you for listening and\nhope to see you next time."
}