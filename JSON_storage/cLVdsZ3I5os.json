{
  "video_id": "cLVdsZ3I5os",
  "title": "Robert Playter: Boston Dynamics CEO on Humanoid and Legged Robotics | Lex Fridman Podcast #374",
  "date": "2023-04-28",
  "transcript": [
    {
      "timestamp": "0:00",
      "section": "Full Transcript",
      "text": "- And so our goal was\na natural-looking gait. It was surprisingly hard\nto get that to work. But we did build an early machine. We called it PETMAN prototype. It was the prototype\nbefore the PETMAN robot, and it had a really nice-looking gait where, you know, it\nwould stick the leg out. It would do heel strike first\nbefore it rolled onto the toe, so you didn't land with a flat foot. You extended your leg a\nlittle bit, but even then, it was hard to get the robot to walk where, when you were walking, that it fully extended its leg and getting that all to work\nwell took such a long time. In fact, I probably didn't really see the nice, natural walking that I expected out of our humanoids\nuntil maybe last year. And the team was developing\non our newer generation of Atlas, you know, some new techniques for developing a\nwalking-control algorithm. And they got that\nnatural-looking motion as sort of a byproduct of just a different process they were applying to\ndeveloping the control. So, that probably took 15\nyears, 10 to 15 years to sort of get that from, you know, the PETMAN prototype was probably in 2008, and what was it, 2022, (laughs) last year that I think I saw good walking on Atlas. (dramatic music) - The following is a\nconversation with Robert Playter, CEO of Boston Dynamics, a\nlegendary robotics company that, over 30 years, has created\nsome of the most elegant, dextrous, and simply\namazing robots ever built, including the humanoid robot\nAtlas and the robot dog Spot, one or both of whom you've\nprobably seen on the Internet, either dancing, doing\nbackflips, opening doors, or throwing around heavy objects. Robert has led both the development of Boston Dynamics humanoid robots and their physics-based\nsimulation software. He has been with the company\nfrom the very beginning, including its roots at MIT, where he received his PhD\nin aeronautical engineering. This was in 1994 at the\nlegendary MIT Leg Lab. He wrote his PhD thesis\non robot gymnastics as part of which he programmed\na bipedal robot to do the world's first 3D robotic somersault. Robert is a great engineer,\nroboticist, and leader, and Boston Dynamics, to\nme as a roboticist, is a truly inspiring company. This conversation was a\nbig honor and pleasure, and I hope to do a lot of great work with these robots in the years to come. This is the Lex Fridman podcast. To support it, please\ncheck out our sponsors in the description. And now, dear friends,\nhere's Robert Playter. When did you first fall\nin love with robotics? (Lex laughs) Let's start with love and robots. - Well, love is relevant because I think the fascination, the deep fascination is really about movement, and\nI was visiting MIT looking for a place to get a PhD, and I wanted to do some laboratory work. And one of my professors in\nthe aero department said, \"Go see this guy Marc Raibert down in the basement of the AI lab.\" And so I walked down there and saw him. He showed me his robots, and he showed me this\nrobot doing a somersault. (Lex laughs) And I just immediately\nwent, \"Whoa,\" you know. - [Lex] Yeah. - \"Robots can do that?\" And because of my own\ninterest in gymnastics, there was, like, this\nimmediate connection, and, you know, I was\nin an aeroastro degree because, you know, flight and movement was all so fascinating to me. And then it turned out that, you know, robotics\nhad this big challenge. How do you balance? How do you build a legged robot\nthat can really get around? That was a fascination,\nand it still exists today. We're still working on\nperfecting motion in robots. - What about the elegance and the beauty of the movement itself? Is there something maybe\ngrounded in your appreciation of movement from your gymnastics days? Was there something you just\nfundamentally appreciated about the elegance and beauty of movement? - You know, we had this concept in gymnastics of letting your\nbody do what it wanted to do. When you get really good at gymnastics, part of what you're doing\nis putting your body into a position where the physics and the body's inertia and\nmomentum will kinda push you in the right direction in a\nvery natural and organic way. And the thing that Marc\nwas doing, you know, in the basement of that laboratory\nwas trying to figure out how to build machines to take\nadvantage of those ideas. How do you build something\nso that the physics of the machine just\nkind of inherently wants to do what it wants to do? And he was building these springy\npogo-stick type, you know. His first cut at legged\nlocomotion was a pogo stick where it's bouncing, and\nthere's a spring mass system that's oscillating, has its own sort of natural frequency\nthere and sort of figuring out how to augment those natural\nphysics with also intent. How do you then control\nthat but not overpower it? It's that coordination that I\nthink creates real potential. We could call it beauty, you know. You could call it, I don't know, synergy. People have different words for it. But I think that that was\ninherent from the beginning. That was clear to me that that's part of what Marc was trying to do. He asked me to do that\nin my research work. So, you know, that's where it got going. - So, part of the thing that\nI think I'm calling elegance and beauty in this case, which was there, even with the pogo stick\nis maybe the efficiency, so letting the body do\nwhat it wants to do, trying to discover the efficient movement. - It's definitely more efficient. It also becomes easier\nto control in its own way because the physics are solving\nsome of the problem itself. It's not like you have to\ndo all this calculation and overpower the physics. The physics naturally, inherently want to do the right thing. There can even be, you\nknow, feedback mechanisms, stabilizing mechanisms\nthat occur simply by virtue of the physics of the body. And it's, you know,\nnot all in the computer or not even all in your\nmind as a person (laughs). And there's something\ninteresting in that melding. - You were with Marc for\nmany, many, many years, but you were there in\nthis kinda legendary space of Leg Lab and MIT in\nthe basement (laughs). All great things happen in the basement. (Robert laughs) Is there some memories from\nthat time that you have? Because it's such cutting-edge work in robotics and artificial intelligence. - The memories, the distinctive\nlessons, I would say I learned in that time period and that I think Marc was\na great teacher of was it's okay to pursue your\ninterests, your curiosity, do something because you love it. You'll do it a lot better if you love it. That is a lasting lesson\nthat I think we apply at the company still and\nreally is a core value. - So, the interesting thing is, with people like Russ Tedrake and others, like, the students that work at those robotics labs are, like, some of the happiest people I've ever met. I don't know what that is. (laughs) I meet a lot of PhD students. A lot of them are kind of broken (laughing) by the wear\nand tear of the process, but roboticists are, while\nthey work extremely hard and work long hours, there's a happiness there. The only other group of people\nI've met like that are people that skydive a lot. (both laughing) For some reason, there's a\ndeep, fulfilling happiness maybe from, like, a long period of struggle to get a thing to work, and it works, and there's a magic to it. I don't know exactly 'cause\nit's so fundamentally hands-on, and you're bringing a thing to life. I don't know what it\nis, but they're happy. - You know, our attrition at\nthe company is really low. People come, and they love the pursuit. And I think part of that is that there's perhaps a\nnatural connection to it. It's a little bit easier to\nconnect when you have a robot that's moving around in the\nworld, and part of your goal is to make it move around in the world. You can identify with that. This is one of the unique things about the kinds of\nrobots we're building is this physical interaction lets\nyou perhaps identify with it. So, I think that is a source of happiness. I don't think it's unique to robotics. I think anybody also who is just pursuing something they love, it's\neasier to work hard at it and be good at it, and not\neverybody gets to find that. I do feel lucky in that way. And I think we're lucky as an organization that we've been able to\nbuild a business around this and that keeps people engaged. - So, if it's all right,\nlet's linger on Marc for a little bit longer, Marc Raibert. So, he's a legend. He's a legendary engineer and roboticist. What have you learned about\nlife, about robotics from Marc through all the many years\nyou've worked with him? - I think the most important\nlesson, which was, you know, have the courage of your convictions and do what you think is interesting. Be willing to try to find\nbig, big problems to go after. And at the time, you\nknow, legged locomotion, especially in a dynamic\nmachine, nobody had solved it. And that felt like a\nmulti-decade problem to go after. And so, you know, have the\ncourage to go after that because you're interested. Don't worry if it's gonna make money. You know, that's been a theme. That's really probably the\nmost important lesson I think that I got from Marc. - How crazy is the effort\nof doing legged robotics at that time, especially? - You know, Marc got some\nstuff to work starting from simple ideas. So, maybe the other,\nanother important idea that has really become a\nvalue of the company is try to simplify a thing\nto the core essence. While, you know, Marc was\nshowing videos of animals running across the Savannah or climbing mountains, what he started with was a pogo stick because he was trying to\nreduce the problem to something that was manageable, and\ngetting the pogo stick to balance had in it\nthe fundamental problems that, if we solved those, you\ncould eventually extrapolate to something that galloped\nlike a horse, and so look for those simplifying principles. - How tough is the job\nof simplifying a robot? - So, I'd say, in the early\ndays, the thing that made the researchers at Boston\nDynamics special is that we worked on figuring out what that central principle was and then building software or machines around that principle,\nand that was not easy in the early days. And it took real expertise\nin understanding the dynamics of motion and feedback-control\nprinciples, how to build, you know, with the computers at the time, how to build a feedback-control algorithm that was simple enough that\nit could run in real time at 1,000 hertz and actually\nget that machine to work. And that was not something\neverybody was doing, you know, at that time. Now, the world's changing now,\nand I think the approaches to controlling robots are going to change, and they're going to become\nmore broadly available. But at the time, there weren't many groups who could really sort of\nwork at that principled level with both the software and\nmake the hardware work. And I'll say one other thing\nabout you were sort of talking about what are the special things. The other thing was it's good\nto break stuff, you know. You know, use the robots,\nbreak them, repair them, you know, fix and repeat,\n(laughs) test, fix, and repeat. And that's also a core\nprinciple that has become part of the company, and it lets\nyou be fearless in your work. Too often, if you are working\nwith a very expensive robot, maybe one that you\nbought from somebody else or that you don't know how to fix, then you treat it with kid gloves, and you can't actually make progress. You have to be able to break something. And so, I think that's\nbeen a principle as well. - So, just to linger on\nthat, psychologically, how do you deal with that? 'Cause I remember I built a RC car. It had some custom stuff\nlike a computer on it and all that kind of stuff, cameras and because I didn't sleep much, the code I wrote had an issue\nwhere it didn't stop the car, and the car got confused and at full speed at, like, 20, 25 miles an\nhour, it slammed into a wall. And I just remember sitting\nthere alone in a deep sadness, sort of full of regret,\nI think, almost anger, but also, like, sadness\nbecause you think about, well, these robots, especially\nfor autonomous vehicles, like, you should be taking\nsafety very seriously even in these kinds of things,\nbut just no good feelings. It made me more afraid\nprobably to do these kind of experiments in the future. Perhaps the right way to\nhave seen that is positively. Like, it's too- - It depends if you\ncould have built that car or just gotten another one, right? That would've been the approach. I remember when I got to grad school, you know, I got some training\nabout operating a lathe and a mill up in the machine shop, and I could start to make my own parts. And I remember breaking some\npiece of equipment in the lab and then realizing 'cause\nmaybe this was a unique part, and I couldn't go buy it, and I realized, \"Oh, I can just go make it.\" That was an enabling feeling. - [Lex] Yeah. - Then, you're not afraid. It might take time. It might take more work than you thought it was gonna be required\nto get this thing done, but you can just go make it. And that's freeing in a\nway that nothing else is. - You mentioned the feedback\ncontrol, the dynamics, sorry for the romantic question, but in the early days and\neven now, is the dynamics, probably more appropriate\nfor the early days, is it more art or science? - There's a lot of science\naround it, and trying to develop, you know, scientific principles\nthat let you extrapolate from, like, one legged machine to another, you know, develop a core set of principles like a spring-mass bouncing\nsystem and then figure out how to apply that from a one-legged machine to a two- or a four-legged machine. Those principles are really important and were definitely a\ncore part of our work. There's also, you know, when we started to pursue humanoid robots,\nthere was so much complexity in that machine that, you\nknow, one of the benefits of the humanoid form is\nyou have some intuition about how it should\nlook while it's moving. And that's a little\nbit of an art, I think, or maybe it's just\ntapping into a knowledge that you have deep in\nyour body and then trying to express that in the machine,\nbut that's an intuition that's a little bit more on the art side. Maybe it predates your knowledge. Before you have the knowledge\nof how to control it, you try to work through\nthe art channel. (laughs) - [Lex] Yeah.\n- And humanoids sort of make that available to you. If it had been a different shape, maybe you wouldn't have had\nthe same intuition about it. - Yeah, so your knowledge about moving through the world is not\nmade explicit to you. That's why it's art. - Yeah, it might be hard to\nactually articulate exactly. (laughing) You know?\n- Yeah. - And being a competitive athlete, there's something about seeing a movement. You know, a coach, one\nof the greatest strengths a coach has is being\nable to see, you know, some little change in\nwhat the athlete is doing and then being able to\narticulate that to the athlete, you know, and then maybe\neven trying to say, \"And you should try to feel this.\" So, there's something just in seeing, and again, you know, sometimes\nit's hard to articulate what it is you're seeing, but\njust perceiving the motion at a rate that is, again,\nsometimes hard to put into words. - Yeah, I wonder how it is\npossible to achieve sort of truly elegant movement. You have a movie like \"Ex Machina.\" I'm not sure if you've seen it, but the main actress in\nthat who plays the AI robot I think is a ballerina. I mean, just the natural elegance and the, I don't know,\neloquence of movement, (laughs) it looks efficient and easy,\nand just it looks right. It looks beautiful.\n- It looks right is sort of the key, yeah? - And then, you look at,\nespecially early robots, I mean, they're so cautious\nin the way they move that it's not the\ncaution that looks wrong. It's something about the\nmovement that looks wrong that feels like it's very\ninefficient, unnecessarily so. And it's hard to put\nthat into words exactly. - We think that, and part of the reason why people are attracted\nto the machines we build is because the inherent dynamics of movement are closer to right because we try to use,\nyou know, walking gaits, or we build a machine around this gait where you're trying to work\nwith the dynamics of the machine instead of to stop them. You know, some of the early\nwalking machines, you know, you're essentially,\nyou're really trying hard to not let them fall over, and so you're always stopping\nthe tipping motion, you know. And sort of the insight\nof dynamic stability in a legged machine is to go\nwith it, you know, (laughs) let the tipping happen. You know, let yourself fall, but then catch yourself\nwith that next foot. And there's something\nabout getting those physics to be expressed in the\nmachine that people interpret as lifelike, or elegant, or just natural looking. And so, I think if you\nget the physics right, it also ends up being\nmore efficient, likely. There's a benefit that it probably ends up being more stable in the long run. You know, it could walk\nstably over a wider range of conditions, and it's more beautiful and attractive at the same time. - So, how hard is it to get\nthe humanoid robot Atlas to do some of the things that\nit's recently been doing? Let's forget the flips and all of that. Let's just look at the running. Maybe you can correct me, but there's something about running. I mean, that's not careful at all. That's you're falling forward. You're jumping forward and are falling. So, (laughing) how hard\nis it to get that right? - Our first humanoid, we needed to deliver natural-looking walking, you know. We took a contract from the army. They wanted a robot that\ncould walk naturally. They wanted to put a suit on the robot and be able to test it\nin a gas environment. And so, they wanted the\nmotion to be natural. And so, our goal was a\nnatural-looking gait. It was surprisingly hard\nto get that to work. But we did build an early machine. We called it PETMAN prototype. It was the prototype\nbefore the PETMAN robot, and it had a really nice-looking gait where, you know, it\nwould stick the leg out. It would do heel strike first\nbefore it rolled onto the toe, so you didn't land with a flat foot. You extended your leg a little bit, but even then it was hard\nto get the robot to walk where, when you were walking,\nthat it fully extended its leg and essentially landed on an extended leg. And if you watch closely how you walk, you probably land on an extended leg, but then you immediately flex your knee as you start to make that contact, and getting that all to work\nwell took such a long time. In fact, I probably didn't really see the nice, natural walking that I expected out of our humanoids\nuntil maybe last year. And the team was developing\non our newer generation of Atlas, you know, some new techniques for developing a\nwalking-control algorithm. And they got that\nnatural-looking motion as sort of a byproduct of just a different process they were applying to\ndeveloping the control. So, that probably took 15\nyears, 10 to 15 years to sort of get that from, you know, the PETMAN prototype was probably\nin 2008, and what was it, 2022, (laughs) last year that I think I saw good walking on Atlas. - If you could just, like, linger on it, what are some challenges\nof getting good walking? So, is this partially, like, a hardware, like, actuator problem? Is it the control? Is it the artistic\nelement of just observing the whole system operating in\ndifferent conditions together? I mean, is there some\nkind of interesting quirks or challenges you can speak\nto, like the heel strike or all this kind of stuff?\n- Yeah, so one of the things that makes,\nlike, this straight leg a challenge is you're sort\nof up against a singularity, a mathematical singularity\nwhere, you know, when when your leg is fully extended, it can't go further the\nother direction, right? You can only move in one\ndirection, and that makes all of the calculations around\nhow to produce torques at that joint or positions\nmakes it more complicated. And so, (laughs) having\nall of the mathematics so it can deal with these\nsingular configurations is one of many (laughs) challenges that we face. And I'd say, you know, in\nthose earlier days, again, we were working with these\nreally simplified models. So, we're trying to boil all the physics of the complex human body\ninto a simpler subsystem that we can more easily\ndescribe in mathematics. And sometimes those simpler\nsubsystems don't have all of that complexity of the\nstraight leg built into them. And so, what's happened\nmore recently is we're able to apply techniques that\nlet us take the full physics of the robot into account and deal with some of\nthose strange situations like the straight leg. - So, is there a fundamental\nchallenge here that it's, maybe you can correct me,\nbut is it underactuated? Are you falling? - Underactuated is the right word, right? You can't push the robot in\nany direction you want to. - Yeah.\n- Right? And so, that is one of the hard problems of legged locomotion. - And you have to do that\nfor natural movement? - It's not necessarily\nrequired for natural movement. It's just required, you know,\nwe don't have, you know, a gravity force that you can\nhook yourself onto to apply an external force in\nthe direction you want at all times, right? The only external forces\nare being mediated through your feet, and how\nthey get mediated depend on how you place your feet,\nand you know, you can't just, you know, God's hand\ncan't reach down and push in any direction you want,\n(laughs) you know, so. - Is there some extra\nchallenge to the fact that Atlas is such a big robot? - There is. The humanoid form is\nattractive in many ways, but it's also a challenge in many ways. You have this big upper\nbody that has a lot of mass and inertia, and\nthrowing that inertia around increases the complexity\nof maintaining balance. And as soon as you pick up\nsomething heavy in your arms, you've made that problem even harder. And so, in the early work in the Leg Lab and in the early days at\nthe company, you know, we were pursuing these quadruped robots, which had a kind of\nbuilt-in simplification. You had this big rigid body\nand then really light legs. So, when you swing the legs, the leg motion didn't impact\nthe body motion very much. All the mass and inertia was in the body, but when you have the\nhumanoid, that doesn't work. You have big heavy legs. You swing the legs. It affects everything else. (Lex laughs) And so, dealing with all of\nthat interaction does make the humanoid a much more\ncomplicated platform. - And I also saw that at least\nrecently you've been doing more explicit modeling\nof the stuff you pick up. - [Robert] Yeah, yeah. - Which is (laughs) really interesting. So, you have to, what, model the shape, the weight distribution. I don't know, like, you\nhave to, like, include that as part of the modeling,\nas part of the planning 'cause okay, so for people\nwho don't know, so Atlas, at least in, like, a recent\nvideo, like, throws a heavy bag, throws a (laughing) bunch of- - [Robert] Yeah. - stuff. So, what's involved in picking\nup a thing, a heavy thing? And when that thing is a bunch of different non-standard things, I think it also picked up like a barbell and to be able to throw in some cases, what are some interesting\nchallenges there? - So, we were definitely\ntrying to show that the robot and the techniques we're\napplying to Atlas let us deal with heavy things in the world. Because if the robot's gonna be useful, it's actually gotta move stuff around. And that needs to be significant stuff that's an appreciable portion of the body weight of the robot. And we also think this differentiates us from the other humanoid robot activities that you're seeing out there. Mostly, they're not picking stuff up yet, not heavy stuff anyway. But just like you or me, you know, you need to anticipate that moment. You know, you're reaching\nout to pick something up, and as soon as you pick it up, your center of mass is gonna shift. And if you're gonna, you\nknow, turn in a circle, you have to take that\ninertia into account. And if you're gonna\nthrow a thing, you know, all of that has to be sort of included in the model of what you're trying to do. So, the robot needs to have\nsome idea or expectation of what that weight is and\nsort of predict, you know, think a couple of seconds ahead, \"How do I manage now my body\nplus this big heavy thing together (laughs) and still\nmaintain balance, right?\" And so, that's a big change for us, and I think the tools we've\nbuilt are really allowing that to happen quickly now. Some of those motions that you\nsaw in that most recent video we were able to create\nin a matter of days. It used to be that it took\nsix months to do anything new, you know, on the robot, and\nnow we're starting to develop the tools that let us do\nthat in a matter of days. And so, we think that's really exciting. That means that the ability\nto create new behaviors for the robot is gonna\nbe a quicker process. - So, being able to\nexplicitly model new things that it might need to pick\nup, new types of things? - And you know, to some degree, you don't wanna have to\npay too much attention to each specific thing, right? There's sort of a generalization here. Obviously, when you grab a thing, you have to conform your\nhand, your end effector to the surface of that shape,\nbut once it's in your hands, it's probably just the mass\nand inertia that matter, and the shape may not be as important. - [Lex] Yeah. - And so, you know, in some\nways you wanna pay attention to that detailed shape, and in others, you wanna generalize it and say, \"Well, all I really care about is the center of mass of this thing, especially if I'm gonna throw\nit up on that scaffolding.\" - And it's easier if the body is rigid. What if there's some, doesn't it throw, like, a sandbag type thing? - That tool bag, you know-\n- Tool bag. - had loose stuff in\nit, so it managed that. There are harder things\nthat we haven't done yet. You know, we could have\nhad a big jointed thing or, I don't know, a bunch\nof loose wire or rope. - What about carrying another robot? How 'bout that? (laughing) - Yeah, we haven't done that yet. - [Lex] Carry Spot. - I guess we did a little bit of a, we did a little skit around Christmas where we had two Spots\nholding up another Spot that was trying to put,\nyou know, a bow on a tree. So, I guess we're doing that\nin a small way. (laughing) - Okay, that's pretty good. Let me ask the all-important question. Do you know how much Atlas can curl? (Robert laughing drown out Lex speaking) (Lex laughs) I mean, you know, for us\nhumans, that's really one of the most fundamental questions you can ask another human being, curl, bench, et cetera.\n(Robert laughs) - It probably can't curl\nas much as we can yet, but a metric that I\nthink is interesting is, you know, another way of\nlooking at that strength is, you know, the box jump. So, how high of a box can you jump onto? - [Lex] Question. - And Atlas, I don't\nknow the exact height. It was probably a meter\nhigh or something like that. It was a pretty pretty tall\njump that Atlas was able to manage when we last tried to do this. And I have video of my\nchief technical officer doing the same jump, and he\nreally struggled, you know, to get-\n- Oh, the human? - The human getting all\nthe way on top of this box. But then, you know,\nAtlas was able to do it. We're now thinking about the\nnext generation of Atlas, and we're probably gonna be in the realm of a person can't do it, you\nknow, with the next generation. The robots, the actuators\nare gonna get stronger where it really is the\ncase that at least some of these joints, some of these\nmotions will be stronger. - And to understand how high it can jump, you probably had to do\nquite a bit of testing. - Oh, yeah, and there's\nlots of videos of it trying and failing, and you know,\nthat's all, you know, we don't always release those videos, but they're a lot of\nfun to look at. (laughs) - So, we'll talk a little bit about that. But can you talk to the jumping? 'Cause you talked about the walking, and it took a long time, many, many years to get the walking to be natural, but there's also really natural-looking, robust, resilient jumping. How hard is it to do the jumping? - Well, again, this stuff\nhas really evolved rapidly in the last few years. You know, the first time we\ndid a somersault, you know, there was a lot of kind\nof manual iteration. What is the trajectory? You know, how hard do you throw? In fact, in these early days, when I'd see early experiments\nthat the team was doing, I might make suggestions about\nhow to change the technique, again, kind of borrowing\nfrom my own intuition about how backflips work. But frankly they don't need that anymore. So, in the early days,\nyou had to iterate kind of in almost a manual way trying to change these trajectories\nof the arms or the legs to try to get, you know, a\nsuccessful backflip to happen. But more recently, we're running these model-predictive control techniques where the robot essentially\ncan think in advance for the next second or two\nabout how its motion is going to transpire, and you can, you know, solve for optimal trajectories\nto get from A to B. So, this is happening in\na much more natural way, and we're really seeing\nan acceleration happen in the development of these behaviors, again, partly due to these\noptimization techniques, sometimes learning techniques, so it's hard in that there's a\nlot of mathematics behind it, but we're figuring that out. - So, you can do\nmodel-predictive control for, I mean, I don't even\nunderstand what that looks like when the entire robot is in the air flying and doing a back (laughs). - Yeah, well-\n- I mean. (laughs) - But that's the cool part, right? So, you know, the physics, we can calculate physics\npretty well using, you know, Newton's laws about how it's\ngoing to evolve over time and you know, the sick trick,\nwhich was a front somersault with a half twist is\na good example, right? You saw the robot on various\nversions of that trick. I've seen it land in\ndifferent configurations, and it still manages to stabilize\nitself, and so, you know, what this model-predictive\ncontrol means is, again, in real time, the robot is\nprojecting ahead, you know, a second into the future and\nsort of exploring options. And if I move my arm a\nlittle bit more this way, how is that gonna affect the outcome? And so, it can do these\ncalculations, many of them, you know, and basically solve for where, you know, given where I am now, maybe I took off a little bit screwy from how I had planned, I can adjust. - [Lex] So, you're adjusting in the air for the landing.\n- Adjust on the fly. So, the model-predictive\ncontrol lets you adjust on the fly, and of course, I think this is what, you know, people adapt as well. When we do it, even a gymnastics trick, we try to set it up so it's\nclose to the same every time. But we figured out how to do\nsome adjustment on the fly, and now we're starting to figure out that the robots can do\nthis adjustment on the fly as well using these techniques. - In the air. I mean, it just feels, from a robotics perspective, just surreal. - You talked about underactuated, right? - [Lex] Yes.\n- So, when you're- - That's totally true.\n- When you're in the air, there's some things you\ncan't change, right? You can't change the momentum\nwhile it's in the air 'cause you can't apply an\nexternal force, a torque, and so the momentum isn't gonna change. So, how do you work within the constraint of that fixed momentum to\nstill get from A to B (laughs) where you wanna be? - That's really (laughing) underactuated. (Robert laughs) You're in the air. I mean, you become a drone\nfor a brief moment in time. No, you're not even a (laughing)\ndrone 'cause you can't- - [Robert] Can't hover. - You can't hover. You can't.\n- You're gonna impact soon. Be ready. (laughs)\n- Yeah. Have you considered like\na hover type thing or no? No?\n- No. - It's too much weight?\n- No. (Lex laughing) - I mean, it's just\nincredible and just even to have the guts to try a\nbackflip with such a large body. That's wild. (Robert laughs) But, like how- - We definitely broke a\nfew robots trying that. - [Lex] (laughing) Yeah. (Robert laughs) - But that's where the\nbuild it, break it, fix it, you know, strategy comes in. You gotta be willing to break. And what ends up happening is by breaking the robot repeatedly,\nyou find the weak points, and then you end up redesigning it so it doesn't break so easily\nnext time, you know. (laughs) - Through the breaking\nprocess you learn a lot, like, a lot of lessons,\nand you keep improving not just how to make the backflip work, but everything just-\n- Yeah. And how to build the machine better. - Yeah.\n- Yeah. - I mean, is there something\nabout just the guts to come up with an idea\nof saying, \"You know what? Let's try (laughing) to\nmake it to a backflip\"? - Well, I think the\ncourage to do a backflip in the first place and\nto not worry too much about the ridicule of somebody saying, \"Why the heck are you doing\nbackflips with robots?\" - [Lex] Sure. - Because a lot of people\nhave asked that, you know. (Lex laughs) (laughing) \"Why are you doing this?\" - Why go to the moon (Robert laughs) in this decade and do\nthe other things, JFK? (Robert laughs) Not because it's easy, because it's hard. - [Robert] Yeah, exactly. (laughs) (Lex laughs) - Don't ask questions. Okay, so the jumping, I mean, there's a lot of incredible stuff. If we can just rewind a little bit to the DARPA Robotics\nChallenge in 2015, I think, which was, for people who aren't familiar with the DARPA challenges, it was first with autonomous vehicles,\nand there's a lot of interesting challenges around that. And the DARPA Robotics Challenge was when humanoid robots were\ntasked to do all kinds of, you know, manipulation, walking- - Driving a vehicle.\n- driving a car, all these kinds of challenges\nwith, if I remember correctly, sort of some slight capability\nto communicate with humans, but the communication was very poor. So, basically it has to be\nalmost entirely autonomous. - It could have periods where the communication\nwas entirely interrupted, and the robot had to be able to proceed. - [Lex] Yeah. - But you could provide\nsome high-level guidance to the robot, basically\nlow-bandwidth communications- - Yeah\n- to steer it. - I watched that challenge\nwith kind of tears in my eyes eating popcorn with-\n- Us, too. (both laughing) - But I wasn't personally\nlosing, you know, hundreds of thousands, millions of dollars and many years of incredible, hard work by some of the most brilliant\nroboticists in the world. So, that was why the tragic, that's why tears came.\n(Robert laughs) So, anyway, just looking\nback to that time, what have you learned\nfrom that experience? And maybe if you could\ndescribe what it was sort of the setup for\npeople who haven't seen it. - Well, so there was a contest where a bunch of different\nrobots were asked to do a series of tasks, some\nof those that you mentioned, drive a vehicle, get out, open a door, go identify a valve, shut a valve, use a tool to maybe\ncut a hole in a surface and then crawl over some stairs and maybe some rough terrain. So, the idea was have\na general-purpose robot that could do lots of different things, had to be mobility, and\nmanipulation, on-board perception. And there was a contest, which DARPA likes at the\ntime, was running sort of follow-on to the grand challenge, which was, \"Let's try to\npush vehicle autonomy along.\" Right? They encouraged people\nto build autonomous cars. So, they were trying to basically\npush an industry forward. Our role in this was to build a humanoid. At the time, it was our sort of first-generation Atlas robot, and we built maybe 10 of them, I don't remember the exact number. And DARPA distributed those\nto various teams that sort of won a contest, showed that\nthey could, you know, program these robots and then use them to compete against each other, and then other robots\nwere introduced as well. Some teams built their own robots. Carnegie Mellon, for example,\nbuilt their own robot. And all these robots competed\nto see who could sort of get through this maze the fastest. And again, I think the purpose was to kind of push the whole industry forward. We provided the robot and\nsome baseline software, but we didn't actually\ncompete as a participant where we were trying to,\nyou know, drive the robot through this maze. We were just trying to\nsupport the other teams. It was humbling because\nit was really a hard task. And honestly, the tears were because, mostly, the robots\ndidn't do it. (laughs) You know, they fell down,\nyou know, repeatedly. It was hard to get through this contest. Some did, and you know,\nthey were rewarded and won. But it was humbling\nbecause of just how hard, these tasks weren't all that hard. A person could have done it very easily, but it was really hard to get\nthe robots to do it, you know. And the-\n- The general nature of it, the variety of it. - [Robert] The variety. - And also, I don't know\nif the tasks were (sighs) sort of the task in\nthemselves help us understand what is difficult and what is not. I don't know if that was obvious before the contest was designed, so you kind of tried to figure that out. And I think Atlas is really\na general robot platform, and it's perhaps not best\nsuited for the specific tasks of that contest, like just for example, probably the hardest task is\nnot the driving of the car but getting in and out of the car. (Robert laughs) And Atlas probably is,\nyou know, if you were to design a robot that can\nget into the car easily and get out easily, you\nprobably would not make Atlas that particular car. - Yeah, the robot was a little bit big- - Yeah.\n- to get in and out of that car, right? - [Lex] It doesn't fit, yeah. - This is the curse of\na general-purpose robot, that they're not perfect at any one thing, but they might be able to\ndo a wide variety of things. And that is the goal\nat the end of the day. You know, I think we all wanna\nbuild general-purpose robots that can be used for lots\nof different activities, but it's hard, and the wisdom in building successful robots\nup until this point have been, \"Go build a robot for a specific task, and it'll do it very well.\" And as long as you\ncontrol that environment, it'll operate perfectly,\nbut robots need to be able to deal with uncertainty. If they're gonna be useful\nto us in the future, they need to be able to deal\nwith unexpected situations. And that's sort of the goal of a general-purpose\nor multipurpose robot. And that's just darn hard. And so, yeah, there was these\ncurious little failures. Like, I remember a robot, you know, the first time you start\nto try to push on the world with a robot, you forget\nthat the world pushes back and will push you over (laughs)\nif you're not ready for it. And the robot, you know,\nreached to grab the door handle. I think it missed the\ngrasp of the door handle, was expecting that its hand\nwas on the door handle, and so when it tried to turn the knob, it just threw itself over. It didn't realize, \"Oh, I\nhad missed the door handle. I was expecting a force\nback from the door. It wasn't there, and\nthen I lost my balance.\" And so, these little simple things that you and I would\ntake totally for granted and deal with, (laughs)\nthe robots don't know how to deal with yet, and\nso you have to start to deal with all of those circumstances. (laughs) - Well, I think a lot\nof us experience this even when sober but drunk, too. Sort of, you pick up a\nthing and expect it to be, what is it, heavy, and\nit turns out to be light. - [Robert] Yeah, and then, \"Whoa.\" - Oh, yeah, and then, and I'm\nsure if your depth perception for whatever reason is screwed up, if you're drunk or some other reason, and then you think you're\nputting your hand on the table, and you miss it, I mean it's\nthe same kind of situation. - [Robert] Yeah. - But there's a-\n- Which is why you need to be able to predict forward\njust a little bit, and so that's where this model-predictive\ncontrol stuff comes in. Predict forward what you\nthink's gonna happen, and if that does happen,\nyou're in good shape. If something else happens, you better start predicting again. - So, like, regenerate a plan.\n(Robert laughs) - [Robert] Yeah. - I mean, that also requires\na very fast feedback loop of updating what your prediction, how it matches to the actual real world. - [Robert] Yeah, those things\nhave to run pretty quickly. - What's the challenge of\nrunning things pretty quickly, 1,000 hertz, of acting\nand sensing quickly? - You know, there's a few\ndifferent layers of that. At the lowest level, you\nlike to run things typically at around 1,000 hertz,\nwhich means that, you know, at each joint of the robot,\nyou're measuring position or force and then trying\nto control your actuator, whether it's a hydraulic\nor electric motor trying to control the force coming\nout of that actuator. And you wanna do that really fast, something like 1,000 hertz,\nand that means you can't have too much calculation\ngoing on at that joint. But that's pretty manageable these days, and it's fairly common. And then, there's another layer that you're probably\ncalculating, you know, maybe at 100 hertz, maybe 10 times slower, which is now starting to look\nat the overall body motion and thinking about the\nlarger physics of the robot. And then, there's yet another\nloop that's probably happening a little bit slower, which\nis where you start to bring, you know, your perception in, your vision, and things like that, and\nso you need to run all of these loops sort of simultaneously. You do have to manage your computer time so that you can squeeze in\nall the calculations you need in real time in a very consistent way. And the amount of calculation\nwe can do is increasing as computers get better,\nwhich means we can start to do more sophisticated calculations. I can have a more complex model\ndoing my forward prediction, and that might allow me to\ndo even better predictions as I get better and better. And it used to be, again,\nyou know, 10 years ago, we had to have pretty simple\nmodels that we were running, you know, at those fast rates\n'cause the computers weren't as capable about calculating forward with a sophisticated model,\nbut as computation gets better, we can do more of that. - What about the actual pipeline\nof software engineering, how easy it is to keep updating Atlas, like, do continuous development on it? So, how many computers are on there? Is there a nice pipeline? - It's an important part of\nbuilding a team around it, which means, you know, you need\nto also have software tools, simulation tools, you know, so we have always made strong use of physics-based\nsimulation tools to do some of this calculation, basically\ntest it in simulation before you put it on the robot. But you also want the same\ncode that you're running in simulation to be the\nsame code you're running on the hardware, and so\neven getting to the point where it was the same code\ngoing from one to the other, we probably didn't really get that working until, you know, several years ago. But you know, that was\na bit of a milestone. And so, you wanna certainly\nwork these pipelines so that you can make\nit as easy as possible and have a bunch of people\nworking in parallel. You know, we only have, you\nknow, four of the Atlas robots, the modern Atlas robots at\nthe company, and you know, we probably have, you\nknow, 40 developers there all trying to gain access to it. And so, you need to share resources and use some of the software pipeline. - Well, that's a really\nexciting step to be able to run the exact same code in simulation\nas on the actual robot. How hard is it to do a realistic simulation, physics-based simulation\nof Atlas such that, I mean, the dream is like,\nif it works in simulation, it works perfectly in reality.\n(Robert laughs) How hard is it to sort of keep\nworking on closing that gap? - The root of some of our\nphysics-based simulation tools really started at MIT, and we built some good physics-based\nmodeling tools there. The early days of the\ncompany, we were trying to develop those tools\nas a commercial product, so we continued to develop them. It wasn't a particularly\nsuccessful commercial product, but we ended up with some nice physics-based\nsimulation tools so that, when we started\ndoing legged robotics again, we had a really nice tool to work with. And the things we paid\nattention to were things that weren't necessarily handled very well in the commercial tools you\ncould buy off the shelf, like interaction with the\nworld, like foot-ground contact. And so, trying to model\nthose contact events well in a way that captured the important parts of the interaction was a\nreally important element to get right and to also do in a way that was computationally\nfeasible and could run fast 'cause if your simulation\nruns too slow, you know, then your developers are\nsitting around waiting for stuff to run and compile, and so it's always about efficient, fast operation as well. So, that's been a big part of it. You know, I think developing\nthose tools in parallel to the development of\nthe platform and trying to scale them has really\nbeen essential, I'd say, to us being able to\nassemble a team of people that could do this. - Yeah, how to simulate contact, period, so foot-ground contact but\nsort of for manipulation because don't you want to\nmodel all kinds of surfaces? - Yeah. So, it will be even more\ncomplex with manipulation 'cause there's a lot\nmore going on. (laughs) - Yeah.\n- You know. And you need to capture, I don't know, things slipping and moving,\nyou know, in your hand. It's a level of complexity\nthat I think goes above foot-ground contact when you really start doing\ndextrous manipulation. So, there's challenges ahead still. - So, how far are we away\nfrom me being able to walk with Atlas in the sand along the beach (Robert laughs) and us both drinking a beer? (Robert laughing) - [Robert] Well, I- - Sip it out of a can, out of a can. - Maybe Atlas could spill his beer 'cause he's got nowhere\nto put it. (laughing) Atlas could walk on the sand. - So, can it?\n- Yeah, yeah. Yeah, I mean, you know,\nhave we really had him out on the beach? You know, we take them outside often, you know, rocks, hills,\nthat sort of thing, even just around our lab in Waltham. We probably haven't been\non the sand, but I'm- - So, soft surfaces, normally?\n- I don't doubt that we could deal with it. We might have to spend\na little bit of time to sort of make that work. We had to take BigDog\nto Thailand years ago, and we did this great video of the robot walking in the sand, walking into the ocean up\nto, I don't know, its belly or something like that and\nthen turning around and walking out all while playing-\n- Oh, that's- - [Robert] some cool beach music. - Yeah.\n- Great show, but then, you know, we didn't\nreally clean the robot off, and the saltwater was really\nhard on it, so you know, we put it in a box, shipped it back. By the time it came back, we had some problems\n(laughing) with corrosion. - It's the salt water. It's not like-\n- Salt tough (laughs). - It's not, like, sand getting into the components or\nsomething like this. - [Robert] Yeah, yeah.\n- But I'm sure, if this is a big priority,\nyou can make it like- - Right.\n- waterproof it or something.\n- Right, right. That just wasn't our goal at the time. - Well, it's a personal goal of mine to walk along,\n(Robert laughs) walk along the beach, but\nit's a human problem, too. You get sand everywhere. It's just a giant mess. (Robert laughs) So, soft surfaces are okay. So, I mean, can we just linger\non the robotics challenge? There's a pile of, like,\nrubble they had to walk over. How difficult is that task? - In the early days of developing BigDog, the loose rock was the epitome\nof the hard walking surface because you stepped down, and you had these little\npoint feet on the robot, and the rock can roll,\nand you have to deal with that last-minute, you know, change in your foot placement. - Yeah, so you step on the\nthing, and that thing responds to you stepping on it. - Yeah, and it moves where\nyour point of support is. And so, that became kinda\nthe essence of the test. And so, that was the\nbeginning of us starting to build rock piles in our parking lots, and we would actually\nbuild boxes full of rocks and bring 'em into the\nlab, and then we would have the robots walking across\nthese boxes of rocks because that became the essential test. - So, you mentioned BigDog. Can we maybe take a stroll through the history of Boston Dynamics? So, what and who is BigDog? By the way, is who, (Robert laughs) do you try not to\nanthropomorphize the robots? Do you try to remember that they're, this is like the division I have 'cause, for me, it's impossible. For me, there's a magic to\nthe being that is a robot. It is not human, but it is, the same magic that a living\nbeing has when it moves about the world is there in the robot. So, I don't know what question I'm asking, but should I say what or who I guess? Who is BigDog? What is BigDog?\n(Robert laughs) - Well, I'll say to\naddress the meta question, we don't try to draw hard\nlines around it being an it, or a him, or a her. It's okay, right? I think part of the magic of\nthese kinds of machines is by nature of their organic\nmovement, of their dynamics, we tend to want to identify with them. We tend to look at them and\nsort of attribute maybe feeling to that because we've only seen things that move like this that were alive. And so, this is an opportunity. It means that you could\nhave feelings for a machine, and you know, people have\nfeelings for their cars. You know, they get attracted\nto 'em, attached to them. So, that's inherently,\ncould be a good thing as long as we manage\nwhat that interaction is. So, we don't put strong\nboundaries around this and ultimately think it's a benefit, but it's also, can be a bit of a curse because I think people\nlook at these machines, and they attribute a level of intelligence that the machines don't have. Why? Because, again, they've\nseen things move like this that we're living beings,\nwhich are intelligent, and so they wanna attribute\nintelligence to the robots that isn't appropriate yet, even though they move\nlike an intelligent being. - But you try to acknowledge that the anthropomorphization\nis there and try to, first of all,\nacknowledge that it's there. - And have a little fun with it. - And have little fun.\n- You know, our most recent video,\nit's just kind of fun, you know, to look at the robot. We started off the video\nwith Atlas kind of looking around for where the bag of tools was 'cause the guy up on the scaffolding says, \"Send me some tools.\" Atlas has to kinda look\naround and see where they are. And there's a little\npersonality there that is fun. It's entertaining. It makes our jobs interesting and I think in the long\nrun can enhance interaction between humans and robots in a way that isn't available to machines\nthat don't move that way. - This is something to me\npersonally is very interesting. I happen to have a lot of legged robots. (both laughing) I hope to have a lot of\nSpots in my possession. I'm interested in celebrating robotics and celebrating companies, companies that do incredible stuff\nlike Boston Dynamics. You know, I'm a little crazy,\nand you say you don't want to, you want to align, you\nwanna help the company 'cause I ultimately want a company like Boston Dynamics to succeed. And part of that we'll\ntalk about, you know, success kind of requires making money. And so, the kinda stuff\nI'm particularly interested in may not be the thing that\nmakes money in the short term. I can make an argument\nthat will in the long term. But the kinda stuff I've been\nplaying with is a robust way of having the quadrupeds, the\nrobot dogs communicate emotion with their body movement- - Hmm.\n- the same kinda stuff you do with a dog- - Yeah.\n- but not hard coded, but in a robust way-\n- Mm-hmm. - and be able to communicate\nexcitement, or fear- - Mm-hmm. - boredom, all these kinds of stuff. And I think as a base layer\nof function, of behavior to add on top of a robot, I think that's a really powerful way to make the robot more usable for humans, for whatever application.\n- I think it's gonna be really important, and it's\na thing we're beginning to pay attention to. A differentiator for the\ncompany has always been we really want the robot to work. We want it to be useful. Making it work at first meant the legged locomotion really works. It can really get around,\nand it doesn't fall down. But beyond that, now it\nneeds to be a useful tool. And our customers are, for\nexample, factory owners, people who are running a\nprocess-manufacturing facility. And the robot needs to be able to get through this complex\nfacility in a reliable way, you know, taking measurements. We need for people who\nare operating those robots to understand what the robots are doing. If the robot needs help\nor, you know, is in trouble or something, it needs\nto be able to communicate and a physical indication of some sort so that a person looks\nat the robot and goes, \"Oh, I know what that robot's doing. That robot's going to go take measurements of my vacuum pump with\nits thermal camera.\" You know, you wanna be\nable to indicate that, or even just the robot's\nabout to turn, you know, in front of you and\nmaybe indicate (laughs) that it's going to turn. And so, you sort of see and\ncan anticipate its motion. So, this kind of communication is going to become more and more important. It wasn't sort of our\nstarting point, you know, but now the robots are\nreally out in the world, and you know, we have about 1,000 of 'em out with customers right now. This layer of physical indication,\nI think, is gonna become more and more important. - We'll talk about where it goes 'cause there's a lot of\ninteresting possibilities. But if you can return back to\nthe origins of Boston Dynamics with the more research, the R&D side, before we talk about how\nto build robots at scale. So, BigDog. What's-\n- So- - Who's BigDog? - So, the company started in 1992, and in probably 2003, I believe, is when we\ntook a contract from, so, basically, 10 years, 11\nyears we weren't doing robotics. We did a little bit of robotics with Sony. They had Aibo. They had their Aibo robot. We were developing some software for that. That kinda got us a little bit involved with robotics again. Then, there was this opportunity\nto do a DARPA contract where they wanted to build a robot dog. And we won a contract to build that. And so, that was the genesis of BigDog, and it was a quadruped,\nand it was the first time we built a robot that\nhad everything on board. You could actually take the robot out into the wild and operate it. So, it had an onboard power plan. It had onboard computers. It had hydraulic actuators\nthat needed to be cooled. So, we had cooling systems built in, everything integrated into the robot. And that was a pretty rough start, right? It was 10 years that we\nwere not a robotics company. We were a simulation\ncompany, and then we had to build a robot in about a year. So, that was a little bit\nof a rough transition. (Lex laughs) (Robert laughs) - I mean, can you just\ncomment on the roughness of that transition? 'Cause BigDog, I mean, this is this big\nquadruped, four legs robot. - We built a few different\nversions of them, but the very earliest ones, you\nknow, didn't work very well, (laughs) and we would take 'em\nout, and it was hard to get, you know, a go-kart engine\ndriving a hydraulic- - Oh, is that what it was? (Robert laughs) I was-\n- And you know, having that all work while trying to get, you know, the robot to stabilize itself, and so-\n- So. what was the power plan? What was the engine? It seemed like my vague\nrecollection, (laughs) I don't know. It felt very loud, and aggressive, and kind of thrown together\nis what it kind of- - Oh, it absolutely was, right? We weren't trying to design\nthe best robot hardware at the time, and we wanted to\nbuy an off-the-shelf engine. And so, many of the early\nversions of BigDog had literally go-kart engines or something like that. Usually, it-\n- It was gas powered? - Yeah, a gas-powered two-stroke engine. (Lex laughs) And the reason why it was two stroke is two-stroke engines are lighter weight, and we generally didn't\nput mufflers on them 'cause we're trying to save the weight, and we didn't care about the noise. (laughing) And some of these\nthings were horribly loud, but we're trying to manage\nweight because managing weight in a legged robot is always important because it has to carry everything. - That said, that thing was big- - Well-\n- what I've seen the videos of.\n- Yeah. I mean, the early\nversions, you know, stood about, I don't know,\nbelly high, chest high. You know, they probably\nweighed maybe a couple of hundred pounds, but\nyou know, over the course of probably five years, we\nwere able to get that robot to really manage a remarkable\nlevel of rough terrain. So, you know, we started out\nwith just walking on the flat, and then we started walking\non rocks, and then inclines, and then mud, and then slippery mud. And you know, by the end of\nthat program, we were convinced that legged locomotion in\na robot could actually work 'cause you know, going into\nit, we didn't know that. We had built quadrupeds at MIT, but they used a giant hydraulic\npump, you know, in the lab. They used a giant computer\nthat was in the lab. They were always tethered to the lab. This was the first time\nsomething that was sort of self-contained, you know,\nwalked around in the world and balanced, and the purpose\nwas to prove to ourself that the legged locomotion\ncould really work. And so, BigDog really\ncut that open for us. And it was the beginning of what became a whole series of robots. So, once we showed to\nDARPA that you could make a legged robot that could work, there was a period at DARPA where robotics got really\nhot, and there was lots of different programs,\nand you know, we were able to build other robots. We built other quadrupeds\nlike LS3 designed to carry heavy loads. We built Cheetah, which\nwas designed to explore, what are the limits to\nhow fast you can run? You know, we began to\nbuild sort of a portfolio of machines and software that let us build not just one robot, but\na whole family of robots. - So, push the limits in\nall kinds of directions in terms-\n- Yeah, and to discover those principles. You know, you asked earlier about the art and science\nof legged locomotion. We were able to develop\nprinciples of legged locomotion so that we knew how to build a small legged robot or a big one. So, leg length, you\nknow, was now a parameter that we could play with. Payload was a parameter\nwe could play with. So, we built the LS3, which\nwas an 800-pound robot designed to carry a 400-pound payload. And we learned the design rules, basically developed the design rules. How do you scale different robot systems to, you know, their terrain,\nto their walking speed, to their payload? - So, when was Spot born? - Around 2012 or so, so, again, almost 10 years\ninto sort of a run with DARPA where we built a bunch\nof different quadrupeds. We had sort of a different thread where we started building humanoids. We saw that probably an end was coming where the government was\ngonna kind of back off from a lot of robotics investment. And in order to maintain\nprogress, we just deduced that, \"Well, we probably\nneed to sell ourselves to somebody who wants to\ncontinue to invest in this area,\" and that was Google. And so, at Google, we would\nmeet regularly with Larry Page, and Larry just started\nasking us, you know, \"What's your product gonna be?\" And you know, the logical thing, the thing that we had the most\nhistory with that we wanted to continue developing was a quadruped. But we knew it needed to be smaller. We knew it couldn't have a gas engine. We thought it probably couldn't\nbe hydraulically actuated. So, that began the process of\nexploring if we could migrate to a smaller, electrically actuated robot. And that was really the genesis of Spot. - So, not a gas engine, and\nthe actuators are electric. - [Robert] Yes. - So, can you maybe\ncomment on what it's like at Google working with Larry Page, having those meetings, and thinking of what will a robot look like\nthat could be built at scale, like, starting to think about a product? - Larry always liked the toothbrush test. He wanted products that\nyou used every day. What they really wanted was, you know, a consumer-level product, something that would work in your house. We didn't think that was\nthe right next thing to do, because to be a consumer-level product, cost is gonna be very important. Probably needed to cost\na few thousand dollars. And we were building these machines that cost hundreds of\nthousands of dollars, maybe a million dollars to build. And of course, we were\nonly building, like, two, but we didn't see how to get all the way to this consumer-level product- - In a short amount of time. - In a short amount of time. And he suggested that we make\nthe robots really inexpensive, and part of our philosophy has always been build the best hardware you can. Make the machine operate\nwell so that you're trying to solve, you know,\ndiscover the hard problem that you don't know about. Don't make it harder by building a crappy machine, basically. Build the best machine you can. There's plenty of hard problems to solve that are gonna have to do with, you know, underactuated\nsystems and balance. And so, we wanted to build these high-quality machines still, and we thought that was important for us to continue learning about really what was the important parts that make robots work. And so, there was a little bit of a philosophical difference there. And so, ultimately that's\nwhy we're building robots for the industrial sector now because the industry can\nafford a more expensive machine because, you know, their\nproductivity depends on keeping their factory going. And so, if Spot costs, you\nknow, $100,000 or more, that's not such a big expense to them, whereas at the consumer level, no one's gonna buy a robot like that. And I think we might eventually get to a consumer-level product\nthat will be that cheap, but I think the path to\nget in there needs to go through these really nice machines so that we can then learn how to simplify. - So, what can you say to\nalmost the engineering challenge of bringing down cost of a robot so that, presumably, when you\ntry to build a robot at scale, that also comes into play when\nyou're trying to make money on a robot even in the industrial setting? But how interesting, how\nchallenging of a thing is that, in particular probably new to an R&D company?\n(Robert laughs) - Yeah, I'm glad you\nbrought that last part up. The transition from an R&D\ncompany to a commercial company, that's the thing you\nworry about, you know, 'cause you've got these\nengineers who love hard problems, who wanna figure out\nhow to make robots work. And you don't know if you\nhave engineers that wanna work on the quality, and reliability, and cost that is ultimately required. And indeed, you know, we have\nbrought on a lot of new people who are inspired by those problems. But the big takeaway lesson for me is we have good people. We have engineers who\nwanna solve problems, and the quality, and cost,\nand manufacturability is just another kind of problem. And because they're so\ninvested in what we're doing, they're interested in and will go work on those problems as well. And so, I think we're managing\nthat transition very well. In fact, I'm really pleased that, I mean, it's a huge undertaking by the way, right? So, you know, to get reliability\nto where it needs to be, we have to have fleets of robots that we're just operating\n24/7 in our offices to go find those rare\nfailures and eliminate them. It's just a totally\ndifferent kind of activity than the research activity\nwhere you get it to work, you know, the one robot you have to work in a repeatable way, (laughs) you know, at the high-stakes demo. It's just very different. But I think we're making\nremarkable progress, I guess. - So, one of the cool\nthings, I got a chance to visit Boston Dynamics, and I mean, one of the things that's really cool is to see a large number\nof robots moving about because I think one of\nthe things you notice in the research environment\nat MIT, for example, I don't think anyone\never has a working robot for a prolonged period of time. - (laughing) Exactly. - So, like, most robots\nare just sitting there in a sad state of despair waiting to be born,\n(Robert laughs) brought to life for a\nbrief moment of time. I just remember there's\na Spot robot just had, like, a cowboy hat on and\nwas just walking randomly for whatever reason. I don't even know, but\nthere's a kind of a sense of sentience to it because it doesn't seem like anybody was\n(laughing) supervising it. - Well-\n- It was just doing its thing.\n- I'm gonna stop way short of the sentience. - Sure.\n- It is the case that, if you come to our\noffice, you know, today and walk around the hallways, you're gonna see a dozen robots\njust kind of walking around- - Yes.\n- all the time. And that's really a\nreliability test for us. So, we have these robots programmed to do autonomous missions, get\nup off their charging dock, walk around the building, collect data at a few different places,\nand go sit back down. And we want that to be\na very reliable process 'cause that's what somebody\nwho's running a brewery, a factory, that's what\nthey need the robot to do, and so we have to dog-food our own robot. We have to test it in that way. And so, on a weekly basis, we\nhave robots that are accruing something like 1,500 or maybe\n2,000 kilometers of walking and you know, over 1,000\nhours of operation every week. And that's something that\nI don't think anybody else in the world can do 'cause,\nA, you have to have a fleet of robots to just accrue that\nmuch information. (laughing) You have to be willing to\ndedicate it to that test. But that's essential. - [Lex] That's how you\nget the reliability. - That's how you get it. - What about some of the cost cutting from the manufacturer's side? What have you learned from\nthe manufacturer's side of the transition from R&D to- - And we're still learning a lot there. We're learning how to cast parts instead of mill it all out\nof, you know, billet aluminum. We're learning how to\nget plastic molded parts, and we're learning about\nhow to control that process (laughs) so that you can build the same robot twice in a row. There's a lot to learn there. And we're only partway\nthrough that process. We've set up a manufacturing\nfacility in Waltham. It's about a mile from our headquarters, and we're doing final assembly and tests of both Spots and Stretches,\nyou know, at that factory. And it's hard because, to be\nhonest, we're still iterating on the design of the robot. As we find failures from\nthese reliability tests, we need to go engineer\nchanges, and those changes need to now be propagated to\nthe manufacturing line. And that's a hard process, especially when you wanna\nmove as fast as we do. And that's been challenging. You know, the folks who\nare working supply chain who are trying to get the\ncheapest parts for us, kind of requires that you buy a\nlot of 'em to make 'em cheap, and then we go change the\ndesign from underneath 'em, and they're like, \"What are you doing?\" And so, you know, getting\neverybody on the same page here that, yep, we still need to move fast, but we also need to try to\nfigure out how to reduce cost, that's one of the challenges of this migration we're going through. - And over the past few years, challenges to the supply chain, I mean, I imagine you've been a part of a bunch of stressful meetings. - Yeah, things got more\nexpensive and harder to get, and yeah, so it's all been a challenge. - Is there still room for simplification? - Oh, yeah, much more,\nand you know, these are really just the first\ngeneration of these machines. We're already thinking about\nwhat the next generation of Spot's gonna look like. Spot was built as a\nplatform, so you could put almost any sensor on it. You know, we provided data communications, mechanical connections, power connections. But for example, in the\napplications that we're excited about where you're\nmonitoring these factories for their health, there's\nprobably a simpler machine that we could build that's\nreally focused on that use case. And that's the difference between the general-purpose\nmachine or the platform versus the purpose-built machine. And so, even though even in the factory we'd still like the robot to\ndo lots of different tasks, if we really knew on day one\nthat we're gonna be operating in a factory with these\nthree sensors in it, we would have it all\nintegrated in a package that would be easier, less\nexpensive, and more reliable. So, we're contemplating\nbuilding, you know, a next generation of that machine. - So, we should mention that, so Spot for people who\nsomehow are not familiar, is a yellow, robotic dog and has been featured\nin many dance videos. It also has gained an arm. So, what can you say about\nthe arm that Spot has, about the challenges of this design, and the manufacturer of it? - We think the future of mobile robots is mobile manipulation. You know, in the past 10 years, it was getting mobility to work, getting the legged locomotion to work. If you ask, what's the hard\nproblem in the next 10 years, it's getting a mobile robot to do useful manipulation for you. And so, we wanted Spot to have an arm to experiment with those problems. And the arm is almost as\ncomplex as the robot itself, you know, and it's an attachable payload. It has, you know, several motors, and actuators, and sensors. It has a camera in the end of its hand, so you know, you can\nsort of see something, and the robot will control\nthe motion of its hand to go pick it up autonomously. So, in the same way the\nrobot walks and balances, managing its own foot\nplacement to stay balanced, we want manipulation to\nbe mostly autonomous, where the robot, you indicate, \"Okay, go grab that bottle,\" and then the robot will just\ngo do it using the camera in its hand and then sort\nof closing in on the grasp. But it's a whole nother complex robot on top of a complex legged robot. And of course, we made the\nhand look a little like a head, (laughs) you know,\nbecause again, we want it to be sort of identifiable. In the last year, a lot of\nour sales have been people who already have a robot now buying an arm to add to that robot. - Oh, interesting. And so, the arm is for sale? - [Robert] Oh, yeah, oh, yeah. It's an option. - What's the interface\nlike to work with the arm? I could just ask that question in general about robots from Boston Dynamics. Is it designed to be easily and efficiently operated\nremotely by a human being? Or, is there also the capability\nto push towards autonomy? - We want both. In the next version of the\nsoftware that we release, which will be version 3.3,\nwe're gonna offer the ability, if you have a autonomous\nmission for the robot, we're gonna include the\noption that it can go through a door, which means\nit's gonna have to have an arm, and it's gonna have to use\nthat arm to open the door. And so, that'll be an\nautonomous manipulation task that you can program\neasily with the robot- - Oh.\n- strictly through, you know, we have a tablet interface,\nand so on the tablet, you know, you sort of see the view that Spot sees. You say, \"There's the door handle. You know, the hinges are on\nthe left, and it opens in. The rest is up to you. Take care of it.\"\n- Oh, wow. So, it just takes care of everything? - Yeah. So, and for a task like opening doors, you can automate most of that. And we've automated a few other tasks. We had a customer who had a high-powered breaker\nswitch, essentially. It's an electric utility,\nOntario Power Generation. And when they're gonna\ndisconnect, you know, their power supply, right, that could be a gas generator, could be a nuclear power\nplant, you know, from the grid, you have to disconnect\nthis breaker switch. Well, as you can imagine,\nthere's, you know, hundreds or thousands of amps\nand volts (laughing) involved in this breaker switch. And it's a dangerous event\n'cause occasionally you'll get what's called an arc flash. As you just do this disconnect, the power, the sparks jump across,\nand people die doing this. And so, Ontario Power Generation\nused our Spot and the arm through the interface to\noperate this disconnect- - That's great.\n- in an interactive way. And they showed it to us, and\nwe were so excited about it and said, \"You know, I bet\nwe can automate that task.\" And so, we got some examples\nof that breaker switch, and I believe in the next\ngeneration of the software now we're gonna deliver back\nto Ontario Power Generation, they're gonna be able\nto just point the robot at that breaker. They'll indicate, \"That's the switch.\" There's sort of two\nactions you have to do. You have to flip up this\nlittle cover, press a button, then get a ratchet,\nstick it into a socket, and literally unscrew\nthis giant breaker switch. So, there's a bunch of different tasks, and we basically automated\nthem so that the human says, \"Okay, there's the switch. Go do that part. That right there is the socket where you're gonna put your tool, and you're gonna open it up.\" And so you can remotely\nsort of indicate this on the tablet, and then\nthe robot just does everything in between. - And it does everything,\nall the coordinated movement of all the different actuators\nthat includes the body and the arm.\n- Yeah, maintains its balance. It walks itself, you know, into position so it's within reach, and\nthe arm is in a position where it can do the whole task. So, it manages the whole body. - So, how does one become\na big enough customer to request features? 'Cause I personally want a\nrobot that gets me a beer. (Robert laughs) I mean, that has to be,\nlike, one of the most, I suppose, in the industrial setting, that's a non-alcoholic beverage of picking up objects and\nbringing the objects to you. - We love working with customers who have challenging problems like this and this one in particular because we felt like what they were doing,\nA, it was a safety feature. B, we saw that the robot could do it 'cause they teleoperated\nit the first time. Probably took 'em an hour to\ndo it the first time, right? But the robot was clearly\ncapable, and we thought, \"Oh, this is a great\nproblem for us to work on to figure out how to automate\na manipulation task.\" And so, we took it on not because\nwe were gonna make a bunch of money from it in selling\nthe robot back to them but because it motivated\nus to go solve what we saw as the next logical step. But many of our customers, in fact, our bigger customers, typically ones who are gonna run a utility, or a factory, or something like that, we\ntake that kind of direction from them, especially\nif they're gonna buy 10, or 20, or 30 robots, and they say, \"I really need it to do\nthis,\" well, that's exactly the right kind of problem\nthat we wanna be working on. - Mm-hmm.\n- Yeah, and so- - Note to self, \"Buy 10 Spots,\n(Robert laughs) and aggressively push\nfor beer manipulation.\" (Robert laughs) I think it's fair to say\nit's notoriously difficult to make a lot of money\nas a robotics company. How can you make money\nas a robotics company? Can you speak to that? It seems that a lot of\nrobotics companies fail. It's difficult to build robots. It's difficult to build\nrobots at a low enough cost where customers, even in\nthe industrial setting, want to purchase them, and it's\ndifficult to build robots that are useful, sufficiently useful. - [Robert] Yeah.\n- So, what can you speak to? And Boston Dynamics has been\nsuccessful for many years of finding a way to make money. - Well, in the early\ndays, of course, you know, the money we made was from\ndoing contract R&D work, and we made money, but you\nknow, we weren't growing, and we weren't selling a product. And then, we went through several owners who, you know, had a vision\nof not only developing advanced technology, but\neventually developing products. And so, both, you know,\nGoogle, and SoftBank, and now Hyundai, you know, had\nthat vision and were willing to, you know, provide that investment. Now, our discipline is that we\nneed to go find applications that are broad enough that\nyou could imagine selling thousands of robots\nbecause it doesn't work if you don't sell thousands or\ntens of thousands of robots. If you only sell hundreds,\nyou will commercially fail. And that's where most of the small robot companies have died. And that's a challenge because, you know, A, you need to field the robots. They need to start to become\nreliable, and as we've said, that takes time and\ninvestment to get there. And so, it really does take visionary investment to get there. But we believe that we\nare going to make money in this industrial monitoring space because, you know, if a chip fab, if the line goes down because a vacuum pump failed someplace, that can be a very expensive process. It can be a million dollars\na day in lost production, maybe you have to throw away some of the product along the\nway, and so the robot, if you can prevent that by inspecting the\nfactory every single day, maybe every hour if you have to, there's a real return on investment there. But there needs to be a\ncritical mass of this task. And we're focusing on a few\nthat we believe are ubiquitous in the industrial production environment. And that's using a thermal\ncamera to keep things from overheating, using an acoustic imager to find compressed air\nleaks, using visual cameras to read gauges, measuring vibration. These are standard things that you do to prevent unintended\nshutdown of a factory. And this takes place in a beer factory. We're working with AB InBev. It takes place in chip fabs. You know, we're working\nwith GlobalFoundries. It takes place in electric utilities and nuclear power plants. And so, the same robot can be applied in all of these industries. And as I said, we have about, actually it's 1,100 Spots out now. To really get, you know,\nprofitability, we need to be at 1,000 a year, maybe\n1,500 a year, you know, for that sort of part of the business. So, it still needs to grow,\nbut we're on a good path. So, I think that's totally achievable. - So, the application\nshould require crossing that 1,000-robot barrier. - It really should, yeah. I wanna mention, you know,\nour second robot, Stretch. - Yeah, tell me about Stretch. What's Stretch? Who is Stretch? - Stretch started differently than Spot. You know, Spot we built\nbecause we had decades of experience building quadrupeds. We had it in our blood. We had to build a quadruped product, but we had to go figure out\nwhat the application was, and we actually discovered this\nfactory-patrol application, basically preventative maintenance by seeing what our customers did with it. Stretch was very different. We started knowing that there was warehouses\nall over the world. There's shipping containers\nmoving all around the world full of boxes that are mostly\nbeing moved by hand. By some estimates, we think\nthere's a trillion boxes, (laughs) cardboard boxes shipped\naround the world each year. And a lot of it's done manually. It became clear early on\nthat there was an opportunity for a mobile robot in\nhere to move boxes around. And the commercial experience\nhas been very different between Stretch and with Spot. As soon as we started talking\nto people, potential customers about what Stretch was gonna be used for, they immediately started saying, \"Oh, I'll buy that robot. You know, in fact, I'm\ngonna put in an order for 20 right now.\" We just started shipping\nthe robot in January after, you know, several\nyears of development. - [Lex] Of this year? - Of this year. So, our first deliveries of\nStretch to customers were DHL and Maersk in January. We're delivering to Gap\nright now, and we have about seven or eight other customers, all who've already\nagreed in advance to buy between 10 and 20 robots, and so we've already got commitments for, you know, a couple\nhundred of these robots. This one's gonna go, right? It's so obvious that there's a need, and we're not just gonna unload trucks. We're gonna do any box-moving\ntask in the warehouse. And so, it too will be\na multipurpose robot, and we'll eventually have\nit doing palletizing, or depalletizing, or loading\ntrucks, or unloading trucks. There's definitely thousands of robots. There's probably tens\nof thousands of robots of this in the future, so\nit's gonna be profitable. - Can you describe what\nStretch looks like? - It looks like a big, strong\nrobot arm on a mobile base. The base is about the size of a pallet, and we wanted it to be\nthe size of a pallet because that's what lives\nin warehouses, right, pallets of goods sitting everywhere, so it needed to be able\nto fit in that space. - [Lex] It's not a legged robot. - It's not a legged robot. So, it was our first, it was actually a bit of a commitment from us, a challenge for us to build\na non-balancing robot. (Lex laughs) - To do the much easier\nproblem but to do it well. - Well, because, you know, it wasn't gonna have this balance problem. And in fact, the very first version of the logistics robot we\nbuilt was a balancing robot, and that's called Handle. And there's-\n- That thing was epic. - Oh, it's a beautiful machine. - It's an incredible machine. (Robert laughs) (Lex laughs) I mean, it looks epic. It looks like, I mean, out of a sci-fi movie of some sorts. I mean, can you actually just linger on, like, the design of that thing? 'Cause that's another leap into something you probably haven't done. It's a different kind of balancing. - Yeah, so let me-\n- It's wild. - I love talking about the\nhistory of how Handle came about (Lex laughs) because it connects all\nof our robots, actually. So, I'm gonna start with Atlas. When we had Atlas\ngetting fairly far along, we wanted to understand,\nI was telling you earlier, the challenge of the human form is that you have this mass up high,\nand balancing that inertia, that mass up high is its\nown unique challenge. And so, we started trying to get Atlas to balance standing on one foot, like on a balance beam\nusing its arms like this, and you know, you can do this, I'm sure. I can do this, right? Like, if you're walking a tightrope, how do you do that balance? So, that's sort of, you know,\ncontrolling the inertia, controlling the momentum of the robot. We were starting to\nfigure that out on Atlas. And so, our first concept of Handle, which was a robot that was\ngonna be on two wheels, so it had to balance, but it\nwas gonna have a big, long arm so it could reach a box\nat the top of a truck, and it needed yet another\ncounterbalance, a big tail, to help it balance while\nit was using its arm. So, the reason why this\nrobot sort of looks epic, some people said it looked like an ostrich or maybe, you know, an\nostrich moving around, was the wheels, the leg. It has legs, so it can extend its legs. So, it's wheels on legs. We always wanted to build wheels on legs. It had a tail, and it had this arm, and they're all moving\nsimultaneously and in coordination to maintain balance because we had figured out the mathematics of\ndoing this momentum control, how to maintain that balance. And so, part of the reason why we built this two-legged robot was we had figured this thing out. We wanted to see it in\nthis kind of machine, and we thought maybe this\nkind of machine would be good in a warehouse, and so we built it. And it's a beautiful machine. It moves in a graceful way\nlike nothing else we've built. But it wasn't the right machine\nfor a logistics application. We decided it was too slow and couldn't pick boxes\nfast enough, basically. - Oh.\n- And it- - Do it beautifully with elegance.\n- It did beautifully, but it just wasn't efficient enough. - [Lex] Aw. - So, we let it go. - [Lex] Yeah. - But I think we'll come back\nto that machine eventually. - The fact that it's possible,\nthe fact that you showed that you could do so many\nthings at the same time in coordination and so beautifully,\nthere's something there. - [Robert] Yeah. - That was a demonstration\nof what is possible. - Basically, we made a hard decision, and this was really kind of a\nhard-nosed business decision. It indicated us not doing\nit just for the beauty of the mathematics or the curiosity, but no, we actually\nneed to build a business that can make money in the long run. And so, we ended up building Stretch, which has a big, heavy base\nwith a giant battery in the base of it that allows it\nto run for two shifts, 16 hours worth of operation. And that big battery sort of\nhelps it stay balanced, right? So, it can move a 50-pound\nbox around with its arm and not tip over it. It's omnidirectional, it can move in any direction,\nand it has a nice suspension built into it so it can\ndeal with, you know, gaps or things on the floor and roll over it. But it's not a balancing robot. It's a mobile robot arm that\ncan work to carry, or pick, or place a box up to 50 pounds\nanywhere in the warehouse. - Take a box from point\nA to point B anywhere. - Yeah, palletize, depalletize. We're starting with unloading trucks because there's so many\ntrucks and containers where goods are shipped,\nand it's a brutal job. You know, in the summer,\nit can be 120 degrees inside that container. People don't wanna do that job, and it's backbreaking labor, right? Again, these can be up to 50-pound boxes. And so, we feel like this\nis a productivity enhancer, and for the people who used to\ndo that job unloading trucks, they're actually operating the robot now. And so, by building robots\nthat are easy to control, and it doesn't take an\nadvanced degree to manage, you can become a robot operator. And so, as we've introduced these robots to both DHL, and Maersk, and\nGap, the warehouse workers who were doing that manual labor are now the robot operators,\nand so we see this as ultimately a benefit to them as well. - Can you say how much Stretch costs? - Not yet, but I will\nsay that, when we engage with our customers, they'll\nbe able to see a return on investment in typically two years. - Okay, so that's something\nthat you're constantly thinking about, how- - [Robert] Yeah. - And I suppose you\nhave to do the same kind of thinking with Spot. So-\n- Yes. - it seems like with\nStretch the application is, like, directly obvious. - [Robert] Yeah, it's a slam dunk. - Yeah, and so you have a\nlittle more flexibility. - Well, I think we know the target. We know what we're going after. - [Lex] Yeah. - And with Spot, it took\nus a while to figure out what we were going after. - Well, let me return to that question about maybe the\nconversation you were having a while ago with Larry Page, maybe looking to the longer future of\nsocial robotics, of using Spot to connect with human\nbeings perhaps in the home. Do you see a future there if we were to sort of hypothesize\nor dream about a future where Spot-like robots\nare in the home as pets, a social robot?\n- We definitely think about it, and we would like to get there. We think the pathway to\ngetting there is, you know, likely through these\nindustrial applications and then mass manufacturing, you know. Let's figure out how to build the robots, how to make the software\nso that they can really do a broad set of skills. That's going to take real\ninvestment to get there. Performance first, right? A principle of the company has always been really make the robots do useful stuff. And so, you know, the\nsocial robot companies that try to start someplace else by just making a cute interaction, mostly they haven't survived. And so, we think the utility\nreally needs to come first, and that means you have to solve some of these hard problems. And so, to get there, we're\ngonna go through the design and software development in industrial, and then that's eventually\ngonna let you reach a scale that could then be\naddressed to a commercial, a consumer-level market, and\nso, yeah, maybe we'll be able to build a smaller Spot with an arm that could really go\nget your beer for you. - Mm-hmm. - But there's things we\nneed to figure out still, how to safely, really safely, and if you're gonna be\ninteracting with children, you better be safe. (laughs) And right now, we count on a little bit of standoff distance\nbetween the robot and people so that you don't pinch a\nfinger, you know, in the robot. So, you've got a lot of\nthings you need to go solve before you jump to that\nconsumer-level product. - Well, there's a kind\nof trade off in safety because it feels like, in\nthe home, you can fall. Like, you don't have to be as good. Like, you're allowed to\nfail in different ways, in more ways as long as\nit's safe for the humans. So, it just feels like an\neasier problem to solve 'cause it feels like, in the factory, you're not allowed to fail. - That may be true, but\nI also think the variety of things a consumer-level\nrobot would be expected to do will also be quite broad. - [Lex] Yeah. - And they're gonna want to get the beer and know the difference between\nthe beer and a Coca-Cola or my snack. You know, they're all gonna\nwant you to clean up the dishes, you know, from the table\nwithout breaking 'em. (laughs) Those are pretty complex tasks, and so there's still\nwork to be done there. - So, to push back on that,\nhere's what application I think that'll be very interesting. I think the application\nof being a pet, a friend, so, like, no tasks. Just be cute, not cute, not cute. A dog is more than just cute. A dog is a friend, is a companion. There's something about just\nhaving interacted with them. And maybe 'cause I'm hanging out alone with robot dogs a little too much, but, like, there's a connection there. And it feels like that connection\nshould not be disregarded. You-\n- No. It should not be disregarded. Robots that can somehow communicate through their physical gestures you're gonna be more\nattached to in the long run. Do you remember Aibo-\n- Mm-hmm. - the Sony Aibo? - Yep.\n- They sold over 100,000 of those, maybe 150,000, you know, what probably wasn't considered a successful product for them. They suspended that eventually, and then they brought it back. Sony brought it back, and people definitely,\nyou know, treated this as a pet, as a companion. And I think that will come around again. Will you get away without\nhaving any other utility? Maybe in a world where we can really talk to our simple little pet\nbecause, you know, ChatGPT or some other generative\nAI has made it possible for you to really talk in what\nseems like a meaningful way. Maybe that'll open the\nsocial robot up again. That's probably not a\npath we're gonna go down because, again, we're so focused\non performance and utility. We can add those other things also, but we really wanna start from that foundation of utility, I think. - Yeah. But I also wanna predict\nthat you're wrong on that, which is that the very path you're taking, which is creating a great robot platform, will very easily take a leap to adding a ChatGPT-like capability, maybe GPT 5. And there's just so many\nopen-source alternatives that you could just plop\ndown on top of Spot. And because you have this robust platform, and you're figuring out\nhow to mass-manufacture it, and how to drive the cost down, and how to make it, you know, reliable, all those kinds of things,\nit'll be the natural transition to where just adding ChatGPT on top of it could-\n- Oh, I do think that being able to verbally converse or even converse through gestures, you know, part of these learning models is that, you know, you can now\nlook at video and imagery and associate, you know, intent with that. Those will all help in the communication between robots and people, for sure. And that's gonna happen\nobviously more quickly than any of us were expecting. (laughs) - I mean, what else do you want from life? A friend to get you a beer\n(Robert laughs) and then just talk shit\nabout the state of the world. (Robert laughs) I mean, there's a deep\nloneliness within all of us. And I think a beer and a good\nchat solves so much of it or takes us a long way to solving a lot of it.\n- It'll be interesting to see, you know, when a generative AI can give you that warm feeling that\nyou connected, you know, and that, \"Oh, yeah, you remember me. You're my friend. You know, we have a history.\" You know, that history matters, right? - [Lex] Memory of joint, like- - Memory of, yeah. (laughs) - Having witnessed,\nthat's what friendship, that's what connection,\nthat's what love is. In many cases, some of the\ndeepest friendships you have is having gone through a\ndifficult time together- - Mm-hmm.\n- and having a shared memory of an amazing time or a difficult time and kind of that memory\ncreating this, like, foundation based on which you can then\nexperience the world together. The silly, the mundane stuff\nof day to day is somehow built on a foundation of having gone through some shit in the past. And the current systems are\nnot personalized in that way but-\n- Right. - I think that's a technical problem, not some kind of fundamental limitation, so combine that with an\nembodied robot like Spot, which already has magic in its movement, I think it's a very\ninteresting possibility of where that takes us. But of course, you have to\nbuild that on top of a company that's making money\nwith real applications, with real customers, and\nwith robots that are safe, and work, and reliable,\nand manufactured at scale. - And I think we're in a\nunique position in that because of, you know, our\ninvestors, primarily Hyundai, but also SoftBank still owns 20% of us. They're not totally fixated\non driving us to profitability as soon as possible. That's not the goal. The goal really is a\nlonger-term vision of creating, you know, what does\nmobility mean in the future? How is this mobile robot\ntechnology going to influence us, and can we shape that? And they want both. And so, we as a company are\ntrying to strike that balance between, \"Let's build a\nbusiness that makes money.\" I've been describing that to my own team as self-destination. If I wanna drive my own ship,\nwe need to have a business that's profitable in the end. Otherwise, somebody else is\ngonna drive the ship for us. So, that's really important. But we're gonna retain the\naspiration that we're gonna build the next generation of\ntechnology at the same time. And the real trick will\nbe if we can do both. - Speaking of ships, let me\nask you about a competitor and somebody who's become a friend. So, Elon Musk and Tesla\nhave announced they've been in the early days of\nbuilding a humanoid robot. How does that change the\nlandscape of your work? So, from an outside\nperspective, it seems like, well, as a fan of robotics,\nit just seems exciting. - Right, very exciting, right? When Elon speaks, people listen. And so, it suddenly brought\na bright light onto the work that we'd been doing, you\nknow, for over a decade. And I think that's only gonna help. And in fact, what we've seen\nis that, in addition to Tesla, we're seeing a proliferation\nof robotic companies arise now. - Including humanoid? - [Robert] Yes. - Oh, wow.\n- Yeah. And interestingly, many of them as they're, you know,\nraising money, for example, will claim whether or not they have a former Boston Dynamics employee on their staff as a criteria. (both laughing) - Yeah, that's true. I would do that as a\ncompany, yeah, for sure. - Yeah, so-\n- Shows you're legit, yeah. - Yeah, so, you know,\n(Lex laughs) it has brung a tremendous validation to what we're doing and excitement. Competitive juices are flowing,\nyou know, the whole thing. So, it's all good. - Elon has also kind of stated that, you know, maybe he implied that\nthe problem is solvable in the near term, which is\na low-cost humanoid robot that's a relatively\ngeneral use case robot. So, I think Elon is known for\nsort of setting these kinds of incredibly ambitious\ngoals, maybe missing deadlines but actually pushing not just\nthe particular team he leads but the entire world to,\nlike, accomplishing those. Do you see Boston Dynamics in\nthe near future being pushed in that kind of way, like\nthis excitement of competition kinda pushing Atlas maybe\nto do more cool stuff, trying to drive the cost\nof Atlas down perhaps? I mean, I guess I wanna\nask if there's some kind of exciting energy in Boston Dynamics due to this little bit of competition. - Oh, yeah, definitely. When we released our most\nrecent video of Atlas, you know, I think you had seen it, the scaffolding and throwing the box of tools around and then doing the flip at the end, we were trying to show the world that not only can we do\nthis parkour mobility thing, but we can pick up and move heavy things because, if you're gonna work in a manufacturing environment, that's what you gotta be able to do. And for the reasons I\nexplained to you earlier, it's not trivial to do so, you know, changing the center of mass, you know, by picking up a 50-pound block, you know, for a robot that weighs 150 pounds, that's a lot to accommodate. So, we're trying to show\nthat we can do that, so it's totally been energizing. You know, we see the\nnext phase of Atlas being more dextrous hands that can\nmanipulate and grab more things that we're gonna start by\nmoving big things around that are heavy and that affect balance. And why is that? Well, really tiny dextrous\nthings probably are gonna be hard for a while yet, you know. Maybe you could go build a\nspecial-purpose robot arm, you know, for stuffing, you know, chips into electronics boards,\nbut we don't really wanna really fine work like that. I think more course work\nwhere you're using two hands to pick up and balance an unwieldy thing maybe in a manufacturing environment, maybe in a construction environment, those are the things that we\nthink robots are gonna be able to do with the level of\ndexterity that they're gonna have in the next few years, and\nthat's where we're headed. And you know, Elon has\nseen the same thing, right? He's talking about using the robots in a manufacturing environment. We think there's something\nvery interesting there about having a two-armed robot because, when you have two\narms, you can transfer a thing from one hand to the other. You can turn it around. You know, you can reorient it\nin a way that you can't do it if you just have one hand\non it, and so there's a lot that extra arm brings to the table. - So, I think in terms of mission, you mentioned Boston\nDynamics really wants to see what's the limits of what's possible. And so, the cost comes\nsecond, or it's a component, but first figure out\nwhat are the limitations. I think, with Elon, he's\nreally driving the cost down. Is there some inspiration,\nsome lessons you see there of the challenge of driving the cost down, especially with Atlas\nwith a humanoid robot? - Well, I think the thing that\nhe's certainly been learning by building car factories is what that looks like in scaling. By scaling, you can get\nefficiencies that drive costs down- - Sure.\n- very well. And the smart thing\nthat, you know, they have in their favor is, you know,\nthey know how to manufacture. They know how to build electric motors. They know how to build, you know, computers and vision systems,\nso there's a lot of overlap between modern automotive\ncompanies and robots. But hey, we have a modern robotic, I mean, automotive company behind us as well. (Lex laughs) - So, bring it on. - Who's doing pretty well, right? The electric vehicles from\nHyundai are doing pretty well. - I love it. So, we've talked about some\nof the low-level control, some of the incredible\nstuff that's going on and basic perception, but\nhow much do you see currently and in the future of\nBoston Dynamics's sort of higher-level machine\nlearning applications? Do you see customers adding\non those capabilities, or do you see Boston\nDynamics doing that in house? - Some kinds of things we really believe are probably gonna be more broadly available,\nmaybe even commoditized, you know, using a machine learning, like a vision algorithm so a robot can recognize\nsomething in the environment. That ought to be something\nyou can just download. Like, I'm going to a new\nenvironment, and I have a new kind of door handle or piece of\nequipment I wanna inspect. You ought to be able\nto just download that. And I think people besides Boston Dynamics will provide that. And we've actually built\nan API that lets people add these vision algorithms to Spot, and we're currently\nworking with some partners who are providing that. Levatas is a example of a small provider who's giving us software\nfor reading gauges, and actually, another partner in Europe, Reply, is doing the same thing. So, we see ultimately an ecosystem of providers doing stuff like that. I think ultimately you might even be able to do the same thing with behaviors. So, this technology will\nalso be brought to bear on controlling the robot,\nthe motions of the robot. And you know, we're using\nlearning, reinforcement learning to develop algorithms for both\nlocomotion and manipulation. And ultimately, this is gonna mean you can add new behaviors to\na robot, you know, quickly. And that could potentially be done outside of Boston Dynamics. Right now, that's all internal to us. I think you need to understand\nat a deep level, you know, the robot control to do that. But eventually, that could be outside. But it's certainly a place where these approaches\nare gonna be brought to bear in robotics. - So, reinforcement learning\nis part of the process. So, you do use reinforcement learning. - [Robert] Yes. (Lex sighs) So, there's increasing levels\nof learning with these robots? - [Robert] Yes. - And that's for locomotion,\nfor manipulation, for perception? - [Robert] Yes. - Well, what do you think in general about all the exciting advancements of transformer neural networks, most beautifully illustrated through the large language\nmodels like GPT 4? - Like everybody else,\nwe're all, you know, I'm surprised at how far they've come. I'm a little bit nervous about the, there's anxiety around them, obviously, for, I think, good reasons, right? Disinformation is a curse,\nan unintended consequence of social media that could be\nexacerbated with these tools. So, if you use them to\ndeploy disinformation, it could be a real risk. But I also think that the risks\nassociated with these kinds of models don't have a whole lot to do with the way we're gonna\nuse them in our robots. If I'm using a robot, I'm\nbuilding a robot to do, you know, a manual task of some sort. I can judge very easily, is it\ndoing the task I asked it to? Is it doing it correctly? There's sort of a built-in\nmechanism for judging. Is it doing the right thing? Did it successfully do the task? - Yeah, physical reality\nis a good verifier. - It's a good verifier. That's exactly it, and\nwhereas if you're asking for, yeah, I don't know, you're trying to ask a\ntheoretical question in ChatGPT, it could be true, or it may not be true. And it's hard to have that verifier, what is that truth (laughs)\nthat you're comparing against, whereas, in physical\nreality, you know the truth. And this is an important difference. And so, I think there is reason\nto be a little bit concerned about, you know, how these tools, large language models could be used. But I'm not very worried about\nhow they're gonna be used, well, how learning algorithms in general are going\nto be used on robotics. It's really a different\napplication that has different ways of verifying what's going on. - Well, the nice thing\nabout language models is that I ultimately see, I'm really excited about the possibility of\nhaving conversations with Spot. - [Robert] Yeah. - There's no, I would say,\nnegative consequences to that but just increasing the\nbandwidth and the variety of ways you can communicate\nwith this particular robot. - [Robert] Yeah. - So, you could communicate visually. You can communicate through\nsome interface and to be able to communicate verbally\nagain with a beer and so on. I think that's really exciting to make that much, much easier. - We have this partner\nLevatas that's adding the vision algorithms\nfor gauge reading for us. Just this week I saw a demo\nwhere they hooked up, you know, a language tool to Spot,\nand they're talking to Spot to give commands.\n- Nice, I love it. - Yeah. - Can you tell me about the\nBoston Dynamics AI Institute? What is it, and what is its mission? - So, it's a separate organization, the Boston Dynamics Artificial\nIntelligence Institute. It's led by Marc Raibert, the\nfounder of Boston Dynamics, and the former CEO, and\nmy old advisor at MIT. Marc has always loved the research, the pure research without the confinement or demands of commercialization. And he wanted to continue to, you know, pursue that\nunadulterated research and so suggested to Hyundai that he set up this institute, and they agree that it's\nworth additional investment to kinda continue pushing this forefront. And we expect to be working together where you know Boston Dynamics is, again, both commercialize and do research, but the sort of time horizon of the research we're\ngonna do is, you know, in the next, let's say\nfive years, you know. What can we do in the next five years? Let's work on those problems. And I think the goal\nof the AI Institute is to work even further out. Certainly, you know, the analogy\nof legged locomotion again, when we started that, that\nwas a multi-decade problem. And so, I think Marc\nwants to have the freedom to pursue really hard\nover-the-horizon problems. That'll be the goal of the institute. - So, we mentioned some of the\ndangers, some of the concerns about large language models. That said, you know, there's\nbeen a long-running fear of these embodied robots. Why do you think people are afraid (Robert laughs) of legged robots? - Yeah, I wanted to show you this. So, this is in the Wall Street Journal, and this is all about ChatGPT, right? But look at the picture. - Yeah. - [Robert] It's a humanoid robot. - That's saying, \"I will replace you.\" - That looks scary, and it says, \"I'm gonna replace you.\" - [Lex] Yeah. - And so, the humanoid robot is the embodiment of this ChatGPT tool that there's reason to\nbe a little bit nervous about how it gets deployed. - [Lex] Yeah. - So, I'm nervous about that connection. It's unfortunate that\nthey chose to use a robot as that embodiment. As you and I just said, there's\nbig differences in this. But people are afraid because\nwe've been taught to be afraid for over 100 years. So, you know, the word robot was developed by a playwright named Karel Capek in 1921, a Czech playwright,\n\"Rossum's Universal Robots.\" And in that first depiction of a robot, the robots took over (laughs)\nat the end of the story. And you know, people love to be afraid. And so, we've been\nentertained by these stories for 100 years, and I think that's as much why people are afraid as anything else, as we've been sort of taught that this is the logical progression through fiction. I think it's fiction. - I think what people more\nand more will realize, just like you said, that the threat, like say you have a\nsuper-intelligent AI embodied in a robot. That's much less threatening\nbecause it's visible. It's verifiable. It's right there in physical reality. And we humans know how to\ndeal with physical reality. I think it's much scarier when\nyou have arbitrary scaling of intelligent AI systems\nin the digital space that they could pretend to be human. So, robot Spot is not gonna pretend. It could pretend it's human all it wants. (Lex laughs) You could put ChatGPT on top of it, but you're gonna know it's not human because you have a contact\nwith physical reality. - And you're gonna know\nwhether or not it's doing what you asked it to do. - Yeah, like, it's not gonna, (laughs) I mean, I'm sure it can start,\njust like a dog lies to you. It's like, \"I wasn't part\nof tearing up that couch.\" So, Spot can try\n(Robert laughs) to lie that like, you know, \"It wasn't me that's spilled that thing,\" but you're going to kind\nof figure it out eventually if it happens multiple times, you know. But I think that- - Humanity has figured out\nhow to make machines safe. - [Lex] Yeah. - And there's, you know,\nthe regulatory environments and certification protocols\nthat we've developed in order to figure out how to make machines safe. We don't know and don't have\nthat experience with software that can be propagated\nworldwide in an instant. And so, I think we needed\nto develop those protocols and those tools, and so\nthat's work to be done. But I don't think the fear of that and that work should\nnecessarily impede our ability to now get robots out because again, I think we can judge when\na robot's being safe. - So, and again, just like in that image, there's a fear that\nrobots will take our jobs. I took a ride. I was in San Francisco. I took a ride in a Waymo vehicle. It's an autonomous vehicle, and I've done it several times. They're doing incredible work over there, but (laughs) people flicked it off. - Oh, really?\n- Flicked off the car. So, (laughs) I mean, that's a long story of what the psychology of that is. It could be maybe big tech,\nor I don't know exactly what they're flicking off. - [Robert] Yeah. - But there is an element of, like, \"These robots are taking our jobs,\" or irreversibly transforming society such that it will have economic impact, and the little guy would lose a lot, would lose their well-being. Is there something to\nbe said about the fear that robots will take our jobs? - You know, at every significant\ntechnological transformation, there's been fear of, you\nknow, an automation anxiety- - Yes.\n- that it's gonna have a broader impact than we expected. And there will be, you\nknow, jobs will change. Sometime in the future, we're\ngonna look back at people who manually unloaded\nthese boxes from trailers, and we're gonna say, \"Why did\nwe ever do that manually?\" But there's a lotta people\nwho are doing that job today that could be impacted. But I think the reality\nis, as I said before, we're gonna build the technology so that those very same\npeople can operate it. And so, I think there's a pathway to upskilling and operating. Just like, look, we used\nto farm with hand tools, and now we farm with machines, and nobody has really\nregretted that transformation. And I think the same can be\nsaid for a lot of manual labor that we're doing today. And on top of that, you know, look, we're entering a new world where\ndemographics are gonna have strong impact on economic growth, and you know, the advanced, the first world is losing\npopulation quickly. In Europe, they're worried\nabout hiring enough people just to keep the logistics\nsupply chain going. And you know, part of this\nis the response to COVID, and everybody's sort of thinking back what they really wanna do with their life, but these jobs are getting\nharder and harder to fill. And I'm hearing that over and over again. So, I think, frankly, this\nis the right technology at the right time where we're\ngonna need some of this work to be done, and we're gonna want tools to enhance that productivity. - And the scary impact, I think, again, GPT comes to the rescue in terms of being much more terrifying. (Robert laughs) (Lex laughs) The scary impact of, basically, so I'm, I guess, a software\nperson, so I program a lot. And the fact that people like\nme could be easily replaced by GPT, that's going to have a- - Well, and lot, you know,\nanyone who deals with texts and writing a draft proposal\nmight be easily done with ChatGPT now. - Yeah.\n- where- - Consultants.\n- it wasn't before. - [Lex] Journalists. - Yeah. - [Lex] Everybody is sweating. - But on the other hand, you\nalso want it to be right. And they don't know how\nto make it right yet. But it might make a good starting\npoint for you to iterate. - Boy, do I have to talk to\nyou about modern journalism. (Robert laughs) That's another conversation altogether, but yes, more right than the average, the mean journalist, yes. You spearheaded the weaponization letter Boston Dynamics has. Can you describe what that letter states and the general topic of\nthe use of robots in war? - We authored a letter and then got several leading robotics\ncompanies around the world, including, you know, Unitree in China, and Agility here in the United States, and ANYmal in Europe, and, you know, some others\nto cosign a letter that said we won't put weapons on our robots. And part of the motivation\nthere is, you know, as these robots start to\nbecome commercially available, you can see videos online of\npeople who've gotten a robot, and strapped a gun on it, and\nshown that they can, you know, operate the gun remotely while\ndriving the robot around. And so, having a robot that\nhas this level of mobility and that can easily be configured in a way that could harm somebody\nfrom a remote operator is justifiably a scary thing. And so, we felt like it was important to draw a bright line there and say, \"We're not going to allow this,\" for, you know, reasons that we\nthink ultimately it's better for the whole industry\nif it grows in a way where robots are ultimately\ngoing to help us all and make our lives more\nfulfilled and productive. But by goodness, you're gonna\nhave to trust the technology, to let it in. And if you think the\nrobot's gonna harm you, that's gonna impede the\ngrowth of that industry. So, we thought it was\nimportant to draw a bright line and then publicize that. And our plan is to, you\nknow, begin to engage with lawmakers and regulators. Let's figure out what\nthe rules are going to be around the use of this\ntechnology and use our position as leaders in this industry and technology to help force that issue. In fact, I have a policy,\nyou know, director at my company whose job it\nis to engage with the public, to engage with interested\nparties, including regulators, to sort of begin these discussions. - Yeah, it's a really important topic, and it's an important\ntopic for people that worry about the impact of robots on our society with autonomous weapon systems. So, I'm glad you're sort\nof leading the way in this. You are the CEO of Boston Dynamics. What's it take to be a\nCEO of a robotics company? So, you started as a\nhumble engineer, (laughs) a PhD. Just looking at your journey, what does it take to go\nfrom building the thing to leading a company? What are some of the\nbig challenges for you? - Courage I would put front and\ncenter for multiple reasons. I talked earlier about the\ncourage to tackle hard problems. So, I think there's courage\nrequired not just of me but of all of the people\nwho work at Boston Dynamics. I also think we have a lot\nof really smart people. We have people who are\nway smarter than I am. And it takes a kinda courage\nto be willing to lead them and to trust that you have\nsomething to offer to somebody who probably is maybe a\nbetter engineer than I am. Adaptability, you know, it's\nbeen a great career for me. I never would've guessed I'd stayed in one place for 30 years, and\nthe job has always changed. I didn't really aspire to be\nCEO from the very beginning, but it was the natural\nprogression of things. There always needed to be some level of management that was needed. And so, you know, when I saw something that needed to be done\nthat wasn't being done, I just stepped in to go do it. And oftentimes because we were full of such strong engineers,\noftentimes that was in the management direction, or it was in the business\ndevelopment direction or organizational, hiring. Geez, I was the main person\nhiring at Boston Dynamics for probably 20 years, so I\nwas the head of HR, basically. You know, just willingness\nto sort of tackle any piece of the business that needs\nit and be willing to shift. - Is there something you\ncould say to what it takes to hire a great team? What's a good interview process? How do you know the guy or gal\nare gonna make a great member of a engineering team that's doing some of the hardest work in the world? - You know, we developed\nan interview process that I was quite fond of. It's a little bit of a\nhard interview process because the best\ninterviews, you ask somebody about what they're interested\nin and what they're good at, and if they can describe to you something that they worked on, and you\nsaw they really did the work, they solved the problems, and\nyou saw their passion for it, but what makes that hard is you have to ask a probing question about it. You have to be smart enough\nabout what they're telling you they're expert at to ask a good question. And so, it takes a pretty\ntalented team to do that. But if you can do that,\nthat's how you tap into, \"Ah, this person cares about their work. They really did the work. They're excited about it.\" That's the kind of person\nI want at my company. You know, at Google, they taught us about their interview process, and it was a little bit different. You know, we evolved the\nprocess at Boston Dynamics where it didn't matter\nif you were an engineer, or you were an administrative assistant, or a financial person, or a technician. You gave us a presentation. You came in, and you\ngave us a presentation. You had to stand up and\ntalk in front of us. And I just thought that was\ngreat to tap into those things I just described to you. At Google, they taught us,\nand I understand why, right. They're hiring tens of\nthousands of people. They need a more standardized process. So, they would sort of\nerr on the other side where they would ask\nyou a standard question. I'm gonna ask you a programming question, and I'm just gonna ask you to, you know, write code in front of me. That's a terrifying, you\nknow, application process. - [Lex] Yeah. - It does let you compare\ncandidates really well, but it doesn't necessarily\nlet you tap into who they are. - Yeah.\n- (laughs) Right? 'Cause you're asking them\nto answer your question instead of you asking them about\nwhat they're interested in. But frankly, that\nprocess is hard to scale. And even at Boston Dynamics, we're not doing that\nwith everybody anymore. But we are still doing that with, you know, the technical people because we too now need to sort of increase our rate of hiring. Not everybody's giving\na presentation anymore. - But you're still\nultimately trying to find that basic seed of passion- - Yeah, and talent.\n- for the world. - You know, did they really do it? Did they find something\ninteresting or curious, you know, and do they care about it? (laughs) - I think somebody I admire is Jim Keller, and he likes details. So, one of the ways you could, (laughs) if you get a person to talk\nabout what they're interested in, how many details, like, how much of the whiteboard can you fill out? - Yeah.\n- What they- - Well, I think you figure out\ndid they really do the work if they know some of the details. - Yes.\n- And if they have to wash over the details,\nwell, then they didn't do it. - They didn't do it.\n(Robert laughs) 'Cause especially with engineering, the work is in the details. - Yeah. - I have to go there briefly (sighs) just to get your kind of thoughts on the long-term future of robotics. There's been discussions on the GPT side, on the large language model\nside of whether there's consciousness inside\nthese language models. And I think there's\nfear, but I think there's also excitement or at least the wide world of opportunity and\npossibility in embodied robots having something like,\nlet's start with emotion, love towards other human beings and perhaps the display, real\nor fake, of consciousness. Is this something you think about in terms of long-term future? Because, as we've talked about, people do anthropomorphize these robots. It's difficult not to project some level of, I use the word sentience, some level of sovereignty, identity, all the things we think as human. That's what anthropomorphization\nis, is we project humanness onto mobile, especially legged robots. Is that something almost from a science-fiction\nperspective you think about? Or, do you try to avoid ever, try to avoid the topic of\nconsciousness altogether? - I'm certainly not an expert in it, (Lex laughs)\nand I don't spend- - Is anybody?\n- a lot of time thinking about this, right? And I do think it's fairly\nremote for the machines that we're dealing with. You're right that people anthropomorphize. They read into the robots'\nintelligence and emotion that isn't there because\nthey see physical gestures that are similar to\nthings they might even see in people or animals. I don't know much about how these large\nlanguage models really work. I believe it's a kind\nof statistical averaging of the most common responses, you know, to a series of words, right? It's sort of a very\nelaborate word completion. And I'm dubious that that has anything to do with consciousness. And I even wonder if that model of sort of simulating consciousness\nby stringing words together that are statistically\nassociated with one another, whether or not that kind of knowledge, if you wanna call that knowledge, would be the kind of knowledge\nthat allowed a sentient being to grow or evolve. It feels to me like there's\nsomething about truth or emotions that's just a very\ndifferent kind of knowledge that is absolute. The interesting thing about\ntruth is it's absolute, and it doesn't matter how\nfrequently it's represented in the worldwide web. If you know it to be\ntrue, it it can only be, it may only be there once,\nbut by God, that's true. And I think emotions are a\nlittle bit like that, too. You know something, you know, and I just think that's a\ndifferent kind of knowledge than the way these large\nlanguage models derive sort of simulated- - It does seem that-\n- intelligence. - things that are true very well might be statistically well\nrepresented on the Internet because the Internet's made up of humans. So, I tend to suspect that\nlarge language models are going to be able to simulate\nconsciousness very effectively. And I actually believe that current GPT 4, when fine-tuned correctly,\nwould be able to do just that. And there's going to be a lot of very complicated\nethical questions that have to be dealt with that have\nnothing to do with robotics and everything to do with- - There needs to be some\nprocess of labeling, I think, (laughs) what is true because there is also\ndisinformation available on the web, and these models are going\nto consider that kind of information as well. And again, you can't average\nsomething that's true and something that's\nuntrue and get something that's moderately true. (laughs) It's either right, or it's wrong. And so, how is that process,\nand this is obviously something that the purveyors of\nthese, Bard and ChatGPT, I'm sure this is what they're working on. - Well, if you interact on\nsome controversial topics with these models, they're\nactually refreshingly nuanced. Well, you realize there's\nno one truth, you know. What caused the war in Ukraine, right? Any geopolitical conflict, you\ncan ask any kind of question, especially the ones that\nare politically tense, divisive, and so on. GPT is very good at presenting, it presents the different hypotheses. It presents calmly\n(laughing) sort of the amount of evidence for each one. It's really refreshing. It makes you realize\nthat truth is nuanced, and it does that well. And I think, with consciousness, it would very accurately say, \"Well, it sure as hell feels\nlike I'm one of you humans, but where's my body? (Robert laughs) I don't understand.\" Like, you're going to be confused. The cool thing about GPT is\nit seems to be easily confused in the way we are. Like, you wake up in a new\nroom, and you ask, \"Where am I?\" It seems to be able to\ndo that extremely well. It'll tell you one thing, like a fact about when a war started,\nand when you correct it, say, \"Well, that's not consistent,\" it'll be confused. It'll be, \"Yeah, you're right.\" It'll have that same\nelement, childlike element with humility of trying to\nfigure out its way in the world. And I think that's a really tricky area to sort of figure out with\nus humans of what we want to allow AI systems to say to us. Because then, if there's\nelements of sentience that are on display, you can then start to manipulate human emotion,\nall that kinda stuff. But I think that's a really serious and aggressive discussion\nthat needs to be had (laughing) on the software side. I think, again, embodiment,\nrobotics are actually saving us from the arbitrary scaling\nof software systems versus creating more problems. But that said, I really believe in that connection\nbetween human and robot. There's magic there. And I think there's also, I think, a lot of money to be made there. And Boston Dynamics is leading the world in the most elegant movement done by robots. (Robert laughs) So, I can't wait-\n- Well, thank you. - to what maybe other\npeople that built on top of Boston Dynamics robots or\nBoston Dynamics by itself. So, you had one wild career, one place on one set of problems\nbut incredibly successful. Can you give advice to young\nfolks today in high school, maybe in college looking\nout into this future where so much robotics and AI seems to be defining the trajectory of human civilization. Can you give 'em advice\non how to have a career they can be proud of or how to have a life they can be proud of? - Well, I would say, you\nknow, follow your heart and your interest. Again, this was an organizing\nprinciple, I think, behind the Leg Lab at MIT that turned into a value at Boston Dynamics, which was follow your curiosity. Love what you're doing. You'll have a lot more fun,\nand you'll be a lot better at it as a result. I think it's hard to plan, you know. Don't get too hung up on\nplanning too far ahead. Find things that you like doing and then see where it takes you. You can always change direction. You will find things that, you know, \"Ah, that wasn't a good move. I'm gonna pack up and\ngo do something else.\" So, when people are\ntrying to plan a career, I always feel like, \"Ah,\nthere's a few happy mistakes that happen along the way\nand just live with that it.\" You know, but make choices then. So, avail yourselves to these\ninteresting opportunities, like when I happened to run\ninto Marc down in the lab, the basement of the AI lab, but be willing to make a decision and then pivot if you see something\nexciting to go at, you know, 'cause, if you're out and about enough, you'll find things like\nthat that get you excited. - So, there was a feeling\nwhen you first met Marc and saw the robots that\nthere's something interesting. - \"Oh, boy, I gotta go do this.\" There was no doubt.\n(Lex laughs) (Robert laughs) - What do you think in 100 years, whoo, what do you think Boston\nDynamics is doing? Even bigger, what do you think is the role of robots in society? Do you think we'll be seeing\nbillions of robots everywhere? Do you think about that long-term vision? - Well, I do think that, I think that robots will be ubiquitous, and they will be out amongst us, and they'll be certainly doing, you know, some of the hard labor that we do today. I don't think people don't wanna work. People wanna work. People need to work to,\nI think, feel productive. We don't wanna offload all\nof the work to the robots 'cause I'm not sure if people would know what to do with themselves.\n(Lex laughs) And I think just self-satisfaction\nand feeling productive is such an ingrained part of being human that we need to keep doing this work. So, we're definitely gonna have to work in a complimentary fashion,\nand I hope that the robots and the computers don't end up being able to do all the creative work. Right?\n- Yeah. - 'Cause that's the part that's, you know, that's the rewarding. The creative part of solving\na problem is the thing that gives you that serotonin\nrush that you never forget, you know, (laughs) or that adrenaline rush that you never forget, and\nso, you know, people need to be able to do that creative work and just feel productive, and sometimes you can feel productive over fairly simple work\nthat's just well done, you know, and that you\ncan see the result of. So, yeah, you know, I don't know, there was a cartoon, was it \"Wall-E,\" where they had this big ship, and all the people were just overweight, lying on their beach chairs kinda sliding around on the deck of the movie because they didn't do anything anymore. - Yeah.\n- Well, we definitely don't wanna\nbe there, (laughs) you know. We need to work in some\ncomplimentary fashion where we keep all of our\nfaculties and our physical health, and we're doing some labor, right, but in a complimentary fashion somehow. - And I think a lotta that has\nto do with the interaction, the collaboration with\nrobots and with AI systems. I'm hoping there's a lot of\ninteresting possibilities there. - I think that could\nbe really cool, right? If you can work in an interaction\nand really be helpful, robots, you know, you can\nask a robot to do a job you wouldn't ask a person to do, and that would be a real asset. You wouldn't feel guilty\nabout it, you know. (laughs) You'd say, \"Just do it.\" - Yeah.\n- It's a machine. And I don't have to have\nqualms about that, you know. - The ones that are machines,\nI also hope to see a future, and it is hope. I do have optimism about the future where some of the robots are pets, have an emotional connection to us humans and because one of the problems\nthat humans have to solve is this kind of general loneliness. The more love you have in your life, the more friends you have in your life, I think that makes a more\nenriching life, helps you grow. And I don't fundamentally see why some of those friends can't be robots. - There's an interesting\nlong-running study, maybe it's in Harvard, just\nnice report article written about it recently. They've been studying this group of a few thousand people\nnow for 70 or 80 years. And the conclusion is that\ncompanionship and friendship are the things that make for\na better and happier life. And so, I agree with you, and I think that could\nhappen with a machine that is probably, you know,\nsimulating intelligence. I'm not convinced there will\never be true intelligence in these machines, sentience. But they could simulate it, and they could collect your history. You know, I guess it remains to be seen whether they can establish that real deep, you know, when you sit with a friend, and they remember something\nabout you and bring that up, and you feel that connection,\nit remains to be seen if a machine's gonna be\nable to do that for you. - Well, I have to say, inklings of that already started happening for me. Some of my best friends are robots. (Robert laughs) And I have you to thank\nfor leading the way in the accessibility, and the\nease of use of such robots, and the elegance of their movement. Robert, you're an incredible person. Boston Dynamics is an incredible company. I've just been a fan for many, many years for everything you stand for, for everything you do in the world. If you're interested in\ngreat engineering, robotics, go join them. Build cool stuff. I'll forever celebrate\nthe work you're doing, and it's just a big honor that you would sit with me today and talk. It means a lot, so thank you so much. Keep doing great work. - Thank you, Lex. I'm honored to be here,\nand I appreciate it. It was fun. - Thanks for listening\nto this conversation with Robert Playter. To support this podcast, please check out our sponsors in the description. And now, let me leave you some words from Alan Turing in 1950, defining what is now\ntermed the Turing test. \"A computer would deserve\nto be called intelligent if it could deceive a human into believing that it was human.\" Thank you for listening and\nhope to see you next time."
    }
  ],
  "full_text": "- And so our goal was\na natural-looking gait. It was surprisingly hard\nto get that to work. But we did build an early machine. We called it PETMAN prototype. It was the prototype\nbefore the PETMAN robot, and it had a really nice-looking gait where, you know, it\nwould stick the leg out. It would do heel strike first\nbefore it rolled onto the toe, so you didn't land with a flat foot. You extended your leg a\nlittle bit, but even then, it was hard to get the robot to walk where, when you were walking, that it fully extended its leg and getting that all to work\nwell took such a long time. In fact, I probably didn't really see the nice, natural walking that I expected out of our humanoids\nuntil maybe last year. And the team was developing\non our newer generation of Atlas, you know, some new techniques for developing a\nwalking-control algorithm. And they got that\nnatural-looking motion as sort of a byproduct of just a different process they were applying to\ndeveloping the control. So, that probably took 15\nyears, 10 to 15 years to sort of get that from, you know, the PETMAN prototype was probably in 2008, and what was it, 2022, (laughs) last year that I think I saw good walking on Atlas. (dramatic music) - The following is a\nconversation with Robert Playter, CEO of Boston Dynamics, a\nlegendary robotics company that, over 30 years, has created\nsome of the most elegant, dextrous, and simply\namazing robots ever built, including the humanoid robot\nAtlas and the robot dog Spot, one or both of whom you've\nprobably seen on the Internet, either dancing, doing\nbackflips, opening doors, or throwing around heavy objects. Robert has led both the development of Boston Dynamics humanoid robots and their physics-based\nsimulation software. He has been with the company\nfrom the very beginning, including its roots at MIT, where he received his PhD\nin aeronautical engineering. This was in 1994 at the\nlegendary MIT Leg Lab. He wrote his PhD thesis\non robot gymnastics as part of which he programmed\na bipedal robot to do the world's first 3D robotic somersault. Robert is a great engineer,\nroboticist, and leader, and Boston Dynamics, to\nme as a roboticist, is a truly inspiring company. This conversation was a\nbig honor and pleasure, and I hope to do a lot of great work with these robots in the years to come. This is the Lex Fridman podcast. To support it, please\ncheck out our sponsors in the description. And now, dear friends,\nhere's Robert Playter. When did you first fall\nin love with robotics? (Lex laughs) Let's start with love and robots. - Well, love is relevant because I think the fascination, the deep fascination is really about movement, and\nI was visiting MIT looking for a place to get a PhD, and I wanted to do some laboratory work. And one of my professors in\nthe aero department said, \"Go see this guy Marc Raibert down in the basement of the AI lab.\" And so I walked down there and saw him. He showed me his robots, and he showed me this\nrobot doing a somersault. (Lex laughs) And I just immediately\nwent, \"Whoa,\" you know. - [Lex] Yeah. - \"Robots can do that?\" And because of my own\ninterest in gymnastics, there was, like, this\nimmediate connection, and, you know, I was\nin an aeroastro degree because, you know, flight and movement was all so fascinating to me. And then it turned out that, you know, robotics\nhad this big challenge. How do you balance? How do you build a legged robot\nthat can really get around? That was a fascination,\nand it still exists today. We're still working on\nperfecting motion in robots. - What about the elegance and the beauty of the movement itself? Is there something maybe\ngrounded in your appreciation of movement from your gymnastics days? Was there something you just\nfundamentally appreciated about the elegance and beauty of movement? - You know, we had this concept in gymnastics of letting your\nbody do what it wanted to do. When you get really good at gymnastics, part of what you're doing\nis putting your body into a position where the physics and the body's inertia and\nmomentum will kinda push you in the right direction in a\nvery natural and organic way. And the thing that Marc\nwas doing, you know, in the basement of that laboratory\nwas trying to figure out how to build machines to take\nadvantage of those ideas. How do you build something\nso that the physics of the machine just\nkind of inherently wants to do what it wants to do? And he was building these springy\npogo-stick type, you know. His first cut at legged\nlocomotion was a pogo stick where it's bouncing, and\nthere's a spring mass system that's oscillating, has its own sort of natural frequency\nthere and sort of figuring out how to augment those natural\nphysics with also intent. How do you then control\nthat but not overpower it? It's that coordination that I\nthink creates real potential. We could call it beauty, you know. You could call it, I don't know, synergy. People have different words for it. But I think that that was\ninherent from the beginning. That was clear to me that that's part of what Marc was trying to do. He asked me to do that\nin my research work. So, you know, that's where it got going. - So, part of the thing that\nI think I'm calling elegance and beauty in this case, which was there, even with the pogo stick\nis maybe the efficiency, so letting the body do\nwhat it wants to do, trying to discover the efficient movement. - It's definitely more efficient. It also becomes easier\nto control in its own way because the physics are solving\nsome of the problem itself. It's not like you have to\ndo all this calculation and overpower the physics. The physics naturally, inherently want to do the right thing. There can even be, you\nknow, feedback mechanisms, stabilizing mechanisms\nthat occur simply by virtue of the physics of the body. And it's, you know,\nnot all in the computer or not even all in your\nmind as a person (laughs). And there's something\ninteresting in that melding. - You were with Marc for\nmany, many, many years, but you were there in\nthis kinda legendary space of Leg Lab and MIT in\nthe basement (laughs). All great things happen in the basement. (Robert laughs) Is there some memories from\nthat time that you have? Because it's such cutting-edge work in robotics and artificial intelligence. - The memories, the distinctive\nlessons, I would say I learned in that time period and that I think Marc was\na great teacher of was it's okay to pursue your\ninterests, your curiosity, do something because you love it. You'll do it a lot better if you love it. That is a lasting lesson\nthat I think we apply at the company still and\nreally is a core value. - So, the interesting thing is, with people like Russ Tedrake and others, like, the students that work at those robotics labs are, like, some of the happiest people I've ever met. I don't know what that is. (laughs) I meet a lot of PhD students. A lot of them are kind of broken (laughing) by the wear\nand tear of the process, but roboticists are, while\nthey work extremely hard and work long hours, there's a happiness there. The only other group of people\nI've met like that are people that skydive a lot. (both laughing) For some reason, there's a\ndeep, fulfilling happiness maybe from, like, a long period of struggle to get a thing to work, and it works, and there's a magic to it. I don't know exactly 'cause\nit's so fundamentally hands-on, and you're bringing a thing to life. I don't know what it\nis, but they're happy. - You know, our attrition at\nthe company is really low. People come, and they love the pursuit. And I think part of that is that there's perhaps a\nnatural connection to it. It's a little bit easier to\nconnect when you have a robot that's moving around in the\nworld, and part of your goal is to make it move around in the world. You can identify with that. This is one of the unique things about the kinds of\nrobots we're building is this physical interaction lets\nyou perhaps identify with it. So, I think that is a source of happiness. I don't think it's unique to robotics. I think anybody also who is just pursuing something they love, it's\neasier to work hard at it and be good at it, and not\neverybody gets to find that. I do feel lucky in that way. And I think we're lucky as an organization that we've been able to\nbuild a business around this and that keeps people engaged. - So, if it's all right,\nlet's linger on Marc for a little bit longer, Marc Raibert. So, he's a legend. He's a legendary engineer and roboticist. What have you learned about\nlife, about robotics from Marc through all the many years\nyou've worked with him? - I think the most important\nlesson, which was, you know, have the courage of your convictions and do what you think is interesting. Be willing to try to find\nbig, big problems to go after. And at the time, you\nknow, legged locomotion, especially in a dynamic\nmachine, nobody had solved it. And that felt like a\nmulti-decade problem to go after. And so, you know, have the\ncourage to go after that because you're interested. Don't worry if it's gonna make money. You know, that's been a theme. That's really probably the\nmost important lesson I think that I got from Marc. - How crazy is the effort\nof doing legged robotics at that time, especially? - You know, Marc got some\nstuff to work starting from simple ideas. So, maybe the other,\nanother important idea that has really become a\nvalue of the company is try to simplify a thing\nto the core essence. While, you know, Marc was\nshowing videos of animals running across the Savannah or climbing mountains, what he started with was a pogo stick because he was trying to\nreduce the problem to something that was manageable, and\ngetting the pogo stick to balance had in it\nthe fundamental problems that, if we solved those, you\ncould eventually extrapolate to something that galloped\nlike a horse, and so look for those simplifying principles. - How tough is the job\nof simplifying a robot? - So, I'd say, in the early\ndays, the thing that made the researchers at Boston\nDynamics special is that we worked on figuring out what that central principle was and then building software or machines around that principle,\nand that was not easy in the early days. And it took real expertise\nin understanding the dynamics of motion and feedback-control\nprinciples, how to build, you know, with the computers at the time, how to build a feedback-control algorithm that was simple enough that\nit could run in real time at 1,000 hertz and actually\nget that machine to work. And that was not something\neverybody was doing, you know, at that time. Now, the world's changing now,\nand I think the approaches to controlling robots are going to change, and they're going to become\nmore broadly available. But at the time, there weren't many groups who could really sort of\nwork at that principled level with both the software and\nmake the hardware work. And I'll say one other thing\nabout you were sort of talking about what are the special things. The other thing was it's good\nto break stuff, you know. You know, use the robots,\nbreak them, repair them, you know, fix and repeat,\n(laughs) test, fix, and repeat. And that's also a core\nprinciple that has become part of the company, and it lets\nyou be fearless in your work. Too often, if you are working\nwith a very expensive robot, maybe one that you\nbought from somebody else or that you don't know how to fix, then you treat it with kid gloves, and you can't actually make progress. You have to be able to break something. And so, I think that's\nbeen a principle as well. - So, just to linger on\nthat, psychologically, how do you deal with that? 'Cause I remember I built a RC car. It had some custom stuff\nlike a computer on it and all that kind of stuff, cameras and because I didn't sleep much, the code I wrote had an issue\nwhere it didn't stop the car, and the car got confused and at full speed at, like, 20, 25 miles an\nhour, it slammed into a wall. And I just remember sitting\nthere alone in a deep sadness, sort of full of regret,\nI think, almost anger, but also, like, sadness\nbecause you think about, well, these robots, especially\nfor autonomous vehicles, like, you should be taking\nsafety very seriously even in these kinds of things,\nbut just no good feelings. It made me more afraid\nprobably to do these kind of experiments in the future. Perhaps the right way to\nhave seen that is positively. Like, it's too- - It depends if you\ncould have built that car or just gotten another one, right? That would've been the approach. I remember when I got to grad school, you know, I got some training\nabout operating a lathe and a mill up in the machine shop, and I could start to make my own parts. And I remember breaking some\npiece of equipment in the lab and then realizing 'cause\nmaybe this was a unique part, and I couldn't go buy it, and I realized, \"Oh, I can just go make it.\" That was an enabling feeling. - [Lex] Yeah. - Then, you're not afraid. It might take time. It might take more work than you thought it was gonna be required\nto get this thing done, but you can just go make it. And that's freeing in a\nway that nothing else is. - You mentioned the feedback\ncontrol, the dynamics, sorry for the romantic question, but in the early days and\neven now, is the dynamics, probably more appropriate\nfor the early days, is it more art or science? - There's a lot of science\naround it, and trying to develop, you know, scientific principles\nthat let you extrapolate from, like, one legged machine to another, you know, develop a core set of principles like a spring-mass bouncing\nsystem and then figure out how to apply that from a one-legged machine to a two- or a four-legged machine. Those principles are really important and were definitely a\ncore part of our work. There's also, you know, when we started to pursue humanoid robots,\nthere was so much complexity in that machine that, you\nknow, one of the benefits of the humanoid form is\nyou have some intuition about how it should\nlook while it's moving. And that's a little\nbit of an art, I think, or maybe it's just\ntapping into a knowledge that you have deep in\nyour body and then trying to express that in the machine,\nbut that's an intuition that's a little bit more on the art side. Maybe it predates your knowledge. Before you have the knowledge\nof how to control it, you try to work through\nthe art channel. (laughs) - [Lex] Yeah.\n- And humanoids sort of make that available to you. If it had been a different shape, maybe you wouldn't have had\nthe same intuition about it. - Yeah, so your knowledge about moving through the world is not\nmade explicit to you. That's why it's art. - Yeah, it might be hard to\nactually articulate exactly. (laughing) You know?\n- Yeah. - And being a competitive athlete, there's something about seeing a movement. You know, a coach, one\nof the greatest strengths a coach has is being\nable to see, you know, some little change in\nwhat the athlete is doing and then being able to\narticulate that to the athlete, you know, and then maybe\neven trying to say, \"And you should try to feel this.\" So, there's something just in seeing, and again, you know, sometimes\nit's hard to articulate what it is you're seeing, but\njust perceiving the motion at a rate that is, again,\nsometimes hard to put into words. - Yeah, I wonder how it is\npossible to achieve sort of truly elegant movement. You have a movie like \"Ex Machina.\" I'm not sure if you've seen it, but the main actress in\nthat who plays the AI robot I think is a ballerina. I mean, just the natural elegance and the, I don't know,\neloquence of movement, (laughs) it looks efficient and easy,\nand just it looks right. It looks beautiful.\n- It looks right is sort of the key, yeah? - And then, you look at,\nespecially early robots, I mean, they're so cautious\nin the way they move that it's not the\ncaution that looks wrong. It's something about the\nmovement that looks wrong that feels like it's very\ninefficient, unnecessarily so. And it's hard to put\nthat into words exactly. - We think that, and part of the reason why people are attracted\nto the machines we build is because the inherent dynamics of movement are closer to right because we try to use,\nyou know, walking gaits, or we build a machine around this gait where you're trying to work\nwith the dynamics of the machine instead of to stop them. You know, some of the early\nwalking machines, you know, you're essentially,\nyou're really trying hard to not let them fall over, and so you're always stopping\nthe tipping motion, you know. And sort of the insight\nof dynamic stability in a legged machine is to go\nwith it, you know, (laughs) let the tipping happen. You know, let yourself fall, but then catch yourself\nwith that next foot. And there's something\nabout getting those physics to be expressed in the\nmachine that people interpret as lifelike, or elegant, or just natural looking. And so, I think if you\nget the physics right, it also ends up being\nmore efficient, likely. There's a benefit that it probably ends up being more stable in the long run. You know, it could walk\nstably over a wider range of conditions, and it's more beautiful and attractive at the same time. - So, how hard is it to get\nthe humanoid robot Atlas to do some of the things that\nit's recently been doing? Let's forget the flips and all of that. Let's just look at the running. Maybe you can correct me, but there's something about running. I mean, that's not careful at all. That's you're falling forward. You're jumping forward and are falling. So, (laughing) how hard\nis it to get that right? - Our first humanoid, we needed to deliver natural-looking walking, you know. We took a contract from the army. They wanted a robot that\ncould walk naturally. They wanted to put a suit on the robot and be able to test it\nin a gas environment. And so, they wanted the\nmotion to be natural. And so, our goal was a\nnatural-looking gait. It was surprisingly hard\nto get that to work. But we did build an early machine. We called it PETMAN prototype. It was the prototype\nbefore the PETMAN robot, and it had a really nice-looking gait where, you know, it\nwould stick the leg out. It would do heel strike first\nbefore it rolled onto the toe, so you didn't land with a flat foot. You extended your leg a little bit, but even then it was hard\nto get the robot to walk where, when you were walking,\nthat it fully extended its leg and essentially landed on an extended leg. And if you watch closely how you walk, you probably land on an extended leg, but then you immediately flex your knee as you start to make that contact, and getting that all to work\nwell took such a long time. In fact, I probably didn't really see the nice, natural walking that I expected out of our humanoids\nuntil maybe last year. And the team was developing\non our newer generation of Atlas, you know, some new techniques for developing a\nwalking-control algorithm. And they got that\nnatural-looking motion as sort of a byproduct of just a different process they were applying to\ndeveloping the control. So, that probably took 15\nyears, 10 to 15 years to sort of get that from, you know, the PETMAN prototype was probably\nin 2008, and what was it, 2022, (laughs) last year that I think I saw good walking on Atlas. - If you could just, like, linger on it, what are some challenges\nof getting good walking? So, is this partially, like, a hardware, like, actuator problem? Is it the control? Is it the artistic\nelement of just observing the whole system operating in\ndifferent conditions together? I mean, is there some\nkind of interesting quirks or challenges you can speak\nto, like the heel strike or all this kind of stuff?\n- Yeah, so one of the things that makes,\nlike, this straight leg a challenge is you're sort\nof up against a singularity, a mathematical singularity\nwhere, you know, when when your leg is fully extended, it can't go further the\nother direction, right? You can only move in one\ndirection, and that makes all of the calculations around\nhow to produce torques at that joint or positions\nmakes it more complicated. And so, (laughs) having\nall of the mathematics so it can deal with these\nsingular configurations is one of many (laughs) challenges that we face. And I'd say, you know, in\nthose earlier days, again, we were working with these\nreally simplified models. So, we're trying to boil all the physics of the complex human body\ninto a simpler subsystem that we can more easily\ndescribe in mathematics. And sometimes those simpler\nsubsystems don't have all of that complexity of the\nstraight leg built into them. And so, what's happened\nmore recently is we're able to apply techniques that\nlet us take the full physics of the robot into account and deal with some of\nthose strange situations like the straight leg. - So, is there a fundamental\nchallenge here that it's, maybe you can correct me,\nbut is it underactuated? Are you falling? - Underactuated is the right word, right? You can't push the robot in\nany direction you want to. - Yeah.\n- Right? And so, that is one of the hard problems of legged locomotion. - And you have to do that\nfor natural movement? - It's not necessarily\nrequired for natural movement. It's just required, you know,\nwe don't have, you know, a gravity force that you can\nhook yourself onto to apply an external force in\nthe direction you want at all times, right? The only external forces\nare being mediated through your feet, and how\nthey get mediated depend on how you place your feet,\nand you know, you can't just, you know, God's hand\ncan't reach down and push in any direction you want,\n(laughs) you know, so. - Is there some extra\nchallenge to the fact that Atlas is such a big robot? - There is. The humanoid form is\nattractive in many ways, but it's also a challenge in many ways. You have this big upper\nbody that has a lot of mass and inertia, and\nthrowing that inertia around increases the complexity\nof maintaining balance. And as soon as you pick up\nsomething heavy in your arms, you've made that problem even harder. And so, in the early work in the Leg Lab and in the early days at\nthe company, you know, we were pursuing these quadruped robots, which had a kind of\nbuilt-in simplification. You had this big rigid body\nand then really light legs. So, when you swing the legs, the leg motion didn't impact\nthe body motion very much. All the mass and inertia was in the body, but when you have the\nhumanoid, that doesn't work. You have big heavy legs. You swing the legs. It affects everything else. (Lex laughs) And so, dealing with all of\nthat interaction does make the humanoid a much more\ncomplicated platform. - And I also saw that at least\nrecently you've been doing more explicit modeling\nof the stuff you pick up. - [Robert] Yeah, yeah. - Which is (laughs) really interesting. So, you have to, what, model the shape, the weight distribution. I don't know, like, you\nhave to, like, include that as part of the modeling,\nas part of the planning 'cause okay, so for people\nwho don't know, so Atlas, at least in, like, a recent\nvideo, like, throws a heavy bag, throws a (laughing) bunch of- - [Robert] Yeah. - stuff. So, what's involved in picking\nup a thing, a heavy thing? And when that thing is a bunch of different non-standard things, I think it also picked up like a barbell and to be able to throw in some cases, what are some interesting\nchallenges there? - So, we were definitely\ntrying to show that the robot and the techniques we're\napplying to Atlas let us deal with heavy things in the world. Because if the robot's gonna be useful, it's actually gotta move stuff around. And that needs to be significant stuff that's an appreciable portion of the body weight of the robot. And we also think this differentiates us from the other humanoid robot activities that you're seeing out there. Mostly, they're not picking stuff up yet, not heavy stuff anyway. But just like you or me, you know, you need to anticipate that moment. You know, you're reaching\nout to pick something up, and as soon as you pick it up, your center of mass is gonna shift. And if you're gonna, you\nknow, turn in a circle, you have to take that\ninertia into account. And if you're gonna\nthrow a thing, you know, all of that has to be sort of included in the model of what you're trying to do. So, the robot needs to have\nsome idea or expectation of what that weight is and\nsort of predict, you know, think a couple of seconds ahead, \"How do I manage now my body\nplus this big heavy thing together (laughs) and still\nmaintain balance, right?\" And so, that's a big change for us, and I think the tools we've\nbuilt are really allowing that to happen quickly now. Some of those motions that you\nsaw in that most recent video we were able to create\nin a matter of days. It used to be that it took\nsix months to do anything new, you know, on the robot, and\nnow we're starting to develop the tools that let us do\nthat in a matter of days. And so, we think that's really exciting. That means that the ability\nto create new behaviors for the robot is gonna\nbe a quicker process. - So, being able to\nexplicitly model new things that it might need to pick\nup, new types of things? - And you know, to some degree, you don't wanna have to\npay too much attention to each specific thing, right? There's sort of a generalization here. Obviously, when you grab a thing, you have to conform your\nhand, your end effector to the surface of that shape,\nbut once it's in your hands, it's probably just the mass\nand inertia that matter, and the shape may not be as important. - [Lex] Yeah. - And so, you know, in some\nways you wanna pay attention to that detailed shape, and in others, you wanna generalize it and say, \"Well, all I really care about is the center of mass of this thing, especially if I'm gonna throw\nit up on that scaffolding.\" - And it's easier if the body is rigid. What if there's some, doesn't it throw, like, a sandbag type thing? - That tool bag, you know-\n- Tool bag. - had loose stuff in\nit, so it managed that. There are harder things\nthat we haven't done yet. You know, we could have\nhad a big jointed thing or, I don't know, a bunch\nof loose wire or rope. - What about carrying another robot? How 'bout that? (laughing) - Yeah, we haven't done that yet. - [Lex] Carry Spot. - I guess we did a little bit of a, we did a little skit around Christmas where we had two Spots\nholding up another Spot that was trying to put,\nyou know, a bow on a tree. So, I guess we're doing that\nin a small way. (laughing) - Okay, that's pretty good. Let me ask the all-important question. Do you know how much Atlas can curl? (Robert laughing drown out Lex speaking) (Lex laughs) I mean, you know, for us\nhumans, that's really one of the most fundamental questions you can ask another human being, curl, bench, et cetera.\n(Robert laughs) - It probably can't curl\nas much as we can yet, but a metric that I\nthink is interesting is, you know, another way of\nlooking at that strength is, you know, the box jump. So, how high of a box can you jump onto? - [Lex] Question. - And Atlas, I don't\nknow the exact height. It was probably a meter\nhigh or something like that. It was a pretty pretty tall\njump that Atlas was able to manage when we last tried to do this. And I have video of my\nchief technical officer doing the same jump, and he\nreally struggled, you know, to get-\n- Oh, the human? - The human getting all\nthe way on top of this box. But then, you know,\nAtlas was able to do it. We're now thinking about the\nnext generation of Atlas, and we're probably gonna be in the realm of a person can't do it, you\nknow, with the next generation. The robots, the actuators\nare gonna get stronger where it really is the\ncase that at least some of these joints, some of these\nmotions will be stronger. - And to understand how high it can jump, you probably had to do\nquite a bit of testing. - Oh, yeah, and there's\nlots of videos of it trying and failing, and you know,\nthat's all, you know, we don't always release those videos, but they're a lot of\nfun to look at. (laughs) - So, we'll talk a little bit about that. But can you talk to the jumping? 'Cause you talked about the walking, and it took a long time, many, many years to get the walking to be natural, but there's also really natural-looking, robust, resilient jumping. How hard is it to do the jumping? - Well, again, this stuff\nhas really evolved rapidly in the last few years. You know, the first time we\ndid a somersault, you know, there was a lot of kind\nof manual iteration. What is the trajectory? You know, how hard do you throw? In fact, in these early days, when I'd see early experiments\nthat the team was doing, I might make suggestions about\nhow to change the technique, again, kind of borrowing\nfrom my own intuition about how backflips work. But frankly they don't need that anymore. So, in the early days,\nyou had to iterate kind of in almost a manual way trying to change these trajectories\nof the arms or the legs to try to get, you know, a\nsuccessful backflip to happen. But more recently, we're running these model-predictive control techniques where the robot essentially\ncan think in advance for the next second or two\nabout how its motion is going to transpire, and you can, you know, solve for optimal trajectories\nto get from A to B. So, this is happening in\na much more natural way, and we're really seeing\nan acceleration happen in the development of these behaviors, again, partly due to these\noptimization techniques, sometimes learning techniques, so it's hard in that there's a\nlot of mathematics behind it, but we're figuring that out. - So, you can do\nmodel-predictive control for, I mean, I don't even\nunderstand what that looks like when the entire robot is in the air flying and doing a back (laughs). - Yeah, well-\n- I mean. (laughs) - But that's the cool part, right? So, you know, the physics, we can calculate physics\npretty well using, you know, Newton's laws about how it's\ngoing to evolve over time and you know, the sick trick,\nwhich was a front somersault with a half twist is\na good example, right? You saw the robot on various\nversions of that trick. I've seen it land in\ndifferent configurations, and it still manages to stabilize\nitself, and so, you know, what this model-predictive\ncontrol means is, again, in real time, the robot is\nprojecting ahead, you know, a second into the future and\nsort of exploring options. And if I move my arm a\nlittle bit more this way, how is that gonna affect the outcome? And so, it can do these\ncalculations, many of them, you know, and basically solve for where, you know, given where I am now, maybe I took off a little bit screwy from how I had planned, I can adjust. - [Lex] So, you're adjusting in the air for the landing.\n- Adjust on the fly. So, the model-predictive\ncontrol lets you adjust on the fly, and of course, I think this is what, you know, people adapt as well. When we do it, even a gymnastics trick, we try to set it up so it's\nclose to the same every time. But we figured out how to do\nsome adjustment on the fly, and now we're starting to figure out that the robots can do\nthis adjustment on the fly as well using these techniques. - In the air. I mean, it just feels, from a robotics perspective, just surreal. - You talked about underactuated, right? - [Lex] Yes.\n- So, when you're- - That's totally true.\n- When you're in the air, there's some things you\ncan't change, right? You can't change the momentum\nwhile it's in the air 'cause you can't apply an\nexternal force, a torque, and so the momentum isn't gonna change. So, how do you work within the constraint of that fixed momentum to\nstill get from A to B (laughs) where you wanna be? - That's really (laughing) underactuated. (Robert laughs) You're in the air. I mean, you become a drone\nfor a brief moment in time. No, you're not even a (laughing)\ndrone 'cause you can't- - [Robert] Can't hover. - You can't hover. You can't.\n- You're gonna impact soon. Be ready. (laughs)\n- Yeah. Have you considered like\na hover type thing or no? No?\n- No. - It's too much weight?\n- No. (Lex laughing) - I mean, it's just\nincredible and just even to have the guts to try a\nbackflip with such a large body. That's wild. (Robert laughs) But, like how- - We definitely broke a\nfew robots trying that. - [Lex] (laughing) Yeah. (Robert laughs) - But that's where the\nbuild it, break it, fix it, you know, strategy comes in. You gotta be willing to break. And what ends up happening is by breaking the robot repeatedly,\nyou find the weak points, and then you end up redesigning it so it doesn't break so easily\nnext time, you know. (laughs) - Through the breaking\nprocess you learn a lot, like, a lot of lessons,\nand you keep improving not just how to make the backflip work, but everything just-\n- Yeah. And how to build the machine better. - Yeah.\n- Yeah. - I mean, is there something\nabout just the guts to come up with an idea\nof saying, \"You know what? Let's try (laughing) to\nmake it to a backflip\"? - Well, I think the\ncourage to do a backflip in the first place and\nto not worry too much about the ridicule of somebody saying, \"Why the heck are you doing\nbackflips with robots?\" - [Lex] Sure. - Because a lot of people\nhave asked that, you know. (Lex laughs) (laughing) \"Why are you doing this?\" - Why go to the moon (Robert laughs) in this decade and do\nthe other things, JFK? (Robert laughs) Not because it's easy, because it's hard. - [Robert] Yeah, exactly. (laughs) (Lex laughs) - Don't ask questions. Okay, so the jumping, I mean, there's a lot of incredible stuff. If we can just rewind a little bit to the DARPA Robotics\nChallenge in 2015, I think, which was, for people who aren't familiar with the DARPA challenges, it was first with autonomous vehicles,\nand there's a lot of interesting challenges around that. And the DARPA Robotics Challenge was when humanoid robots were\ntasked to do all kinds of, you know, manipulation, walking- - Driving a vehicle.\n- driving a car, all these kinds of challenges\nwith, if I remember correctly, sort of some slight capability\nto communicate with humans, but the communication was very poor. So, basically it has to be\nalmost entirely autonomous. - It could have periods where the communication\nwas entirely interrupted, and the robot had to be able to proceed. - [Lex] Yeah. - But you could provide\nsome high-level guidance to the robot, basically\nlow-bandwidth communications- - Yeah\n- to steer it. - I watched that challenge\nwith kind of tears in my eyes eating popcorn with-\n- Us, too. (both laughing) - But I wasn't personally\nlosing, you know, hundreds of thousands, millions of dollars and many years of incredible, hard work by some of the most brilliant\nroboticists in the world. So, that was why the tragic, that's why tears came.\n(Robert laughs) So, anyway, just looking\nback to that time, what have you learned\nfrom that experience? And maybe if you could\ndescribe what it was sort of the setup for\npeople who haven't seen it. - Well, so there was a contest where a bunch of different\nrobots were asked to do a series of tasks, some\nof those that you mentioned, drive a vehicle, get out, open a door, go identify a valve, shut a valve, use a tool to maybe\ncut a hole in a surface and then crawl over some stairs and maybe some rough terrain. So, the idea was have\na general-purpose robot that could do lots of different things, had to be mobility, and\nmanipulation, on-board perception. And there was a contest, which DARPA likes at the\ntime, was running sort of follow-on to the grand challenge, which was, \"Let's try to\npush vehicle autonomy along.\" Right? They encouraged people\nto build autonomous cars. So, they were trying to basically\npush an industry forward. Our role in this was to build a humanoid. At the time, it was our sort of first-generation Atlas robot, and we built maybe 10 of them, I don't remember the exact number. And DARPA distributed those\nto various teams that sort of won a contest, showed that\nthey could, you know, program these robots and then use them to compete against each other, and then other robots\nwere introduced as well. Some teams built their own robots. Carnegie Mellon, for example,\nbuilt their own robot. And all these robots competed\nto see who could sort of get through this maze the fastest. And again, I think the purpose was to kind of push the whole industry forward. We provided the robot and\nsome baseline software, but we didn't actually\ncompete as a participant where we were trying to,\nyou know, drive the robot through this maze. We were just trying to\nsupport the other teams. It was humbling because\nit was really a hard task. And honestly, the tears were because, mostly, the robots\ndidn't do it. (laughs) You know, they fell down,\nyou know, repeatedly. It was hard to get through this contest. Some did, and you know,\nthey were rewarded and won. But it was humbling\nbecause of just how hard, these tasks weren't all that hard. A person could have done it very easily, but it was really hard to get\nthe robots to do it, you know. And the-\n- The general nature of it, the variety of it. - [Robert] The variety. - And also, I don't know\nif the tasks were (sighs) sort of the task in\nthemselves help us understand what is difficult and what is not. I don't know if that was obvious before the contest was designed, so you kind of tried to figure that out. And I think Atlas is really\na general robot platform, and it's perhaps not best\nsuited for the specific tasks of that contest, like just for example, probably the hardest task is\nnot the driving of the car but getting in and out of the car. (Robert laughs) And Atlas probably is,\nyou know, if you were to design a robot that can\nget into the car easily and get out easily, you\nprobably would not make Atlas that particular car. - Yeah, the robot was a little bit big- - Yeah.\n- to get in and out of that car, right? - [Lex] It doesn't fit, yeah. - This is the curse of\na general-purpose robot, that they're not perfect at any one thing, but they might be able to\ndo a wide variety of things. And that is the goal\nat the end of the day. You know, I think we all wanna\nbuild general-purpose robots that can be used for lots\nof different activities, but it's hard, and the wisdom in building successful robots\nup until this point have been, \"Go build a robot for a specific task, and it'll do it very well.\" And as long as you\ncontrol that environment, it'll operate perfectly,\nbut robots need to be able to deal with uncertainty. If they're gonna be useful\nto us in the future, they need to be able to deal\nwith unexpected situations. And that's sort of the goal of a general-purpose\nor multipurpose robot. And that's just darn hard. And so, yeah, there was these\ncurious little failures. Like, I remember a robot, you know, the first time you start\nto try to push on the world with a robot, you forget\nthat the world pushes back and will push you over (laughs)\nif you're not ready for it. And the robot, you know,\nreached to grab the door handle. I think it missed the\ngrasp of the door handle, was expecting that its hand\nwas on the door handle, and so when it tried to turn the knob, it just threw itself over. It didn't realize, \"Oh, I\nhad missed the door handle. I was expecting a force\nback from the door. It wasn't there, and\nthen I lost my balance.\" And so, these little simple things that you and I would\ntake totally for granted and deal with, (laughs)\nthe robots don't know how to deal with yet, and\nso you have to start to deal with all of those circumstances. (laughs) - Well, I think a lot\nof us experience this even when sober but drunk, too. Sort of, you pick up a\nthing and expect it to be, what is it, heavy, and\nit turns out to be light. - [Robert] Yeah, and then, \"Whoa.\" - Oh, yeah, and then, and I'm\nsure if your depth perception for whatever reason is screwed up, if you're drunk or some other reason, and then you think you're\nputting your hand on the table, and you miss it, I mean it's\nthe same kind of situation. - [Robert] Yeah. - But there's a-\n- Which is why you need to be able to predict forward\njust a little bit, and so that's where this model-predictive\ncontrol stuff comes in. Predict forward what you\nthink's gonna happen, and if that does happen,\nyou're in good shape. If something else happens, you better start predicting again. - So, like, regenerate a plan.\n(Robert laughs) - [Robert] Yeah. - I mean, that also requires\na very fast feedback loop of updating what your prediction, how it matches to the actual real world. - [Robert] Yeah, those things\nhave to run pretty quickly. - What's the challenge of\nrunning things pretty quickly, 1,000 hertz, of acting\nand sensing quickly? - You know, there's a few\ndifferent layers of that. At the lowest level, you\nlike to run things typically at around 1,000 hertz,\nwhich means that, you know, at each joint of the robot,\nyou're measuring position or force and then trying\nto control your actuator, whether it's a hydraulic\nor electric motor trying to control the force coming\nout of that actuator. And you wanna do that really fast, something like 1,000 hertz,\nand that means you can't have too much calculation\ngoing on at that joint. But that's pretty manageable these days, and it's fairly common. And then, there's another layer that you're probably\ncalculating, you know, maybe at 100 hertz, maybe 10 times slower, which is now starting to look\nat the overall body motion and thinking about the\nlarger physics of the robot. And then, there's yet another\nloop that's probably happening a little bit slower, which\nis where you start to bring, you know, your perception in, your vision, and things like that, and\nso you need to run all of these loops sort of simultaneously. You do have to manage your computer time so that you can squeeze in\nall the calculations you need in real time in a very consistent way. And the amount of calculation\nwe can do is increasing as computers get better,\nwhich means we can start to do more sophisticated calculations. I can have a more complex model\ndoing my forward prediction, and that might allow me to\ndo even better predictions as I get better and better. And it used to be, again,\nyou know, 10 years ago, we had to have pretty simple\nmodels that we were running, you know, at those fast rates\n'cause the computers weren't as capable about calculating forward with a sophisticated model,\nbut as computation gets better, we can do more of that. - What about the actual pipeline\nof software engineering, how easy it is to keep updating Atlas, like, do continuous development on it? So, how many computers are on there? Is there a nice pipeline? - It's an important part of\nbuilding a team around it, which means, you know, you need\nto also have software tools, simulation tools, you know, so we have always made strong use of physics-based\nsimulation tools to do some of this calculation, basically\ntest it in simulation before you put it on the robot. But you also want the same\ncode that you're running in simulation to be the\nsame code you're running on the hardware, and so\neven getting to the point where it was the same code\ngoing from one to the other, we probably didn't really get that working until, you know, several years ago. But you know, that was\na bit of a milestone. And so, you wanna certainly\nwork these pipelines so that you can make\nit as easy as possible and have a bunch of people\nworking in parallel. You know, we only have, you\nknow, four of the Atlas robots, the modern Atlas robots at\nthe company, and you know, we probably have, you\nknow, 40 developers there all trying to gain access to it. And so, you need to share resources and use some of the software pipeline. - Well, that's a really\nexciting step to be able to run the exact same code in simulation\nas on the actual robot. How hard is it to do a realistic simulation, physics-based simulation\nof Atlas such that, I mean, the dream is like,\nif it works in simulation, it works perfectly in reality.\n(Robert laughs) How hard is it to sort of keep\nworking on closing that gap? - The root of some of our\nphysics-based simulation tools really started at MIT, and we built some good physics-based\nmodeling tools there. The early days of the\ncompany, we were trying to develop those tools\nas a commercial product, so we continued to develop them. It wasn't a particularly\nsuccessful commercial product, but we ended up with some nice physics-based\nsimulation tools so that, when we started\ndoing legged robotics again, we had a really nice tool to work with. And the things we paid\nattention to were things that weren't necessarily handled very well in the commercial tools you\ncould buy off the shelf, like interaction with the\nworld, like foot-ground contact. And so, trying to model\nthose contact events well in a way that captured the important parts of the interaction was a\nreally important element to get right and to also do in a way that was computationally\nfeasible and could run fast 'cause if your simulation\nruns too slow, you know, then your developers are\nsitting around waiting for stuff to run and compile, and so it's always about efficient, fast operation as well. So, that's been a big part of it. You know, I think developing\nthose tools in parallel to the development of\nthe platform and trying to scale them has really\nbeen essential, I'd say, to us being able to\nassemble a team of people that could do this. - Yeah, how to simulate contact, period, so foot-ground contact but\nsort of for manipulation because don't you want to\nmodel all kinds of surfaces? - Yeah. So, it will be even more\ncomplex with manipulation 'cause there's a lot\nmore going on. (laughs) - Yeah.\n- You know. And you need to capture, I don't know, things slipping and moving,\nyou know, in your hand. It's a level of complexity\nthat I think goes above foot-ground contact when you really start doing\ndextrous manipulation. So, there's challenges ahead still. - So, how far are we away\nfrom me being able to walk with Atlas in the sand along the beach (Robert laughs) and us both drinking a beer? (Robert laughing) - [Robert] Well, I- - Sip it out of a can, out of a can. - Maybe Atlas could spill his beer 'cause he's got nowhere\nto put it. (laughing) Atlas could walk on the sand. - So, can it?\n- Yeah, yeah. Yeah, I mean, you know,\nhave we really had him out on the beach? You know, we take them outside often, you know, rocks, hills,\nthat sort of thing, even just around our lab in Waltham. We probably haven't been\non the sand, but I'm- - So, soft surfaces, normally?\n- I don't doubt that we could deal with it. We might have to spend\na little bit of time to sort of make that work. We had to take BigDog\nto Thailand years ago, and we did this great video of the robot walking in the sand, walking into the ocean up\nto, I don't know, its belly or something like that and\nthen turning around and walking out all while playing-\n- Oh, that's- - [Robert] some cool beach music. - Yeah.\n- Great show, but then, you know, we didn't\nreally clean the robot off, and the saltwater was really\nhard on it, so you know, we put it in a box, shipped it back. By the time it came back, we had some problems\n(laughing) with corrosion. - It's the salt water. It's not like-\n- Salt tough (laughs). - It's not, like, sand getting into the components or\nsomething like this. - [Robert] Yeah, yeah.\n- But I'm sure, if this is a big priority,\nyou can make it like- - Right.\n- waterproof it or something.\n- Right, right. That just wasn't our goal at the time. - Well, it's a personal goal of mine to walk along,\n(Robert laughs) walk along the beach, but\nit's a human problem, too. You get sand everywhere. It's just a giant mess. (Robert laughs) So, soft surfaces are okay. So, I mean, can we just linger\non the robotics challenge? There's a pile of, like,\nrubble they had to walk over. How difficult is that task? - In the early days of developing BigDog, the loose rock was the epitome\nof the hard walking surface because you stepped down, and you had these little\npoint feet on the robot, and the rock can roll,\nand you have to deal with that last-minute, you know, change in your foot placement. - Yeah, so you step on the\nthing, and that thing responds to you stepping on it. - Yeah, and it moves where\nyour point of support is. And so, that became kinda\nthe essence of the test. And so, that was the\nbeginning of us starting to build rock piles in our parking lots, and we would actually\nbuild boxes full of rocks and bring 'em into the\nlab, and then we would have the robots walking across\nthese boxes of rocks because that became the essential test. - So, you mentioned BigDog. Can we maybe take a stroll through the history of Boston Dynamics? So, what and who is BigDog? By the way, is who, (Robert laughs) do you try not to\nanthropomorphize the robots? Do you try to remember that they're, this is like the division I have 'cause, for me, it's impossible. For me, there's a magic to\nthe being that is a robot. It is not human, but it is, the same magic that a living\nbeing has when it moves about the world is there in the robot. So, I don't know what question I'm asking, but should I say what or who I guess? Who is BigDog? What is BigDog?\n(Robert laughs) - Well, I'll say to\naddress the meta question, we don't try to draw hard\nlines around it being an it, or a him, or a her. It's okay, right? I think part of the magic of\nthese kinds of machines is by nature of their organic\nmovement, of their dynamics, we tend to want to identify with them. We tend to look at them and\nsort of attribute maybe feeling to that because we've only seen things that move like this that were alive. And so, this is an opportunity. It means that you could\nhave feelings for a machine, and you know, people have\nfeelings for their cars. You know, they get attracted\nto 'em, attached to them. So, that's inherently,\ncould be a good thing as long as we manage\nwhat that interaction is. So, we don't put strong\nboundaries around this and ultimately think it's a benefit, but it's also, can be a bit of a curse because I think people\nlook at these machines, and they attribute a level of intelligence that the machines don't have. Why? Because, again, they've\nseen things move like this that we're living beings,\nwhich are intelligent, and so they wanna attribute\nintelligence to the robots that isn't appropriate yet, even though they move\nlike an intelligent being. - But you try to acknowledge that the anthropomorphization\nis there and try to, first of all,\nacknowledge that it's there. - And have a little fun with it. - And have little fun.\n- You know, our most recent video,\nit's just kind of fun, you know, to look at the robot. We started off the video\nwith Atlas kind of looking around for where the bag of tools was 'cause the guy up on the scaffolding says, \"Send me some tools.\" Atlas has to kinda look\naround and see where they are. And there's a little\npersonality there that is fun. It's entertaining. It makes our jobs interesting and I think in the long\nrun can enhance interaction between humans and robots in a way that isn't available to machines\nthat don't move that way. - This is something to me\npersonally is very interesting. I happen to have a lot of legged robots. (both laughing) I hope to have a lot of\nSpots in my possession. I'm interested in celebrating robotics and celebrating companies, companies that do incredible stuff\nlike Boston Dynamics. You know, I'm a little crazy,\nand you say you don't want to, you want to align, you\nwanna help the company 'cause I ultimately want a company like Boston Dynamics to succeed. And part of that we'll\ntalk about, you know, success kind of requires making money. And so, the kinda stuff\nI'm particularly interested in may not be the thing that\nmakes money in the short term. I can make an argument\nthat will in the long term. But the kinda stuff I've been\nplaying with is a robust way of having the quadrupeds, the\nrobot dogs communicate emotion with their body movement- - Hmm.\n- the same kinda stuff you do with a dog- - Yeah.\n- but not hard coded, but in a robust way-\n- Mm-hmm. - and be able to communicate\nexcitement, or fear- - Mm-hmm. - boredom, all these kinds of stuff. And I think as a base layer\nof function, of behavior to add on top of a robot, I think that's a really powerful way to make the robot more usable for humans, for whatever application.\n- I think it's gonna be really important, and it's\na thing we're beginning to pay attention to. A differentiator for the\ncompany has always been we really want the robot to work. We want it to be useful. Making it work at first meant the legged locomotion really works. It can really get around,\nand it doesn't fall down. But beyond that, now it\nneeds to be a useful tool. And our customers are, for\nexample, factory owners, people who are running a\nprocess-manufacturing facility. And the robot needs to be able to get through this complex\nfacility in a reliable way, you know, taking measurements. We need for people who\nare operating those robots to understand what the robots are doing. If the robot needs help\nor, you know, is in trouble or something, it needs\nto be able to communicate and a physical indication of some sort so that a person looks\nat the robot and goes, \"Oh, I know what that robot's doing. That robot's going to go take measurements of my vacuum pump with\nits thermal camera.\" You know, you wanna be\nable to indicate that, or even just the robot's\nabout to turn, you know, in front of you and\nmaybe indicate (laughs) that it's going to turn. And so, you sort of see and\ncan anticipate its motion. So, this kind of communication is going to become more and more important. It wasn't sort of our\nstarting point, you know, but now the robots are\nreally out in the world, and you know, we have about 1,000 of 'em out with customers right now. This layer of physical indication,\nI think, is gonna become more and more important. - We'll talk about where it goes 'cause there's a lot of\ninteresting possibilities. But if you can return back to\nthe origins of Boston Dynamics with the more research, the R&D side, before we talk about how\nto build robots at scale. So, BigDog. What's-\n- So- - Who's BigDog? - So, the company started in 1992, and in probably 2003, I believe, is when we\ntook a contract from, so, basically, 10 years, 11\nyears we weren't doing robotics. We did a little bit of robotics with Sony. They had Aibo. They had their Aibo robot. We were developing some software for that. That kinda got us a little bit involved with robotics again. Then, there was this opportunity\nto do a DARPA contract where they wanted to build a robot dog. And we won a contract to build that. And so, that was the genesis of BigDog, and it was a quadruped,\nand it was the first time we built a robot that\nhad everything on board. You could actually take the robot out into the wild and operate it. So, it had an onboard power plan. It had onboard computers. It had hydraulic actuators\nthat needed to be cooled. So, we had cooling systems built in, everything integrated into the robot. And that was a pretty rough start, right? It was 10 years that we\nwere not a robotics company. We were a simulation\ncompany, and then we had to build a robot in about a year. So, that was a little bit\nof a rough transition. (Lex laughs) (Robert laughs) - I mean, can you just\ncomment on the roughness of that transition? 'Cause BigDog, I mean, this is this big\nquadruped, four legs robot. - We built a few different\nversions of them, but the very earliest ones, you\nknow, didn't work very well, (laughs) and we would take 'em\nout, and it was hard to get, you know, a go-kart engine\ndriving a hydraulic- - Oh, is that what it was? (Robert laughs) I was-\n- And you know, having that all work while trying to get, you know, the robot to stabilize itself, and so-\n- So. what was the power plan? What was the engine? It seemed like my vague\nrecollection, (laughs) I don't know. It felt very loud, and aggressive, and kind of thrown together\nis what it kind of- - Oh, it absolutely was, right? We weren't trying to design\nthe best robot hardware at the time, and we wanted to\nbuy an off-the-shelf engine. And so, many of the early\nversions of BigDog had literally go-kart engines or something like that. Usually, it-\n- It was gas powered? - Yeah, a gas-powered two-stroke engine. (Lex laughs) And the reason why it was two stroke is two-stroke engines are lighter weight, and we generally didn't\nput mufflers on them 'cause we're trying to save the weight, and we didn't care about the noise. (laughing) And some of these\nthings were horribly loud, but we're trying to manage\nweight because managing weight in a legged robot is always important because it has to carry everything. - That said, that thing was big- - Well-\n- what I've seen the videos of.\n- Yeah. I mean, the early\nversions, you know, stood about, I don't know,\nbelly high, chest high. You know, they probably\nweighed maybe a couple of hundred pounds, but\nyou know, over the course of probably five years, we\nwere able to get that robot to really manage a remarkable\nlevel of rough terrain. So, you know, we started out\nwith just walking on the flat, and then we started walking\non rocks, and then inclines, and then mud, and then slippery mud. And you know, by the end of\nthat program, we were convinced that legged locomotion in\na robot could actually work 'cause you know, going into\nit, we didn't know that. We had built quadrupeds at MIT, but they used a giant hydraulic\npump, you know, in the lab. They used a giant computer\nthat was in the lab. They were always tethered to the lab. This was the first time\nsomething that was sort of self-contained, you know,\nwalked around in the world and balanced, and the purpose\nwas to prove to ourself that the legged locomotion\ncould really work. And so, BigDog really\ncut that open for us. And it was the beginning of what became a whole series of robots. So, once we showed to\nDARPA that you could make a legged robot that could work, there was a period at DARPA where robotics got really\nhot, and there was lots of different programs,\nand you know, we were able to build other robots. We built other quadrupeds\nlike LS3 designed to carry heavy loads. We built Cheetah, which\nwas designed to explore, what are the limits to\nhow fast you can run? You know, we began to\nbuild sort of a portfolio of machines and software that let us build not just one robot, but\na whole family of robots. - So, push the limits in\nall kinds of directions in terms-\n- Yeah, and to discover those principles. You know, you asked earlier about the art and science\nof legged locomotion. We were able to develop\nprinciples of legged locomotion so that we knew how to build a small legged robot or a big one. So, leg length, you\nknow, was now a parameter that we could play with. Payload was a parameter\nwe could play with. So, we built the LS3, which\nwas an 800-pound robot designed to carry a 400-pound payload. And we learned the design rules, basically developed the design rules. How do you scale different robot systems to, you know, their terrain,\nto their walking speed, to their payload? - So, when was Spot born? - Around 2012 or so, so, again, almost 10 years\ninto sort of a run with DARPA where we built a bunch\nof different quadrupeds. We had sort of a different thread where we started building humanoids. We saw that probably an end was coming where the government was\ngonna kind of back off from a lot of robotics investment. And in order to maintain\nprogress, we just deduced that, \"Well, we probably\nneed to sell ourselves to somebody who wants to\ncontinue to invest in this area,\" and that was Google. And so, at Google, we would\nmeet regularly with Larry Page, and Larry just started\nasking us, you know, \"What's your product gonna be?\" And you know, the logical thing, the thing that we had the most\nhistory with that we wanted to continue developing was a quadruped. But we knew it needed to be smaller. We knew it couldn't have a gas engine. We thought it probably couldn't\nbe hydraulically actuated. So, that began the process of\nexploring if we could migrate to a smaller, electrically actuated robot. And that was really the genesis of Spot. - So, not a gas engine, and\nthe actuators are electric. - [Robert] Yes. - So, can you maybe\ncomment on what it's like at Google working with Larry Page, having those meetings, and thinking of what will a robot look like\nthat could be built at scale, like, starting to think about a product? - Larry always liked the toothbrush test. He wanted products that\nyou used every day. What they really wanted was, you know, a consumer-level product, something that would work in your house. We didn't think that was\nthe right next thing to do, because to be a consumer-level product, cost is gonna be very important. Probably needed to cost\na few thousand dollars. And we were building these machines that cost hundreds of\nthousands of dollars, maybe a million dollars to build. And of course, we were\nonly building, like, two, but we didn't see how to get all the way to this consumer-level product- - In a short amount of time. - In a short amount of time. And he suggested that we make\nthe robots really inexpensive, and part of our philosophy has always been build the best hardware you can. Make the machine operate\nwell so that you're trying to solve, you know,\ndiscover the hard problem that you don't know about. Don't make it harder by building a crappy machine, basically. Build the best machine you can. There's plenty of hard problems to solve that are gonna have to do with, you know, underactuated\nsystems and balance. And so, we wanted to build these high-quality machines still, and we thought that was important for us to continue learning about really what was the important parts that make robots work. And so, there was a little bit of a philosophical difference there. And so, ultimately that's\nwhy we're building robots for the industrial sector now because the industry can\nafford a more expensive machine because, you know, their\nproductivity depends on keeping their factory going. And so, if Spot costs, you\nknow, $100,000 or more, that's not such a big expense to them, whereas at the consumer level, no one's gonna buy a robot like that. And I think we might eventually get to a consumer-level product\nthat will be that cheap, but I think the path to\nget in there needs to go through these really nice machines so that we can then learn how to simplify. - So, what can you say to\nalmost the engineering challenge of bringing down cost of a robot so that, presumably, when you\ntry to build a robot at scale, that also comes into play when\nyou're trying to make money on a robot even in the industrial setting? But how interesting, how\nchallenging of a thing is that, in particular probably new to an R&D company?\n(Robert laughs) - Yeah, I'm glad you\nbrought that last part up. The transition from an R&D\ncompany to a commercial company, that's the thing you\nworry about, you know, 'cause you've got these\nengineers who love hard problems, who wanna figure out\nhow to make robots work. And you don't know if you\nhave engineers that wanna work on the quality, and reliability, and cost that is ultimately required. And indeed, you know, we have\nbrought on a lot of new people who are inspired by those problems. But the big takeaway lesson for me is we have good people. We have engineers who\nwanna solve problems, and the quality, and cost,\nand manufacturability is just another kind of problem. And because they're so\ninvested in what we're doing, they're interested in and will go work on those problems as well. And so, I think we're managing\nthat transition very well. In fact, I'm really pleased that, I mean, it's a huge undertaking by the way, right? So, you know, to get reliability\nto where it needs to be, we have to have fleets of robots that we're just operating\n24/7 in our offices to go find those rare\nfailures and eliminate them. It's just a totally\ndifferent kind of activity than the research activity\nwhere you get it to work, you know, the one robot you have to work in a repeatable way, (laughs) you know, at the high-stakes demo. It's just very different. But I think we're making\nremarkable progress, I guess. - So, one of the cool\nthings, I got a chance to visit Boston Dynamics, and I mean, one of the things that's really cool is to see a large number\nof robots moving about because I think one of\nthe things you notice in the research environment\nat MIT, for example, I don't think anyone\never has a working robot for a prolonged period of time. - (laughing) Exactly. - So, like, most robots\nare just sitting there in a sad state of despair waiting to be born,\n(Robert laughs) brought to life for a\nbrief moment of time. I just remember there's\na Spot robot just had, like, a cowboy hat on and\nwas just walking randomly for whatever reason. I don't even know, but\nthere's a kind of a sense of sentience to it because it doesn't seem like anybody was\n(laughing) supervising it. - Well-\n- It was just doing its thing.\n- I'm gonna stop way short of the sentience. - Sure.\n- It is the case that, if you come to our\noffice, you know, today and walk around the hallways, you're gonna see a dozen robots\njust kind of walking around- - Yes.\n- all the time. And that's really a\nreliability test for us. So, we have these robots programmed to do autonomous missions, get\nup off their charging dock, walk around the building, collect data at a few different places,\nand go sit back down. And we want that to be\na very reliable process 'cause that's what somebody\nwho's running a brewery, a factory, that's what\nthey need the robot to do, and so we have to dog-food our own robot. We have to test it in that way. And so, on a weekly basis, we\nhave robots that are accruing something like 1,500 or maybe\n2,000 kilometers of walking and you know, over 1,000\nhours of operation every week. And that's something that\nI don't think anybody else in the world can do 'cause,\nA, you have to have a fleet of robots to just accrue that\nmuch information. (laughing) You have to be willing to\ndedicate it to that test. But that's essential. - [Lex] That's how you\nget the reliability. - That's how you get it. - What about some of the cost cutting from the manufacturer's side? What have you learned from\nthe manufacturer's side of the transition from R&D to- - And we're still learning a lot there. We're learning how to cast parts instead of mill it all out\nof, you know, billet aluminum. We're learning how to\nget plastic molded parts, and we're learning about\nhow to control that process (laughs) so that you can build the same robot twice in a row. There's a lot to learn there. And we're only partway\nthrough that process. We've set up a manufacturing\nfacility in Waltham. It's about a mile from our headquarters, and we're doing final assembly and tests of both Spots and Stretches,\nyou know, at that factory. And it's hard because, to be\nhonest, we're still iterating on the design of the robot. As we find failures from\nthese reliability tests, we need to go engineer\nchanges, and those changes need to now be propagated to\nthe manufacturing line. And that's a hard process, especially when you wanna\nmove as fast as we do. And that's been challenging. You know, the folks who\nare working supply chain who are trying to get the\ncheapest parts for us, kind of requires that you buy a\nlot of 'em to make 'em cheap, and then we go change the\ndesign from underneath 'em, and they're like, \"What are you doing?\" And so, you know, getting\neverybody on the same page here that, yep, we still need to move fast, but we also need to try to\nfigure out how to reduce cost, that's one of the challenges of this migration we're going through. - And over the past few years, challenges to the supply chain, I mean, I imagine you've been a part of a bunch of stressful meetings. - Yeah, things got more\nexpensive and harder to get, and yeah, so it's all been a challenge. - Is there still room for simplification? - Oh, yeah, much more,\nand you know, these are really just the first\ngeneration of these machines. We're already thinking about\nwhat the next generation of Spot's gonna look like. Spot was built as a\nplatform, so you could put almost any sensor on it. You know, we provided data communications, mechanical connections, power connections. But for example, in the\napplications that we're excited about where you're\nmonitoring these factories for their health, there's\nprobably a simpler machine that we could build that's\nreally focused on that use case. And that's the difference between the general-purpose\nmachine or the platform versus the purpose-built machine. And so, even though even in the factory we'd still like the robot to\ndo lots of different tasks, if we really knew on day one\nthat we're gonna be operating in a factory with these\nthree sensors in it, we would have it all\nintegrated in a package that would be easier, less\nexpensive, and more reliable. So, we're contemplating\nbuilding, you know, a next generation of that machine. - So, we should mention that, so Spot for people who\nsomehow are not familiar, is a yellow, robotic dog and has been featured\nin many dance videos. It also has gained an arm. So, what can you say about\nthe arm that Spot has, about the challenges of this design, and the manufacturer of it? - We think the future of mobile robots is mobile manipulation. You know, in the past 10 years, it was getting mobility to work, getting the legged locomotion to work. If you ask, what's the hard\nproblem in the next 10 years, it's getting a mobile robot to do useful manipulation for you. And so, we wanted Spot to have an arm to experiment with those problems. And the arm is almost as\ncomplex as the robot itself, you know, and it's an attachable payload. It has, you know, several motors, and actuators, and sensors. It has a camera in the end of its hand, so you know, you can\nsort of see something, and the robot will control\nthe motion of its hand to go pick it up autonomously. So, in the same way the\nrobot walks and balances, managing its own foot\nplacement to stay balanced, we want manipulation to\nbe mostly autonomous, where the robot, you indicate, \"Okay, go grab that bottle,\" and then the robot will just\ngo do it using the camera in its hand and then sort\nof closing in on the grasp. But it's a whole nother complex robot on top of a complex legged robot. And of course, we made the\nhand look a little like a head, (laughs) you know,\nbecause again, we want it to be sort of identifiable. In the last year, a lot of\nour sales have been people who already have a robot now buying an arm to add to that robot. - Oh, interesting. And so, the arm is for sale? - [Robert] Oh, yeah, oh, yeah. It's an option. - What's the interface\nlike to work with the arm? I could just ask that question in general about robots from Boston Dynamics. Is it designed to be easily and efficiently operated\nremotely by a human being? Or, is there also the capability\nto push towards autonomy? - We want both. In the next version of the\nsoftware that we release, which will be version 3.3,\nwe're gonna offer the ability, if you have a autonomous\nmission for the robot, we're gonna include the\noption that it can go through a door, which means\nit's gonna have to have an arm, and it's gonna have to use\nthat arm to open the door. And so, that'll be an\nautonomous manipulation task that you can program\neasily with the robot- - Oh.\n- strictly through, you know, we have a tablet interface,\nand so on the tablet, you know, you sort of see the view that Spot sees. You say, \"There's the door handle. You know, the hinges are on\nthe left, and it opens in. The rest is up to you. Take care of it.\"\n- Oh, wow. So, it just takes care of everything? - Yeah. So, and for a task like opening doors, you can automate most of that. And we've automated a few other tasks. We had a customer who had a high-powered breaker\nswitch, essentially. It's an electric utility,\nOntario Power Generation. And when they're gonna\ndisconnect, you know, their power supply, right, that could be a gas generator, could be a nuclear power\nplant, you know, from the grid, you have to disconnect\nthis breaker switch. Well, as you can imagine,\nthere's, you know, hundreds or thousands of amps\nand volts (laughing) involved in this breaker switch. And it's a dangerous event\n'cause occasionally you'll get what's called an arc flash. As you just do this disconnect, the power, the sparks jump across,\nand people die doing this. And so, Ontario Power Generation\nused our Spot and the arm through the interface to\noperate this disconnect- - That's great.\n- in an interactive way. And they showed it to us, and\nwe were so excited about it and said, \"You know, I bet\nwe can automate that task.\" And so, we got some examples\nof that breaker switch, and I believe in the next\ngeneration of the software now we're gonna deliver back\nto Ontario Power Generation, they're gonna be able\nto just point the robot at that breaker. They'll indicate, \"That's the switch.\" There's sort of two\nactions you have to do. You have to flip up this\nlittle cover, press a button, then get a ratchet,\nstick it into a socket, and literally unscrew\nthis giant breaker switch. So, there's a bunch of different tasks, and we basically automated\nthem so that the human says, \"Okay, there's the switch. Go do that part. That right there is the socket where you're gonna put your tool, and you're gonna open it up.\" And so you can remotely\nsort of indicate this on the tablet, and then\nthe robot just does everything in between. - And it does everything,\nall the coordinated movement of all the different actuators\nthat includes the body and the arm.\n- Yeah, maintains its balance. It walks itself, you know, into position so it's within reach, and\nthe arm is in a position where it can do the whole task. So, it manages the whole body. - So, how does one become\na big enough customer to request features? 'Cause I personally want a\nrobot that gets me a beer. (Robert laughs) I mean, that has to be,\nlike, one of the most, I suppose, in the industrial setting, that's a non-alcoholic beverage of picking up objects and\nbringing the objects to you. - We love working with customers who have challenging problems like this and this one in particular because we felt like what they were doing,\nA, it was a safety feature. B, we saw that the robot could do it 'cause they teleoperated\nit the first time. Probably took 'em an hour to\ndo it the first time, right? But the robot was clearly\ncapable, and we thought, \"Oh, this is a great\nproblem for us to work on to figure out how to automate\na manipulation task.\" And so, we took it on not because\nwe were gonna make a bunch of money from it in selling\nthe robot back to them but because it motivated\nus to go solve what we saw as the next logical step. But many of our customers, in fact, our bigger customers, typically ones who are gonna run a utility, or a factory, or something like that, we\ntake that kind of direction from them, especially\nif they're gonna buy 10, or 20, or 30 robots, and they say, \"I really need it to do\nthis,\" well, that's exactly the right kind of problem\nthat we wanna be working on. - Mm-hmm.\n- Yeah, and so- - Note to self, \"Buy 10 Spots,\n(Robert laughs) and aggressively push\nfor beer manipulation.\" (Robert laughs) I think it's fair to say\nit's notoriously difficult to make a lot of money\nas a robotics company. How can you make money\nas a robotics company? Can you speak to that? It seems that a lot of\nrobotics companies fail. It's difficult to build robots. It's difficult to build\nrobots at a low enough cost where customers, even in\nthe industrial setting, want to purchase them, and it's\ndifficult to build robots that are useful, sufficiently useful. - [Robert] Yeah.\n- So, what can you speak to? And Boston Dynamics has been\nsuccessful for many years of finding a way to make money. - Well, in the early\ndays, of course, you know, the money we made was from\ndoing contract R&D work, and we made money, but you\nknow, we weren't growing, and we weren't selling a product. And then, we went through several owners who, you know, had a vision\nof not only developing advanced technology, but\neventually developing products. And so, both, you know,\nGoogle, and SoftBank, and now Hyundai, you know, had\nthat vision and were willing to, you know, provide that investment. Now, our discipline is that we\nneed to go find applications that are broad enough that\nyou could imagine selling thousands of robots\nbecause it doesn't work if you don't sell thousands or\ntens of thousands of robots. If you only sell hundreds,\nyou will commercially fail. And that's where most of the small robot companies have died. And that's a challenge because, you know, A, you need to field the robots. They need to start to become\nreliable, and as we've said, that takes time and\ninvestment to get there. And so, it really does take visionary investment to get there. But we believe that we\nare going to make money in this industrial monitoring space because, you know, if a chip fab, if the line goes down because a vacuum pump failed someplace, that can be a very expensive process. It can be a million dollars\na day in lost production, maybe you have to throw away some of the product along the\nway, and so the robot, if you can prevent that by inspecting the\nfactory every single day, maybe every hour if you have to, there's a real return on investment there. But there needs to be a\ncritical mass of this task. And we're focusing on a few\nthat we believe are ubiquitous in the industrial production environment. And that's using a thermal\ncamera to keep things from overheating, using an acoustic imager to find compressed air\nleaks, using visual cameras to read gauges, measuring vibration. These are standard things that you do to prevent unintended\nshutdown of a factory. And this takes place in a beer factory. We're working with AB InBev. It takes place in chip fabs. You know, we're working\nwith GlobalFoundries. It takes place in electric utilities and nuclear power plants. And so, the same robot can be applied in all of these industries. And as I said, we have about, actually it's 1,100 Spots out now. To really get, you know,\nprofitability, we need to be at 1,000 a year, maybe\n1,500 a year, you know, for that sort of part of the business. So, it still needs to grow,\nbut we're on a good path. So, I think that's totally achievable. - So, the application\nshould require crossing that 1,000-robot barrier. - It really should, yeah. I wanna mention, you know,\nour second robot, Stretch. - Yeah, tell me about Stretch. What's Stretch? Who is Stretch? - Stretch started differently than Spot. You know, Spot we built\nbecause we had decades of experience building quadrupeds. We had it in our blood. We had to build a quadruped product, but we had to go figure out\nwhat the application was, and we actually discovered this\nfactory-patrol application, basically preventative maintenance by seeing what our customers did with it. Stretch was very different. We started knowing that there was warehouses\nall over the world. There's shipping containers\nmoving all around the world full of boxes that are mostly\nbeing moved by hand. By some estimates, we think\nthere's a trillion boxes, (laughs) cardboard boxes shipped\naround the world each year. And a lot of it's done manually. It became clear early on\nthat there was an opportunity for a mobile robot in\nhere to move boxes around. And the commercial experience\nhas been very different between Stretch and with Spot. As soon as we started talking\nto people, potential customers about what Stretch was gonna be used for, they immediately started saying, \"Oh, I'll buy that robot. You know, in fact, I'm\ngonna put in an order for 20 right now.\" We just started shipping\nthe robot in January after, you know, several\nyears of development. - [Lex] Of this year? - Of this year. So, our first deliveries of\nStretch to customers were DHL and Maersk in January. We're delivering to Gap\nright now, and we have about seven or eight other customers, all who've already\nagreed in advance to buy between 10 and 20 robots, and so we've already got commitments for, you know, a couple\nhundred of these robots. This one's gonna go, right? It's so obvious that there's a need, and we're not just gonna unload trucks. We're gonna do any box-moving\ntask in the warehouse. And so, it too will be\na multipurpose robot, and we'll eventually have\nit doing palletizing, or depalletizing, or loading\ntrucks, or unloading trucks. There's definitely thousands of robots. There's probably tens\nof thousands of robots of this in the future, so\nit's gonna be profitable. - Can you describe what\nStretch looks like? - It looks like a big, strong\nrobot arm on a mobile base. The base is about the size of a pallet, and we wanted it to be\nthe size of a pallet because that's what lives\nin warehouses, right, pallets of goods sitting everywhere, so it needed to be able\nto fit in that space. - [Lex] It's not a legged robot. - It's not a legged robot. So, it was our first, it was actually a bit of a commitment from us, a challenge for us to build\na non-balancing robot. (Lex laughs) - To do the much easier\nproblem but to do it well. - Well, because, you know, it wasn't gonna have this balance problem. And in fact, the very first version of the logistics robot we\nbuilt was a balancing robot, and that's called Handle. And there's-\n- That thing was epic. - Oh, it's a beautiful machine. - It's an incredible machine. (Robert laughs) (Lex laughs) I mean, it looks epic. It looks like, I mean, out of a sci-fi movie of some sorts. I mean, can you actually just linger on, like, the design of that thing? 'Cause that's another leap into something you probably haven't done. It's a different kind of balancing. - Yeah, so let me-\n- It's wild. - I love talking about the\nhistory of how Handle came about (Lex laughs) because it connects all\nof our robots, actually. So, I'm gonna start with Atlas. When we had Atlas\ngetting fairly far along, we wanted to understand,\nI was telling you earlier, the challenge of the human form is that you have this mass up high,\nand balancing that inertia, that mass up high is its\nown unique challenge. And so, we started trying to get Atlas to balance standing on one foot, like on a balance beam\nusing its arms like this, and you know, you can do this, I'm sure. I can do this, right? Like, if you're walking a tightrope, how do you do that balance? So, that's sort of, you know,\ncontrolling the inertia, controlling the momentum of the robot. We were starting to\nfigure that out on Atlas. And so, our first concept of Handle, which was a robot that was\ngonna be on two wheels, so it had to balance, but it\nwas gonna have a big, long arm so it could reach a box\nat the top of a truck, and it needed yet another\ncounterbalance, a big tail, to help it balance while\nit was using its arm. So, the reason why this\nrobot sort of looks epic, some people said it looked like an ostrich or maybe, you know, an\nostrich moving around, was the wheels, the leg. It has legs, so it can extend its legs. So, it's wheels on legs. We always wanted to build wheels on legs. It had a tail, and it had this arm, and they're all moving\nsimultaneously and in coordination to maintain balance because we had figured out the mathematics of\ndoing this momentum control, how to maintain that balance. And so, part of the reason why we built this two-legged robot was we had figured this thing out. We wanted to see it in\nthis kind of machine, and we thought maybe this\nkind of machine would be good in a warehouse, and so we built it. And it's a beautiful machine. It moves in a graceful way\nlike nothing else we've built. But it wasn't the right machine\nfor a logistics application. We decided it was too slow and couldn't pick boxes\nfast enough, basically. - Oh.\n- And it- - Do it beautifully with elegance.\n- It did beautifully, but it just wasn't efficient enough. - [Lex] Aw. - So, we let it go. - [Lex] Yeah. - But I think we'll come back\nto that machine eventually. - The fact that it's possible,\nthe fact that you showed that you could do so many\nthings at the same time in coordination and so beautifully,\nthere's something there. - [Robert] Yeah. - That was a demonstration\nof what is possible. - Basically, we made a hard decision, and this was really kind of a\nhard-nosed business decision. It indicated us not doing\nit just for the beauty of the mathematics or the curiosity, but no, we actually\nneed to build a business that can make money in the long run. And so, we ended up building Stretch, which has a big, heavy base\nwith a giant battery in the base of it that allows it\nto run for two shifts, 16 hours worth of operation. And that big battery sort of\nhelps it stay balanced, right? So, it can move a 50-pound\nbox around with its arm and not tip over it. It's omnidirectional, it can move in any direction,\nand it has a nice suspension built into it so it can\ndeal with, you know, gaps or things on the floor and roll over it. But it's not a balancing robot. It's a mobile robot arm that\ncan work to carry, or pick, or place a box up to 50 pounds\nanywhere in the warehouse. - Take a box from point\nA to point B anywhere. - Yeah, palletize, depalletize. We're starting with unloading trucks because there's so many\ntrucks and containers where goods are shipped,\nand it's a brutal job. You know, in the summer,\nit can be 120 degrees inside that container. People don't wanna do that job, and it's backbreaking labor, right? Again, these can be up to 50-pound boxes. And so, we feel like this\nis a productivity enhancer, and for the people who used to\ndo that job unloading trucks, they're actually operating the robot now. And so, by building robots\nthat are easy to control, and it doesn't take an\nadvanced degree to manage, you can become a robot operator. And so, as we've introduced these robots to both DHL, and Maersk, and\nGap, the warehouse workers who were doing that manual labor are now the robot operators,\nand so we see this as ultimately a benefit to them as well. - Can you say how much Stretch costs? - Not yet, but I will\nsay that, when we engage with our customers, they'll\nbe able to see a return on investment in typically two years. - Okay, so that's something\nthat you're constantly thinking about, how- - [Robert] Yeah. - And I suppose you\nhave to do the same kind of thinking with Spot. So-\n- Yes. - it seems like with\nStretch the application is, like, directly obvious. - [Robert] Yeah, it's a slam dunk. - Yeah, and so you have a\nlittle more flexibility. - Well, I think we know the target. We know what we're going after. - [Lex] Yeah. - And with Spot, it took\nus a while to figure out what we were going after. - Well, let me return to that question about maybe the\nconversation you were having a while ago with Larry Page, maybe looking to the longer future of\nsocial robotics, of using Spot to connect with human\nbeings perhaps in the home. Do you see a future there if we were to sort of hypothesize\nor dream about a future where Spot-like robots\nare in the home as pets, a social robot?\n- We definitely think about it, and we would like to get there. We think the pathway to\ngetting there is, you know, likely through these\nindustrial applications and then mass manufacturing, you know. Let's figure out how to build the robots, how to make the software\nso that they can really do a broad set of skills. That's going to take real\ninvestment to get there. Performance first, right? A principle of the company has always been really make the robots do useful stuff. And so, you know, the\nsocial robot companies that try to start someplace else by just making a cute interaction, mostly they haven't survived. And so, we think the utility\nreally needs to come first, and that means you have to solve some of these hard problems. And so, to get there, we're\ngonna go through the design and software development in industrial, and then that's eventually\ngonna let you reach a scale that could then be\naddressed to a commercial, a consumer-level market, and\nso, yeah, maybe we'll be able to build a smaller Spot with an arm that could really go\nget your beer for you. - Mm-hmm. - But there's things we\nneed to figure out still, how to safely, really safely, and if you're gonna be\ninteracting with children, you better be safe. (laughs) And right now, we count on a little bit of standoff distance\nbetween the robot and people so that you don't pinch a\nfinger, you know, in the robot. So, you've got a lot of\nthings you need to go solve before you jump to that\nconsumer-level product. - Well, there's a kind\nof trade off in safety because it feels like, in\nthe home, you can fall. Like, you don't have to be as good. Like, you're allowed to\nfail in different ways, in more ways as long as\nit's safe for the humans. So, it just feels like an\neasier problem to solve 'cause it feels like, in the factory, you're not allowed to fail. - That may be true, but\nI also think the variety of things a consumer-level\nrobot would be expected to do will also be quite broad. - [Lex] Yeah. - And they're gonna want to get the beer and know the difference between\nthe beer and a Coca-Cola or my snack. You know, they're all gonna\nwant you to clean up the dishes, you know, from the table\nwithout breaking 'em. (laughs) Those are pretty complex tasks, and so there's still\nwork to be done there. - So, to push back on that,\nhere's what application I think that'll be very interesting. I think the application\nof being a pet, a friend, so, like, no tasks. Just be cute, not cute, not cute. A dog is more than just cute. A dog is a friend, is a companion. There's something about just\nhaving interacted with them. And maybe 'cause I'm hanging out alone with robot dogs a little too much, but, like, there's a connection there. And it feels like that connection\nshould not be disregarded. You-\n- No. It should not be disregarded. Robots that can somehow communicate through their physical gestures you're gonna be more\nattached to in the long run. Do you remember Aibo-\n- Mm-hmm. - the Sony Aibo? - Yep.\n- They sold over 100,000 of those, maybe 150,000, you know, what probably wasn't considered a successful product for them. They suspended that eventually, and then they brought it back. Sony brought it back, and people definitely,\nyou know, treated this as a pet, as a companion. And I think that will come around again. Will you get away without\nhaving any other utility? Maybe in a world where we can really talk to our simple little pet\nbecause, you know, ChatGPT or some other generative\nAI has made it possible for you to really talk in what\nseems like a meaningful way. Maybe that'll open the\nsocial robot up again. That's probably not a\npath we're gonna go down because, again, we're so focused\non performance and utility. We can add those other things also, but we really wanna start from that foundation of utility, I think. - Yeah. But I also wanna predict\nthat you're wrong on that, which is that the very path you're taking, which is creating a great robot platform, will very easily take a leap to adding a ChatGPT-like capability, maybe GPT 5. And there's just so many\nopen-source alternatives that you could just plop\ndown on top of Spot. And because you have this robust platform, and you're figuring out\nhow to mass-manufacture it, and how to drive the cost down, and how to make it, you know, reliable, all those kinds of things,\nit'll be the natural transition to where just adding ChatGPT on top of it could-\n- Oh, I do think that being able to verbally converse or even converse through gestures, you know, part of these learning models is that, you know, you can now\nlook at video and imagery and associate, you know, intent with that. Those will all help in the communication between robots and people, for sure. And that's gonna happen\nobviously more quickly than any of us were expecting. (laughs) - I mean, what else do you want from life? A friend to get you a beer\n(Robert laughs) and then just talk shit\nabout the state of the world. (Robert laughs) I mean, there's a deep\nloneliness within all of us. And I think a beer and a good\nchat solves so much of it or takes us a long way to solving a lot of it.\n- It'll be interesting to see, you know, when a generative AI can give you that warm feeling that\nyou connected, you know, and that, \"Oh, yeah, you remember me. You're my friend. You know, we have a history.\" You know, that history matters, right? - [Lex] Memory of joint, like- - Memory of, yeah. (laughs) - Having witnessed,\nthat's what friendship, that's what connection,\nthat's what love is. In many cases, some of the\ndeepest friendships you have is having gone through a\ndifficult time together- - Mm-hmm.\n- and having a shared memory of an amazing time or a difficult time and kind of that memory\ncreating this, like, foundation based on which you can then\nexperience the world together. The silly, the mundane stuff\nof day to day is somehow built on a foundation of having gone through some shit in the past. And the current systems are\nnot personalized in that way but-\n- Right. - I think that's a technical problem, not some kind of fundamental limitation, so combine that with an\nembodied robot like Spot, which already has magic in its movement, I think it's a very\ninteresting possibility of where that takes us. But of course, you have to\nbuild that on top of a company that's making money\nwith real applications, with real customers, and\nwith robots that are safe, and work, and reliable,\nand manufactured at scale. - And I think we're in a\nunique position in that because of, you know, our\ninvestors, primarily Hyundai, but also SoftBank still owns 20% of us. They're not totally fixated\non driving us to profitability as soon as possible. That's not the goal. The goal really is a\nlonger-term vision of creating, you know, what does\nmobility mean in the future? How is this mobile robot\ntechnology going to influence us, and can we shape that? And they want both. And so, we as a company are\ntrying to strike that balance between, \"Let's build a\nbusiness that makes money.\" I've been describing that to my own team as self-destination. If I wanna drive my own ship,\nwe need to have a business that's profitable in the end. Otherwise, somebody else is\ngonna drive the ship for us. So, that's really important. But we're gonna retain the\naspiration that we're gonna build the next generation of\ntechnology at the same time. And the real trick will\nbe if we can do both. - Speaking of ships, let me\nask you about a competitor and somebody who's become a friend. So, Elon Musk and Tesla\nhave announced they've been in the early days of\nbuilding a humanoid robot. How does that change the\nlandscape of your work? So, from an outside\nperspective, it seems like, well, as a fan of robotics,\nit just seems exciting. - Right, very exciting, right? When Elon speaks, people listen. And so, it suddenly brought\na bright light onto the work that we'd been doing, you\nknow, for over a decade. And I think that's only gonna help. And in fact, what we've seen\nis that, in addition to Tesla, we're seeing a proliferation\nof robotic companies arise now. - Including humanoid? - [Robert] Yes. - Oh, wow.\n- Yeah. And interestingly, many of them as they're, you know,\nraising money, for example, will claim whether or not they have a former Boston Dynamics employee on their staff as a criteria. (both laughing) - Yeah, that's true. I would do that as a\ncompany, yeah, for sure. - Yeah, so-\n- Shows you're legit, yeah. - Yeah, so, you know,\n(Lex laughs) it has brung a tremendous validation to what we're doing and excitement. Competitive juices are flowing,\nyou know, the whole thing. So, it's all good. - Elon has also kind of stated that, you know, maybe he implied that\nthe problem is solvable in the near term, which is\na low-cost humanoid robot that's a relatively\ngeneral use case robot. So, I think Elon is known for\nsort of setting these kinds of incredibly ambitious\ngoals, maybe missing deadlines but actually pushing not just\nthe particular team he leads but the entire world to,\nlike, accomplishing those. Do you see Boston Dynamics in\nthe near future being pushed in that kind of way, like\nthis excitement of competition kinda pushing Atlas maybe\nto do more cool stuff, trying to drive the cost\nof Atlas down perhaps? I mean, I guess I wanna\nask if there's some kind of exciting energy in Boston Dynamics due to this little bit of competition. - Oh, yeah, definitely. When we released our most\nrecent video of Atlas, you know, I think you had seen it, the scaffolding and throwing the box of tools around and then doing the flip at the end, we were trying to show the world that not only can we do\nthis parkour mobility thing, but we can pick up and move heavy things because, if you're gonna work in a manufacturing environment, that's what you gotta be able to do. And for the reasons I\nexplained to you earlier, it's not trivial to do so, you know, changing the center of mass, you know, by picking up a 50-pound block, you know, for a robot that weighs 150 pounds, that's a lot to accommodate. So, we're trying to show\nthat we can do that, so it's totally been energizing. You know, we see the\nnext phase of Atlas being more dextrous hands that can\nmanipulate and grab more things that we're gonna start by\nmoving big things around that are heavy and that affect balance. And why is that? Well, really tiny dextrous\nthings probably are gonna be hard for a while yet, you know. Maybe you could go build a\nspecial-purpose robot arm, you know, for stuffing, you know, chips into electronics boards,\nbut we don't really wanna really fine work like that. I think more course work\nwhere you're using two hands to pick up and balance an unwieldy thing maybe in a manufacturing environment, maybe in a construction environment, those are the things that we\nthink robots are gonna be able to do with the level of\ndexterity that they're gonna have in the next few years, and\nthat's where we're headed. And you know, Elon has\nseen the same thing, right? He's talking about using the robots in a manufacturing environment. We think there's something\nvery interesting there about having a two-armed robot because, when you have two\narms, you can transfer a thing from one hand to the other. You can turn it around. You know, you can reorient it\nin a way that you can't do it if you just have one hand\non it, and so there's a lot that extra arm brings to the table. - So, I think in terms of mission, you mentioned Boston\nDynamics really wants to see what's the limits of what's possible. And so, the cost comes\nsecond, or it's a component, but first figure out\nwhat are the limitations. I think, with Elon, he's\nreally driving the cost down. Is there some inspiration,\nsome lessons you see there of the challenge of driving the cost down, especially with Atlas\nwith a humanoid robot? - Well, I think the thing that\nhe's certainly been learning by building car factories is what that looks like in scaling. By scaling, you can get\nefficiencies that drive costs down- - Sure.\n- very well. And the smart thing\nthat, you know, they have in their favor is, you know,\nthey know how to manufacture. They know how to build electric motors. They know how to build, you know, computers and vision systems,\nso there's a lot of overlap between modern automotive\ncompanies and robots. But hey, we have a modern robotic, I mean, automotive company behind us as well. (Lex laughs) - So, bring it on. - Who's doing pretty well, right? The electric vehicles from\nHyundai are doing pretty well. - I love it. So, we've talked about some\nof the low-level control, some of the incredible\nstuff that's going on and basic perception, but\nhow much do you see currently and in the future of\nBoston Dynamics's sort of higher-level machine\nlearning applications? Do you see customers adding\non those capabilities, or do you see Boston\nDynamics doing that in house? - Some kinds of things we really believe are probably gonna be more broadly available,\nmaybe even commoditized, you know, using a machine learning, like a vision algorithm so a robot can recognize\nsomething in the environment. That ought to be something\nyou can just download. Like, I'm going to a new\nenvironment, and I have a new kind of door handle or piece of\nequipment I wanna inspect. You ought to be able\nto just download that. And I think people besides Boston Dynamics will provide that. And we've actually built\nan API that lets people add these vision algorithms to Spot, and we're currently\nworking with some partners who are providing that. Levatas is a example of a small provider who's giving us software\nfor reading gauges, and actually, another partner in Europe, Reply, is doing the same thing. So, we see ultimately an ecosystem of providers doing stuff like that. I think ultimately you might even be able to do the same thing with behaviors. So, this technology will\nalso be brought to bear on controlling the robot,\nthe motions of the robot. And you know, we're using\nlearning, reinforcement learning to develop algorithms for both\nlocomotion and manipulation. And ultimately, this is gonna mean you can add new behaviors to\na robot, you know, quickly. And that could potentially be done outside of Boston Dynamics. Right now, that's all internal to us. I think you need to understand\nat a deep level, you know, the robot control to do that. But eventually, that could be outside. But it's certainly a place where these approaches\nare gonna be brought to bear in robotics. - So, reinforcement learning\nis part of the process. So, you do use reinforcement learning. - [Robert] Yes. (Lex sighs) So, there's increasing levels\nof learning with these robots? - [Robert] Yes. - And that's for locomotion,\nfor manipulation, for perception? - [Robert] Yes. - Well, what do you think in general about all the exciting advancements of transformer neural networks, most beautifully illustrated through the large language\nmodels like GPT 4? - Like everybody else,\nwe're all, you know, I'm surprised at how far they've come. I'm a little bit nervous about the, there's anxiety around them, obviously, for, I think, good reasons, right? Disinformation is a curse,\nan unintended consequence of social media that could be\nexacerbated with these tools. So, if you use them to\ndeploy disinformation, it could be a real risk. But I also think that the risks\nassociated with these kinds of models don't have a whole lot to do with the way we're gonna\nuse them in our robots. If I'm using a robot, I'm\nbuilding a robot to do, you know, a manual task of some sort. I can judge very easily, is it\ndoing the task I asked it to? Is it doing it correctly? There's sort of a built-in\nmechanism for judging. Is it doing the right thing? Did it successfully do the task? - Yeah, physical reality\nis a good verifier. - It's a good verifier. That's exactly it, and\nwhereas if you're asking for, yeah, I don't know, you're trying to ask a\ntheoretical question in ChatGPT, it could be true, or it may not be true. And it's hard to have that verifier, what is that truth (laughs)\nthat you're comparing against, whereas, in physical\nreality, you know the truth. And this is an important difference. And so, I think there is reason\nto be a little bit concerned about, you know, how these tools, large language models could be used. But I'm not very worried about\nhow they're gonna be used, well, how learning algorithms in general are going\nto be used on robotics. It's really a different\napplication that has different ways of verifying what's going on. - Well, the nice thing\nabout language models is that I ultimately see, I'm really excited about the possibility of\nhaving conversations with Spot. - [Robert] Yeah. - There's no, I would say,\nnegative consequences to that but just increasing the\nbandwidth and the variety of ways you can communicate\nwith this particular robot. - [Robert] Yeah. - So, you could communicate visually. You can communicate through\nsome interface and to be able to communicate verbally\nagain with a beer and so on. I think that's really exciting to make that much, much easier. - We have this partner\nLevatas that's adding the vision algorithms\nfor gauge reading for us. Just this week I saw a demo\nwhere they hooked up, you know, a language tool to Spot,\nand they're talking to Spot to give commands.\n- Nice, I love it. - Yeah. - Can you tell me about the\nBoston Dynamics AI Institute? What is it, and what is its mission? - So, it's a separate organization, the Boston Dynamics Artificial\nIntelligence Institute. It's led by Marc Raibert, the\nfounder of Boston Dynamics, and the former CEO, and\nmy old advisor at MIT. Marc has always loved the research, the pure research without the confinement or demands of commercialization. And he wanted to continue to, you know, pursue that\nunadulterated research and so suggested to Hyundai that he set up this institute, and they agree that it's\nworth additional investment to kinda continue pushing this forefront. And we expect to be working together where you know Boston Dynamics is, again, both commercialize and do research, but the sort of time horizon of the research we're\ngonna do is, you know, in the next, let's say\nfive years, you know. What can we do in the next five years? Let's work on those problems. And I think the goal\nof the AI Institute is to work even further out. Certainly, you know, the analogy\nof legged locomotion again, when we started that, that\nwas a multi-decade problem. And so, I think Marc\nwants to have the freedom to pursue really hard\nover-the-horizon problems. That'll be the goal of the institute. - So, we mentioned some of the\ndangers, some of the concerns about large language models. That said, you know, there's\nbeen a long-running fear of these embodied robots. Why do you think people are afraid (Robert laughs) of legged robots? - Yeah, I wanted to show you this. So, this is in the Wall Street Journal, and this is all about ChatGPT, right? But look at the picture. - Yeah. - [Robert] It's a humanoid robot. - That's saying, \"I will replace you.\" - That looks scary, and it says, \"I'm gonna replace you.\" - [Lex] Yeah. - And so, the humanoid robot is the embodiment of this ChatGPT tool that there's reason to\nbe a little bit nervous about how it gets deployed. - [Lex] Yeah. - So, I'm nervous about that connection. It's unfortunate that\nthey chose to use a robot as that embodiment. As you and I just said, there's\nbig differences in this. But people are afraid because\nwe've been taught to be afraid for over 100 years. So, you know, the word robot was developed by a playwright named Karel Capek in 1921, a Czech playwright,\n\"Rossum's Universal Robots.\" And in that first depiction of a robot, the robots took over (laughs)\nat the end of the story. And you know, people love to be afraid. And so, we've been\nentertained by these stories for 100 years, and I think that's as much why people are afraid as anything else, as we've been sort of taught that this is the logical progression through fiction. I think it's fiction. - I think what people more\nand more will realize, just like you said, that the threat, like say you have a\nsuper-intelligent AI embodied in a robot. That's much less threatening\nbecause it's visible. It's verifiable. It's right there in physical reality. And we humans know how to\ndeal with physical reality. I think it's much scarier when\nyou have arbitrary scaling of intelligent AI systems\nin the digital space that they could pretend to be human. So, robot Spot is not gonna pretend. It could pretend it's human all it wants. (Lex laughs) You could put ChatGPT on top of it, but you're gonna know it's not human because you have a contact\nwith physical reality. - And you're gonna know\nwhether or not it's doing what you asked it to do. - Yeah, like, it's not gonna, (laughs) I mean, I'm sure it can start,\njust like a dog lies to you. It's like, \"I wasn't part\nof tearing up that couch.\" So, Spot can try\n(Robert laughs) to lie that like, you know, \"It wasn't me that's spilled that thing,\" but you're going to kind\nof figure it out eventually if it happens multiple times, you know. But I think that- - Humanity has figured out\nhow to make machines safe. - [Lex] Yeah. - And there's, you know,\nthe regulatory environments and certification protocols\nthat we've developed in order to figure out how to make machines safe. We don't know and don't have\nthat experience with software that can be propagated\nworldwide in an instant. And so, I think we needed\nto develop those protocols and those tools, and so\nthat's work to be done. But I don't think the fear of that and that work should\nnecessarily impede our ability to now get robots out because again, I think we can judge when\na robot's being safe. - So, and again, just like in that image, there's a fear that\nrobots will take our jobs. I took a ride. I was in San Francisco. I took a ride in a Waymo vehicle. It's an autonomous vehicle, and I've done it several times. They're doing incredible work over there, but (laughs) people flicked it off. - Oh, really?\n- Flicked off the car. So, (laughs) I mean, that's a long story of what the psychology of that is. It could be maybe big tech,\nor I don't know exactly what they're flicking off. - [Robert] Yeah. - But there is an element of, like, \"These robots are taking our jobs,\" or irreversibly transforming society such that it will have economic impact, and the little guy would lose a lot, would lose their well-being. Is there something to\nbe said about the fear that robots will take our jobs? - You know, at every significant\ntechnological transformation, there's been fear of, you\nknow, an automation anxiety- - Yes.\n- that it's gonna have a broader impact than we expected. And there will be, you\nknow, jobs will change. Sometime in the future, we're\ngonna look back at people who manually unloaded\nthese boxes from trailers, and we're gonna say, \"Why did\nwe ever do that manually?\" But there's a lotta people\nwho are doing that job today that could be impacted. But I think the reality\nis, as I said before, we're gonna build the technology so that those very same\npeople can operate it. And so, I think there's a pathway to upskilling and operating. Just like, look, we used\nto farm with hand tools, and now we farm with machines, and nobody has really\nregretted that transformation. And I think the same can be\nsaid for a lot of manual labor that we're doing today. And on top of that, you know, look, we're entering a new world where\ndemographics are gonna have strong impact on economic growth, and you know, the advanced, the first world is losing\npopulation quickly. In Europe, they're worried\nabout hiring enough people just to keep the logistics\nsupply chain going. And you know, part of this\nis the response to COVID, and everybody's sort of thinking back what they really wanna do with their life, but these jobs are getting\nharder and harder to fill. And I'm hearing that over and over again. So, I think, frankly, this\nis the right technology at the right time where we're\ngonna need some of this work to be done, and we're gonna want tools to enhance that productivity. - And the scary impact, I think, again, GPT comes to the rescue in terms of being much more terrifying. (Robert laughs) (Lex laughs) The scary impact of, basically, so I'm, I guess, a software\nperson, so I program a lot. And the fact that people like\nme could be easily replaced by GPT, that's going to have a- - Well, and lot, you know,\nanyone who deals with texts and writing a draft proposal\nmight be easily done with ChatGPT now. - Yeah.\n- where- - Consultants.\n- it wasn't before. - [Lex] Journalists. - Yeah. - [Lex] Everybody is sweating. - But on the other hand, you\nalso want it to be right. And they don't know how\nto make it right yet. But it might make a good starting\npoint for you to iterate. - Boy, do I have to talk to\nyou about modern journalism. (Robert laughs) That's another conversation altogether, but yes, more right than the average, the mean journalist, yes. You spearheaded the weaponization letter Boston Dynamics has. Can you describe what that letter states and the general topic of\nthe use of robots in war? - We authored a letter and then got several leading robotics\ncompanies around the world, including, you know, Unitree in China, and Agility here in the United States, and ANYmal in Europe, and, you know, some others\nto cosign a letter that said we won't put weapons on our robots. And part of the motivation\nthere is, you know, as these robots start to\nbecome commercially available, you can see videos online of\npeople who've gotten a robot, and strapped a gun on it, and\nshown that they can, you know, operate the gun remotely while\ndriving the robot around. And so, having a robot that\nhas this level of mobility and that can easily be configured in a way that could harm somebody\nfrom a remote operator is justifiably a scary thing. And so, we felt like it was important to draw a bright line there and say, \"We're not going to allow this,\" for, you know, reasons that we\nthink ultimately it's better for the whole industry\nif it grows in a way where robots are ultimately\ngoing to help us all and make our lives more\nfulfilled and productive. But by goodness, you're gonna\nhave to trust the technology, to let it in. And if you think the\nrobot's gonna harm you, that's gonna impede the\ngrowth of that industry. So, we thought it was\nimportant to draw a bright line and then publicize that. And our plan is to, you\nknow, begin to engage with lawmakers and regulators. Let's figure out what\nthe rules are going to be around the use of this\ntechnology and use our position as leaders in this industry and technology to help force that issue. In fact, I have a policy,\nyou know, director at my company whose job it\nis to engage with the public, to engage with interested\nparties, including regulators, to sort of begin these discussions. - Yeah, it's a really important topic, and it's an important\ntopic for people that worry about the impact of robots on our society with autonomous weapon systems. So, I'm glad you're sort\nof leading the way in this. You are the CEO of Boston Dynamics. What's it take to be a\nCEO of a robotics company? So, you started as a\nhumble engineer, (laughs) a PhD. Just looking at your journey, what does it take to go\nfrom building the thing to leading a company? What are some of the\nbig challenges for you? - Courage I would put front and\ncenter for multiple reasons. I talked earlier about the\ncourage to tackle hard problems. So, I think there's courage\nrequired not just of me but of all of the people\nwho work at Boston Dynamics. I also think we have a lot\nof really smart people. We have people who are\nway smarter than I am. And it takes a kinda courage\nto be willing to lead them and to trust that you have\nsomething to offer to somebody who probably is maybe a\nbetter engineer than I am. Adaptability, you know, it's\nbeen a great career for me. I never would've guessed I'd stayed in one place for 30 years, and\nthe job has always changed. I didn't really aspire to be\nCEO from the very beginning, but it was the natural\nprogression of things. There always needed to be some level of management that was needed. And so, you know, when I saw something that needed to be done\nthat wasn't being done, I just stepped in to go do it. And oftentimes because we were full of such strong engineers,\noftentimes that was in the management direction, or it was in the business\ndevelopment direction or organizational, hiring. Geez, I was the main person\nhiring at Boston Dynamics for probably 20 years, so I\nwas the head of HR, basically. You know, just willingness\nto sort of tackle any piece of the business that needs\nit and be willing to shift. - Is there something you\ncould say to what it takes to hire a great team? What's a good interview process? How do you know the guy or gal\nare gonna make a great member of a engineering team that's doing some of the hardest work in the world? - You know, we developed\nan interview process that I was quite fond of. It's a little bit of a\nhard interview process because the best\ninterviews, you ask somebody about what they're interested\nin and what they're good at, and if they can describe to you something that they worked on, and you\nsaw they really did the work, they solved the problems, and\nyou saw their passion for it, but what makes that hard is you have to ask a probing question about it. You have to be smart enough\nabout what they're telling you they're expert at to ask a good question. And so, it takes a pretty\ntalented team to do that. But if you can do that,\nthat's how you tap into, \"Ah, this person cares about their work. They really did the work. They're excited about it.\" That's the kind of person\nI want at my company. You know, at Google, they taught us about their interview process, and it was a little bit different. You know, we evolved the\nprocess at Boston Dynamics where it didn't matter\nif you were an engineer, or you were an administrative assistant, or a financial person, or a technician. You gave us a presentation. You came in, and you\ngave us a presentation. You had to stand up and\ntalk in front of us. And I just thought that was\ngreat to tap into those things I just described to you. At Google, they taught us,\nand I understand why, right. They're hiring tens of\nthousands of people. They need a more standardized process. So, they would sort of\nerr on the other side where they would ask\nyou a standard question. I'm gonna ask you a programming question, and I'm just gonna ask you to, you know, write code in front of me. That's a terrifying, you\nknow, application process. - [Lex] Yeah. - It does let you compare\ncandidates really well, but it doesn't necessarily\nlet you tap into who they are. - Yeah.\n- (laughs) Right? 'Cause you're asking them\nto answer your question instead of you asking them about\nwhat they're interested in. But frankly, that\nprocess is hard to scale. And even at Boston Dynamics, we're not doing that\nwith everybody anymore. But we are still doing that with, you know, the technical people because we too now need to sort of increase our rate of hiring. Not everybody's giving\na presentation anymore. - But you're still\nultimately trying to find that basic seed of passion- - Yeah, and talent.\n- for the world. - You know, did they really do it? Did they find something\ninteresting or curious, you know, and do they care about it? (laughs) - I think somebody I admire is Jim Keller, and he likes details. So, one of the ways you could, (laughs) if you get a person to talk\nabout what they're interested in, how many details, like, how much of the whiteboard can you fill out? - Yeah.\n- What they- - Well, I think you figure out\ndid they really do the work if they know some of the details. - Yes.\n- And if they have to wash over the details,\nwell, then they didn't do it. - They didn't do it.\n(Robert laughs) 'Cause especially with engineering, the work is in the details. - Yeah. - I have to go there briefly (sighs) just to get your kind of thoughts on the long-term future of robotics. There's been discussions on the GPT side, on the large language model\nside of whether there's consciousness inside\nthese language models. And I think there's\nfear, but I think there's also excitement or at least the wide world of opportunity and\npossibility in embodied robots having something like,\nlet's start with emotion, love towards other human beings and perhaps the display, real\nor fake, of consciousness. Is this something you think about in terms of long-term future? Because, as we've talked about, people do anthropomorphize these robots. It's difficult not to project some level of, I use the word sentience, some level of sovereignty, identity, all the things we think as human. That's what anthropomorphization\nis, is we project humanness onto mobile, especially legged robots. Is that something almost from a science-fiction\nperspective you think about? Or, do you try to avoid ever, try to avoid the topic of\nconsciousness altogether? - I'm certainly not an expert in it, (Lex laughs)\nand I don't spend- - Is anybody?\n- a lot of time thinking about this, right? And I do think it's fairly\nremote for the machines that we're dealing with. You're right that people anthropomorphize. They read into the robots'\nintelligence and emotion that isn't there because\nthey see physical gestures that are similar to\nthings they might even see in people or animals. I don't know much about how these large\nlanguage models really work. I believe it's a kind\nof statistical averaging of the most common responses, you know, to a series of words, right? It's sort of a very\nelaborate word completion. And I'm dubious that that has anything to do with consciousness. And I even wonder if that model of sort of simulating consciousness\nby stringing words together that are statistically\nassociated with one another, whether or not that kind of knowledge, if you wanna call that knowledge, would be the kind of knowledge\nthat allowed a sentient being to grow or evolve. It feels to me like there's\nsomething about truth or emotions that's just a very\ndifferent kind of knowledge that is absolute. The interesting thing about\ntruth is it's absolute, and it doesn't matter how\nfrequently it's represented in the worldwide web. If you know it to be\ntrue, it it can only be, it may only be there once,\nbut by God, that's true. And I think emotions are a\nlittle bit like that, too. You know something, you know, and I just think that's a\ndifferent kind of knowledge than the way these large\nlanguage models derive sort of simulated- - It does seem that-\n- intelligence. - things that are true very well might be statistically well\nrepresented on the Internet because the Internet's made up of humans. So, I tend to suspect that\nlarge language models are going to be able to simulate\nconsciousness very effectively. And I actually believe that current GPT 4, when fine-tuned correctly,\nwould be able to do just that. And there's going to be a lot of very complicated\nethical questions that have to be dealt with that have\nnothing to do with robotics and everything to do with- - There needs to be some\nprocess of labeling, I think, (laughs) what is true because there is also\ndisinformation available on the web, and these models are going\nto consider that kind of information as well. And again, you can't average\nsomething that's true and something that's\nuntrue and get something that's moderately true. (laughs) It's either right, or it's wrong. And so, how is that process,\nand this is obviously something that the purveyors of\nthese, Bard and ChatGPT, I'm sure this is what they're working on. - Well, if you interact on\nsome controversial topics with these models, they're\nactually refreshingly nuanced. Well, you realize there's\nno one truth, you know. What caused the war in Ukraine, right? Any geopolitical conflict, you\ncan ask any kind of question, especially the ones that\nare politically tense, divisive, and so on. GPT is very good at presenting, it presents the different hypotheses. It presents calmly\n(laughing) sort of the amount of evidence for each one. It's really refreshing. It makes you realize\nthat truth is nuanced, and it does that well. And I think, with consciousness, it would very accurately say, \"Well, it sure as hell feels\nlike I'm one of you humans, but where's my body? (Robert laughs) I don't understand.\" Like, you're going to be confused. The cool thing about GPT is\nit seems to be easily confused in the way we are. Like, you wake up in a new\nroom, and you ask, \"Where am I?\" It seems to be able to\ndo that extremely well. It'll tell you one thing, like a fact about when a war started,\nand when you correct it, say, \"Well, that's not consistent,\" it'll be confused. It'll be, \"Yeah, you're right.\" It'll have that same\nelement, childlike element with humility of trying to\nfigure out its way in the world. And I think that's a really tricky area to sort of figure out with\nus humans of what we want to allow AI systems to say to us. Because then, if there's\nelements of sentience that are on display, you can then start to manipulate human emotion,\nall that kinda stuff. But I think that's a really serious and aggressive discussion\nthat needs to be had (laughing) on the software side. I think, again, embodiment,\nrobotics are actually saving us from the arbitrary scaling\nof software systems versus creating more problems. But that said, I really believe in that connection\nbetween human and robot. There's magic there. And I think there's also, I think, a lot of money to be made there. And Boston Dynamics is leading the world in the most elegant movement done by robots. (Robert laughs) So, I can't wait-\n- Well, thank you. - to what maybe other\npeople that built on top of Boston Dynamics robots or\nBoston Dynamics by itself. So, you had one wild career, one place on one set of problems\nbut incredibly successful. Can you give advice to young\nfolks today in high school, maybe in college looking\nout into this future where so much robotics and AI seems to be defining the trajectory of human civilization. Can you give 'em advice\non how to have a career they can be proud of or how to have a life they can be proud of? - Well, I would say, you\nknow, follow your heart and your interest. Again, this was an organizing\nprinciple, I think, behind the Leg Lab at MIT that turned into a value at Boston Dynamics, which was follow your curiosity. Love what you're doing. You'll have a lot more fun,\nand you'll be a lot better at it as a result. I think it's hard to plan, you know. Don't get too hung up on\nplanning too far ahead. Find things that you like doing and then see where it takes you. You can always change direction. You will find things that, you know, \"Ah, that wasn't a good move. I'm gonna pack up and\ngo do something else.\" So, when people are\ntrying to plan a career, I always feel like, \"Ah,\nthere's a few happy mistakes that happen along the way\nand just live with that it.\" You know, but make choices then. So, avail yourselves to these\ninteresting opportunities, like when I happened to run\ninto Marc down in the lab, the basement of the AI lab, but be willing to make a decision and then pivot if you see something\nexciting to go at, you know, 'cause, if you're out and about enough, you'll find things like\nthat that get you excited. - So, there was a feeling\nwhen you first met Marc and saw the robots that\nthere's something interesting. - \"Oh, boy, I gotta go do this.\" There was no doubt.\n(Lex laughs) (Robert laughs) - What do you think in 100 years, whoo, what do you think Boston\nDynamics is doing? Even bigger, what do you think is the role of robots in society? Do you think we'll be seeing\nbillions of robots everywhere? Do you think about that long-term vision? - Well, I do think that, I think that robots will be ubiquitous, and they will be out amongst us, and they'll be certainly doing, you know, some of the hard labor that we do today. I don't think people don't wanna work. People wanna work. People need to work to,\nI think, feel productive. We don't wanna offload all\nof the work to the robots 'cause I'm not sure if people would know what to do with themselves.\n(Lex laughs) And I think just self-satisfaction\nand feeling productive is such an ingrained part of being human that we need to keep doing this work. So, we're definitely gonna have to work in a complimentary fashion,\nand I hope that the robots and the computers don't end up being able to do all the creative work. Right?\n- Yeah. - 'Cause that's the part that's, you know, that's the rewarding. The creative part of solving\na problem is the thing that gives you that serotonin\nrush that you never forget, you know, (laughs) or that adrenaline rush that you never forget, and\nso, you know, people need to be able to do that creative work and just feel productive, and sometimes you can feel productive over fairly simple work\nthat's just well done, you know, and that you\ncan see the result of. So, yeah, you know, I don't know, there was a cartoon, was it \"Wall-E,\" where they had this big ship, and all the people were just overweight, lying on their beach chairs kinda sliding around on the deck of the movie because they didn't do anything anymore. - Yeah.\n- Well, we definitely don't wanna\nbe there, (laughs) you know. We need to work in some\ncomplimentary fashion where we keep all of our\nfaculties and our physical health, and we're doing some labor, right, but in a complimentary fashion somehow. - And I think a lotta that has\nto do with the interaction, the collaboration with\nrobots and with AI systems. I'm hoping there's a lot of\ninteresting possibilities there. - I think that could\nbe really cool, right? If you can work in an interaction\nand really be helpful, robots, you know, you can\nask a robot to do a job you wouldn't ask a person to do, and that would be a real asset. You wouldn't feel guilty\nabout it, you know. (laughs) You'd say, \"Just do it.\" - Yeah.\n- It's a machine. And I don't have to have\nqualms about that, you know. - The ones that are machines,\nI also hope to see a future, and it is hope. I do have optimism about the future where some of the robots are pets, have an emotional connection to us humans and because one of the problems\nthat humans have to solve is this kind of general loneliness. The more love you have in your life, the more friends you have in your life, I think that makes a more\nenriching life, helps you grow. And I don't fundamentally see why some of those friends can't be robots. - There's an interesting\nlong-running study, maybe it's in Harvard, just\nnice report article written about it recently. They've been studying this group of a few thousand people\nnow for 70 or 80 years. And the conclusion is that\ncompanionship and friendship are the things that make for\na better and happier life. And so, I agree with you, and I think that could\nhappen with a machine that is probably, you know,\nsimulating intelligence. I'm not convinced there will\never be true intelligence in these machines, sentience. But they could simulate it, and they could collect your history. You know, I guess it remains to be seen whether they can establish that real deep, you know, when you sit with a friend, and they remember something\nabout you and bring that up, and you feel that connection,\nit remains to be seen if a machine's gonna be\nable to do that for you. - Well, I have to say, inklings of that already started happening for me. Some of my best friends are robots. (Robert laughs) And I have you to thank\nfor leading the way in the accessibility, and the\nease of use of such robots, and the elegance of their movement. Robert, you're an incredible person. Boston Dynamics is an incredible company. I've just been a fan for many, many years for everything you stand for, for everything you do in the world. If you're interested in\ngreat engineering, robotics, go join them. Build cool stuff. I'll forever celebrate\nthe work you're doing, and it's just a big honor that you would sit with me today and talk. It means a lot, so thank you so much. Keep doing great work. - Thank you, Lex. I'm honored to be here,\nand I appreciate it. It was fun. - Thanks for listening\nto this conversation with Robert Playter. To support this podcast, please check out our sponsors in the description. And now, let me leave you some words from Alan Turing in 1950, defining what is now\ntermed the Turing test. \"A computer would deserve\nto be called intelligent if it could deceive a human into believing that it was human.\" Thank you for listening and\nhope to see you next time."
}