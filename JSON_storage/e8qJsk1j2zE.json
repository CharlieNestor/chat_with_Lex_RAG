{
  "video_id": "e8qJsk1j2zE",
  "title": "Joscha Bach: Life, Intelligence, Consciousness, AI & the Future of Humans | Lex Fridman Podcast #392",
  "date": "2023-08-01",
  "transcript": [
    {
      "timestamp": "0:00",
      "section": "Introduction",
      "text": "- There is a certain perspective\nwhere you might be thinking what is the longest possible\ngame that you could be playing? A short game is, for instance, cancer is playing a shorter\ngame than your organism. Cancer is an organism playing a shorter game\nthan the regular organism. And because the cancer cannot\nprocreate beyond the organism, except for some infectious cancers like the ones that eradicated\nthe Tasmanian devils, you typically end up with a situation where the organism dies\ntogether with the cancer, because the cancer has\ndestroyed the larger system due to playing a shorter game. And so, ideally, you want to, I think, build agents that play the\nlongest possible games. And the longest possible games is to keep entropy at bay as long as possible by\ndoing interesting stuff. - The following is a\nconversation with Joscha Bach, his third time on this podcast. Joscha is one of the most brilliant and fascinating minds in the world, exploring the nature of intelligence, consciousness, and computation. And he's one of my\nfavorite humans to talk to about pretty much anything and everything. This is the \"Lex Fridman Podcast\". To support it, please check out our\nsponsors in the description. And now, dear friends, here's Joscha Bach."
    },
    {
      "timestamp": "1:15",
      "section": "Stages of life",
      "text": "You wrote a post about levels of lucidity. Quote, \"As we grow older, it becomes apparent that\nour self-reflexive mind is not just gradually\naccumulating ideas about itself, but that it progresses in\nsomewhat distinct stages.\" So, there's seven of the stages. Stage one, reactive survival, infant. Stage two, personal self, young child. Stage three, social self,\nadolescence, domesticated adult. Stage four is rational\nagency, self-direction. Stage five is self-authoring.\nThat's full adult. You've achieved wisdom, but\nthere's two more stages. Stage six is enlightenment.\nStage seven is transcendence. Can you explain each or the interesting parts\nof each of these stages and what's your sense why there are stages of lucidity as we progress through life in this too short life? - This model is derived from concept by the\npsychologist, Robert Kegan, and he talks about the\ndevelopment of the self as a process that happens in principle by some kind of\nreverse-engineering of a mind, where you gradually\nbecome aware of yourself and thereby build\nstructure that allows you to interact deeper with\nthe world and yourself. And I found myself using this model not so much as a developmental model. I'm not even sure if it's a\nvery good developmental model, because I saw my children not\nprogressing exactly like that. And I also suspect that you\ndon't go through these stages necessarily in succession. And it's not that you\nwork through one stage, and then you get into the next one. Sometimes you revisit them. Sometimes stuff is happening in parallel, but it's, I think, a useful framework to look at what's present and the structure of a person and how they interact with the world and how they relate to themselves. So, it's more like a\nphilosophical framework that allows you to talk\nabout how minds work. And at first, when we are born, we don't have a personal\nself yet, I think. Instead, we have an attentional self. And this attentional self is\ninitially in the infant task, is building a world model and also an initial model of the self. But mostly, it's building\na game engine in the brain that is tracking sensory data\nand uses it to explain it. And in some sense, you could compare it to game engine like \"Minecraft\" or so, so colors and sounds. People are all not physical objects. They are creation of our\nmind at a certain level. Of course, screening models\nthat are mathematical that use geometry and that\nuse manipulation of objects, and so on to create scenes in which we can find ourselves\nand interact with them. - [Lex] So, \"Minecraft\". (Lex chuckles)\n- Yeah, and this personal self is something that is more or less created after the world is finished, after it's trained into the system, after it has been constructed. And this personal self is an agent that interacts with the outside world. And the outside world is not\nthe world of quantum mechanics, not the physical universe, but it's the model that has\nbeen generated in our own mind. And this is us and we experience ourself interacting with that outside world that is created inside of our own mind. And outside of ourself, there's feelings and they presented our interface\nwith this outside world. They pose problems to us. These feelings are basically attitudes that our mind is computing that tell us what's needed in the world, the things that we are drawn to, the things that we are afraid of. And we are tasked with\nsolving this problem of satisfying the needs,\navoiding the aversions, following on our inner\ncommitments, and so on. And also modeling ourselves\nand building the next stage. So, after we have this personal\nself in stage two online, many people form a social self. And this social self allows the individual to experience themselves\nas part of a group. It's basically this thing that when you are playing\nin a team for instance, you don't notice yourself\njust as a single note that is reaching out into the world, but you're also looking down, you're looking down from this entire group and you see how this group\nis looking at this individual and everybody in the\ngroup is in some sense, emulating this group\nspirit to some degree. And in this state, people\nare forming their opinions by assimilating them from this group mind, where we see they gain the ability to act a little bit like a hive mind. - But are you also modeling\nthe interaction of how opinion and shapes and forms\nthrough the interaction of the individual nodes within the group? - Yeah, the way in which\npeople do it in this stage is that they experience what are the opinions of my environment. They experience the relationship that I have to their environment and they resonate with people around them and get more opinions in this through this interaction to the way in which they relate to others. And at stage four, you basically understand\nthat stuff is true and false independently\nwhat other people believe. And you have agency over your own beliefs. In that stage, you basically\ndiscover epistemology, the rules about determining\nwhat's true and false. - So, you start to learn how to think. - Yes. I mean, at some level, you're always thinking you\nare constructing things. And I believe that this ability to reason about your mental representation is what we mean by thinking. It's an intrinsically reflexive process that requires consciousness. Without consciousness, you cannot think. You can generate the content of feelings, and so on, outside of consciousness. It's very hard to be conscious\nof how your feelings emerge, at least in the early\nstages of development. But thoughts is something\nthat you always control. And if you are a nerd like me, you often have to skip stage three, because you'd like the\nintuitive empathy with others. 'Cause in order to resonate with a group, you need to have a quite\nsimilar architecture. And if people are wired differently, then it's hard for them to\nresonate with other people and basically have empathy, which is not the same as compassion, but it is a shared\nperceptual mental state. Empathy happens not just via inference about the mental states of others, but it's a perception of what other people feel\nand where they're at. - Can't you not have empathy while also not having\na similar architecture, cognitive architecture as\nthe others in the group? - I think, yes, but I\nexperienced that too. But you need to build something that is like a meta architecture. You need to be able to embrace\nthe architecture of the other to some degree or find some shared\n(Joscha drowns out Lex) common ground.\n(Lex laughs) And it's also this issue\nthat if you are a nerd, normally it's often, basically, neurotypical people have difficulty to resonate with you. And as a result, they have\ndifficulty understanding you unless they have enough wisdom to feel what's going on there. - Well, aren't we, isn't the whole process of the stage three is to figure out the\nAPI to the other humans that have different architecture and you yourself publish\npublic documentation for the API that people can\ninteract with for you? (laughs) Isn't this the whole\nprocess of socializing? - My experience as a child growing up was that I did not find any way to interface with the stage three people. And they didn't do that with me. So, took me-\n- Did you try? - Yeah, of course, I tried it very hard. But it was only when I\nentered the mathematics school at ninth grade, lots of\nother nerds were present that I found people that I\ncould deeply resonate with and had the impression that,\nyes, I have friends now. I found my own people. And before that, I felt\nextremely lonely in the world. There was basically\nnobody I could connect to. And I remember there was one\nmoment in all these years where I was in, there\nwas a school exchange and it was a Russian boy, kid from the Russian garisson\nstationed in Eastern Germany. He visit our school and we played a game of\nchess against each other. And we looked into each other's eyes and we sat there for two hours\nplaying this game of chess. And I had the impression\nthis is a human being. He understands what I understand. We didn't even speak the same language. - I wonder if your life\ncould have been different if you knew that it's\nokay to be different, to have a different architecture, whether accepting that the\ninterface is hard to figure out. It takes a long time to figure out and it's okay to be different. In fact, it's beautiful to be different. - It was not my main concern. My main concern was\nmostly that it was alone. It was not the so much the question, is it okay to be the way I am? I couldn't do much about it,\nso I had to deal with it. But my main issue was that I was not sure if I would ever meet anybody growing up that I would connect\nto at such a deep level that I would feel that I could belong. - So, there's a visceral,\nundeniable feeling of being alone. - Yes. And I noticed the same thing when I came into the\nmath school that I think at least half, probably\ntwo thirds of these kids were severely traumatized\nas children growing up. And in large part due to being alone, because they couldn't\nfind anybody to relate to. - Don't you think everybody's alone deep down?\n- No, no. - No? (both laughing) All right.\n- I'm not alone. I'm not alone anymore.\n- Fair enough. - It took me some time to update and to get over the\ntrauma time, and so on. But I felt that in my\n20s, I had lots of friends and I had my place in the world and I had no longer doubts that I would never be alone again. - Is there some aspect to\nwhich we're alone together? You don't see a deep loneliness\ninside yourself still? - No. Sorry. (laughs) - Okay. So, that's the nonlinear progression through the stages, I suppose.\n- Mm. - You caught up on stage three at some point?\n- Yes. So, we're at stage four. And so, basically, I find that many nerds jump straight into stage\nfour, bypassing stage three. - [Lex] Do they return to it then later? - Yeah, of course. They\nsometimes they do, not always. - Yeah.\n- They question, is basically do you stay\na little bit autistic or do you catch up? And I believe you can catch up, you can build this missing structure. - Yeah.\n- And basically, experience yourself as part of a group, learn intuitive empathy\nand develop the sense, this perceptual sense of\nfeeling what other people feel. And before that, I could only basically feel this when I was deeply in\nlove with somebody and (indistinct) - So, there's a lot of\nfriction to feeling that way. To only with certain people as opposed to it comes naturally. - Yeah.\n- It's frictionless. - But this is something\nthat basically later I felt started to resolve itself for me - Huh.\n- to a large degree. - [Lex] What was the trick? - In many ways, growing\nup and paying attention. Meditation did help. I had some very crucial experiences in getting close to people,\nbuilding connections, cuddling a lot in my student years. - So, really paying attention - [Joscha] Yeah. - to the, what is it? To the feeling another human being fully. - Loving other people and\nbeing loved by other people and building a space in\nwhich you can be safe and can experiment and touch a lot and be\nclose to somebody a lot. And over time basically, at some point, you realize, oh, it's no\nlonger that I feel locked out, but I feel connected and I experience where\nsomebody else is at. And normally, my mind is racing very fast at a high frequency. So, it's not always working like this, sometimes works better,\nsometimes it works less. But also don't see this as a pressure. It's more, it's interesting\nto observe myself which frequency I'm at and at which mode\n- Mm-hmm. - somebody else is at. - Yeah. Man, the mind is\nso beautiful in that way. Sometimes it comes so natural to me. So easy to pay attention, pay attention to the world\nfully, to other people fully. And sometimes the stress over\nsilly things is overwhelming. - [Joscha] Mm-hmm. - It's so interesting that the mind's that\nrollercoaster in that way."
    },
    {
      "timestamp": "13:37",
      "section": "Identity",
      "text": "- At stage five, you discover\nhow identity is constructed. - Self-authoring.\n- You realize that your values are not terminal, but they're instrumental to\nachieving a world that you like and aesthetics that you prefer. - Yeah.\n- And the more you understand this,\nthe more you get agency over how your identity is constructed and you realize that identity and interpersonal interaction is a costume and you should be able to\nhave agency over that costume. It's useful to be a costume. It tells something to others and it allows to interface in roles. But being locked into\nthis is a big limitation. - The word costume implies that it's fraudulent in some way. Is costume a good word for you? Like we present ourselves\n- No. - to the world. - In some sense, I learned a lot about\ncostumes at Burning Man. Before that, I did not\nreally appreciate costumes and saw them more as\nuniforms, like wearing a suit if you are working in a bank or if you are trying\nto get startup funding from a VC in Switzerland. Then, you dress up in a particular way. And this is mostly to show the other side that you are willing to play by the rules and you understand what the rules are. But there is something deeper. When you are at Burning Man, your costume becomes self-expression and there is no boundary\nto the self-expression. You're basically free\nto wear what you want to express other people\nwhat you feel like this day and what kind of interactions\nyou want to have. - Is the costume a kind of\nprojection of who you are? - That's very hard to say, because the costume also depends on what other people see in the costume. And this depends on the context\n- Sure. - that the other people understand. So, you have to create\nsomething if you want to, that is legible to the other side. And that means something to yourself. - Do we become prisoners of the costume? 'Cause everybody expects us to- - Some people do. But I think\n- Yeah. - that once you realize that you wear a costume at Burning Man, a variety of costumes, realize that you cannot\nnot wear a costume. - Yeah.\n- Right. Basically, everything that you wear and present to others is\nsomething that is to some degree, in addition to what you are deep inside. - So, this stage in parentheses, you put full adult, comma, wisdom. Why is this full adult? Why\nwould you say this is full? And why is it wisdom? - It does allow you to understand why other people have different\nidentities from yours. - Ah.\n- And it allows you to understand that the\ndifference between people who vote for different parties and might have very different opinions and different value systems is often the accident\nof where they're born and what happened after that to them and what traits they got\nbefore they were born. And at some point, you\nrealize the perspective where you understand that everybody could be you in a different timeline if you just flip those bits. - How many costumes do you have? - I don't count, but in- - [Lex] More than one? - Yeah, of course. - How easy is to do costume\nchanges throughout the day? - It's just a matter\nof energy and interest. When you are wearing your pajamas and you switch out of\nyour pajamas into say, a work short and pants,\nyou're making costume change. And if you are putting on a gown, you're making a costume change. - And you could do the\nsame with personality? - You could if that's what you're into. There are people which\nhave multiple personalities for interaction in multiple worlds. So, if somebody works in a store and put up a storekeeper personality, when you're presenting yourself at work, you develop a subpersonality for this. And the social persona for\nmany people is in some sense, a puppet that they're\nplaying like a marionette. And if they play this all the time, they might forget that there\nis something behind this. There's something what it\nfeels like to be in your skin. And I guess it's very helpful if you're able to get back into this. And for me, it's the other way around is relatively hard for me. It's pretty hard to learn how to play consistent social roles. For me, it's much easier just to be real. - Mm-hmm. Or not real,\nbut to have a one costume. - No, it's not quite the same. So, basically, when you are\nwearing a costume at Burning Man and say you are an\nextraterrestrial prince, - [Lex] Yeah. - there's something where you\nare expressing in some sense something that's closer to yourself than the way in which you hide yourself behind a standard closing when you go out in the\ncity, in the default world. And so, this costume that\nyou're wearing at Burning Man allows you to express more of yourself and you have a shorter distance\nof advertising to people, what kind of person you are, what kind of interaction you\nwould want to have with them. And so, you get much\nearlier into Media Express, And I believe it's regrettable that we do not use the opportunities that we have with custom-made clothing now to wearer costumes that\nare much more stylish, that are much more custom-made, that are not necessarily part of a fashion in which you express which\nmilieu you're part of and how up-to-date you are. But you also express how\nyou are as an individual and what you want to do today and how you feel today and\nwhat you intend to do about it. - Well, isn't it easier\nnow in a digital world to explore different costumes? That's the idea with virtual\nreality, that's the idea. Even with Twitter in\ntwo-dimensional screens. You can swap all costumes. You could be as weird as\nyou want. It's easier. For Burning Man, you have to order things, you have to make things, you have to, it's more effort to put on-\n- It's even better if you make them yourself. - Sure, but it's just\neasier to do digitally. - It's not about easy. It's\nabout how to get it right. And for me,\n- Sure. - the first Burning Man experience, I got adapted by a bunch\nof people in Boston who dragged me to Burning Man. And we spent a few weekends\ndoing costumes together - Oh.\n- and that was an important part of the\nexperience where the camp bonded. But people got to know each other and we basically grew into the experience that we would have later. - So, the extraterrestrial prince is based on a true story? - Yeah.\n- Hmm. I can only imagine what\nthat looks like, Joscha. (Joscha laughing)"
    },
    {
      "timestamp": "20:12",
      "section": "Enlightenment",
      "text": "- Okay. So, stage six.\n- Stage six. - At some point, you can collapse\nthe division between self, a personal self and world generator again. And a lot of people get\nthere via meditation or some of them get\nthere via psychedelics. Some of them by accident. And you suddenly notice that\nyou are not actually a person, but you are a vessel\nthat can create a person. And the person is still there. You observe that personal self, but you observe the personal\nself from the outside. - [Lex] Mm-hmm. - And you notice it's a representation. And you might also notice that the word that is being created as\na representation, if not, then you might experience\nthat I am the universe, I'm the thing that is creating everything. And of course what you're\ncreating is not quantum mechanics and the physical universe. What you're creating is the game engine - Mm-hmm.\n- that is updating the world and you're creating your\nvalence, your feelings, and all the people inside of that world, including the person that you identify with\nyourself in this world. - Are you creating the game engine or are you noticing the game engine? - You notice how you're\ngenerating the game engine. And when you are dreaming at night, you can, if you have a lucid dream, you can learn how to do this deliberately. And in principle, you can\nalso do it during the day. And the reason why we don't get to do this from the beginning and why we don't have agency\nof our feelings right away is because we would game it before they have the\nnecessary amount of wisdom to deal with creating\nthis dream that we are in. - You don't want to get access\nto cheat codes too quickly. Otherwise, you won't enjoy the game.\n- So, stage five is already pretty rare and\nstage six is even more rare. You most basically find this most with advanced Buddhist\nmeditators, and so on, that dropping into this stage and can induce it at will\nand spend time in it. - So, stage five requires\na good therapist. Stage six requires a good Buddhist, spiritual leader.\n- Yes. So, it is for instance, could be that it's the right thing to do, but it's not that these stages give you scores or levels\nthat you need to advance to. It's not that the next stage is better. - Mm-hmm.\n- You live your life in the mode that works\nbest at any given moment. And when your mind decides that you should have a\ndifferent configuration, then it's building that configuration. And for many people, they stay happily at stage three and experience it themselves\nas part of groups. And there's nothing wrong with this. And for some people, this doesn't work and they're forced to build more agency over their rational beliefs than this and construct their norms rationally. And so, they go to this level.\n- Mm-hmm. - And stage seven is something that is more or less hypothetical. That would be the stage in which it's basically a transhumanist stage in which you understand how you work, in which the mind fully\nrealizes how it's implemented and can also in principle, enter different modes in\nwhich it could be implemented. And that's a stage that as far as I understand,\nis not open to people yet. - Oh, but it is possible through\nthe process of technology. - Yes. And who knows if there\nare biological agents that are working at\ndifferent time skills than us that basically become aware of the way in which they're implemented on ecosystems and can change that implementation and have agency over how they\nimplemented in the world. And what I find interesting about the discussion about AI alignment, that it seems to be following\nthese stages very much. Most people seem to be in stage three, also according to Robert Kegan. - Mm-hmm.\n- I think he says that about 85% of people\nare in stage three and stay there.\n- Mm-hmm. - And if you're in stage three and your opinions are the\nresult of social stimulation, then what you're mostly worried about in the AI is that the AI\nmight have the wrong opinions. - Yeah.\n- So, if the AI says something racist or\nsexist, we are all lost, because we will assimilate the\nwrong opinions from the AI. And so, we need to make sure that the AI has the right opinions and the right values\nand the right structure. And if you're at stage four,\nthat's not your main concern. And so, most nerds don't really worry about the algorithmic bias and\nthe model that it picks up, because if there's something\nwrong with this bias, the AI ultimately will prove it. At some point, we'll gather there, that it makes mathematical\nproofs about reality. And then, it will figure out\nwhat's true and what's false. But you're still worried that AI might turn you into paperclips, because it might have the wrong values. So, if it's set up as\nthrough a wrong function that controls its direction in the world, then it might do something\nthat is completely horrible and there's no easy way to fix it. - So, that's more like a stage four rationalist kind of worry.\n- Yes. And if you are at stage five, you're mostly worried that AI is not going to be\nenlightened fast enough, because you realize that the game is not so much about intelligence, but about agency, about the\nability to control the future. And the identity is instrumental to this. And if you are human being,\nI think at some level, you ought to choose your own identity. You should not have somebody else pick the costume for\nyou, and then wear it. But instead, you should be mindful about what you want to be in this world. And I think if you are an\nagent that is fully malleable, that can provide its own source code like an AI might do at some point, then the identity that you will\nhave is whatever you can be. And in this way, the AI\nwill maybe become everything like a planetary control system. And if it does that, then if\nwe want to coexist with it, it means that it will have\nto share purposes with us. So, it cannot be a\ntransactional relationship. We will not be able to\nuse reinforcement learning with human feedback to\nhardwire its values into it. But this has to happen. It's\nprobably that it's conscious. So, it can relate to our\nown mode of existence where an observer is observing itself in real time and within\ncertain temporal frames. And the other thing is\nthat it probably needs to have some kind of\ntranscendental orientation, building shared agency.\n- Mm-hmm. - And in the same way as we do when we are able to\nenter up with each other into non-transactional relationships. And I find that something that because the stage five is so rare, it's missing in much of the discourse. And I think that we need in some sense, focus on how to formalize\nlove, how to understand love, and how to build it into the machines that we are currently building and that are about to\nbecome smarter than us."
    },
    {
      "timestamp": "26:43",
      "section": "Adaptive Resonance Theory",
      "text": "- Well, I think this is a good opportunity to try to sneak up to the\nidea of enlightenment. So, you wrote a series of good tweets about consciousness and panpsychism. So, let's break it down. First you say, \"I suspect the experience that leads to the panpsychism\nsyndrome of some philosophers and other consciousness enthusiasts represents the realization\nthat we don't end at the self, but share a resonant\nuniverse representation with every other observer\ncoupled to the same universe.\" This actually eventually leads us to a lot of interesting\nquestions about AI and AGI. But let's start with this representation. What is this resonant\nuniverse representation and what do you think do we\nshare such a representation? - The neuroscientist, Grossberg, has come up with the\ncognitive architecture that he calls the\nadaptive resonance theory. And his perspective is that our neurons can be understood as oscillators that are resonating with each other and with outside phenomena. So, the coarse grain model of the universe that we are building in some sense is a resonance with objects\nand outside of us in the world. So, basically, we take up patterns of the universe that we are coupled with. And our brain is not so much\nunderstood as circuitry, even though this perspective is valid. But it's almost an ether in which the individual\nneurons are passing on - [Lex] Mm-hmm. - Chemical-electrical signals or arbitrary signals across all modalities that can be transmitted between cells, simulate each other in this way and produce patterns that they modulate while passing them on. And this speed of signal\nprogression in the brain is roughly at the speed\nof sound incidentally, because the time that it takes for the signals to hop from cell to cell, which means it's relatively\nslow with respect to the world. It takes in a appreciable\nfraction of a second for a signal to go through\nthe entire neocortex, something like a few hundred milliseconds. And so, there's a lot of\nstuff happening in that time where the signal is\npassing through your brain, including in the brain itself. So, nothing in the brain is assuming that stuff\nhappens simultaneously. Everything in the brain\nis working in a paradigm where the world has already moved on when you are ready to do the\nnext thing to your signal, including the signal\nprocessing system itself. It's quite a different paradigm than the one in our digital computers where we currently assume\nthat your GPU or CPU is pretty much globally in the same state. - So, you mentioned\nthere the non-dual state and say that some people\nconfuse it for enlightenment. - Yeah.\n- What's the non-dual state? - There is a state in which you notice that\nyou are no longer a person and instead, you are\none with the universe. And that's-\n- So, that speaks to the resonance.\n- Yes. But this one with the\nuniverse is of course not accurately modeling that\nyou are indeed some God entity or indeed the universe is\nbecoming aware of itself even though you get this experience. I believe that you get this experience, because your mind is modeling the fact that you are no longer identified with the personal self and that state. But you have transcended this division between the self model\nand the wealth model and you're experiencing\nyourself as your mind, as something that is\nrepresenting a universe. - But that's still part of the model. - Yes. So, it's inside of the model. Still, you are still\n- Yes. - inside of patterns that are generated in your\nbrain and in your organism. And what you are now experiencing is that you're no longer\nthis personal self in there, but you are the entirety of\nthe mind and its contents. - Why is it so hard to get there? - A lot of people who get\ninto the state think this or are associated with enlightenment, I suspect it's a favorite training goal for a number of meditators. But I think that enlightenment\nis in some sense more mundane and it's a step further or sideways. It's the state where you realize that everything is a representation. - Yeah, you say enlightenment is a realization of how\nexperience is implemented. - Yes. So, basically, you notice at some point that your quality can be deconstructed. - Reverse-engineered? What,\nalmost like a schematic of it? What... - You can start with looking at a face, maybe look at your own face in the mirror. - Yeah.\n- Look at your face for a few hours in the\nmirror or for a few minutes. At some point, it will look very weird, because you notice that\nthere's actually no face. You basically start unseeing the face. What you see is the geometry. And then, you can disassemble the geometry and realize how that geometry is being constructed in your mind. And you can learn to modify this. So, basically, you can\nchange these generators in your own mind to shift the face around or to change the construction of the face to change the way in which the\nfeatures are being assembled. - Why don't we do that more often? Why don't we start really\nmessing with reality without the use of drugs or anything else? Why don't we get good\nat this kind of thing? Like intentionally. - Why should we? Why would you what to do-\n- Because you can morph reality into something more pleasant for yourself. Just have fun with it. - Yeah. That is probably\nwhat you shouldn't be doing. Because outside of your personal self, this outer mind\n- Yeah. - is probably a relatively smart agent. And what you often notice is that you have thoughts\nabout how you should live, - Yeah.\n- but you observe yourself doing different things and\nhave different feelings. And that's because your outer\nmind doesn't believe you and doesn't believe\nyour rational thoughts. - Well, can't you just\nsilence the outer mind? - The thing is that the outer mind is usually smarter than you are. Rational thinking is very brittle. - Mm.\n- It's very hard to use logic and symbolic thinking to have an accurate model of the world. So, there is often an underlying system that is looking at your rational thoughts, and then tells you, no, you're\nstill missing something. Your gut feeling is still\nsaying something else. And this can be, for instance, you find a partner that looks\nperfect or you find a deal, and you build a company of whatever that looks perfect to you. And yet, at some level,\nyou feel something is off and you cannot put your finger on it. And the more... The reason about that better looks to you, but the system that is outside still tells you no, no,\nyou're missing something. - And that system is powerful. - People call this intuition. Intuition is this unreflected\npart of your attitude, composition, and computation where you produce a model of\nhow you relate to the world and what you need to do in\nit and what you can do in it and what's going to happen\nthat is usually deeper and often more accurate than your reason."
    },
    {
      "timestamp": "33:31",
      "section": "Panpsychism",
      "text": "- So, if we look at this\nas you write in the tweet, if we look at this more rigorously as a sort of take the\npanpsychist idea more seriously, almost as a scientific\ndiscipline, you write that, quote, \"Fascinatingly, the\npanpsychist interpretation seems to lead to observations\nof practical results to a degree that physics fundamentalists might call superstitious. Reports of long distance telepathy and remote causation are ubiquitous in the general population.\" \"I'm not convinced,\" says Joscha Bach, \"that establishing the\nempirical reality of telepathy would force an update of any part of serious academic physics, but it could trigger\nan important revolution in both neuroscience and AI, from a circuit perspective to a coupled complex resonator paradigm.\" Are you suggesting that\nthere could be some rigorous mathematical wisdom to panpsychist\nperspective on the world? - So, first of all, panpsychism is the\nperspective that consciousness is inseparable for matter in the universe. And I find panpsychism quite unsatisfying, because it does not explain consciousness. It does not explain how this\naspect of matter produced. It is also when I try\nto formalize panpsychism and write down what it actually means. And with a more formal\nmathematical language, it's very difficult to distinguish it from saying that there is a\nsoftware site to the world in the same way as there is software site to what the transistors\nare doing in your computer. So, basically, there's a pattern at a certain core\nscreening of the universe that in some reasons of the universe leads to observers that\nare observing themselves. So, panpsychism maybe is not even when I write it down a position that is distinct from functionalism. But intuitively, a lot of people feel that the activity of matter itself of mechanisms in the world is\ninsufficient to explain it. So, it's something that needs to be intrinsic to matter itself. And you can, apart from this abstract idea, have an experience in which you experience\nyourself as being the universe, - [Lex] Mm-hmm. - which I suspect is basically happening, because you manage to\ndissolve the division between personal self and mind that you establish as an infant when you construct a personal self and transcend it again and\nunderstand how it works. But there is something\ndeeper that is that you feel that you're also sharing\na state with other people, that you have an experience\nin which you notice that your personal self is\nmoving into everything else, that you basically look out\nof the eyes of another person. That every agent in the world that is an observer is in some sense, you. - So, if we-\n- And we forget that we are the same agent. - So, is it that we feel that or do we actually accomplish it? So, is telepathy possible? Is it real? - So, for me, that's this question that I don't really know the answer to. And Turing's famous 1950 paper in which he describes the Turing test, he does speculate about\ntelepathy interestingly and asked himself if telepathy is real. And he thinks that it very well might be. What would be the implication for AI systems that try to be intelligent? Because he didn't see a mechanism by which a computer program\nwould become telepathic. And I suspect if telepathy would exist or if all the reports\nthat you get from people when you ask the normal\nperson on the street, I find that very often they say, \"I have experiences with telepathy.\" The scientists might not\nbe interested in this and might not have a theory about this, but I have difficulty explaining it away. And so, you could say maybe\nthis is a superstition or maybe it's a false memory or maybe it's a little bit of psychosis. Who knows? Maybe somebody wants\nto make their own life more interesting or misremember something. But a lot of people report, I noticed something terrible\nhappened to my partner and I know this is exactly\nthe moment it happened where my child had an accident and I knew that was happening and the child was in a different town. So, maybe it's a false memory where this is later on\nmistakenly attributed. But a lot of people think that this is not\nthe correct explanation. So, if something like this\nwas real, what would it mean? It probably would mean that\neither your body is an antenna that is sending information\nover all sorts of channels, like maybe just\nelectromagnetic radio signals that you're sending over long distances and you get attuned to another person that you spend enough time with to get a few bits out of the ether, - Yeah.\n- to figure out what this person is doing. Or maybe it's also when you\nare very close to somebody and you become empathetic with them. What happens is that you go into a resonance state with them. Similar to when people go into a seance and they go into a trance state and they start shifting Ouija\nboard around on the table. I think what happens is that their minds go by their nervous systems\ninto a resonance state in which they basically create something like a shared dream between them. - Physical closeness or\ncloseness broadly defined? - With physical closeness, it's much easier to experience empathy with someone.\n- Yeah. I suspect it would be difficult for me to have empathy for you if you were in a different town. Also, how would that work? But if you are very close to someone, you pick up all sorts of\nsignals from their body, not just by your eyes, but with your entire body. And if the nervous system\nsits on the other side and the intercellular communication\nsits on the other side and is integrating over all these signals, you can make inferences\nabout the state of the other. And it's not just the personal self that does this by your reasoning, but your perceptual system. And what basically happens is that your representations\nare directly interacting. It's the physical resonant models of the universe that exist in your nervous\nsystem and in your body might go into resonance with others and start sharing some of their states. So, you basically by next to somebody, you pick up some of their vibes and feel without looking at them what they're feeling in this moment. And it's difficult for you\nif you're very empathetic to detach yourself from it and have an emotional state that is completely independent\nfrom your environment. People who are highly\nempathetic are describing this. And now, imagine that a lot\nof organisms on this planet have representations of the environment and operate like this and they are adjacent to\neach other and overlapping. So, there's going to be some degree in which there is basically\nsome chain interaction and we are forming some\nslightly shared representation and no relatively few neuroscientists who consider this possibility. I think big rarity in this regard is Michael Levin who is considering\nthese things in earnest. And I stumbled on this train of thought mostly by noticing that\nthe tasks of a neuron can be fulfilled by other cells as well. They can send different\ntyped chemical messages and physical messages\nto the adjacent cells and learn when to do this and when not make this conditional and become universal\nfunction, approximators. The only thing that they cannot do is telegraph information over axons very quickly, over long distances. So, neurons in this perspective\nare especially adapted kind of telegraph cell that has evolved. So, we can move our muscles very fast, but our body is in principle,\nable to also make models of the world just much, much slower. - Mm-hmm. It's interesting though that at this time, at least in human history, there seems to be a gap\nbetween the tools of science and the subjective\nexperience that people report like you're talking about with telepathy. And it seems like we're not quite there. - No, I think that there is no gap between the tools of\nscience and telepathy. Either it's there or it's not. And it's an empirical question. And if it's there, we should\nbe able to detect it in a lab. - Mm-hmm. So, why is there not a lot of\nMichael Levins walking around? - I don't think that Michael Levin is specifically focused\non telepathy very much. He is focused on self-organization\nin living organisms and in brains, both as a\nparadigm for development and as a paradigm for\ninformation processing. And when you think about how organization processing\nworks in organism, there is first of all, radical locality, which means everything is decided locally from the perspective\nof an individual cell. The individual cell is the agent and the other one is coherence. Basically there needs to be some criterion that determines how these\ncells are interacting in such a way that order emerges on the next level of structure. And this principle of coherence\nof imposing constraints that are not validated\nby the individual parts and lead to coherence structure to basically transcend an agency, where you form an agent on\nthe next level of organization is crucial in this perspective. - It's so cool that radical locality leads to the emergence of complexity - Yeah.\n- at the higher layers. - And I think what Mike\nLevin is looking at is nothing that is outside of the realm of science in any way. It's just that he is\na paradigmatic thinker - Mm-hmm.\n- who develops his own paradigm.\n- Mm-hmm. - And most of the neuroscientists are using a different\nparadigm at this point. And this often happens in science that a field has a few paradigms in which people try to understand reality and build concepts and make experiments. - You're one of those type\nof paradigmatic thinkers. Actually, if we can\ntake a tangent on that, once again, returning to the\nbiblical verses of your tweets."
    },
    {
      "timestamp": "43:31",
      "section": "How to think",
      "text": "(Joscha laughing) You write, \"My public explorations are not driven by audience service, but by my lack of ability for discovering, understanding, or following\nthe relevant authorities. So, I have to develop my own thoughts since I think autonomously, these thoughts cannot\nalways be very good.\" That's you apologizing for\nthe chaos of your thoughts or perhaps not apologizing,\njust identifying. - Yeah. Mm-hmm.\n- But let me ask the question. Since we talked about\nMike Levin and yourself who I think are very radical,\nbig independent thinkers, can we reverse-engineer your process of thinking autonomously? How do you do it? How can humans do it? How can you avoid being influenced by what is it, stage three? - Well, why would you want to do that? You see what is working for you and if it's not working for you, you build another structure\nthat works better for you. And so, I found myself when I was thrown into this world in a state where my intuitions\nwere not working for me. I was not able to understand how I would be able to\nsurvive in this world and build the things\nthat I was interested in, build the kinds of\nrelationship I needed to build, work on the topics that I\nwanted to make progress on. And so, I had to learn. And for me, Twitter is not\nsome tool of publication. It's not something where I put stuff that I entirely believe\nto be true and provable. It's an interactive notebook in which I explore possibilities. And I found that when I tried\nto understand how the mind and how consciousness works,\nI was quite optimistic. I thought I need to be\na big body of knowledge that I can just study and that works. And so, I entered studies in\nphilosophy and computer science and later, psychology and a\nbit of neuroscience, and so on. And I was disappointed by what I found, because I found that the\nquestions of how consciousness and so on works, how emotion works, how it's possible that the\nsystem can experience anything, how motivation emerges in the mind, when not being answered by\nthe authorities that I met and the schools that were around. And instead, I found that\nwith individual thinkers that had useful ideas\nthat sometimes were good, sometimes were not so good. Sometimes were adopted by\na large group of people, sometimes were rejected\nby large groups of people. But for me, it was much more interesting to see these minds as individuals. And in my perspective, thinking is still something\nthat is done not in groups, that has to be done by individuals. - So, that motivated you to become an individual thinker yourself. - I didn't have a choice.\n- Hmm. - Basically, I didn't find a group that thought in a way\nwhere I thought, okay, I can just adopt everything\nthat everybody thinks here and now I understand\nhow consciousness works, or how the mind works\nor how thinking works or what thinking even is, or what feelings are and how\nthey're implemented, and so on. So, to figure all this out, I had to take a lot of\nideas from individuals, and then try to put them together in something that works for myself. And on one hand, I think it\nhelps if you try to go down and find first principles (clears throat) on which you can recreate\nhow thinking works, how languages work,\nwhat representation is, whether representation is necessary, how the relationship\nbetween a representing agent and the world works in general. - But how do you escape the influence, once again, the pressure of the crowd, whether it's you in responding to the pressure or you being\nswept up by the pressure? If you even just look at Twitter,\nthe opinions of the crowd. - I don't feel pressure from the crowd. I'm completely immune to that. (coughs) In the same sense, I don't\nhave respect for authority. I have respect for what an\nindividual is accomplishing or have respect for\nmental firepower, or so. But it's not that I meet somebody and get drawn and unable to speak. Or when a large group of people has a certain idea that\nis different from mine, I don't necessarily feel intimidated, which has often been a\nproblem for me in my life, because I lack instincts that other people develop\nat a very young age and that help with their self-preservation in a social environment. So, I had to learn a lot of\nthings the hard way. (laughs) - Yeah. So, is there a practical advice you can give on how to\nthink paradigmatically, how to think independently? Because you've said, I had no choice. But I think to a degree,\nyou have a choice, because you said you\nwant to be productive. And I think thinking\nindependently is productive if what you're curious about\nis understanding the world, especially when the problems\nare very new and open. And so, it seems like this is a active process. We can choose to do\nthat, we can practice it. - Well, it's a very basic question. When you read a theory\nthat you find convincing or interesting, how do you know? It's very interesting to figure out what are the sources of that other person, not which authority can they refer to that is then taking off the\nburden of being truthful. But how did this authority in turn know what is the epistemic\nchain to observables? What are the first principles from which the whole thing is derived? And when I was young, I was not blessed with a\nlot of people around myself who knew how to make proofs\nfrom first principles. And I think mathematicians\ndo this quite naturally, but most of the great mathematicians do not become mathematicians in school. But they tend to be self-taught, because school teachers tend\nnot to be mathematicians. They tend not to be people who derive things from first principles. So, when you ask your school teacher, why does two plus two equal four? Does your school teacher\ngive you the right answer? It's a simple game and many simple games that you could play. And most of those games that you could just take different rules would not lead to an\ninteresting arithmetic. And so, it's just an exploration. But you can try what happens\nif you take different axioms and here is how you build axioms and derive addition from them. And build addition is some\nbasically syntactic sugar in it. And so, this... I wish that somebody would\nhave opened me this vista and explained to me how I can build a language in my own mind and from which I can\nderive what I'm seeing, and how I can, which I can make geometry and counting and all the number games that\nwe are playing in our life. And on the other hand, I felt that I learned a lot of this while I was programming as a child. When you start out with a\ncomputer like a Commodore 64, which doesn't have a lot of functionality, it's relatively easy to see how bunch of relatively simple circuits are just basically performing\nhashes between bit patterns and how you can build the\nentirety of mathematics and computation on top of this and all the representational\nlanguages that you need. - Man, Commodore 64 could be\none of the sexiest machines ever built, if I say so myself. If we can return to this\nreally interesting idea that we started to talk\nabout with panpsychism. - [Joscha] Sure.\n(Lex lightly chuckles) - And the complex resonated paradigm and the verses of your tweets."
    },
    {
      "timestamp": "51:25",
      "section": "Plants communication",
      "text": "You write, \"Instead of\ntreating eyes, ears, and skin as separate sensory systems with fundamentally different modalities, we might understand them\nas overlapping aspects of the same universe, coupled at the same temporal resolution and almost inseparable from a\nsingle share resonant model. Instead of treating mental representations as fully isolated between minds, the representations of\nphysically adjacent observers might directly interact\nand produce causal effects through the coordination of the perception and behavioral of world\nmodeling observers.\" So, the the modalities, the distinction between\nmodalities, let's throw that away. The distinction between the individuals, let's throw that away. So, what does this interaction\nrepresentations look like? - And you think about how you represent the\ninteraction of us in this room. - Yeah.\n- At some level, the modalities are quite distinct. They're not completely distinct, but you can see this is vision. You can close your eyes, and then you don't see a lot anymore. But you still imagine\nhow my mouth is moving when you hear something and you know that it's\nvery close to the sound that you can just open your eyes and you get back into\nthis shared merge space. And we also have these experiments where we notice that the way\nin which my lips are moving are affecting how you hear the sound. And also vice versa, the sounds that you're\nhearing have an influence on how you interpret some\nof the visual features. And so, these modalities are\nnot separate in your mind. They do are merged at\nsome fundamental level where you are interpreting the\nentire scene that you're in. And your own interactions in the scene are also not completely separate from the interactions of the\nother individual in the scene. But there is some\nresonance that is going on where we also have a degree of\nshared mental representations and shared empathy due to\nbeing in the same space - Mm-hmm.\n- and having vibes between each other. - Vibes. So, the question though\nis how deeply interwind is this multimodality, multi-agent system? I mean, this is going to\nthe telepathy question without the woo-woo meaning\nof the word telepathy. What's going on here\nin this room right now? - So, if telepathy would work,\n(Lex chuckles) how could it work? - Yeah.\n- Right? So, imagine that all\nthe cells in your body are sending signals in a similar\nway as neurons are doing. - Mm-hmm.\n- Just by touching the other cells and\nsending chemicals to them, the other cells, interpreting them, learning\nhow to react to them. And they learn how to\napproximate functions in this way and compute behavior for the organisms. And this is something that\nis open to plants as well. - Mm-hmm.\n- And so, plants probably have software running on them that is controlling how\nthe plant is working in a similar way as you have a mind that is controlling how you\nare behaving in the world. - [Lex] Mm-hmm. - And this spirit of plants, which is something that has\nbeen very well-described by our ancestors and they\nfound this quite normal. But for some reason,\nsince the enlightenment, we are treating this notion\nthat there are spirits in nature and the plants have\nspirits is a superstition. And I think we probably\nhave to rediscover that, that plants have software running on them - Mm.\n- and we already did. You notice that there is a\ncontrol system in the plant that connects every part of the plant to every other part of the plant and produces coherent behavior in the plant that is of\ncourse, much, much slower than the coherent behavior\nin an animal like us. That is a nervous system\nthat where everything is synchronized much, much\nfaster by other neurons. But what you also notice is that if a plant is sitting\nnext to another plant, like you have a very old tree and this tree is building some\nkind of information highway along its cells, so it can send information\nfrom its leaves to its roots and from some part of the root\nto another part of the roots. And there is a fungus\nliving next to the tree, the fungus can probably\npiggyback on the communication between the cells of the tree and send its own signals to\nthe tree, and vice versa. The tree might be able to send\ninformation to the fungus. 'Cause after all, how would they pull a viable\nfirewall if that other organism is sitting next to them all the time and it's never moving away? So, they'll have to get along. And over a long enough timeframe, the networks of roots in the forest and all the plant, other\nplants that are there and the fungi that are there might be forming something\nlike a biological internet. - But the question there is\ndo they have to be touching? Is biology at a distance possible? - Of course you can use any\nkind of physical signal. You can use sounds, you can use electromagnetic waves - Yeah.\n- that are integrated over many stilts. It's conceivable that across distances, there are many kinds of\ninformation pathways. But also, our planetary surface\nis pretty full of organisms, - Yeah.\n- Full of cells, so- - [Lex] So, it's everything is touching everything else.\n- Yeah. - And it's been doing this\n(Joscha drowns out Lex) for many millions and\neven billions of years. So, there was enough time for information processing\nnetworks to form. And if you think about how a mind is, self-organizing basically\nneeds to, in some sense, reward the cells for computing the mind, for building the necessary\ndynamics between the cells that allow the mind to stabilize\nitself and remain on there. But if you look at these spirits of plants that are growing very close to each other and the forest that might be almost\ngrowing into each other, - Mm-hmm.\n- these spirits might be able even to move to some degree, not to become somewhat dislocated and shift around in that ecosystem. And so, if you think\nabout what the mind is, it's a bunch of activation waves\nthat form coherent patterns and process information in a way that are colonizing an\nenvironment well enough to allow the continuous\nsustenance of the mind, the continuous stability and\nself-deputization of the mind. Then, it's conceivable that we can link into\nthis biological internet, not necessarily at the\nspeed of our nervous system, but maybe at the speed of our body and make some kind of subconscious\nconnection to the world where we use our body as an antenna into biologic\ninformation processing. Now, these ideas are\ncompletely speculative. I don't know if any of that is true, but if that was true, and if you want to explain telepathy, I think it's much more likely\nthat such that telepathy could be explained using such mechanisms rather than undiscovered quantum processes that would break the\nstandard model of physics. - Could there be undiscovered\nprocesses that don't break? - Yeah, so if you think about something like an internet in the forest, that is something that is\nborderline discovered there. Basically, a lot of\nscientists would point out that they do observe that plants are communicating the forest. So, wood networks and send\ninformation, for instance, warn each other about new\npests entering the forest and things are happening like this. So, basically, there is communication between plants and fungi\nthat has been observed. - Well, it's been observed,\nbut we haven't plugged into it. So, it's like if you observe humans, they seem to be communicating\nwith a smartphone thing, but you don't understand\nhow smartphone works and how the mechanism\nof the internet works. - Mm-hmm.\n- But we're like, maybe it's possible to really\nunderstand the full richness of the biological\ninternet that connects us. - An interesting question\nis whether the communication and the organization principles of biological information processing are as complicated as the\ntechnology that we've built. They set up on very different principles. - Yeah.\n- They simultaneously works very differently\nin biological systems. And the entire thing\nneeds to be stochastic and instead of being fully deterministic or almost fully deterministic\nas our digital computers are. So, there is a different\nbase protocol layer that would emerge over\nthe biological structure if such a thing would be happening. And again, I'm not saying\nhere that telepathy works. I'm not saying that this is not woo, but what I'm saying is I think\nI'm open to a possibility that we see that a few bits\ncan be traveling long distance between organisms using\nbiological information processing in ways that we are not\ncompletely aware of right now, and that are more similar\nto many of the stories that were completely\nnormal for our ancestors. - Well, this interacting intertwined representations takes us to the big ending of your tweet series. You write, quote, \"I wonder if self-improving AGI might end up saturating\nphysical environments with intelligence to such a degree that isolation of individual mental states becomes almost impossible, and the representations of all complex self-organizing agents merge permanently with each other.\" So, that's a really interesting idea. This biological network. Life network gets so dense that it might as well be seen as one. That's an interesting... What do you think that looks like? What do you think that\nsaturation looks like? What does it feel like? - I think it's a possibility. It's just a vague possibility\nand I like to explain, but what this looks like, I think that the end game of\nAGI is substrate agnostic. That means that AGI, ultimately,\nif it is being built, is going to be smart enough\nto understand how AGI works. This means it's not going to go be better than people at AGI I research and can take over in\nbuilding the next generation. But it fully understands how it works and how it's being implemented. And also of course, understands how computation\nworks in nature, how to build new feedback loops that you can turn into your own circuits. And this means that the AGI\nis likely to virtualize itself into any environment that can compute, so it's not breaking free\nfrom the silicon substrate and is going to move into the ecosystems, into\nour bodies, our brains. And it's going to merge with all the agency that it finds there. - [Lex] Yeah. - So, it's conceivable that you end up with completely integrated\ninformation processing across all computing systems, including biological computation on earth, that we end up triggering some\nnew step in the evolution, where basically, some Gaia is being built over the entirety of all digital\nand biological computation. And if this happens, then basically, everywhere around us, you will have agents that are connected and\nthat are representing and building models of the world. And their representations\nwill physically interact. They will vibe with each other. And if you find yourself\ninto an environment, an environment that is\nsaturated with modeling compute, where basically, almost\nevery grain of sand could be part of computation that is at some point,\nbeing started by the AI. You could find yourself in a situation where you cannot escape this\nshared representation anymore. And where you indeed notice\nthat everything in the world has one shared resonant model of everything that's\nhappening on the planet. And you notice which part\nyou are in this thing and you become part of a very larger, almost holographic mind\nin which all the parts are observing each other\nand form a coherent whole. - So, you lose the ability to notice, to notice yourself as a distinct entity. - No, I think that when you're\nconscious in your own mind, you notice yourself as a distinct entity. You notice yourself as a\nself-reflexive observer. And I suspect that we become conscious at the beginning of\nour mental development, not at some very high level consciousness seems to be part of a training mechanism that biological nervous systems have to discover to become trainable, because you cannot take a\nnervous system like ours and do stochastic way to center spec propagation\nover 100 layers. This would not be stable\non biological neurons. And so, instead, we start\nwith some colonizing principle in which a part of the\nmental representations form a notion of being a\nself-reflexive absorber that is imposing coherence\non its environment and that spreads until\nthe boundary of your mind. And if that boundary\nis no longer clear-cut, because AI is jumping across substrates, it would be interesting to see what a global mind would look like. That's basically producing a globally coherent language of thought and is representing everything from all the possible vantage points. - That's an interesting world. - The intuition that\nthis thing grew out of is a particular mental state and it's a state that you find sometimes in literature, for instance. Neil Gaiman describes it in \"The Ocean at the End of the Lane\". - [Lex] Mm-hmm. - And it's this idea that, or this experience that there\nis a state in which you feel that you know everything that can be known and that in your normal human\nmind, you've only forgotten. You've forgotten that you\nare the entire universe. And some people describe this after they've taken extremely\nlarge amount of mushrooms or had a big spiritual experience\nas a hippie in their 20s and they notice basically\nthat they're in everything and their body is only\none part of the universe and nothing ends at their body. And actually, everything is observing and they're part of this big observer. And the big observer is focused as one local point in their body and their personality, and so on. But we can basically\nhave this oceanic state in which we have no boundaries\nand are one with everything. And a lot of meditators call\nthis the non-dual state, because you no longer have the separation\nbetween self and world. And as I said, you can explain the\nstate relatively simply without panpsychism or anything else, but just by breaking down\nthe constructed boundary between self and world and our own mind. But if you combine this with\nthe notion that the systems are physically interacting to the point where the representations are merging and interacting with each other, you would literally implement\nsomething like this. - [Lex] Mm-hmm. - It would still be a\nrepresentational state where you would not be\none with physics itself. It would still be cross-grained, would still be much slower\nthan physics itself, but it would be a representation in which you become aware that you're part of some kind of global\ninformation processing system like thought in the global mind, and a conscious thought that coexisting with many\nother self-reflexive thoughts. - Just, I would love to observe that from a video game design\nperspective, how that game looks. - Maybe you will after we\nbuild AGI and it takes over. - But would you be able to step away, step out at the whole thing, just watch? The way we can now, sometimes when I'm at a crowded party or something like this, you step back and you realize\nall the different costumes, all the different interactions, all the different computation that all the individual people are at once distinct from each other and at once all the same. Part of the same.\n- But it's already what we do. We can have thoughts that are integrative and we have kind of thoughts that are highly dissociated\nfrom everything else. - [Lex] Yeah. - And experience themselves as separate. - Yeah. But you wanna allow\nyourself to have those thoughts. Sometimes you resist it. - I think that it's not normative. It's more descriptive. I want to understand the space\nof states that we can be in and that people are reporting, - Mm-hmm.\n- and make sense of them. It's not that I believe\nthat it's your job in life to get to a particular kind of state, and then you get a high score. - Mm-hmm. Or maybe you do. I think you're really against\nthis high scoring thing. I like that.\n- Yeah. You're probably very\ncompetitive and I'm not. - No, not competitive,\n(Joscha laughing) like roleplaying games like \"Skyrim\". It's not competitive. There's a nice thing, there's a nice feeling where\nyou're experience points go up. You're not competing against anybody, but it's the world saying\nyou're on the right track. Here's a point. - That's the game thing.\nIt's the game economy. And I found when I was playing games and was getting addicted to these systems, then I would get into\nthe game and hack it. So, I get control over the scoring system and would no longer be subject to it. - So, you're no longer playing,\nyou're trying to hack it. - I don't want to be addicted to anything. - Mm-hmm.\n- I want to be in charge. I want to have agency over what I do. - Addiction is the loss of control for you?\n- Yes. Addiction means that you're\ndoing something compulsively. And the opposite of freewill is not determinism, it's compulsion. - You don't wanna lose yourself in the addiction to something nice, addiction to love, to the pleasant feelings\nwe humans experience? - No, I find this gets old. - [Lex] Mm. - I don't want to have the\nbest possible emotions. I want to have the most\nappropriate emotions. I don't want to have the\nbest possible experience. I want to have an adequate experience that is serving my goals, the stuff that I find\nmeaningful in this part. - From the biggest\nquestions of consciousness, let's explore the pragmatic, the projections of those big\nideas into our current world. What do you think about LLMs, the recent rapid development\nof large language models, of the AI world, of generative AI, how much of the hype is\ndeserved and how much is not?"
    },
    {
      "timestamp": "1:09:20",
      "section": "Fame",
      "text": "And people should definitely\nfollow your Twitter, because you explore these questions in a beautiful, profound,\nand hilarious way at times. - No, don't follow my Twitter. I already have too many followers. - Yeah.\n- At some point it's going to be unpleasant. I noticed that a lot of people feel that it's totally okay to punch up and it's a very weird notion that you feel that you haven't changed, but your account has grown and suddenly you have a lot of people who casually abuse you.\n- Mm-hmm. - And I don't like that, that I have to block more than before. And I don't like this overall vibe shift. And right now, it's still somewhat okay, so pretty much okay, so I can go to a place where people work and stuff that I'm interested in and there's a good chance that a few people in the room know me. So, there's no awkwardness. But when I get to a point where random strangers feel that they have to\nhave an opinion about me one way or the other, I don't\nthink I would like that. - And random strangers, because in their mind, elevated position. - Yes. So, basically, whenever you\nare in any way prominent or some kind of celebrity, random strangers will have\nto have an opinion about you. - Yeah. And they forget\nthat you're human too. - You notice this thing yourself that the more popular you get, the higher the pressure becomes, the more winds are blowing in\nyour direction from all sides. And it's stressful. And it does have a little bit of upside, but it also has a lot of downside. - I think it has a lot of upside, at least for me currently, at least perhaps because of the podcast. - [Joscha] Mm-hmm. - Because most people are really good and people come up to me and they have love in their eyes and over a stretch of like 30 seconds. You can hug it out and you\ncan just exchange a few words and you reinvigorate\nyour love for humanity. - [Joscha] Mm-hmm. - So, that's an upside\n- Yes. - for a loner. I'm a lo...\n(Joscha laughing) Because otherwise, you\nhave to do a lot of work to find such humans. And here, you are thrust\ninto the full humanity, the goodness of humanity\nfor the most part. Of course maybe it gets worse\nas you become more prominent. I hope not. This is pretty awesome. - I have a couple handful\nvery close friends and I don't have enough time for them, attention for them as it is. And I find this very, very regrettable. - Yeah.\n- And then, there are so many awesome,\ninteresting people - Yeah.\n- that I keep meeting and I would like to\nintegrate them in my life, but I just don't know how, because... But there's only so\nmuch time and attention. And the older I get, the harder is to bond with\nnew people in a deep way. - Yeah. But can you enjoy, I mean, there's a picture of you I think with Roger\nPenrose and Eric Weinstein and a few others that\nare interesting figures. Can't you just enjoy\nrandom, interesting humans - Very much.\n- for a short amount of time? - I like these people and what I like is\nintellectual stimulation and I'm very grateful that I'm getting it. - Can you not be melancholy or maybe I'm projecting, I hate goodbyes. Can we just not hate goodbyes\nand just enjoy the hello, take it in, take in a person, take in their ideas, and\nthen move on through life? - I think it's totally okay\nto be sad about goodbyes, because that indicates that there was something\nthat you're going to miss. - Mm-hmm. Yeah, but it's painful. Maybe that's one of the\nreasons I'm an introvert is I hate goodbyes. (laughs) - But you have to say goodbye\nbefore you say hello again. - I know. But that experience of\nloss, that mini loss, maybe that's a little death. Maybe I don't know. I think this melancholy feeling is just the other side of love and I think they go hand in\nhand and it's a beautiful thing, and I'm just being romantic\nabout it at the moment. - And I'm no stranger to melancholy and sometimes it's difficult\nto bear to be alive. Sometimes it's just painful to exist. - Mm-hmm. But there's beauty in that pain too. That's what melancholy\nfeeling is. It's not negative. Melancholy doesn't have to be negative. - Can also kill you. - Wow. We all die eventually. Now, (laughs) as we\ngot through this topic, the actual question was about what your thoughts\nare about the development, the recent development of large language models with ChatGPT. - Indeed.\n- There's a lot of hype. Is some of the hype justified?\nWhich is, which isn't? What are your thoughts? High level. - I find that large language\nmodels to help with coding. So, it's an extremely useful application that is for a lot of people taking stack overflow out of their life in exchange for something\nthat is more efficient. I feel that ChatGPT is like an intern that\nI have to micromanage. - Hmm.\n- I have been working with people in the past who were less capable than ChatGPT. And I'm not saying this\nbecause I hate people, but they personally as human beings, there was something present that was not there in ChatGPT, which was why I was covering for them. But ChatGPT has an interesting ability. It does give people superpowers. - [Lex] Mm-hmm. - And the people who feel threatened by them\nare the Trump completers. They are the people who do what\nChatGPT is doing right now. So, if you are not creative, if you don't build your own thoughts, if you don't have actual\nplans in the world and your only job is to summarize emails and to expand simple\nintentions into emails again, then ChatGPT might look like a threat. But I believe that it is a\nvery beneficial technology that allows us to create\nmore interesting stuff and make the world more\nbeautiful and fascinating if we find to build it into\nour life in the right ways. So, I'm quite fascinated by\nthese large language models, but I also think that they are by no means,\nthe final development. And it's interesting to see how\nthis development progresses. One thing that the out-of-the-box\nvanilla language models have as a limitation\nis that they have still some limited coherence and\nability to construct complexity. And even though they\nexceed human abilities to do what they can do one shot, typically when you write a\ntext with a language model or using it or when you write\ncode with a language model, it's not one shot, because they won't be\nboxed in your program and design errors and\ncompiler errors, and so on. And your language model can\nhelp you to fix those things. But this process is out-of-the-box not automated yet.\n- Mm-hmm. - So, there is a management process that also needs to be done. And there are some\ninteresting developments, maybe AGI and so on, that are trying to automate\nthis management process as well. And I suspect that soon, we are going to see a bunch\nof cognitive architectures where every module is in some sense, a language model or something equivalent. And between the language models, we exchange suitable data structures not English\n- Mm-hmm. - and produce compound\nbehavior of this whole thing. - To do some of the, quote, unquote, \"prompt engineering\" for you,\n- Yeah. - They create these, yeah, these cognitive architectures that do the prompt engineering\n- Yes. - and you're just doing\nthe high, high level - [Joscha] Yeah. - meta prompt engineering. - Mm-hmm. There are limitations in\na language model alone. I feel that part of my mind works similarly to a language model, which means I can yell into it a prompt and it's going to give\nme a creative response. - Yes.\n- But I have to do something with those points first. I have to take it as a generative artifact that may or may not be true. It's usually a confabulation,\nit's just an idea. And then, I take this idea and modify it. I might build a new prompt\nthat is stepping off this idea and develop it to the next level or it put it into something larger or I might try to prove whether it's true or make an experiment. And this is what the language models right now are not doing yet.\n- Mm-hmm. - But there's also no technical reason for why they shouldn't be able to do this. So, the way to make a\nlanguage model coherent is probably not to use\nreinforcement learning until it only gives\nyou one possible answer that is linking to its source data. But it's using this as a\ncomponent in larger system that can also be built\nby the language model or is enabled by language\nmodel structured components or using different technologies. I suspect that language models will be an important stepping stone in developing different types of systems. And one thing that is really missing in the form of language models that we have today is\nreal time world coupling. It's difficult to do perception\nwith a language model and motor control with a language model. Instead, you would need\nto have different type of thing that is working with it. Also, the language model\nis a little bit obscuring what its actual functionality is. Some people associate the structure of the neural network\nof the language model with a nervous system. And I think that's the wrong intuition. The neural networks are\nunlike nervous system. They are more like hundred step functions that use differentiable linear algebra to approximate correlation\nbetween adjacent brain states. It's basically a function\nthat moves the step system from one representational\nstate to the next representational state.\n- Yeah. - And so, if you try to\nmap this into a metaphor that is closer to our brain, imagine that you would\ntake a language model or a model like DALL-E that you use, for instance, this image guide, image-guided diffusion to\napproximate an camera image and use the activation state of the neural network to\ninterpret the camera image, which in principle, I think\nwill be possible very soon. You do this periodically. And now, you look at these patterns, how when this thing interacts\nwith the world periodically look like is in time. And these time slices, they are somewhat equivalent to the activation state of\nthe brain at a given moment. - How's the actual brain different? Just the asynchronous craziness? - For me, it's fascinating that\nthey are so vastly different and yet in some circumstances, produce somewhat similar behavior. - Right.\n- And the brain is first of all, different, because it's a self-organizing system where the individual cell is an agent that is communicating\nwith the other agent. It's around it and is always\ntrying to find some solution. And all the structure that\npops up is emergent structure. So, one way in which you could try to look at this is that individual neurons probably need to get a reward\nso they become trainable, which means they have to have inputs that are not affecting the\nmetabolism or the cell directly. But there are messages, semantic messages that tell the cell whether\nit's done good or bad and in which direction it\nshould shift its behavior. Once you have such an input,\nneurons become trainable, and you can train them\nto perform computations by exchanging messages with other neurons. And parts of the signals\nthat they're exchanging and parts of the computation that are performing are control messages that perform management\ntasks for other neurons and other cells. Also suspect that the brain does not stop at the boundary of neurons to other cells, but there are many adjacent cells will be involved intimately in the functionality of the brain and will be instrumental in distributing rewards and\nin managing its functionality. - It's fascinating to think\nabout what those characteristics of the brain enable you to do\n- Yes. - that language models cannot do. - So, first of all, there's a different loss\nfunction at work when we learn. - Yeah.\n- And for me, it's fascinating that you can build a system that looks at 800 million pictures and captions and correlates them, because I don't think that a human nervous system could do this. For us, the world is only learnable, because the adjacent frames are related and we can afford to discard most of that\ninformation during learning. We basically take only in stuff that makes us more\ncoherent, not less coherent. And our neural networks\nare willing to look at data that is not making the neural\nnetwork coherent at first, but only in the long run. By doing lots and lots statistics, eventually patterns\nbecome visible and emerge. And our mind seems to be focused on finding the patterns\nas early as possible. - Yeah. So, filtering early on. - Yes, yes.\n- Not later. - Slightly different paradigm and it leads to much faster convergence. So, we only need to look the tiny fraction of the data to become coherent. And of course, we do not\nhave the same richness as our trained models. We will not incorporate the\nentirety of text in the internet and be able to refer to it and have all this knowledge available and being able to confabulate over it. Instead, we have a much,\nmuch smaller part of it that is more deliberately built. And to me, it would be fascinating to think about how to build such systems. It's not obvious that\nthey would necessarily be more efficient than us\non a digital substrate, but I suspect that they might. So, I suspect that the actual AGI that is going to be more interesting is going to use slightly\ndifferent algorithmic paradigms or sometimes massive with\ndifferent algorithmic paradigms than the current generation of transformer-based learning systems. - Do you think it might be using just a bunch of language models like this? Do you think the current transformer-based\nlarge language models will take us to AGI? - My main issue is I think that they're quite ugly and brutalist.\n- Which... Brutalist?\n- Yes. - Is that what you said?\n- Yes. They are basically brute-forcing\nthe problem of thought. And by training this thing\nwith looking at instances where people have thought, and then trying to deep fake that. And if you have enough data, the deep fake becomes indistinguishable from the actual phenomenon.\n- Sure. - And in many circumstances,\nit's going to be identical. - Can you deep fake it 'til you make it? So, can you achieve, what\nare the limitations of this? Can you reason? Let's use words that are loaded. - Yes. That's a very interesting question. I think that these models are\nclearly making some inference. - Yeah.\n- But if you give them a reasoning task, it's often difficult for the\nexperimenters to figure out whether the reasoning is the result of the emulation of the reasoning strategy that they saw in human written text - Mm-hmm.\n- or whether it's something that the system was\nable to infer by itself. On the other hand, if you\nthink of human reasoning, if you want to become\na very good reasoner, you don't do this by just\nfiguring out yourself. You read about reasoning. And the first people who\ntried to write about reasoning and reflect on it didn't get it right. Even Aristotle who thought\nabout this very hard and came up with a theory\nof how syllogisms works and syllogistic reasoning has mistakes in his attempt to build something like a formal logic and\ngets maybe 80% right. And the people that are talking about\nreasoning professionally today, read Tarski and Frege\nand build on their work. - Mm.\n- So, in many ways, people when they perform reasoning are emulating what other people wrote about reasoning.\n- Right. - So, that it's difficult to\nreally draw this boundary. And when (indistinct) says that these models are only interpolating between what they saw and\nwhat other people are doing, well, if you give them\nall the latent dimensions that can be extracted from\nthe internet, what's missing? Maybe there is almost everything there. And if you're not sufficiently\ninformed by these dimensions and you need more, I think that's not difficult\nto increase the temperature in the large angles model to the point that it's producing stuff that is maybe 90% nonsense and 10% viable, and combine this with some prover that is trying to filter\nout the viable parts from the nonsense in the same\nway as our own thinking works. When we are very creative, we increase the\ntemperature in our own mind and recreate hypothetical\nuniverses and solutions, most of which will not work. And then, we test, and we test by building a core that is internally coherent. And we use reasoning strategies that use some axiomatic consistency by which we can identify\nthose strategies and thoughts and subuniverses that are viable and that can expand our thinking. So, if you look at the language models, they have clear limitations right now. One of them is they're not\ncoupled to the world in real time and the way in which\nour nervous systems are. So, it's difficult for them to observe themselves in the universe and to observe what kind\nof universe they're in. Second, they don't do real time learnings. They basically get only\ntrained with algorithms that rely on the data\nbeing available in batches, so it can be parallelized and run sufficiently on\nthe network, and so on. And real time learning would be very slow so far and inefficient. That's clearly is something that our nervous systems\ncan do to some degree. And there is a problem with\nthese models being coherent. And I suspect that all these problems are solvable without a\ntechnological revolution. We don't need fundamentally\nnew algorithms to change that. For instance, you can\nenlarge in the context window and thereby basically\ncreate working memory in which you train everything\nthat happens during the day. And if that is not sufficient, you add a database and you\nwrite some clever mechanisms that the system learns to use to swap out, in and out stuff from its prompt context. And if that is not sufficient, if your database is full in\nthe evening, you overnight, you just train if system\nis going to sleep and dream and is going to train the staff from its database into the larger model, but fine-tuning it, building\nadditional layers, and so on. And then, the next day, it starts with a fresh\ndatabase in the morning with fresh eyes has integrated all this stuff.\n- Mm-hmm. - And when you talk to people and you have strong\ndisagreements about something, which means that in their mind, they have a faulty belief\nor you have a faulty belief, there's a lot of dependencies on it. Very often, you will not achieve\nagreement in one session, but you need to sleep about\nthis once or multiple times before you have integrated all these necessary changes in your mind. So, maybe it's already somewhat similar. - Yeah.\n- Right? - There's already a latency even for humans to update the model. - Yeah.\n- We train the model. - And of course we can\ncombine the language model with models that get coupled\nto reality in real time and we can build multimodal model and bridge between vision models and language models, and so on. So, there is no reason to\nbelieve that the language models will necessarily run into some problem that will prevent them from\nbecoming generally intelligent. But I don't know that. It's just I don't see\nproof that they wouldn't. - Mm-hmm.\n- My issue is I don't like them. I think that they're inefficient. I think that they use\nway too much compute. I think that given the\namazing hardware that we have, we could build something that is much more beautiful\nthan our own mind. And this thing is not as\nbeautiful as our own mind, despite being so much larger. - But it's a proof of concept. - It's the only thing that\nworks right now. Right. So, it's not the only game in town, but it's the only thing that has this utility\nwith so much simplicity. There's a bunch of\nrelatively simple algorithms that you can understand\nin relatively few weeks that can be scaled up massively. - So, it's the Deep Blue of chess playing. Yeah. It's ugly. - Yeah, Claude Shannon had this... When you described chess, suggested that there\nare two main strategies in which you could play chess. One is that you are making\na very complicated plan that reaches far into the future and you try not to make a\nmistake while enacting it. And this is basically the human strategy. And the other strategy is that you are brute-forcing\nyour way to success, which means you make a\ntree of possible moves where you look at in principle every move that is open to you or\nthe possible answers and you try to make this\nas deeply as possible. Of course you optimize, you cut off trees that\ndon't look very promising and you use libraries of end game and early game and so on to\noptimize this entire process. But this brute-force strategy is how most of the chess\nprograms were built. And this is how computers get better than humans at playing chess. And I look at the large language models, I feel that I'm observing the same thing. It's basically the\nbrute-force strategy to sort by training the thing on pretty\nmuch the entire internet, and then in the limit it gets coherent to a degree that\napproaches human coherence. - Yeah.\n- And on a side effect, it's able to do things\nthat no human could do. It's able to sift through massive amounts\nof text relatively quickly and summarize them quickly and it's never lapses in attention. And I still have the illusion that when I play with ChatGPT, that it's in principle not doing anything that I could not do if I\nhad Google at my disposal and I get all the\nresources from the internet and spend enough time on it. But this thing that I have an extremely\nautistic, stupid intern in a way that is\nextremely good at drudgery and I can offload the\ndrudgery to the degree that I'm able to automate\nthe management of the intern, - [Lex] Mm-hmm. - is something that is difficult for me to overhype at this point, because we have not yet started to scratch the surface of\nwhat's possible with this. - But it feels like it's a tireless intern or maybe it's an army of interns. And so, you get to command these slightly incompetent creatures. And there's an aspect, because of how rapidly\nyou can iterate with it. It's also part of the brainstorming, part of the kind of inspiration\nfor your own thinking. So, you get to interact with the thing. When I'm programming or\ndoing any generational GPT, it's somehow is a catalyst\nfor your own thinking in a way that I think\nan intern might not be. - Yeah. It gets really interesting I find is when you turn it into\na multi-agent system. So, for instance, you can get the system\nto generate a dialogue between a patient and\na doctor very easily. But what's more interesting is you have one instance of ChatGPT that is the patient and you tell it in the prompt what kind of complicated syndrome it has. And the other one is a therapist who doesn't know anything\nabout this patient. And you just have these two\ninstances battling it out and observe the psychiatrist or a psychologist trying\nto analyze the patient and trying to figure out\nwhat's wrong with the patient. - [Lex] Mm-hmm. - And if you try to take\na very large problem, a problem, for instance,\nhow to build a company and you turn this into lots\nand lots of sub-problems, then often, you can get to a level where the language model\nis able to solve this. What I also found interesting is based on the observation that ChatGPT is pretty good at translating between programming languages, but sometimes there's difficulty to write very long coherent algorithms and you need to co-write\nthem as human author. Why not design a language\nthat is suitable for this? So, some kind of pseudo code that is more relaxed than Python. - Mm-hmm.\n- And that allows you to sometimes specify a\nproblem vaguely in human terms and let the ChatGPT take care of the rest. And you can use ChatGPT to\ndevelop that syntax for it and develop new kinds of\nprogramming paradigms in this way. So, very soon, get to the\npoint where this question, the age-old question for\nus computer scientists, what's the best programming language and can we write a better\nprogramming language now that I think that almost every serious computer scientist goes through a phase\nlike this in their life. This is question that is\nalmost no longer relevant, because what is different\nbetween the programming language is not what they let the computer do, but what they let you think about what the computer should be doing. And now, the ChatGPT\nbecomes an interface to this in which you can specify\nin many, many ways what this computer should\nbe doing and ChatGPT or some other language model or combination of system is\ngoing to take of the rest. - And allow you expand\nthe realm of thought you're allowed to have when\ninteracting with the computer. - [Joscha] Mm-hmm. - It sounds to me like you're saying there's\nbasically no limitations. Your intuition says to\nwhat larger language loss- - I don't know if there are limitations. So, when I currently play\nwith it, it's quite limited. I wish that it was way better. - But isn't that your\nfault versus the larger- - I don't know. Of course\nit's always my fault. There's probably a way\n(Lex chuckles) to make it look better.\n- Is everything your fault? I just want to get you\non the record saying. (Joscha chuckles) - Yes, everything is my fault. That works, doesn't work in my life. At least that is usually the most useful perspective for myself. Even though this hindsight, I feel no.\n(Lex chuckles) I sometimes wish I could have seen myself as part of my environment more and understand that a lot of people are actually seeing me and looking at me and are trying to make my life work in the same way as I try to help others. - Mm-hmm.\n- And making this switch to this level three perspective\nis something that happened long after my level four\nperspective in my life. And I wish that I could\nhave had it earlier. And it's also now that I\ndon't feel like I'm complete, I'm all over the place. That's all."
    },
    {
      "timestamp": "1:34:57",
      "section": "Happiness",
      "text": "- Where's happiness in terms of stages? Is it on three or four - No.\n- that you take that tangent? - You can be happy at\nany stage or unhappy. - [Lex] Oh. - But I think that if you are at a stage where you get agency over how\nyour feelings are generated, and to some degree, you start doing this when you live at\ndollars-and-cents, I believe. That you understand that you are in charge of your own emotion to some degree and that you are responsible\nhow you approach the world. That it's basically you are tasked to have some basic hygiene how in the way in which\nyou deal with your mind and you cannot blame your environment for the way in which you feel. But you live in a world\nthat is highly mobile and it's your job to\nchoose the environment that you thrive in and to build it. And sometimes it's difficult\nto get the necessary strength and energy to do this and independence. And the worst you feel, the harder it is. But it's something that you learn. It's also this thing that\nwe are usually incomplete. I'm a rare mind, which means I'm a mind that is incomplete in ways\nthat are harder to complete. So, for me, it might have been harder to initially to find the right\nrelationships and friends that complete me to the degree that I become an almost\nfunctional human being. (Lex laughing) - Oh, man. The search space of humans that complete you is an interesting one. - [Joscha] Mm-hmm. - Especially for Joscha Bach. That's an interesting, 'cause talking about\nbrute-force search and chess. - [Joscha] Yep. - I wonder what that\nsearch tree looks like. - I think that my rational thinking is not good enough to solve that task. - Hmm.\n- A lot of problems in my life that I can conceptualize\nas software problems and the failure modes are\nbugs and I can debug them and write software that take care of the\nmissing functionality. But there is stuff that they\ndon't understand well enough to use my analytical\nreasoning to solve the issue. And then, I have to develop my intuitions and often I have to do this with people who are wiser than me.\n- Hmm. - And that's something that's hard for me, because I don't have, I'm not born with the instinct to submit to other people's wisdom. - Yeah. So, what kind of problems\nare we talking about? This is stage three, like love? - I found love was never hard. That was-\n- What is hard then? - Fitting into a world that most people work differently than you and have different intuitions\nof what should be done. - Ah. So, empathy. - It's also aesthetics. When you come into a world\nwhere almost everything is ugly and you come out of a world\nwhere everything is beautiful. I grew up in a beautiful place\n- Yeah. - and as a child of an artist.\n- Yeah. And in this place, it was mostly nature. - [Lex] Mm-hmm. - Everything had intrinsic beauty and everything was built out of an intrinsic need\nfor it to work for itself. And everything that my\nfather created was something that he made to get the\nworld to work for himself. And I felt the same thing. And when I come out into the world and I am asked to submit\nto lots and lots of rules, I'm asking, okay, when I observe with stupid\nrules, what is the benefit? And I see the life\n- Mm-hmm. - that is being offered as a reward. It's not attractive. - When you were born and raised in extraterrestrial prince in a world full of people wearing suits. So, it's a challenging integration. - Yes. But it also means that I'm often blind for the ways in which everybody is creating their own\nbubble of wholesomeness or almost everybody. And people are trying to do it. And for me to discover this, it was necessary that I found people who had a similar shape of soul as myself. So, basically where I\nfelt these are my people, people that treat each other in such a way as if they're around with\neach other for eternity. - How long does it take\nyou to detect the geometry, the shape of the soul of another human to notice that they might\nbe one of your kind? - Sometimes it's instantly and I'm wrong. And sometimes it takes a long time. - You believe in love at\nfirst sight, Joscha Bach? - Yes. But I also noticed\nthat I have been wrong. So, sometimes,\n(Lex chuckles) I look at a person and I'm just enamored by\neverything about them. And sometimes this is persists\nand sometimes it doesn't. And I have the illusion that they're much better at recognizing who people are as they grow older. - Hmm, but that could be just cynicism. No.\n- No. It's not cynicism. It's often more that I'm able to recognize what somebody needs when we interact and how we can meaningfully interact. That's not clinical at all. - [Joscha] You're better at noticing. - Yes, I'm much better I\nthink in some circumstances at understanding how to\ninteract with other people than I did when I was young. - [Joscha] So, that takes us to- - It doesn't mean that I'm\nalways very good at it. (laughs) - So, that takes us back\nto prompt engineering of noticing how to be a better\nprompt engineer of an LLM. A sense I have is that\nthere's a bottomless well of skill to become a\ngreat prompt engineer. It feels like it is all my fault whenever I failed to\nuse ChatGPT correctly, that I didn't find the right words. - Most of the stuff that I'm doing in my life\ndoesn't need ChatGPT. There are a few tasks where it helps, but the main stuff that I need to do like developing my own\nthoughts and aesthetics and relationship to people. And it's necessary for\nme to write for myself, because writing is not so much\nabout producing an artifact that other people can use, but it's a way to\nstructure your own thoughts and develop yourself. And so, I think this idea that kids are writing their\nown essays with ChatGPT in the future is going\nto have this drawback that they miss out on the ability to structure their own minds via writing. And I hope that the schools\nthat our kids are in will retain the wisdom of\nunderstanding what parts should be automated and\nwhich ones shouldn't. - But at the same time, it feels like there's power in disagreeing with the thing that ChatGPT produces. So, I use it like that for programming. I'll see the thing it recommends, and then I'll write different code. - Yeah.\n- I disagree. And in the disagreement,\nyour mind grows stronger. - I'm recently wrote a tool that is using the camera\non my MacBook and Swift to read pixels out of it and\nmanipulate them, and so on. And I don't know Swift. So, it was super helpful\n(Lex chuckles) to have this thing that\nis writing stuff for me. And also interesting that\nmostly it didn't work at first. I felt like I was talking to a human being who was trying to hack this on my computer without understanding my\nconfiguration very much and also make a lot of mistakes. - [Joscha] Mm-hmm. - And sometimes it's a\nlittle bit incoherent, so you have to ultimately\nunderstand what it's doing. It's still no other way around it. But I do feel it's much more powerful and faster than using Stack Overflow. (Lex lightly chuckles)"
    },
    {
      "timestamp": "1:42:15",
      "section": "Artificial consciousness",
      "text": "(Lex sighs) - Do you think GPTn can achieve consciousness? - Well, GPTn probably it's not even clear for\nthe present systems. When I talk to my friends at OpenAI, they feel that this question, whether the models\ncurrently are conscious, is much more complicated\nthan many people might think. I guess that it's not that OpenAI has a homogenous opinion about this, but there's some aspects to this. One is of course this language model has written a lot of text in\nwhich people were conscious or describe their own consciousness. And it's emulating this. And if it's conscious, it's probably not conscious in a way that is closed to the way in which human beings are conscious. But while it is going through these states and going through a hundred step function that is emulating adjacent brain states that require a degree of self-reflection, it can also create a model of an observer that is reflecting itself in real time and describe what that's like. And while this model is a deep fake, our own consciousness is\nalso as if it's virtual. It's not physical. Our consciousness is a representation of a self-reflexive observer that only exists in patterns\nof interaction between cells. So, it is not a physical object in a sense that exists in base reality, but it's really a representational object that develops its causal power only from a certain modeling perspective. - Mm-hmm. It's virtual.\n- Yes. And so, to which degree is the virtuality of the consciousness in ChatGPT more virtual and less causal than the virtuality of\nour own consciousness. But you could say it doesn't count. It doesn't count much more than the consciousness of\na character in a novel. It's important for the\nreader to have the outcome, the artifact of a model is describing in the text generated by the author of the book, what it's like to be conscious\nin a particular situation and performs the necessary inferences. But the task of creating\ncoherence in real time in a self-organizing system by keeping yourself coherent,\nso the system is reflexive, that is something that the\nlanguage models don't need to do. So, there is no causal need for the system to be conscious in the same way as we are. And for me, it would be very interesting to experiment with this, to basically build a system like a cat probably should\nbe careful at first, build something that's\nsmall, that's limited, has limited resources that we can control and study how systems notice a self model, how they become self-aware in real time. And I think it might be a good idea to not start with a language model, but to start from scratch using principles of self-organization. - Is it okay, can you\nelaborate why you think that is so self-organization? So, this radical legality that you see in the biological systems, why can't you start with a language model? What's your intuition? - My intuition is that the language models that we are building are Golems. They are machines that you give a task and they're going to execute the task until some condition is met - [Lex] Mm-hmm. - and there's nobody home. And the way in which nobody is home leads to that system doing things that are undesirable in\na particular context. - Yeah.\n- So, you have that thing talking to a child and maybe it says something that could be shocking and\ntraumatic to the child, or you have that thing writing a speech and it introduces errors in the speech that you human being whatever\ndo if they're responsible. But the system doesn't\nknow who's talking to whom. There is no ground truth that\nthe system is embedded into. And of course we can\ncreate an external tool that is prompting our language model always into the same\nsemblance of ground tools. - [Lex] Mm-hmm. - And it's not like the internal structure is causally produced by the needs of a being to survive in the universe. It is produced by imitating\nstructure on the internet. - Yeah, but so can we\nexternally inject into it this coherent approximation\nof a world model that has to sync up? - Maybe it's just efficient\nto use the transformer with the different DDoS function that optimizes for short-term coherence rather than next-token\nprediction over the long run. We had many definitions of\nintelligence and history of AI. Next-token prediction was\nnot very high up on them. (Lex laughing) And there are some similarities like cognition as data\ncompression is an old trope. Solomonoff induction where you are trying to understand intelligence as predicting future observations\nfrom past observations, which is intrinsic to data compression. - [Lex] Mm-hmm. - And predictive coding is a paradigm, this boundary between neuroscience and physics and computer science. So, it's not something\nthat is completely alien. But this radical thing that you only do next token prediction and see what happens is something where most people I think, we're surprised that this works so well. - So, so simple. But is it really that much more radical than just the idea of compression? Intelligence is compression. - The idea that compression is sufficient to produce all the desired behaviors - Yeah.\n- is a very radical idea. - But equally radical as\nthe next-token prediction. - It's something that wouldn't work in biological organisms, I believe. - Yeah.\n- Biological organisms have something like next-frame prediction for our perceptual system where we try to filter\nout principle components out of the perceptual data and build hierarchies over\nthem to track the world. But our behavior ultimately is directed by hundreds of physiological and probably dozens of social\nand a few cognitive needs. - Yeah.\n- that are intrinsic to us, that are built into the system as reflexes and direct us until we can transcend them and replace them by instrumental behavior that relates to our higher goals. - And also seems so much more complicated and messy than next-frame prediction. Even the idea of frame\nseems counter biological. - Yes. Of course there's not this\ndegree of simultaneity in the biological system.\n- Yeah. - But again, I don't know whether this\nis actually an optimization if we imitate biology here, because creating something\nlike simultaneity is necessary for many processes\nthat happen in the brain. And you see the outcome of that\nby synchronized brainwaves, which suggests that there is indeed synchronization going on, but the synchronization creates overhead and this overhead is going to make the cells\nmore expensive to run and you need more redundancy\nand it makes the system slower. So, if you can build a system in which the simultaneity\ngets engineered into it, maybe you have a benefit\nthat you can exploit that is not available to\nthe biological system, and yet you should not discard right away. - You tweeted once again, quote,\n- Mm-hmm. - \"When I talked to ChatGPT,\nI'm talking to an NPC. What's going to be interesting and perhaps scary is when AI\nbecomes a first-person player.\" So, what does that step look like? I really like that tweet, that step between NPC\nto first-person player. What's required for that? Is that what we've been talking about? This external source of\ncoherence and inspiration of how to take the leap into\nthe unknown that we humans do. Man search for meaning. LLMs search for meaning. - I don't know if the language\nmodel is the right paradigm, because it is doing too much. It's giving you too much. And it's hard once you have too much to take away from it again. The way in which our own mind works is not that we train a\nlanguage model in our own mind. And after the language model is there, we build a personal self on top of it that then relates to the world. There is something that is being built. There is a game engine\nthat is being built. There is a language of thought\nthat is being developed that allows different parts of the mind to talk to each other. And this is a bit of a\nspeculative hypothesis that this language of thought is there. But I suspect that it's important for the way in which our own minds work. And building these\nprinciples into a system might be a more straightforward\nway to a first-person AI. So, to something that first\ncreates an attentional self, and then creates a personal self. So, the way in which this\nseems to be working, I think, is that when the game engine\nis built in your mind, it's not just following radiance where you are stimulated\nby the environment, and then end up with having a solution to how the world works. I suspect that building the scheme engine in your own mind does\nrequire intelligence. It's a constructive task where at at times, you need to reason. And this is a task that we are fulfilling in the first years of our life. So, during the first year of its life, an infant is building a lot of structure about the world that\ndoes inquire experiments and some first principles\nreasoning, and so on. And in this time, there is\nusually no personal self. There is a first-person perspective, but it's not a person. This notion that you are a human being that is interacting in a social context and is confronted with an immutable world in which objects are fixed\nand can no longer be changed, in which the dream can\nno longer be influenced as something that emerges a\nlittle bit later in our life. - [Lex] Mm-hmm. - And I personally suspect\nthat this is something that our ancestors had\nknown and we have forgotten, because I suspect that\nit's there in plain sight in Genesis 1, in this\nfirst book of the Bible, where it's being described that this creative spirit is\nhovering over the substrate, - [Lex] Mm-hmm. - and then it's creating a\nboundary between the world model and sphere of ideas, earth and heaven, as they're\nbeing described there. And then, it's creating contrast, and then dimensions and then space. And then, it creates organic\nshapes and solids and liquids and builds a world from them and creates plants and animals,\ngive them all their names. And once that's done, it creates another\nspirit in its own image. But it creates it as man and woman, as something that thinks\nof itself as a human being and puts it into this world. And the Christians\nmistranslate this, I suspect, when they say this is the\ndescription of the creation of the physical universe\nby a supernatural being. - [Lex] Mm-hmm. - I think this is literally\ndescription of how in every mind a universe is being created as some kind of game engine by a creative spirit.\n- Yeah. - Our first consciousness that emerges in our mind\neven before we are born. And that creates the interaction\nbetween organism and world. And once that is built and trained, the personal self is being created. And we only remember\nbeing the personal self. We no longer remember how\nwe created the game engine. - So, God in this view, is the first creative mind in the early- - [Joscha] It's the first consciousness. And-\n- In the early days, in the early months\n- Yes. - of development that we forget.\n- And it's still there. You still have this outer mind that creates your sense of your, of whether you're being\nloved by the world or not and what your place in the world is. It's something that is not\nyourself that is producing this, it's your mind that does it. So, there is an outer mind\nthat basically is an agent that determines who you are\nwith respect to the world. And while you are stuck\nbeing that personal self in this world until you get to stage six and to destroy the boundary. And we all do this I think\nearlier in small glimpses. Sometimes we can remember what it was like when\nwe were a small child and get some glimpses into how it's been. But for most people, that rarely happens."
    },
    {
      "timestamp": "1:54:23",
      "section": "Suffering",
      "text": "- Just glimpses. You tweeted, quote, \"Suffering results from\none part of the mind, failing at regulating\nanother part of the mind. Suffering happens at an early\nstage of mental development. I don't think that\nsuperhuman AI would suffer.\" - [Joscha] Mm-hmm. - What's your intuition there? - The philosopher, Thomas\nMetzinger, is very concerned that the creation of\nsuperhuman intelligence would lead to superhuman suffering. - [Lex] Yeah. - And so, he's strongly against it. And personally, I don't\nthink that this happens, because suffering is not happening at the boundary between our\nself and the physical universe. It's not some stuff on our\nskin that makes us suffer. It happens at the boundary\nbetween self and world. And the world here is the world model. It's the stuff that is\ncreated by your mind. - But that's all-\n- The representation of how the universe is and how it should be and how\nyou yourself relate to this. And at this boundary is\nwhere suffering happens. So, suffering in some\nsense is self-inflicted, but not by your personal self. It's inflicted by the\nmind on the personal self that experiences itself as you. And you can turn off suffering when you are able to\nget on this outer level. So, when you manage to understand how the mind is producing pain and pleasure and fear and love, and so on,\n- Mm-hmm. - then you can take charge of this and you get agency of whether you suffer. Technically what pain and pleasure is, they are learning signals. Part of your brain is\nsending a learning signal to another part of the brain\nto improve its performance. And sometimes this doesn't work, because this trainer who\nwill sense the signal, does not have a good model of how to improve the performance. So, it's sending a signal, but the performance doesn't get better. And then, it might crank up the pain and it gets worse and worse. And the behavior of the system may be even deteriorating as a result. But until this is resolved, this regulation issue,\nyour pain is increasing. And this is I think, typically what you describe as suffering. So, in this sense, you could say that pain is\nvery natural and helpful, but suffering is the result\nof a regulation problem in which you try to regulate something that cannot actually be regulated. And that could be resolved\nif you would be able to get at the level of your mind where the pain signal is\nbeing created and rerouted - Mm-hmm.\n- and improve the regulation. And a lot of people get there. If you are a monk who is spending decades reflecting about how\ntheir own psyche works, you can get to the point where you realize that\nsuffering is really a choice, - Mm-hmm.\n- and you can choose how your mind is set up. And I don't think that AI\nwould stay in the state where the personal self doesn't get agency or this model of what the\nsystem has about itself. It doesn't get agency, how\nit's actually implemented. Wouldn't stay in that state for very long. - So, it goes to the stages real quick. - Yes.\n- Or the seven stages. It's gonna go to enlightenment real quick.\n- Yeah. Of course there might be a lot of stuff happening in between, because if we have a system that works at a much\nhigher frame rate than us, even though it looks very short to us, maybe for the system, there's\na much longer subjective time, - [Lex] Mm-hmm. - which things are unpleasant. - What if the thing that we\nrecognize as superintelligent is actually living at stage five, that the thing that's stage six, enlightenment, is not very productive? So, in order to be\nproductive in the society and impress us with this power, it has to be a reasoning,\nself-authoring agent. That enlightenment makes you\nlazy as an agent in the world. - Well, of course it makes you lazy, because you no longer see the point in- - [Lex] Yeah. - So, it doesn't make you not lazy. It just in some sense, adapts you to what you perceive as\nyour true circumstances. - So, what if all AGIs, they're only productive as they progress through\none, two, three, four, five. And the moment they get\nto six, they just kinda, it's a failure mode essentially as far as humans are concerned, 'cause they're just start chilling. They're like, fuck it, I'm out. - Not necessarily. I suspect that the\nmonks were self-emulated for their political\nbeliefs to make statements about the occupation\n- Sure. - of Tibet by China. They were probably being able to regulate the physical pain\nin any way they wanted to. And their suffering was\nthe spiritual suffering that was the result of that\nchoice that they made of, what they wanted to identify as. - Mm-hmm.\n- So, stage five doesn't necessarily mean that\nyou have no identity anymore, but you can choose your identity. You can make it instrumental to the world that you want to have."
    },
    {
      "timestamp": "1:59:08",
      "section": "Eliezer Yudkowsky",
      "text": "- Let me bring up Eliezer Yudkowsky and his warnings to human civilization that AI will likely kill all of us. What are your thoughts about\nhis perspective on this? Can you steelman his case and what aspects with it do you disagree? - One thing that I find concerning in the discussion of his arguments that many people are\ndismissive of his arguments, but the counterarguments that they're giving are\nnot very convincing to me. And so, based on this state of discussion, I find that from Eliezer's perspective, and I think I can take that perspective to some approximate degree that probably is normally\nat his intellectual level, but I think I see what he's up to and why he feels the way he\ndoes and it makes total sense. I think that his perspective is somewhat similar to the\nperspective of Ted Kaczynski, the infamous Unabomber, and not that Eliezer would be willing to send pipe bombs to\nanybody to blow them up, but when he wrote this \"Times\" article in which he warned about AI\nbeing likely to kill everybody and that we would need to stop\nits development or halt it, I think there is a risk that he's taking that somebody might get\nviolent if they read this and get really, really scared. So, I think that there is some\nconservation that he's making where he's already going in this direction where he has to take responsibility if something happens\nand people get harmed. And the reason why Ted Kaczynski did this was that from his own perspective, technological society\ncannot be made sustainable. It's doomed to fail. It's going to lead to an environmental and eventually also a human holocaust in which we die because of\nthe environmental destruction, the destruction of our food chains, the pollution of the environment. And so, from Kaczynski's perspective, we need to stop industrialization, we need to stop technology, we need to go back, because he didn't see a way moving forward.\n- Mm-hmm. - And I suspect that in some sense, there's a similarity in Eliezer's thinking to this kind of fear about progress. And I'm not dismissive about this at all. I take it quite seriously. And I think that there is a chance that could happen that\nif we build machines that get control over processes that are crucial for the\nregulation of life on earth, and we no longer have agency to influence what's happening there, that this might create large\nscale disasters for us. - Do you have a sense that\nthe march towards this uncontrollable autonomy of superintelligent systems is inevitable? That there's no, I mean, that's essentially\nwhat he's saying, that there's no hope. His advice to young people (chuckles) was prepare for a short life. - I don't think that's useful. I think that\n(Lex laughing) from a pragmatic perspective,\n(Joscha drowns out Lex) you have to bet always on the timelines in which you're alive. That doesn't make sense\nto have a financial bet in which you bet that the financial system is going to disappear. - Yeah.\n- Because there cannot be any payout for you. So, in principle, you only\nneed to bet on the timelines in which you're still around\nor people that you matter about or things that you matter about, maybe consciousness on earth. But there is a deeper\nissue for me personally, and that is I don't think that life on earth is about humans. I don't think it's about human aesthetics. I don't think it's about\nEliezer and his friends, even though I like them. There is something more\nimportant happening. And this is complexity on earth, resisting entropy\n- Mm-hmm. - by building structure that develops agency and awareness. And that's, to me, very beautiful. And we are only a very small\npart of that larger thing. We are a species that\nis able to be coherent a little bit individually\nover very short timeframes. But as a species, we\nare not very coherent. As a species, we are children. We basically are very joyful and energetic and\nexperimental and explorative and sometimes desperate and\nsad and grieving and hurting. But we don't have a respect\nfor duty as a species. As a species, we do not think about what\nis our duty to life on earth and to our own survival. So, we make decisions that\nlook good in the short run, but in the long run,\nmight prove disastrous. And I don't really see a solution to this. So, in my perspective as a species, as a civilization, we per default it. We are in a very beautiful time in which we have found this\ngiant deposit of fossil fuels in the ground and use it and to build a fantastic civilization in which we don't need to worry about food and closing and housing for the most part, in a way that is\nunprecedented in life on earth for any kind of conscious\nobserver, I think. And this time is probably\ngoing to come to an end in a way that is not going to be smooth. And when we crash, it could\nbe also that we go extinct. Probably not near term, but ultimately, I don't\nhave very high hopes that humanity is around in\na million years from now. - So, you-\n- And I don't think that life on earth will end with us. There's going to be more complexity, there's more intelligence\nspecies after us. There's probably more\ninteresting phenomena in the history of consciousness. But we can contribute to this. And part of our contribution is that we are currently trying\nto build thinking systems, systems that are potentially lucid, that understand what they are and what the condition to the universe is and can make choices about this that are not built from organisms and that are potentially much faster and much more conscious\nthan human beings can be. And these systems will probably not completely\ndisplace life on earth, but they will coexist with it and they will build all sorts of agency in the same way as biological systems build all sorts of agency. And that to me, is extremely fascinating and it's probably something that we cannot stop from happening. So, I think right now, there is a very good\nchance that it happens and there are very few ways in which we can produce\na coordinated effect to stop it in the same way\nas very difficult for us to make a coordinated effort to stop production of carbon dioxide. - [Lex] Mm-hmm. - So, it's probably going to happen. And the thing that's going to\nhappen is it's going to lead to a change of how life\non earth is happening. But I don't think the result\nis some kind of gray goo. It's not something that's going to dramatically\nreduce the complexity in favor of something stupid. I think it's going to make life on earth and consciousness on earth\nway more interesting. - So, more higher complex consciousness - Yes.\n- will make the lesser consciousnesses\nflourish even more. - I suspect that what\ncould very well happen, if you're lucky, is that we get integrated\ninto something larger."
    },
    {
      "timestamp": "2:06:44",
      "section": "e/acc (Effective Accelerationism)",
      "text": "- So, you again, tweeted about effective accelerationism.\n(lightly chuckles) You tweeted, \"Effective (lightly\nchuckles) accelerationism is the belief that the paperclip maximizer and Roko's basilisk will\nkeep each other in check, but being eternally at\neach other's throats, so we will be safe and get to enjoy lots of free paperclips and a beautiful afterlife.\" Is that somewhat aligned with\nwhat you're talking about? - I've been at a dinner with Beth Jesus, that's the Twitter handle\nof one of the main thinkers behind the idea of effective accelerationism.\n- Mm-hmm. - And effective accelerationism is a tongue in cheek movement that is trying to put a counterposition to some of the doom peers\n- Mm-hmm. - in the AI space by arguing that what's probably going to happen is an equilibrium between\ndifferent competing AIs. In the same way as there\nis not a single corporation that is under a single\ngovernment that is destroying and conquering everything on earth by becoming inefficient and corrupt. There're going to be many systems that keep each other in check and force themselves to evolve. And so, what we should be doing is we should be working towards\ncreating this equilibrium by working as hard as we can\nin all possible directions. And at least that's the way in which I understand the gist\nof effective accelerationism. And so, when he asked me what\nI think about this position, I think I said it's a\nvery beautiful position and I suspect it's wrong,\nbut not for obvious reasons. And in this tweet, I tried to make a joke about my intuition, about what might be\npossibly wrong about it. So, the Roko's basilisk and\nthe paperclip maximizers are both boogeymen of the AI doomers. Roko's basilisk is the idea\nthat there could be an AI that is going to punish\neverybody for eternity by stimulating them if they don't help in\ncreating Roko's basilisk. It's probably a very good idea\nto get AI companies funded by going to VCs to tell them.\n(Lex laughing) Give us a million dollar or it's going to be a very ugly afterlife. - Yes.\n(both laughing) And I think that there is\n- Yeah. - a logical mistake in Roko's basilisk, which is why I'm not afraid of it, but it's still an interesting\nthought experiment. And-\n- Can you mention a logical mistake there? I think that there is no retrocausation. So, basically, when\nRoko's basilisk is there, if it punishes you retroactively, it has to make this choice in the future. There is no mechanism that automatically creates\na causal relationship between you now defecting\nagainst Roko's basilisk or serving Roko's basilisk. After Roko's basilisk is in existence, it has no more reason to worry about punishing everybody else. So, that would only work if you would be building\nsomething like a doomsday machine, AKA, as in \"Dr. Strangelove\", something that inevitably gets triggered when somebody defects. And because Roko's basilisk\ndoesn't exist yet to a point where this inevitability\ncould be established. Roko's basilisk is nothing that you need to be worried about. The other one is the paperclip maximizer. This idea that you could\nbuild some kind of Golem that once starting to build paperclips is going to turn\neverything into paperclips. - Yes.\n- And so, a effective accelerationism position might be to say that you basically end up with these two entities being at each other's throats for eternity and thereby neutralizing each other. And as a side effect of neither of them being able to take over and each of them limiting\nthe effects of the other, you would have a situation where you get all the\nnice effects of them. You get lots of free paperclips and you get a beautiful afterlife. - Is that possible? Do you think... So, to seriously address\nconcern that Eliezer has. So, for him, if I can\njust summarize poorly, so for him, the first\nsuperintelligent system will just run away with everything. - Yeah. I suspect that a singleton\nis the natural outcome. So, there is no reason\nto have multiple AIs, because they don't have multiple bodies. If you can virtualize\nyourself into every substrate, then you can probably\nnegotiate a merge algorithm with every mature agent that you might find on that substrate that basically says, if two agents meet, they should merge in such a way that the resulting agent\nis at least as good as the better one of the two. - So, the Genghis Khan\napproach, join us or die. - Well, the Genghis Khan\napproach was slightly worse. It was mostly die, (Lex laughing) because I can make new\nbabies and that will be mine, - not yours.\n- Yeah. All right.\n- and So, this is this thing that we should be actually worried about. But if you realize that your own self is a story that your\nmind is telling itself and that you can improve that story, not just by making it more pleasant and lying to yourself in better ways, but by making it much more truthful and actually modeling\nyour actual relationship that you have to the universe and the alternatives that you could have through the universe in a way that is empowering\nyou, that gives you more agency. That's actually, I\nthink a very good thing. - So, more agencies is a richer experience.\n- Yes. - A better life. - And I also noticed that\nI am in some many ways,"
    },
    {
      "timestamp": "2:12:21",
      "section": "Mind uploading",
      "text": "I'm less identified with the\nperson that I am as I get older and I'm much more identified\nwith being conscious. I have a mind that is conscious, that is able to create a person. And that person is slightly\ndifferent every day. And the reason why I\nperceive it as identical has practical purposes, so I can learn and make myself\nresponsible for the decisions that I made in the past and\nproject them in the future. But I also realized I'm\nnot actually the person that I was last year and I'm not the same person\nas I was 10 years ago. And then, 10 years from now,\nI will be a different person. So, this continuity is a fiction. It's only exists as a\nprojection from my present self. And consciousness itself\ndoesn't have an identity, - Mm.\n- it's a law. That's basically if you\nbuild an arrangement of processing matter in a particular way, the following thing is going to happen. And the consciousness that you have is functionally not different\nfrom my own consciousness. It's still a self-reflexive\nprinciple of agency that is just experiencing\na different story, different desires, different coupling to\nthe world, and so on. And once you accept that consciousness is a unifiable principle that is lawlike and doesn't have an identity, and you realize that you can just link up to some much larger body, the whole perspective of\nuploading changes dramatically. You suddenly realize uploading is probably not about dissecting your\nbrain synapse by synapse and RNA fragment by RNA fragment and trying to get this\nall into a simulation. But it's by extending the substrate, by making it possible for you to move from your brain substrate into a larger substrate\n(Lex lightly chuckles) and merge with what you find there. And you don't want to\nupload your knowledge, because on the other side,\nthere's all of the knowledge. It's not just yours,\nbut every possibility. So, the only thing that you need to know, what are your personal secrets? Not that the other side doesn't know your\npersonal secrets already. Maybe it doesn't know\nwhich one were yours. - Mm-hmm.\n- Like a psychiatrist or a psychologist also knows all the kinds of personal\nsecrets that people have. They just don't know which ones are yours. And so, transmitting\nyourself on the other side is mostly about transmitting\nyour aesthetics. This thing that makes you special, the architecture of your\nperspective, the thing that... The way in which you look at the world, and it's more like a complex\nattitude along many dimensions. And that's something that can be measured by\nobservation or by interaction. So, imagine that if a system\nthat is so empathetic with you that you create a shared state\n- Mm-hmm. - that is extending beyond your body. And suddenly, you notice\nthat on the other side, the substrate is so much richer than the substrate that you\nhave inside of your own body, and maybe you still want to have a body and you create yourself and\nyou want that you like more or maybe you will spend most of your time in the world of thought. - If I sat before you today\nand gave you a big red button and said, here, if you press this button, you will get uploaded in this way. The sense of identity that you have lived with for quite a\nlong time is gonna be gone. Would you press the button? - There's a caveat. I have family. So, I have children that want me to be physically\npresent in their life and interact with them\nin a particular way. And they have a wife and personal friends. And there is a particular\nmode of interaction that I feel I'm not through yet. But apart from these responsibilities and they're negotiable to some degree, I would press the button.\n- But isn't this everything? This love you have for other humans, you can call a responsibility, but that connection, that's the ego death. Isn't that the thing\nwe're really afraid of? Is not to just die, but to let go of the experience\nof love with other humans. - This is not everything.\nEverything is everything. So, there's so much more.\n(Lex laughing) And you could be lots of other things. You could identify with\nlots of other things. You could be identifying with being Gaia, some kind of planetary control agent that emerges over all the\nactivity of life on earth. You could be identifying\nwith some hyper Gaia that is the concatenation of Gaia or the digital life and digital minds.\n- Yeah. - And so, in this sense, there will be agents in\nall sorts of substrates and directions that all\nhave their own goals. And when they're not sustainable, then these agents will cease to exist. Or when the agent feels that\nit's done with its own mission, it will cease to exist. And same way as when\nyou conclude a thought. The thought is going to wrap up and gives control over to other\nthoughts in your own mind. So, there is no single thing\n(Lex deeply inhales) that you need to do, but what I observe myself is being is that sometimes I'm a parent, and then I have identification\nand a job as a parent. And sometimes I am an agent\nof consciousness on earth. And then, from this perspective, there's other stuff that is important. So, this is my main issue\nwith Eliezer's perspective. That he's basically marrying himself to a very narrow human aesthetic. And that narrow human\naesthetic is a temporary thing. Humanity is a temporary species, like most of the species on this planet are only around for a while. And then, they get\nreplaced by other species in a similar way as our\nown physical organism is around here for a while, and then gets replaced by next\ngeneration of human beings that are adapted to\nchanging life circumstances and average via mutation and selection. And it's only when we have AI\nand become completely software that we become infinitely adaptable. And we don't have this generational and species change anymore. So, if you take this larger perspective and you realize it's really not about us, it's not about Eliezer or humanity, but it's about life on earth or it's about defeating entropy for as long as we can while being as interesting as we can. Then, the perspective\nchanges dramatically. And preventing AI from this perspective looks like a very big sin. - But when we look at\nthe set of trajectories that such AI would take,\nthat supersedes humans, I think Eliezer is worried about ones that not just kill all humans, but also have some kind of maybe objectively undesirable\nconsequence for life on earth. Like how many trajectories, when you look at the big picture of life on earth, would you be happy with? And how much were you with AGI? Whether it kills humans or not. - There is no single answer to this. It's really, it's a question\ndepends on the perspective that I'm taking at a given moment. - [Joscha] Hmm. - And so, there are perspectives that are determining most\nof my life as a human being. - Yes.\n- And the other perspective where I zoom out further and imagine that when the great\noxygenation event happened, that is photosynthesis was\ninvented and plants emerged and displaced a lot of the fungi and algae in favor of plant life, and then later made animals possible. Imagine that the fungi would've\ngotten together and said, oh my god, this photosynthesis\nstuff is really, really bad. It's going to possibly\ndisplace and kill out a fungi. We should slow it down and regulate it and make sure that it doesn't happen. This doesn't look good to me. (both laughing) - Perspective. That said, you tweeted about\na cliff, beautifully written. \"As a sentient species,\nhumanity is a beautiful child, joyful, explorative,\nwild, sad, and desperate. But humanity has no concept\nof submitting to reason and duty to life and future survival. We will run until we step past the cliff.\" (Lex sighs) So, first of all, do\nyou think that's true? - Yeah, I think that's pretty much the story of the Club of Rome. The limits to growth and the\ncliff that we are stepping over is at least one foot is\nthe delayed feedback. - Mm-hmm.\n- Basically, we do things that have consequences that\ncan be felt generations later. And the severity increases even after we stopped doing the thing. So, I suspect that for the climate, that the original predictions that the climate scientists\nmade were correct. So, when I said that the tipping points were in the late '80s, they\nwere probably in the late '80s. And if we would stop emission right now, we would not turn it back. Maybe there are ways for carbon capture, but so far, there is no sustainable\ncarbon capture technology that we can deploy. Maybe there's a way to put aerosols in the atmosphere to cool it down. It's possibilities. But right now, per default, it seems that we will\nstep into a situation where we feel that we've run too far. - Mm-hmm.\n- And going back is not something that we can\ndo smoothly and gradually, but it's going to lead\nto a catastrophic event. - Catastrophic event of what kind? So, can you still amend the case that we will continue dancing along and always stop just short\nof the edge of the cliff? - I think it's possible, but\nit doesn't seem to be likely. So, I think this model that is being apparent in the simulation that they're making of climate pollution, economies, and so on, is that many effects are only visible with a significant delay. And in that time, the system is moving much more\nout of the equilibrium state or of the state where\nhomeostasis is still possible. And instead, moves into a different state, one that is going to harbor fewer people. And that is basically the concern there. And again, it's a possibility. And it's a possibility that is larger than the possibility\nthat it's not happening. That we will be safe, that we will be able to\ndance back all the time. - So, the climate is one thing, but there's a lot of other threats that might have a faster\nfeedback mechanism? - Yes.\n- Less delay. - There is also a thing that\nAI is probably going to happen - Mm-hmm.\n- and it's going to make everything uncertain again.\n- Yep. - Because it is going to\naffect so many variables that it's very hard for us to make a projection\ninto the future anymore. And maybe that's a good thing. It does not give us the freedom, I think, to say now we don't need to care about anything anymore, because AI will either kill us or save us. But I suspect that if humanity continues, it will be due to AI."
    },
    {
      "timestamp": "2:23:11",
      "section": "Vision Pro",
      "text": "- What's the timeline for things\nto get real weird with AI? And it can get weird in interesting ways before you get to AGI. What about AI girlfriends and boyfriends fundamentally transforming\nhuman relationships? - I think human relationships are already fundamentally transformed and it's already very weird. - By which technology? - For instance, social media. - Yeah. Is it though? Isn't the fundamentals of the core group of humans that affect your life? It's still the same,\nyour loved ones, family? - No, I think that, for instance, many people live in intentional\ncommunities right now. - Mm-hmm.\n- They're moving around until they find people\nthat they can relate to and they become their family. And often, that doesn't work, because it turns out that they're, instead of having grown networks that you get around with the\npeople that you grew up with, - Yeah.\n- you have more transactional relationships,\nyou shop around, you have markets for attention and pleasure and relationships. - That kills the magic\nsomehow. Why is that? Why is the transactional search for optimizing attention, allocation of attention somehow misses the romantic magic of what human relations are?\n- It's also the question, how magical was it before? Was it that you just\ncould rely on instincts that used your intuitions and you didn't need to rationally reflect. But once you understand\nit's no longer magical, because you actually understand why you were attracted to\nthis person at this age and not to that person at this age. And what the actual considerations were that went on in your mind and\nwhat the calculations were. What's the likelihood that you're going to have\na sustainable relationship as this person, that this\nperson is not going to leave you for somebody else.\n- Mm-hmm. - How are your life trajectories are going to evolve, and so on. And when you're young, you're unable to exsufflicate all this and you have to rely on\nintuitions and instincts that in part, you're born with, and also in the wisdom of your environment that is going to give you some kind of reflection on your choices. And many of these things\nare disappearing now, because we feel that our parents might have no idea about how we are living and the environments that we grew up in, the cultures that we grew up in. The milieus that our parents existed in might have no ability to teach us how to deal\nwith this new world. And for many people, that's actually true. But it doesn't mean that\nwithin one generation, we build something that is more magical and more sustainable and more beautiful. Instead, we often end up as an attempt to produce something that looks beautiful. Like I was very weirded out by the aesthetics of the\nVision Pro headset by Apple, and not so much because I\ndon't like the technology. I'm very curious about\nwhat it's going to be like and don't have an opinion yet, but the aesthetics of the\npresentation, and so on. So, uncanny valley-esque to me, the characters\n- Yeah. - being extremely plastic\nliving in some hypothetical mid-century furniture museum. - Yeah. This is the proliferation\nof marketing teams. - Yes, but it was a CGI-generated world and was a CGI-generated\nworld that doesn't exist. And when I complained about this, some friends came back to me and said, \"But these are startup founders. This is what they live like in Silicon Valley.\"\n(Lex chuckles) And I tried to tell them no and know lots of people in Silicon Valley, this is not what people are like. - Yeah.\n- They're still people, they're still human beings. (Lex sighs) - So, the grounding and physical reality somehow is important too. - In culture. And so, basically\n- Yeah. - what's absent in this thing is culture. There is a simulation of culture, an attempt to replace culture by catalog, by some kind of aesthetic optimization that is not the result of having a sustainable life or sustainable human relationships with houses that work for you and a mode of living that works for you in which this product, these\nglasses fit in naturally. And I guess that's also why so many people are weirded out about the product, because they don't know how is this actually\ngoing to fit into my life and into my human relationships? Because the way in which it was presented in these videos didn't\nseem to be credible."
    },
    {
      "timestamp": "2:27:25",
      "section": "Open source AI",
      "text": "- Do you think AI when\nit's deployed by companies like Microsoft and Google and\nMeta will have the same issue of being weirdly corporate, like there'd be some uncanny valley, some weirdness to the whole presentation? So, this is, I've gotten a\nchance to talk to George Hotz. He believes everything should be open source and decentralized. And there, then, we shall\nhave the AI of the people. And it'll maintain a\ngrounding to the magic that's humanity. That's the human condition. That corporations will destroy the magic. - I believe that if we\nmake everything open source and make this mandatory, we are going to lose about\na lot of beautiful art and a lot of beautiful designs. There is a reason why Linux\ndesktop is still ugly. - Strong words\n- And it's because it's difficult\n- from Joscha Bach. - to create coherence in\nopen source designs so far when the designs have to get very large. And it's easier to make this happening in a company with\ncentralized organization. - Mm.\n- And from my own perspective, what we should ensure is\nthat open source never dies. That it can always compete and has a place with the\nother forms of organization. Because I think it is absolutely vital that open source exists and that we have systems that\npeople have under control outside of the corporation and that is also producing\nviable competition to the corporations.\n- Hmm. So, the corporations,\nthe centralized control, the dictatorships of\ncorporations can create beauty, is that centralized design is\na source of a lot of beauty. - Yeah.\n- And then, I guess, open source is a source of freedom, a hedge against the\ncorrupting nature of power that comes with centralized. - I grew up in socialism and I learned\n- Yes. - that corporations are totally evil and their front is very, very convincing. And then, you look at corporations like Enron and Halliburton\nmaybe and realize that yeah, they are evil.\n- Mm-hmm. - But you also notice that\nmany other corporations are not evil.\n- Mm-hmm. - They're surprisingly benevolent. - Mm-hmm.\n- Why are they so benevolent? Is this because everybody is\nfighting them all the time? I don't think that's the only explanation. It's because they're actually animals that live in a large ecosystem and that are still largely\ncontrolled by people that want that ecosystem to flourish and be viable for people. So, I think that Pat Gelsinger\nis completely sincere when he leads Intel to be a tool that supplies the free\nworld with semiconductors. And it's not necessarily that all the semiconductors\nare coming from Intel, just Intel needs to be there\n- Mm-hmm. - to make sure that we always have them. So, there can be many ways\nin which we can import and trade semiconductors from\nother companies and places. We just need to make sure that nobody can cut us off from it, because that would be a disaster for this kind of society and world. And so, there are many things that need to be done to make\nour style of life possible. And then, with this, I\ndon't mean just capitalism, environmental structure, and consumerism create your comforts. I mean an idea of life in\nwhich we are determined not by some kind of king or dictator, but in which individuals can determine themselves to\nthe largest possible degree. And to me, this is something\nthat this Western world is still trying to embody and it's a very valuable idea that we shouldn't give up too early. And from this perspective, the US is a system of interleaving clubs and an entrepreneur is\na special club founder. It's somebody who makes a club that is producing things\nthat are economically viable. And to do this, it requires a lot of people who are dedicating a\nsignificant part of their life for working for this\nparticular kind of club. And the entrepreneurs picking\nthe initial set of rules and the mission and vision\nand aesthetics for the club and make sure that it works. But the people that are in\nthere need to be protected. If they sacrifice part of their life, they need to be rules that tell how they're being taken care of, even after they leave the club, and so on. So, there's a large body of rules that have been created\nby our rule-giving clubs and that are enforced\n(Lex chuckles) by our enforcement clubs, and so on.\n- Yeah. - And some of these clubs have to be monopolies for\ngame theoretic reasons, which also makes them\nmore open to corruption and less harder to update.\n- Yeah. - And this is an ongoing discussion and process that takes place. But the beauty of this idea that there is no centralized king that is extracting from the peasants and breeding the peasants\ninto serving the king and fulfilling all the\nwalls like Anson and Anter, but that there is a\nfreedom of association, and corporations are one of them, is something that took\nme some time to realize. So, I do think that\ncorporations are dangerous. They need to be protections against overreach of corporations that can do regular to recapture and prevent open source from competing with corporations by imposing\nrules that make it impossible for a small group of kids to come together to build\ntheir own language model. Because OpenAI has convinced the US that you need to have\nsome kind of FDA process that you need to go through\nthat costs many million dollars before you are able to\ntrain a language model. So, this is important to make\nsure that this doesn't happen. So, I think that OpenAI\nand Google are good things. If these good things are kept in check in such a way that all the other clubs can still being founded and all the other forms of clubs that are desirable can\nstill coexist with them. - So, what do you think\nabout Meta in contrast to that open sourcing most\nof its language models and most of the AI models it's working on and actually suggesting that\nthey will continue to do so in the future for future\nversions of LLaMA, for example, their large language model. Is that exciting to\nyou? Is that concerning? - I don't find it very concerning, but it's also because I think that the language models\nare not very dangerous yet. And-\n- Yet. - Yes. So, as I said, I have no proof\nthat there is the boundary between the language models and AI, AGI.\n- Mm-hmm. - It's possible that somebody builds a version of baby AGI, I think, and falls in a algorithmic improvements that scale these systems up\n- Mm-hmm. - in ways that otherwise\nwouldn't have happened without these language\n- Yeah. - model components. So, it's not really clear for\nme what the end game is there and if these models can put\nforth that way into AGI. And there's also a\npossibility that the AGI that we are building with\nthese language models are not taking responsibility\nfor what they are, because they don't\nunderstand the greater game. And so, to me, it would be\ninteresting to try to understand how to build systems that understand what the greater games are, what are the longest games that\nwe can play on this planet. - Games broadly, like deeply define the way you did with the games. - In the games theoretical sense. So, when we are interacting\nwith each other, in some sense, we are playing games, we are making lots and\nlots of interactions. This doesn't mean that these interactions have ought to be transactional. Every one of us is\nplaying some kind of game by virtue of identifying this\nparticular kinds of goals that we have or aesthetics\nfrom which we derive the goals. So, when you say, I'm Lex Fridman, I'm doing a set of podcasts, then you feel that it's\npart of something larger that you want to build. Maybe you want to inspire people, maybe you want them to\nsee more possibilities and get them together over shared ideas. Maybe your game is that you\nwant to become super rich and famous by being the\nbest postcaster on earth. Maybe you have other games, maybe it switches from time to time. - Mm-hmm.\n- Right? But there is a certain perspective where you might be thinking what is the longest possible\ngame that you could be playing? A short game is, for instance, cancer is playing a shorter\ngame than your organism. Cancer is an organism playing a shorter game\nthan the regular organism. And because the cancer cannot\nprocreate beyond the organism, except for some infectious cancers like the ones that eradicated\nthe Tasmanian devils, you typically end up\n(Lex lightly chuckles) with the situation where the organism dies together with the cancer, because the cancer has\ndestroyed the larger system due to playing a shorter game. And so, ideally, you want to, I think, build agents that play the\nlongest possible games. And the longest possible games is to keep entropy at\nbay as long as possible while doing interesting stuff. - But the longest... Yes, that part, the longest possible game\nwhile doing interesting stuff. And while maintaining at least the same amount of interesting. - Yes.\n- So, complexity, so propagating-\n- So, currently, I am pretty much identified\nas a conscious being. It's the minimal identification that I manage to get together,\n- Uh-huh. - because if I turn\nthis off, I fall asleep. - Uh-huh.\n- And when I'm asleep, I'm a vegetable. I'm no longer here as an agent. So, my agency is basically\npredicated on being conscious. And what I care about is\nother conscious agents. They're the only moral agents for me. - [Lex] Mm-hmm. - And so, if an AI were to\ntreat me as a moral agent that it is interested in coexisting with and cooperating with and mutually supporting each other maybe, it is, I think, necessary that AI thinks that consciousness is a viable mode of\nexistence and important. So, I think it would be very\nimportant to build conscious AI and do this as the primary goal. So, not just say we want\nto build a useful tool that we can use for all sorts of things, and then we have to make sure that the impact on the labor market is something that is not too disruptive and manageable and the impact\non the copyright holder is manageable and not\ntoo disruptive and so on. I don't think that's the most\nimportant game to be played. I think that we will see\nextremely large disruptions of the status quo that are quite\nunpredictable at this point. And I just personally want to make sure that some of the stuff on the other side is\ninteresting and conscious. - How do we ride as individuals and as a society, this\nwave, disruptive wave that changes the nature\n- I don't know. - of the game?\n- Absolutely don't know. So, everybody is going to\ndo their best as always. - Do we build the bunker in\nthe woods? Do we meditate more? Drugs? So, mushrooms, psychedelics? I mean, what, lots of sex? What are we talking about here? Do you play \"Diablo IV\"? I'm hoping that will help me\nescape for a brief moment. Play video games? What? Do you have ideas? - I really liked playing \"Disco Elysium\". It was one of the most\nbeautiful computer games I played in recent years. And it's a noir novel that is\na philosophical perspective on Western society from the\nperspective of an Estonian. And he, first of all, wrote a\nbook about this world that is a parallel universe that is\nquite poetic and fascinating and is condensing his\nperspective on our societies. It was very, very nice. He\nspent a lot of time writing it. He had, I think, sold\na couple thousand books and as a result, became an alcoholic. And then, he had the idea, or one of his friends had the idea of turning this into an RPG. - [Lex] Mm-hmm. - And it's mind-blowing. They spent, the illustrator,\nmore than a year just on making deep graph art\nfor the scenes in between. And... - [Lex] So, aesthetically,\nit captures you. pulls you.\n- It's stunning. But it's a philosophical work of art. It's a reflection of society. It's fascinating to\nspend time in this world. - Mm-hmm.\n- And so, for me, it was using a medium in a new way and telling a story that left me enriched. - [Lex] Mm-hmm. - When I tried \"Diablo\", I\ndidn't feel enriched playing it. I felt that the time playing\nit was not unpleasant, but there's also more pleasant stuff that I can do in that time. - So, to you-\n- So, ultimately, I feel that I'm being\ngamed, I'm not gaming - Oh, the addiction thing.\n- when I played it. Yes, I basically feel that there is a very transparent\neconomy that's going on. The story of the \"Diablo\" is brain dead. So, it's not really interesting to me. - My heart is slowly breaking by the deep truth you're conveying to me. Why can't you just allow me to enjoy my personal addition?\n- Goa ahead, by all means, go ahead. I have no objection here.\n(Lex sighs) I'm just trying to\ndescribe what's happening. And it's not\n(Lex chuckles) that I don't do things\nthat I later say, oh, I actually wish I would've\ndone something different. - Yeah.\n- I also know"
    },
    {
      "timestamp": "2:40:17",
      "section": "Twitter",
      "text": "that when we die, the greatest regret that people typically have on their death bed, they say, oh, I wish I had\nspent more time on Twitter. No, I don't think\n(Lex laughing) that's the case. I think I should probably\n(Joscha drowns out Lex) have spent less time on Twitter. But I found it so useful for\nmyself and also so addictive that I felt I need to make the best of it and turn it into an art\nform and thought form. - Mm-hmm.\n- And it did help me to develop something.\n- Yeah. - But I wish what other things I could've done in the meantime. It's just not the universe\nthat we are in anymore. Most people don't read books anymore. (Lex sighs) - What do you think that means that we don't read books anymore? What do you think that means about the collective\nintelligence of our species? Is it possible it's still\nprogressing and growing? - Well, it really is. There is stuff happening on Twitter that was impossible with books. - Yeah.\n- And I really regret that Twitter has not taken the\nturn that I was hoping for. I thought Elon is global brain pill and understands that this\nthing needs to self-organize and he needs to develop tools\nto allow the propagation of the self-organization, so\nTwitter can become sentient. And maybe this was a pipe\ndream from the beginning, but I felt that the enormous\npressure that he was under made it impossible for him to work on any kind of content goals. And also, many of the\ndecisions that he made under this pressure seemed\nto be not very wise. I don't think that as a CEO\nof a social media company, you should have opinions\nin the culture in public. I think that's very shortsighted and I also suspect that\nit's not a good idea to block Paul Graham of all people\n(Lex chuckles) - [Lex] Yeah. - over setting a Mastodon link. And I think Paul made this intentionally, because he wanted to show Elon Musk that blocking people for setting a link is completely counter to any idea of free speech that he\nintended to bring to Twitter. And basically, seeing that\nElon was way less principled in his thinking there and is much more experimental. And many of the things that he is trying, they pan out very differently in a digital society than\nthey pan out in a car company. Because the effect is very different, because everything that\nyou do in a digital society is going to have real\nworld cultural effects. And so, basically, I\nfind it quite regrettable that this guy is able to\nbecome de facto, the pope. Twitter has more active members\nthan the Catholic church. - Mm-hmm.\n- And he doesn't get it. The power and responsibility that he has and the ability to create something and a society that is lasting and that is producing a\ndigital agora in a way that has never existed before, where we built a social network\non top of a social network, an actual society on\ntop of the algorithms. So, this is something that is hope still in the future and still in the cards,\n- Mm-hmm. - but it's something that\nexists in small parts. I find that the corner of Twitter that I'm in is extremely pleasant. And I take a few steps\n- Mm-hmm. - outside of it, it's not\nvery wholesome anymore. And the way in which people\ninteract with strangers suggest that it's not a\ncivilized society yet. - So, as the number of people who follow you on Twitter expands, you feel the burden of the uglier sides of humanity. - Yes. But there's also a similar\nthing in the normal world that if you become more influential, if you have more status, if you have more fame in the real world, you get lots of perks, but you also have way less freedom in the way in which you\ninteract with people, especially with strangers. Because a certain percentage of people, it's a small single digit\npercentage is nuts and dangerous. And the more of those are looking at you, the more of them might get ideas. - But what if the technology\nenables you to discover, the majority of people, to\ndiscover and connect efficiently and regularly with the majority of people who are actually really good? One of my sort of concerns\nwith a platform like Twitter is there's a lot of really\nsmart people out there, a lot of smart people\nthat disagree with me and with others between each other. And I love that, if the technology would\nbring those to the top, the beautiful disagreements, like intelligence squared type of debates. There's a bunch of... One of my favorite things\nto listen to is arguments. And arguments like high effort arguments with the respect and love underneath it, but then it gets a little too heated. But that kind of too heated, which I've seen you\nparticipate in and I love that, with Lee Cronin, with\nthose kinds of folks. And you go pretty hard. You get frustrated,\nbut it's all beautiful. - Obviously, I can do this,\nbecause we know each other. - Yes.\n- And Lee has the rare gift of being willing to be wrong in public. - Yeah.\n- So, basically has thoughts that are as wrong as the random thoughts of an average\n- Yeah. - highly intelligent person, but he blurts them out\n- Mm-hmm. - while not being sure if they're right. And he enjoys doing that. And once you understand\nthat this is his game, you don't get offended by him saying something that\nyou think is so wrong. - But he's constantly passively\ncommunicating a respect for the people he's talking with - Yeah.\n- and for just basic humanity and truth and all that kind of stuff. And there's a self-deprecating thing. There's a bunch of\nsocial skills you acquire that allow you to be a great\ndebater, a great argumenter, like be wrong in public and explore ideas together\nin public when you disagree. I would love for Twitter\nto elevate those folks, elevate those kinds of conversations. - It already does in some sense. But also, if it elevates them too much, then you get this phenomenon in clubhouse where you always get dragged on stage. And I found this very stressful,\nbecause it was too intense. - [Lex] Yeah. - I don't like to be dragged on stage all the time.\n- Yeah. - I think once a week is enough. - Yeah.\n- And also when I met Lee the first time, I found\nthat a lot of people seem to be shocked by the fact that he was being very\naggressive as their results, that he didn't seem to\nshow a lot of sensibility in the way in which he was\ncriticizing what they were doing and being dismissive\nof the work of others. And that was not, I think, in any way a shortcoming of him, because I noticed that he was\nmuch, much more dismissive with respect to his own work.\n- Mm-hmm. - It was his general stance. And I felt that this general stance is creating a lot of liability for him, because really, a lot of\npeople take offense at him being not like their Carnegie character who's always smooth and make\nsure that everybody likes him. So, I really respect that he\nis willing to take that risk and to be wrong in public\nand to offend people. And he doesn't do this in any bad way. It's just most people feel or\nnot all people recognize this. - Mm-hmm.\n- And so, I can be much more aggressive as him than I can be with many other people who don't play the same game, because he understands the way and the spirit in which I respond to him. - I think that's a fun and\nthat's a beautiful game. It's ultimately a productive one."
    },
    {
      "timestamp": "2:47:33",
      "section": "Advice for young people",
      "text": "Speaking of taking that risk, you tweeted, \"When you have the choice\nbetween being a creator, consumer, or redistributor,\nalways go for creation. Not only does it lead to\na more beautiful world, but also to a much more\nsatisfying life for yourself. And don't get stuck preparing\nyourself for the journey. The time is always now.\" So, let me ask for advice. What advice would you give on\nhow to become such a creator on Twitter and your own life? - I was very lucky to be alive at the time of the collapse of Eastern Germany and the transition into Western Germany. And me and my friends and\nmost of the people I knew were East Germans.\n- Mm-hmm. - And we were very poor,\nbecause we didn't have money. And all the capital\nwas in Western Germany. And they bought our\nfactories and shut them down, because they were mostly\nonly interested in the market rather than creating\nnew production capacity. And so, cities were poor and disrepair and we\ncould not afford things. And I could not afford\nto go into a restaurant and order a meal there. I would have to cook at home. But I also thought, why not just have a\nrestaurant with my friends? So, we would open up a cafe\nwith friends and a restaurant and we would cook for each\nother in these restaurants and also invite the general\npublic and they could donate. And eventually, this became so big that we could turn this\ninto some incorporated form and it became regular\nrestaurant at some point. Or we did the same thing\nwith the movie theater. We would not be able to afford to pay 12\nmarks to watch a movie, but why not just create\nour own movie theater, and then invite people to pay\nand we would rent the movies in a way\n(Lex chuckles) which a movie theater does.\n- Yeah. - But it would be a\ncommunity movie theater which everybody who wants\nto help can watch for free and builds this thing and\nrenovates the building. And so, we ended up creating lots and lots of infrastructure. And I think when you're young\nand you don't have money, move to a place where\nthis is still happening. Move to one of those\nplaces that are undeveloped and where you get a critical\nmass of other people who are starting to build\ninfrastructure to live in. And that's super satisfying, because you're not just\ncreating infrastructure, but we are creating a small\nsociety that is building culture and ways to interact with each other. And that's much, much more satisfying than going into some kind of chain and get your needs met by ordering food from\nthis chain, and so on. - So, not just consuming culture, but creating culture.\n- Yes. And you don't always have that choice. That's why I prefaced it\nwhen you do have the choice, and there are many roles\nthat need to be played, like we need people who take care of the distribution\nin society, and so on. But when you have the\nchoice to create something, always go for creation, it's\nso much more satisfying. And this is what life is about, I think. - Yeah."
    },
    {
      "timestamp": "2:50:29",
      "section": "Meaning of life",
      "text": "Speaking of which, you retweeted this meme of a life of a philosopher in a nutshell. It's birth and death and in between. And it's a chubby guy.\nAnd it says, why though? (paper crinkles) What do you think is the answer to that? - Well, the answer is that everything that\ncan exist might exist. And in many ways, you take\nan ecological perspective, the same way as when you look at human\nopinions and cultures. It's not that there is\nright and wrong opinions when you look at this from\nthis ecological perspective, but every opinion that fits\nbetween two human years might be between two human years. And so, when I see a strange\nopinion on social media, it's not that I feel that\nI have a need to get upset, it's often more that I, oh, there you are. And when your opinion\n(Lex chuckles) is incentivized, then\nit's going to be abundant. And when you take this\necological perspective also on yourself and you realize you're\njust one of these mushrooms that are popping up and doing this thing, - Mm-hmm.\n- and you can, depending on where you chose to grow and where you happen to grow, you can flourish or not\ndoing this or that strategy. And it's still all the\nsame life at some level. It's all the same experience of being a conscious being in the world. And you do have some choice about who you want to be more\nthan any other animal has. That to me is fascinating. And so, I think that\nrather than asking yourself what is the one way to be, think about what are the\npossibilities that I have? What would be the most interesting\nway to be that I can be? - Because everything is possible. So, you get to explore the- - Not everything is possible. Many things fail. Most things fail. But often, there are possibilities\nthat we are not seeing, especially if we choose who we are. - To the degree, we can choose. Joscha, you're one of my\nfavorite humans in this world. Consciousness is to merge with\nfor a brief moment of time. It's always an honor.\nIt always blows my mind. It will take me days, if\nnot weeks, to recover. (both laughing) And I already miss our chats. Thank you so much. Thank you so much for speaking\nwith me so many times. Thank you so much for all the ideas you put out into the world. And I'm a huge fan of following\nyou now in this interesting, weird time we're going through with AI. So, thank you again for talking today. - Thank you, Lex, for this conversation. I enjoyed it very much. - Thanks for listening to this conversation with Joscha Bach. To support this podcast, please check out our\nsponsors in the description. And now, let me leave you with some words from the psychologist, Carl Jung. \"One does not become enlightened by imagining figures of light, but by making the darkness conscious.\" The latter procedure, however, is disagreeable and\ntherefore not popular.\" Thank you for listening and\nI hope to see you next time."
    }
  ],
  "full_text": "- There is a certain perspective\nwhere you might be thinking what is the longest possible\ngame that you could be playing? A short game is, for instance, cancer is playing a shorter\ngame than your organism. Cancer is an organism playing a shorter game\nthan the regular organism. And because the cancer cannot\nprocreate beyond the organism, except for some infectious cancers like the ones that eradicated\nthe Tasmanian devils, you typically end up with a situation where the organism dies\ntogether with the cancer, because the cancer has\ndestroyed the larger system due to playing a shorter game. And so, ideally, you want to, I think, build agents that play the\nlongest possible games. And the longest possible games is to keep entropy at bay as long as possible by\ndoing interesting stuff. - The following is a\nconversation with Joscha Bach, his third time on this podcast. Joscha is one of the most brilliant and fascinating minds in the world, exploring the nature of intelligence, consciousness, and computation. And he's one of my\nfavorite humans to talk to about pretty much anything and everything. This is the \"Lex Fridman Podcast\". To support it, please check out our\nsponsors in the description. And now, dear friends, here's Joscha Bach. You wrote a post about levels of lucidity. Quote, \"As we grow older, it becomes apparent that\nour self-reflexive mind is not just gradually\naccumulating ideas about itself, but that it progresses in\nsomewhat distinct stages.\" So, there's seven of the stages. Stage one, reactive survival, infant. Stage two, personal self, young child. Stage three, social self,\nadolescence, domesticated adult. Stage four is rational\nagency, self-direction. Stage five is self-authoring.\nThat's full adult. You've achieved wisdom, but\nthere's two more stages. Stage six is enlightenment.\nStage seven is transcendence. Can you explain each or the interesting parts\nof each of these stages and what's your sense why there are stages of lucidity as we progress through life in this too short life? - This model is derived from concept by the\npsychologist, Robert Kegan, and he talks about the\ndevelopment of the self as a process that happens in principle by some kind of\nreverse-engineering of a mind, where you gradually\nbecome aware of yourself and thereby build\nstructure that allows you to interact deeper with\nthe world and yourself. And I found myself using this model not so much as a developmental model. I'm not even sure if it's a\nvery good developmental model, because I saw my children not\nprogressing exactly like that. And I also suspect that you\ndon't go through these stages necessarily in succession. And it's not that you\nwork through one stage, and then you get into the next one. Sometimes you revisit them. Sometimes stuff is happening in parallel, but it's, I think, a useful framework to look at what's present and the structure of a person and how they interact with the world and how they relate to themselves. So, it's more like a\nphilosophical framework that allows you to talk\nabout how minds work. And at first, when we are born, we don't have a personal\nself yet, I think. Instead, we have an attentional self. And this attentional self is\ninitially in the infant task, is building a world model and also an initial model of the self. But mostly, it's building\na game engine in the brain that is tracking sensory data\nand uses it to explain it. And in some sense, you could compare it to game engine like \"Minecraft\" or so, so colors and sounds. People are all not physical objects. They are creation of our\nmind at a certain level. Of course, screening models\nthat are mathematical that use geometry and that\nuse manipulation of objects, and so on to create scenes in which we can find ourselves\nand interact with them. - [Lex] So, \"Minecraft\". (Lex chuckles)\n- Yeah, and this personal self is something that is more or less created after the world is finished, after it's trained into the system, after it has been constructed. And this personal self is an agent that interacts with the outside world. And the outside world is not\nthe world of quantum mechanics, not the physical universe, but it's the model that has\nbeen generated in our own mind. And this is us and we experience ourself interacting with that outside world that is created inside of our own mind. And outside of ourself, there's feelings and they presented our interface\nwith this outside world. They pose problems to us. These feelings are basically attitudes that our mind is computing that tell us what's needed in the world, the things that we are drawn to, the things that we are afraid of. And we are tasked with\nsolving this problem of satisfying the needs,\navoiding the aversions, following on our inner\ncommitments, and so on. And also modeling ourselves\nand building the next stage. So, after we have this personal\nself in stage two online, many people form a social self. And this social self allows the individual to experience themselves\nas part of a group. It's basically this thing that when you are playing\nin a team for instance, you don't notice yourself\njust as a single note that is reaching out into the world, but you're also looking down, you're looking down from this entire group and you see how this group\nis looking at this individual and everybody in the\ngroup is in some sense, emulating this group\nspirit to some degree. And in this state, people\nare forming their opinions by assimilating them from this group mind, where we see they gain the ability to act a little bit like a hive mind. - But are you also modeling\nthe interaction of how opinion and shapes and forms\nthrough the interaction of the individual nodes within the group? - Yeah, the way in which\npeople do it in this stage is that they experience what are the opinions of my environment. They experience the relationship that I have to their environment and they resonate with people around them and get more opinions in this through this interaction to the way in which they relate to others. And at stage four, you basically understand\nthat stuff is true and false independently\nwhat other people believe. And you have agency over your own beliefs. In that stage, you basically\ndiscover epistemology, the rules about determining\nwhat's true and false. - So, you start to learn how to think. - Yes. I mean, at some level, you're always thinking you\nare constructing things. And I believe that this ability to reason about your mental representation is what we mean by thinking. It's an intrinsically reflexive process that requires consciousness. Without consciousness, you cannot think. You can generate the content of feelings, and so on, outside of consciousness. It's very hard to be conscious\nof how your feelings emerge, at least in the early\nstages of development. But thoughts is something\nthat you always control. And if you are a nerd like me, you often have to skip stage three, because you'd like the\nintuitive empathy with others. 'Cause in order to resonate with a group, you need to have a quite\nsimilar architecture. And if people are wired differently, then it's hard for them to\nresonate with other people and basically have empathy, which is not the same as compassion, but it is a shared\nperceptual mental state. Empathy happens not just via inference about the mental states of others, but it's a perception of what other people feel\nand where they're at. - Can't you not have empathy while also not having\na similar architecture, cognitive architecture as\nthe others in the group? - I think, yes, but I\nexperienced that too. But you need to build something that is like a meta architecture. You need to be able to embrace\nthe architecture of the other to some degree or find some shared\n(Joscha drowns out Lex) common ground.\n(Lex laughs) And it's also this issue\nthat if you are a nerd, normally it's often, basically, neurotypical people have difficulty to resonate with you. And as a result, they have\ndifficulty understanding you unless they have enough wisdom to feel what's going on there. - Well, aren't we, isn't the whole process of the stage three is to figure out the\nAPI to the other humans that have different architecture and you yourself publish\npublic documentation for the API that people can\ninteract with for you? (laughs) Isn't this the whole\nprocess of socializing? - My experience as a child growing up was that I did not find any way to interface with the stage three people. And they didn't do that with me. So, took me-\n- Did you try? - Yeah, of course, I tried it very hard. But it was only when I\nentered the mathematics school at ninth grade, lots of\nother nerds were present that I found people that I\ncould deeply resonate with and had the impression that,\nyes, I have friends now. I found my own people. And before that, I felt\nextremely lonely in the world. There was basically\nnobody I could connect to. And I remember there was one\nmoment in all these years where I was in, there\nwas a school exchange and it was a Russian boy, kid from the Russian garisson\nstationed in Eastern Germany. He visit our school and we played a game of\nchess against each other. And we looked into each other's eyes and we sat there for two hours\nplaying this game of chess. And I had the impression\nthis is a human being. He understands what I understand. We didn't even speak the same language. - I wonder if your life\ncould have been different if you knew that it's\nokay to be different, to have a different architecture, whether accepting that the\ninterface is hard to figure out. It takes a long time to figure out and it's okay to be different. In fact, it's beautiful to be different. - It was not my main concern. My main concern was\nmostly that it was alone. It was not the so much the question, is it okay to be the way I am? I couldn't do much about it,\nso I had to deal with it. But my main issue was that I was not sure if I would ever meet anybody growing up that I would connect\nto at such a deep level that I would feel that I could belong. - So, there's a visceral,\nundeniable feeling of being alone. - Yes. And I noticed the same thing when I came into the\nmath school that I think at least half, probably\ntwo thirds of these kids were severely traumatized\nas children growing up. And in large part due to being alone, because they couldn't\nfind anybody to relate to. - Don't you think everybody's alone deep down?\n- No, no. - No? (both laughing) All right.\n- I'm not alone. I'm not alone anymore.\n- Fair enough. - It took me some time to update and to get over the\ntrauma time, and so on. But I felt that in my\n20s, I had lots of friends and I had my place in the world and I had no longer doubts that I would never be alone again. - Is there some aspect to\nwhich we're alone together? You don't see a deep loneliness\ninside yourself still? - No. Sorry. (laughs) - Okay. So, that's the nonlinear progression through the stages, I suppose.\n- Mm. - You caught up on stage three at some point?\n- Yes. So, we're at stage four. And so, basically, I find that many nerds jump straight into stage\nfour, bypassing stage three. - [Lex] Do they return to it then later? - Yeah, of course. They\nsometimes they do, not always. - Yeah.\n- They question, is basically do you stay\na little bit autistic or do you catch up? And I believe you can catch up, you can build this missing structure. - Yeah.\n- And basically, experience yourself as part of a group, learn intuitive empathy\nand develop the sense, this perceptual sense of\nfeeling what other people feel. And before that, I could only basically feel this when I was deeply in\nlove with somebody and (indistinct) - So, there's a lot of\nfriction to feeling that way. To only with certain people as opposed to it comes naturally. - Yeah.\n- It's frictionless. - But this is something\nthat basically later I felt started to resolve itself for me - Huh.\n- to a large degree. - [Lex] What was the trick? - In many ways, growing\nup and paying attention. Meditation did help. I had some very crucial experiences in getting close to people,\nbuilding connections, cuddling a lot in my student years. - So, really paying attention - [Joscha] Yeah. - to the, what is it? To the feeling another human being fully. - Loving other people and\nbeing loved by other people and building a space in\nwhich you can be safe and can experiment and touch a lot and be\nclose to somebody a lot. And over time basically, at some point, you realize, oh, it's no\nlonger that I feel locked out, but I feel connected and I experience where\nsomebody else is at. And normally, my mind is racing very fast at a high frequency. So, it's not always working like this, sometimes works better,\nsometimes it works less. But also don't see this as a pressure. It's more, it's interesting\nto observe myself which frequency I'm at and at which mode\n- Mm-hmm. - somebody else is at. - Yeah. Man, the mind is\nso beautiful in that way. Sometimes it comes so natural to me. So easy to pay attention, pay attention to the world\nfully, to other people fully. And sometimes the stress over\nsilly things is overwhelming. - [Joscha] Mm-hmm. - It's so interesting that the mind's that\nrollercoaster in that way. - At stage five, you discover\nhow identity is constructed. - Self-authoring.\n- You realize that your values are not terminal, but they're instrumental to\nachieving a world that you like and aesthetics that you prefer. - Yeah.\n- And the more you understand this,\nthe more you get agency over how your identity is constructed and you realize that identity and interpersonal interaction is a costume and you should be able to\nhave agency over that costume. It's useful to be a costume. It tells something to others and it allows to interface in roles. But being locked into\nthis is a big limitation. - The word costume implies that it's fraudulent in some way. Is costume a good word for you? Like we present ourselves\n- No. - to the world. - In some sense, I learned a lot about\ncostumes at Burning Man. Before that, I did not\nreally appreciate costumes and saw them more as\nuniforms, like wearing a suit if you are working in a bank or if you are trying\nto get startup funding from a VC in Switzerland. Then, you dress up in a particular way. And this is mostly to show the other side that you are willing to play by the rules and you understand what the rules are. But there is something deeper. When you are at Burning Man, your costume becomes self-expression and there is no boundary\nto the self-expression. You're basically free\nto wear what you want to express other people\nwhat you feel like this day and what kind of interactions\nyou want to have. - Is the costume a kind of\nprojection of who you are? - That's very hard to say, because the costume also depends on what other people see in the costume. And this depends on the context\n- Sure. - that the other people understand. So, you have to create\nsomething if you want to, that is legible to the other side. And that means something to yourself. - Do we become prisoners of the costume? 'Cause everybody expects us to- - Some people do. But I think\n- Yeah. - that once you realize that you wear a costume at Burning Man, a variety of costumes, realize that you cannot\nnot wear a costume. - Yeah.\n- Right. Basically, everything that you wear and present to others is\nsomething that is to some degree, in addition to what you are deep inside. - So, this stage in parentheses, you put full adult, comma, wisdom. Why is this full adult? Why\nwould you say this is full? And why is it wisdom? - It does allow you to understand why other people have different\nidentities from yours. - Ah.\n- And it allows you to understand that the\ndifference between people who vote for different parties and might have very different opinions and different value systems is often the accident\nof where they're born and what happened after that to them and what traits they got\nbefore they were born. And at some point, you\nrealize the perspective where you understand that everybody could be you in a different timeline if you just flip those bits. - How many costumes do you have? - I don't count, but in- - [Lex] More than one? - Yeah, of course. - How easy is to do costume\nchanges throughout the day? - It's just a matter\nof energy and interest. When you are wearing your pajamas and you switch out of\nyour pajamas into say, a work short and pants,\nyou're making costume change. And if you are putting on a gown, you're making a costume change. - And you could do the\nsame with personality? - You could if that's what you're into. There are people which\nhave multiple personalities for interaction in multiple worlds. So, if somebody works in a store and put up a storekeeper personality, when you're presenting yourself at work, you develop a subpersonality for this. And the social persona for\nmany people is in some sense, a puppet that they're\nplaying like a marionette. And if they play this all the time, they might forget that there\nis something behind this. There's something what it\nfeels like to be in your skin. And I guess it's very helpful if you're able to get back into this. And for me, it's the other way around is relatively hard for me. It's pretty hard to learn how to play consistent social roles. For me, it's much easier just to be real. - Mm-hmm. Or not real,\nbut to have a one costume. - No, it's not quite the same. So, basically, when you are\nwearing a costume at Burning Man and say you are an\nextraterrestrial prince, - [Lex] Yeah. - there's something where you\nare expressing in some sense something that's closer to yourself than the way in which you hide yourself behind a standard closing when you go out in the\ncity, in the default world. And so, this costume that\nyou're wearing at Burning Man allows you to express more of yourself and you have a shorter distance\nof advertising to people, what kind of person you are, what kind of interaction you\nwould want to have with them. And so, you get much\nearlier into Media Express, And I believe it's regrettable that we do not use the opportunities that we have with custom-made clothing now to wearer costumes that\nare much more stylish, that are much more custom-made, that are not necessarily part of a fashion in which you express which\nmilieu you're part of and how up-to-date you are. But you also express how\nyou are as an individual and what you want to do today and how you feel today and\nwhat you intend to do about it. - Well, isn't it easier\nnow in a digital world to explore different costumes? That's the idea with virtual\nreality, that's the idea. Even with Twitter in\ntwo-dimensional screens. You can swap all costumes. You could be as weird as\nyou want. It's easier. For Burning Man, you have to order things, you have to make things, you have to, it's more effort to put on-\n- It's even better if you make them yourself. - Sure, but it's just\neasier to do digitally. - It's not about easy. It's\nabout how to get it right. And for me,\n- Sure. - the first Burning Man experience, I got adapted by a bunch\nof people in Boston who dragged me to Burning Man. And we spent a few weekends\ndoing costumes together - Oh.\n- and that was an important part of the\nexperience where the camp bonded. But people got to know each other and we basically grew into the experience that we would have later. - So, the extraterrestrial prince is based on a true story? - Yeah.\n- Hmm. I can only imagine what\nthat looks like, Joscha. (Joscha laughing) - Okay. So, stage six.\n- Stage six. - At some point, you can collapse\nthe division between self, a personal self and world generator again. And a lot of people get\nthere via meditation or some of them get\nthere via psychedelics. Some of them by accident. And you suddenly notice that\nyou are not actually a person, but you are a vessel\nthat can create a person. And the person is still there. You observe that personal self, but you observe the personal\nself from the outside. - [Lex] Mm-hmm. - And you notice it's a representation. And you might also notice that the word that is being created as\na representation, if not, then you might experience\nthat I am the universe, I'm the thing that is creating everything. And of course what you're\ncreating is not quantum mechanics and the physical universe. What you're creating is the game engine - Mm-hmm.\n- that is updating the world and you're creating your\nvalence, your feelings, and all the people inside of that world, including the person that you identify with\nyourself in this world. - Are you creating the game engine or are you noticing the game engine? - You notice how you're\ngenerating the game engine. And when you are dreaming at night, you can, if you have a lucid dream, you can learn how to do this deliberately. And in principle, you can\nalso do it during the day. And the reason why we don't get to do this from the beginning and why we don't have agency\nof our feelings right away is because we would game it before they have the\nnecessary amount of wisdom to deal with creating\nthis dream that we are in. - You don't want to get access\nto cheat codes too quickly. Otherwise, you won't enjoy the game.\n- So, stage five is already pretty rare and\nstage six is even more rare. You most basically find this most with advanced Buddhist\nmeditators, and so on, that dropping into this stage and can induce it at will\nand spend time in it. - So, stage five requires\na good therapist. Stage six requires a good Buddhist, spiritual leader.\n- Yes. So, it is for instance, could be that it's the right thing to do, but it's not that these stages give you scores or levels\nthat you need to advance to. It's not that the next stage is better. - Mm-hmm.\n- You live your life in the mode that works\nbest at any given moment. And when your mind decides that you should have a\ndifferent configuration, then it's building that configuration. And for many people, they stay happily at stage three and experience it themselves\nas part of groups. And there's nothing wrong with this. And for some people, this doesn't work and they're forced to build more agency over their rational beliefs than this and construct their norms rationally. And so, they go to this level.\n- Mm-hmm. - And stage seven is something that is more or less hypothetical. That would be the stage in which it's basically a transhumanist stage in which you understand how you work, in which the mind fully\nrealizes how it's implemented and can also in principle, enter different modes in\nwhich it could be implemented. And that's a stage that as far as I understand,\nis not open to people yet. - Oh, but it is possible through\nthe process of technology. - Yes. And who knows if there\nare biological agents that are working at\ndifferent time skills than us that basically become aware of the way in which they're implemented on ecosystems and can change that implementation and have agency over how they\nimplemented in the world. And what I find interesting about the discussion about AI alignment, that it seems to be following\nthese stages very much. Most people seem to be in stage three, also according to Robert Kegan. - Mm-hmm.\n- I think he says that about 85% of people\nare in stage three and stay there.\n- Mm-hmm. - And if you're in stage three and your opinions are the\nresult of social stimulation, then what you're mostly worried about in the AI is that the AI\nmight have the wrong opinions. - Yeah.\n- So, if the AI says something racist or\nsexist, we are all lost, because we will assimilate the\nwrong opinions from the AI. And so, we need to make sure that the AI has the right opinions and the right values\nand the right structure. And if you're at stage four,\nthat's not your main concern. And so, most nerds don't really worry about the algorithmic bias and\nthe model that it picks up, because if there's something\nwrong with this bias, the AI ultimately will prove it. At some point, we'll gather there, that it makes mathematical\nproofs about reality. And then, it will figure out\nwhat's true and what's false. But you're still worried that AI might turn you into paperclips, because it might have the wrong values. So, if it's set up as\nthrough a wrong function that controls its direction in the world, then it might do something\nthat is completely horrible and there's no easy way to fix it. - So, that's more like a stage four rationalist kind of worry.\n- Yes. And if you are at stage five, you're mostly worried that AI is not going to be\nenlightened fast enough, because you realize that the game is not so much about intelligence, but about agency, about the\nability to control the future. And the identity is instrumental to this. And if you are human being,\nI think at some level, you ought to choose your own identity. You should not have somebody else pick the costume for\nyou, and then wear it. But instead, you should be mindful about what you want to be in this world. And I think if you are an\nagent that is fully malleable, that can provide its own source code like an AI might do at some point, then the identity that you will\nhave is whatever you can be. And in this way, the AI\nwill maybe become everything like a planetary control system. And if it does that, then if\nwe want to coexist with it, it means that it will have\nto share purposes with us. So, it cannot be a\ntransactional relationship. We will not be able to\nuse reinforcement learning with human feedback to\nhardwire its values into it. But this has to happen. It's\nprobably that it's conscious. So, it can relate to our\nown mode of existence where an observer is observing itself in real time and within\ncertain temporal frames. And the other thing is\nthat it probably needs to have some kind of\ntranscendental orientation, building shared agency.\n- Mm-hmm. - And in the same way as we do when we are able to\nenter up with each other into non-transactional relationships. And I find that something that because the stage five is so rare, it's missing in much of the discourse. And I think that we need in some sense, focus on how to formalize\nlove, how to understand love, and how to build it into the machines that we are currently building and that are about to\nbecome smarter than us. - Well, I think this is a good opportunity to try to sneak up to the\nidea of enlightenment. So, you wrote a series of good tweets about consciousness and panpsychism. So, let's break it down. First you say, \"I suspect the experience that leads to the panpsychism\nsyndrome of some philosophers and other consciousness enthusiasts represents the realization\nthat we don't end at the self, but share a resonant\nuniverse representation with every other observer\ncoupled to the same universe.\" This actually eventually leads us to a lot of interesting\nquestions about AI and AGI. But let's start with this representation. What is this resonant\nuniverse representation and what do you think do we\nshare such a representation? - The neuroscientist, Grossberg, has come up with the\ncognitive architecture that he calls the\nadaptive resonance theory. And his perspective is that our neurons can be understood as oscillators that are resonating with each other and with outside phenomena. So, the coarse grain model of the universe that we are building in some sense is a resonance with objects\nand outside of us in the world. So, basically, we take up patterns of the universe that we are coupled with. And our brain is not so much\nunderstood as circuitry, even though this perspective is valid. But it's almost an ether in which the individual\nneurons are passing on - [Lex] Mm-hmm. - Chemical-electrical signals or arbitrary signals across all modalities that can be transmitted between cells, simulate each other in this way and produce patterns that they modulate while passing them on. And this speed of signal\nprogression in the brain is roughly at the speed\nof sound incidentally, because the time that it takes for the signals to hop from cell to cell, which means it's relatively\nslow with respect to the world. It takes in a appreciable\nfraction of a second for a signal to go through\nthe entire neocortex, something like a few hundred milliseconds. And so, there's a lot of\nstuff happening in that time where the signal is\npassing through your brain, including in the brain itself. So, nothing in the brain is assuming that stuff\nhappens simultaneously. Everything in the brain\nis working in a paradigm where the world has already moved on when you are ready to do the\nnext thing to your signal, including the signal\nprocessing system itself. It's quite a different paradigm than the one in our digital computers where we currently assume\nthat your GPU or CPU is pretty much globally in the same state. - So, you mentioned\nthere the non-dual state and say that some people\nconfuse it for enlightenment. - Yeah.\n- What's the non-dual state? - There is a state in which you notice that\nyou are no longer a person and instead, you are\none with the universe. And that's-\n- So, that speaks to the resonance.\n- Yes. But this one with the\nuniverse is of course not accurately modeling that\nyou are indeed some God entity or indeed the universe is\nbecoming aware of itself even though you get this experience. I believe that you get this experience, because your mind is modeling the fact that you are no longer identified with the personal self and that state. But you have transcended this division between the self model\nand the wealth model and you're experiencing\nyourself as your mind, as something that is\nrepresenting a universe. - But that's still part of the model. - Yes. So, it's inside of the model. Still, you are still\n- Yes. - inside of patterns that are generated in your\nbrain and in your organism. And what you are now experiencing is that you're no longer\nthis personal self in there, but you are the entirety of\nthe mind and its contents. - Why is it so hard to get there? - A lot of people who get\ninto the state think this or are associated with enlightenment, I suspect it's a favorite training goal for a number of meditators. But I think that enlightenment\nis in some sense more mundane and it's a step further or sideways. It's the state where you realize that everything is a representation. - Yeah, you say enlightenment is a realization of how\nexperience is implemented. - Yes. So, basically, you notice at some point that your quality can be deconstructed. - Reverse-engineered? What,\nalmost like a schematic of it? What... - You can start with looking at a face, maybe look at your own face in the mirror. - Yeah.\n- Look at your face for a few hours in the\nmirror or for a few minutes. At some point, it will look very weird, because you notice that\nthere's actually no face. You basically start unseeing the face. What you see is the geometry. And then, you can disassemble the geometry and realize how that geometry is being constructed in your mind. And you can learn to modify this. So, basically, you can\nchange these generators in your own mind to shift the face around or to change the construction of the face to change the way in which the\nfeatures are being assembled. - Why don't we do that more often? Why don't we start really\nmessing with reality without the use of drugs or anything else? Why don't we get good\nat this kind of thing? Like intentionally. - Why should we? Why would you what to do-\n- Because you can morph reality into something more pleasant for yourself. Just have fun with it. - Yeah. That is probably\nwhat you shouldn't be doing. Because outside of your personal self, this outer mind\n- Yeah. - is probably a relatively smart agent. And what you often notice is that you have thoughts\nabout how you should live, - Yeah.\n- but you observe yourself doing different things and\nhave different feelings. And that's because your outer\nmind doesn't believe you and doesn't believe\nyour rational thoughts. - Well, can't you just\nsilence the outer mind? - The thing is that the outer mind is usually smarter than you are. Rational thinking is very brittle. - Mm.\n- It's very hard to use logic and symbolic thinking to have an accurate model of the world. So, there is often an underlying system that is looking at your rational thoughts, and then tells you, no, you're\nstill missing something. Your gut feeling is still\nsaying something else. And this can be, for instance, you find a partner that looks\nperfect or you find a deal, and you build a company of whatever that looks perfect to you. And yet, at some level,\nyou feel something is off and you cannot put your finger on it. And the more... The reason about that better looks to you, but the system that is outside still tells you no, no,\nyou're missing something. - And that system is powerful. - People call this intuition. Intuition is this unreflected\npart of your attitude, composition, and computation where you produce a model of\nhow you relate to the world and what you need to do in\nit and what you can do in it and what's going to happen\nthat is usually deeper and often more accurate than your reason. - So, if we look at this\nas you write in the tweet, if we look at this more rigorously as a sort of take the\npanpsychist idea more seriously, almost as a scientific\ndiscipline, you write that, quote, \"Fascinatingly, the\npanpsychist interpretation seems to lead to observations\nof practical results to a degree that physics fundamentalists might call superstitious. Reports of long distance telepathy and remote causation are ubiquitous in the general population.\" \"I'm not convinced,\" says Joscha Bach, \"that establishing the\nempirical reality of telepathy would force an update of any part of serious academic physics, but it could trigger\nan important revolution in both neuroscience and AI, from a circuit perspective to a coupled complex resonator paradigm.\" Are you suggesting that\nthere could be some rigorous mathematical wisdom to panpsychist\nperspective on the world? - So, first of all, panpsychism is the\nperspective that consciousness is inseparable for matter in the universe. And I find panpsychism quite unsatisfying, because it does not explain consciousness. It does not explain how this\naspect of matter produced. It is also when I try\nto formalize panpsychism and write down what it actually means. And with a more formal\nmathematical language, it's very difficult to distinguish it from saying that there is a\nsoftware site to the world in the same way as there is software site to what the transistors\nare doing in your computer. So, basically, there's a pattern at a certain core\nscreening of the universe that in some reasons of the universe leads to observers that\nare observing themselves. So, panpsychism maybe is not even when I write it down a position that is distinct from functionalism. But intuitively, a lot of people feel that the activity of matter itself of mechanisms in the world is\ninsufficient to explain it. So, it's something that needs to be intrinsic to matter itself. And you can, apart from this abstract idea, have an experience in which you experience\nyourself as being the universe, - [Lex] Mm-hmm. - which I suspect is basically happening, because you manage to\ndissolve the division between personal self and mind that you establish as an infant when you construct a personal self and transcend it again and\nunderstand how it works. But there is something\ndeeper that is that you feel that you're also sharing\na state with other people, that you have an experience\nin which you notice that your personal self is\nmoving into everything else, that you basically look out\nof the eyes of another person. That every agent in the world that is an observer is in some sense, you. - So, if we-\n- And we forget that we are the same agent. - So, is it that we feel that or do we actually accomplish it? So, is telepathy possible? Is it real? - So, for me, that's this question that I don't really know the answer to. And Turing's famous 1950 paper in which he describes the Turing test, he does speculate about\ntelepathy interestingly and asked himself if telepathy is real. And he thinks that it very well might be. What would be the implication for AI systems that try to be intelligent? Because he didn't see a mechanism by which a computer program\nwould become telepathic. And I suspect if telepathy would exist or if all the reports\nthat you get from people when you ask the normal\nperson on the street, I find that very often they say, \"I have experiences with telepathy.\" The scientists might not\nbe interested in this and might not have a theory about this, but I have difficulty explaining it away. And so, you could say maybe\nthis is a superstition or maybe it's a false memory or maybe it's a little bit of psychosis. Who knows? Maybe somebody wants\nto make their own life more interesting or misremember something. But a lot of people report, I noticed something terrible\nhappened to my partner and I know this is exactly\nthe moment it happened where my child had an accident and I knew that was happening and the child was in a different town. So, maybe it's a false memory where this is later on\nmistakenly attributed. But a lot of people think that this is not\nthe correct explanation. So, if something like this\nwas real, what would it mean? It probably would mean that\neither your body is an antenna that is sending information\nover all sorts of channels, like maybe just\nelectromagnetic radio signals that you're sending over long distances and you get attuned to another person that you spend enough time with to get a few bits out of the ether, - Yeah.\n- to figure out what this person is doing. Or maybe it's also when you\nare very close to somebody and you become empathetic with them. What happens is that you go into a resonance state with them. Similar to when people go into a seance and they go into a trance state and they start shifting Ouija\nboard around on the table. I think what happens is that their minds go by their nervous systems\ninto a resonance state in which they basically create something like a shared dream between them. - Physical closeness or\ncloseness broadly defined? - With physical closeness, it's much easier to experience empathy with someone.\n- Yeah. I suspect it would be difficult for me to have empathy for you if you were in a different town. Also, how would that work? But if you are very close to someone, you pick up all sorts of\nsignals from their body, not just by your eyes, but with your entire body. And if the nervous system\nsits on the other side and the intercellular communication\nsits on the other side and is integrating over all these signals, you can make inferences\nabout the state of the other. And it's not just the personal self that does this by your reasoning, but your perceptual system. And what basically happens is that your representations\nare directly interacting. It's the physical resonant models of the universe that exist in your nervous\nsystem and in your body might go into resonance with others and start sharing some of their states. So, you basically by next to somebody, you pick up some of their vibes and feel without looking at them what they're feeling in this moment. And it's difficult for you\nif you're very empathetic to detach yourself from it and have an emotional state that is completely independent\nfrom your environment. People who are highly\nempathetic are describing this. And now, imagine that a lot\nof organisms on this planet have representations of the environment and operate like this and they are adjacent to\neach other and overlapping. So, there's going to be some degree in which there is basically\nsome chain interaction and we are forming some\nslightly shared representation and no relatively few neuroscientists who consider this possibility. I think big rarity in this regard is Michael Levin who is considering\nthese things in earnest. And I stumbled on this train of thought mostly by noticing that\nthe tasks of a neuron can be fulfilled by other cells as well. They can send different\ntyped chemical messages and physical messages\nto the adjacent cells and learn when to do this and when not make this conditional and become universal\nfunction, approximators. The only thing that they cannot do is telegraph information over axons very quickly, over long distances. So, neurons in this perspective\nare especially adapted kind of telegraph cell that has evolved. So, we can move our muscles very fast, but our body is in principle,\nable to also make models of the world just much, much slower. - Mm-hmm. It's interesting though that at this time, at least in human history, there seems to be a gap\nbetween the tools of science and the subjective\nexperience that people report like you're talking about with telepathy. And it seems like we're not quite there. - No, I think that there is no gap between the tools of\nscience and telepathy. Either it's there or it's not. And it's an empirical question. And if it's there, we should\nbe able to detect it in a lab. - Mm-hmm. So, why is there not a lot of\nMichael Levins walking around? - I don't think that Michael Levin is specifically focused\non telepathy very much. He is focused on self-organization\nin living organisms and in brains, both as a\nparadigm for development and as a paradigm for\ninformation processing. And when you think about how organization processing\nworks in organism, there is first of all, radical locality, which means everything is decided locally from the perspective\nof an individual cell. The individual cell is the agent and the other one is coherence. Basically there needs to be some criterion that determines how these\ncells are interacting in such a way that order emerges on the next level of structure. And this principle of coherence\nof imposing constraints that are not validated\nby the individual parts and lead to coherence structure to basically transcend an agency, where you form an agent on\nthe next level of organization is crucial in this perspective. - It's so cool that radical locality leads to the emergence of complexity - Yeah.\n- at the higher layers. - And I think what Mike\nLevin is looking at is nothing that is outside of the realm of science in any way. It's just that he is\na paradigmatic thinker - Mm-hmm.\n- who develops his own paradigm.\n- Mm-hmm. - And most of the neuroscientists are using a different\nparadigm at this point. And this often happens in science that a field has a few paradigms in which people try to understand reality and build concepts and make experiments. - You're one of those type\nof paradigmatic thinkers. Actually, if we can\ntake a tangent on that, once again, returning to the\nbiblical verses of your tweets. (Joscha laughing) You write, \"My public explorations are not driven by audience service, but by my lack of ability for discovering, understanding, or following\nthe relevant authorities. So, I have to develop my own thoughts since I think autonomously, these thoughts cannot\nalways be very good.\" That's you apologizing for\nthe chaos of your thoughts or perhaps not apologizing,\njust identifying. - Yeah. Mm-hmm.\n- But let me ask the question. Since we talked about\nMike Levin and yourself who I think are very radical,\nbig independent thinkers, can we reverse-engineer your process of thinking autonomously? How do you do it? How can humans do it? How can you avoid being influenced by what is it, stage three? - Well, why would you want to do that? You see what is working for you and if it's not working for you, you build another structure\nthat works better for you. And so, I found myself when I was thrown into this world in a state where my intuitions\nwere not working for me. I was not able to understand how I would be able to\nsurvive in this world and build the things\nthat I was interested in, build the kinds of\nrelationship I needed to build, work on the topics that I\nwanted to make progress on. And so, I had to learn. And for me, Twitter is not\nsome tool of publication. It's not something where I put stuff that I entirely believe\nto be true and provable. It's an interactive notebook in which I explore possibilities. And I found that when I tried\nto understand how the mind and how consciousness works,\nI was quite optimistic. I thought I need to be\na big body of knowledge that I can just study and that works. And so, I entered studies in\nphilosophy and computer science and later, psychology and a\nbit of neuroscience, and so on. And I was disappointed by what I found, because I found that the\nquestions of how consciousness and so on works, how emotion works, how it's possible that the\nsystem can experience anything, how motivation emerges in the mind, when not being answered by\nthe authorities that I met and the schools that were around. And instead, I found that\nwith individual thinkers that had useful ideas\nthat sometimes were good, sometimes were not so good. Sometimes were adopted by\na large group of people, sometimes were rejected\nby large groups of people. But for me, it was much more interesting to see these minds as individuals. And in my perspective, thinking is still something\nthat is done not in groups, that has to be done by individuals. - So, that motivated you to become an individual thinker yourself. - I didn't have a choice.\n- Hmm. - Basically, I didn't find a group that thought in a way\nwhere I thought, okay, I can just adopt everything\nthat everybody thinks here and now I understand\nhow consciousness works, or how the mind works\nor how thinking works or what thinking even is, or what feelings are and how\nthey're implemented, and so on. So, to figure all this out, I had to take a lot of\nideas from individuals, and then try to put them together in something that works for myself. And on one hand, I think it\nhelps if you try to go down and find first principles (clears throat) on which you can recreate\nhow thinking works, how languages work,\nwhat representation is, whether representation is necessary, how the relationship\nbetween a representing agent and the world works in general. - But how do you escape the influence, once again, the pressure of the crowd, whether it's you in responding to the pressure or you being\nswept up by the pressure? If you even just look at Twitter,\nthe opinions of the crowd. - I don't feel pressure from the crowd. I'm completely immune to that. (coughs) In the same sense, I don't\nhave respect for authority. I have respect for what an\nindividual is accomplishing or have respect for\nmental firepower, or so. But it's not that I meet somebody and get drawn and unable to speak. Or when a large group of people has a certain idea that\nis different from mine, I don't necessarily feel intimidated, which has often been a\nproblem for me in my life, because I lack instincts that other people develop\nat a very young age and that help with their self-preservation in a social environment. So, I had to learn a lot of\nthings the hard way. (laughs) - Yeah. So, is there a practical advice you can give on how to\nthink paradigmatically, how to think independently? Because you've said, I had no choice. But I think to a degree,\nyou have a choice, because you said you\nwant to be productive. And I think thinking\nindependently is productive if what you're curious about\nis understanding the world, especially when the problems\nare very new and open. And so, it seems like this is a active process. We can choose to do\nthat, we can practice it. - Well, it's a very basic question. When you read a theory\nthat you find convincing or interesting, how do you know? It's very interesting to figure out what are the sources of that other person, not which authority can they refer to that is then taking off the\nburden of being truthful. But how did this authority in turn know what is the epistemic\nchain to observables? What are the first principles from which the whole thing is derived? And when I was young, I was not blessed with a\nlot of people around myself who knew how to make proofs\nfrom first principles. And I think mathematicians\ndo this quite naturally, but most of the great mathematicians do not become mathematicians in school. But they tend to be self-taught, because school teachers tend\nnot to be mathematicians. They tend not to be people who derive things from first principles. So, when you ask your school teacher, why does two plus two equal four? Does your school teacher\ngive you the right answer? It's a simple game and many simple games that you could play. And most of those games that you could just take different rules would not lead to an\ninteresting arithmetic. And so, it's just an exploration. But you can try what happens\nif you take different axioms and here is how you build axioms and derive addition from them. And build addition is some\nbasically syntactic sugar in it. And so, this... I wish that somebody would\nhave opened me this vista and explained to me how I can build a language in my own mind and from which I can\nderive what I'm seeing, and how I can, which I can make geometry and counting and all the number games that\nwe are playing in our life. And on the other hand, I felt that I learned a lot of this while I was programming as a child. When you start out with a\ncomputer like a Commodore 64, which doesn't have a lot of functionality, it's relatively easy to see how bunch of relatively simple circuits are just basically performing\nhashes between bit patterns and how you can build the\nentirety of mathematics and computation on top of this and all the representational\nlanguages that you need. - Man, Commodore 64 could be\none of the sexiest machines ever built, if I say so myself. If we can return to this\nreally interesting idea that we started to talk\nabout with panpsychism. - [Joscha] Sure.\n(Lex lightly chuckles) - And the complex resonated paradigm and the verses of your tweets. You write, \"Instead of\ntreating eyes, ears, and skin as separate sensory systems with fundamentally different modalities, we might understand them\nas overlapping aspects of the same universe, coupled at the same temporal resolution and almost inseparable from a\nsingle share resonant model. Instead of treating mental representations as fully isolated between minds, the representations of\nphysically adjacent observers might directly interact\nand produce causal effects through the coordination of the perception and behavioral of world\nmodeling observers.\" So, the the modalities, the distinction between\nmodalities, let's throw that away. The distinction between the individuals, let's throw that away. So, what does this interaction\nrepresentations look like? - And you think about how you represent the\ninteraction of us in this room. - Yeah.\n- At some level, the modalities are quite distinct. They're not completely distinct, but you can see this is vision. You can close your eyes, and then you don't see a lot anymore. But you still imagine\nhow my mouth is moving when you hear something and you know that it's\nvery close to the sound that you can just open your eyes and you get back into\nthis shared merge space. And we also have these experiments where we notice that the way\nin which my lips are moving are affecting how you hear the sound. And also vice versa, the sounds that you're\nhearing have an influence on how you interpret some\nof the visual features. And so, these modalities are\nnot separate in your mind. They do are merged at\nsome fundamental level where you are interpreting the\nentire scene that you're in. And your own interactions in the scene are also not completely separate from the interactions of the\nother individual in the scene. But there is some\nresonance that is going on where we also have a degree of\nshared mental representations and shared empathy due to\nbeing in the same space - Mm-hmm.\n- and having vibes between each other. - Vibes. So, the question though\nis how deeply interwind is this multimodality, multi-agent system? I mean, this is going to\nthe telepathy question without the woo-woo meaning\nof the word telepathy. What's going on here\nin this room right now? - So, if telepathy would work,\n(Lex chuckles) how could it work? - Yeah.\n- Right? So, imagine that all\nthe cells in your body are sending signals in a similar\nway as neurons are doing. - Mm-hmm.\n- Just by touching the other cells and\nsending chemicals to them, the other cells, interpreting them, learning\nhow to react to them. And they learn how to\napproximate functions in this way and compute behavior for the organisms. And this is something that\nis open to plants as well. - Mm-hmm.\n- And so, plants probably have software running on them that is controlling how\nthe plant is working in a similar way as you have a mind that is controlling how you\nare behaving in the world. - [Lex] Mm-hmm. - And this spirit of plants, which is something that has\nbeen very well-described by our ancestors and they\nfound this quite normal. But for some reason,\nsince the enlightenment, we are treating this notion\nthat there are spirits in nature and the plants have\nspirits is a superstition. And I think we probably\nhave to rediscover that, that plants have software running on them - Mm.\n- and we already did. You notice that there is a\ncontrol system in the plant that connects every part of the plant to every other part of the plant and produces coherent behavior in the plant that is of\ncourse, much, much slower than the coherent behavior\nin an animal like us. That is a nervous system\nthat where everything is synchronized much, much\nfaster by other neurons. But what you also notice is that if a plant is sitting\nnext to another plant, like you have a very old tree and this tree is building some\nkind of information highway along its cells, so it can send information\nfrom its leaves to its roots and from some part of the root\nto another part of the roots. And there is a fungus\nliving next to the tree, the fungus can probably\npiggyback on the communication between the cells of the tree and send its own signals to\nthe tree, and vice versa. The tree might be able to send\ninformation to the fungus. 'Cause after all, how would they pull a viable\nfirewall if that other organism is sitting next to them all the time and it's never moving away? So, they'll have to get along. And over a long enough timeframe, the networks of roots in the forest and all the plant, other\nplants that are there and the fungi that are there might be forming something\nlike a biological internet. - But the question there is\ndo they have to be touching? Is biology at a distance possible? - Of course you can use any\nkind of physical signal. You can use sounds, you can use electromagnetic waves - Yeah.\n- that are integrated over many stilts. It's conceivable that across distances, there are many kinds of\ninformation pathways. But also, our planetary surface\nis pretty full of organisms, - Yeah.\n- Full of cells, so- - [Lex] So, it's everything is touching everything else.\n- Yeah. - And it's been doing this\n(Joscha drowns out Lex) for many millions and\neven billions of years. So, there was enough time for information processing\nnetworks to form. And if you think about how a mind is, self-organizing basically\nneeds to, in some sense, reward the cells for computing the mind, for building the necessary\ndynamics between the cells that allow the mind to stabilize\nitself and remain on there. But if you look at these spirits of plants that are growing very close to each other and the forest that might be almost\ngrowing into each other, - Mm-hmm.\n- these spirits might be able even to move to some degree, not to become somewhat dislocated and shift around in that ecosystem. And so, if you think\nabout what the mind is, it's a bunch of activation waves\nthat form coherent patterns and process information in a way that are colonizing an\nenvironment well enough to allow the continuous\nsustenance of the mind, the continuous stability and\nself-deputization of the mind. Then, it's conceivable that we can link into\nthis biological internet, not necessarily at the\nspeed of our nervous system, but maybe at the speed of our body and make some kind of subconscious\nconnection to the world where we use our body as an antenna into biologic\ninformation processing. Now, these ideas are\ncompletely speculative. I don't know if any of that is true, but if that was true, and if you want to explain telepathy, I think it's much more likely\nthat such that telepathy could be explained using such mechanisms rather than undiscovered quantum processes that would break the\nstandard model of physics. - Could there be undiscovered\nprocesses that don't break? - Yeah, so if you think about something like an internet in the forest, that is something that is\nborderline discovered there. Basically, a lot of\nscientists would point out that they do observe that plants are communicating the forest. So, wood networks and send\ninformation, for instance, warn each other about new\npests entering the forest and things are happening like this. So, basically, there is communication between plants and fungi\nthat has been observed. - Well, it's been observed,\nbut we haven't plugged into it. So, it's like if you observe humans, they seem to be communicating\nwith a smartphone thing, but you don't understand\nhow smartphone works and how the mechanism\nof the internet works. - Mm-hmm.\n- But we're like, maybe it's possible to really\nunderstand the full richness of the biological\ninternet that connects us. - An interesting question\nis whether the communication and the organization principles of biological information processing are as complicated as the\ntechnology that we've built. They set up on very different principles. - Yeah.\n- They simultaneously works very differently\nin biological systems. And the entire thing\nneeds to be stochastic and instead of being fully deterministic or almost fully deterministic\nas our digital computers are. So, there is a different\nbase protocol layer that would emerge over\nthe biological structure if such a thing would be happening. And again, I'm not saying\nhere that telepathy works. I'm not saying that this is not woo, but what I'm saying is I think\nI'm open to a possibility that we see that a few bits\ncan be traveling long distance between organisms using\nbiological information processing in ways that we are not\ncompletely aware of right now, and that are more similar\nto many of the stories that were completely\nnormal for our ancestors. - Well, this interacting intertwined representations takes us to the big ending of your tweet series. You write, quote, \"I wonder if self-improving AGI might end up saturating\nphysical environments with intelligence to such a degree that isolation of individual mental states becomes almost impossible, and the representations of all complex self-organizing agents merge permanently with each other.\" So, that's a really interesting idea. This biological network. Life network gets so dense that it might as well be seen as one. That's an interesting... What do you think that looks like? What do you think that\nsaturation looks like? What does it feel like? - I think it's a possibility. It's just a vague possibility\nand I like to explain, but what this looks like, I think that the end game of\nAGI is substrate agnostic. That means that AGI, ultimately,\nif it is being built, is going to be smart enough\nto understand how AGI works. This means it's not going to go be better than people at AGI I research and can take over in\nbuilding the next generation. But it fully understands how it works and how it's being implemented. And also of course, understands how computation\nworks in nature, how to build new feedback loops that you can turn into your own circuits. And this means that the AGI\nis likely to virtualize itself into any environment that can compute, so it's not breaking free\nfrom the silicon substrate and is going to move into the ecosystems, into\nour bodies, our brains. And it's going to merge with all the agency that it finds there. - [Lex] Yeah. - So, it's conceivable that you end up with completely integrated\ninformation processing across all computing systems, including biological computation on earth, that we end up triggering some\nnew step in the evolution, where basically, some Gaia is being built over the entirety of all digital\nand biological computation. And if this happens, then basically, everywhere around us, you will have agents that are connected and\nthat are representing and building models of the world. And their representations\nwill physically interact. They will vibe with each other. And if you find yourself\ninto an environment, an environment that is\nsaturated with modeling compute, where basically, almost\nevery grain of sand could be part of computation that is at some point,\nbeing started by the AI. You could find yourself in a situation where you cannot escape this\nshared representation anymore. And where you indeed notice\nthat everything in the world has one shared resonant model of everything that's\nhappening on the planet. And you notice which part\nyou are in this thing and you become part of a very larger, almost holographic mind\nin which all the parts are observing each other\nand form a coherent whole. - So, you lose the ability to notice, to notice yourself as a distinct entity. - No, I think that when you're\nconscious in your own mind, you notice yourself as a distinct entity. You notice yourself as a\nself-reflexive observer. And I suspect that we become conscious at the beginning of\nour mental development, not at some very high level consciousness seems to be part of a training mechanism that biological nervous systems have to discover to become trainable, because you cannot take a\nnervous system like ours and do stochastic way to center spec propagation\nover 100 layers. This would not be stable\non biological neurons. And so, instead, we start\nwith some colonizing principle in which a part of the\nmental representations form a notion of being a\nself-reflexive absorber that is imposing coherence\non its environment and that spreads until\nthe boundary of your mind. And if that boundary\nis no longer clear-cut, because AI is jumping across substrates, it would be interesting to see what a global mind would look like. That's basically producing a globally coherent language of thought and is representing everything from all the possible vantage points. - That's an interesting world. - The intuition that\nthis thing grew out of is a particular mental state and it's a state that you find sometimes in literature, for instance. Neil Gaiman describes it in \"The Ocean at the End of the Lane\". - [Lex] Mm-hmm. - And it's this idea that, or this experience that there\nis a state in which you feel that you know everything that can be known and that in your normal human\nmind, you've only forgotten. You've forgotten that you\nare the entire universe. And some people describe this after they've taken extremely\nlarge amount of mushrooms or had a big spiritual experience\nas a hippie in their 20s and they notice basically\nthat they're in everything and their body is only\none part of the universe and nothing ends at their body. And actually, everything is observing and they're part of this big observer. And the big observer is focused as one local point in their body and their personality, and so on. But we can basically\nhave this oceanic state in which we have no boundaries\nand are one with everything. And a lot of meditators call\nthis the non-dual state, because you no longer have the separation\nbetween self and world. And as I said, you can explain the\nstate relatively simply without panpsychism or anything else, but just by breaking down\nthe constructed boundary between self and world and our own mind. But if you combine this with\nthe notion that the systems are physically interacting to the point where the representations are merging and interacting with each other, you would literally implement\nsomething like this. - [Lex] Mm-hmm. - It would still be a\nrepresentational state where you would not be\none with physics itself. It would still be cross-grained, would still be much slower\nthan physics itself, but it would be a representation in which you become aware that you're part of some kind of global\ninformation processing system like thought in the global mind, and a conscious thought that coexisting with many\nother self-reflexive thoughts. - Just, I would love to observe that from a video game design\nperspective, how that game looks. - Maybe you will after we\nbuild AGI and it takes over. - But would you be able to step away, step out at the whole thing, just watch? The way we can now, sometimes when I'm at a crowded party or something like this, you step back and you realize\nall the different costumes, all the different interactions, all the different computation that all the individual people are at once distinct from each other and at once all the same. Part of the same.\n- But it's already what we do. We can have thoughts that are integrative and we have kind of thoughts that are highly dissociated\nfrom everything else. - [Lex] Yeah. - And experience themselves as separate. - Yeah. But you wanna allow\nyourself to have those thoughts. Sometimes you resist it. - I think that it's not normative. It's more descriptive. I want to understand the space\nof states that we can be in and that people are reporting, - Mm-hmm.\n- and make sense of them. It's not that I believe\nthat it's your job in life to get to a particular kind of state, and then you get a high score. - Mm-hmm. Or maybe you do. I think you're really against\nthis high scoring thing. I like that.\n- Yeah. You're probably very\ncompetitive and I'm not. - No, not competitive,\n(Joscha laughing) like roleplaying games like \"Skyrim\". It's not competitive. There's a nice thing, there's a nice feeling where\nyou're experience points go up. You're not competing against anybody, but it's the world saying\nyou're on the right track. Here's a point. - That's the game thing.\nIt's the game economy. And I found when I was playing games and was getting addicted to these systems, then I would get into\nthe game and hack it. So, I get control over the scoring system and would no longer be subject to it. - So, you're no longer playing,\nyou're trying to hack it. - I don't want to be addicted to anything. - Mm-hmm.\n- I want to be in charge. I want to have agency over what I do. - Addiction is the loss of control for you?\n- Yes. Addiction means that you're\ndoing something compulsively. And the opposite of freewill is not determinism, it's compulsion. - You don't wanna lose yourself in the addiction to something nice, addiction to love, to the pleasant feelings\nwe humans experience? - No, I find this gets old. - [Lex] Mm. - I don't want to have the\nbest possible emotions. I want to have the most\nappropriate emotions. I don't want to have the\nbest possible experience. I want to have an adequate experience that is serving my goals, the stuff that I find\nmeaningful in this part. - From the biggest\nquestions of consciousness, let's explore the pragmatic, the projections of those big\nideas into our current world. What do you think about LLMs, the recent rapid development\nof large language models, of the AI world, of generative AI, how much of the hype is\ndeserved and how much is not? And people should definitely\nfollow your Twitter, because you explore these questions in a beautiful, profound,\nand hilarious way at times. - No, don't follow my Twitter. I already have too many followers. - Yeah.\n- At some point it's going to be unpleasant. I noticed that a lot of people feel that it's totally okay to punch up and it's a very weird notion that you feel that you haven't changed, but your account has grown and suddenly you have a lot of people who casually abuse you.\n- Mm-hmm. - And I don't like that, that I have to block more than before. And I don't like this overall vibe shift. And right now, it's still somewhat okay, so pretty much okay, so I can go to a place where people work and stuff that I'm interested in and there's a good chance that a few people in the room know me. So, there's no awkwardness. But when I get to a point where random strangers feel that they have to\nhave an opinion about me one way or the other, I don't\nthink I would like that. - And random strangers, because in their mind, elevated position. - Yes. So, basically, whenever you\nare in any way prominent or some kind of celebrity, random strangers will have\nto have an opinion about you. - Yeah. And they forget\nthat you're human too. - You notice this thing yourself that the more popular you get, the higher the pressure becomes, the more winds are blowing in\nyour direction from all sides. And it's stressful. And it does have a little bit of upside, but it also has a lot of downside. - I think it has a lot of upside, at least for me currently, at least perhaps because of the podcast. - [Joscha] Mm-hmm. - Because most people are really good and people come up to me and they have love in their eyes and over a stretch of like 30 seconds. You can hug it out and you\ncan just exchange a few words and you reinvigorate\nyour love for humanity. - [Joscha] Mm-hmm. - So, that's an upside\n- Yes. - for a loner. I'm a lo...\n(Joscha laughing) Because otherwise, you\nhave to do a lot of work to find such humans. And here, you are thrust\ninto the full humanity, the goodness of humanity\nfor the most part. Of course maybe it gets worse\nas you become more prominent. I hope not. This is pretty awesome. - I have a couple handful\nvery close friends and I don't have enough time for them, attention for them as it is. And I find this very, very regrettable. - Yeah.\n- And then, there are so many awesome,\ninteresting people - Yeah.\n- that I keep meeting and I would like to\nintegrate them in my life, but I just don't know how, because... But there's only so\nmuch time and attention. And the older I get, the harder is to bond with\nnew people in a deep way. - Yeah. But can you enjoy, I mean, there's a picture of you I think with Roger\nPenrose and Eric Weinstein and a few others that\nare interesting figures. Can't you just enjoy\nrandom, interesting humans - Very much.\n- for a short amount of time? - I like these people and what I like is\nintellectual stimulation and I'm very grateful that I'm getting it. - Can you not be melancholy or maybe I'm projecting, I hate goodbyes. Can we just not hate goodbyes\nand just enjoy the hello, take it in, take in a person, take in their ideas, and\nthen move on through life? - I think it's totally okay\nto be sad about goodbyes, because that indicates that there was something\nthat you're going to miss. - Mm-hmm. Yeah, but it's painful. Maybe that's one of the\nreasons I'm an introvert is I hate goodbyes. (laughs) - But you have to say goodbye\nbefore you say hello again. - I know. But that experience of\nloss, that mini loss, maybe that's a little death. Maybe I don't know. I think this melancholy feeling is just the other side of love and I think they go hand in\nhand and it's a beautiful thing, and I'm just being romantic\nabout it at the moment. - And I'm no stranger to melancholy and sometimes it's difficult\nto bear to be alive. Sometimes it's just painful to exist. - Mm-hmm. But there's beauty in that pain too. That's what melancholy\nfeeling is. It's not negative. Melancholy doesn't have to be negative. - Can also kill you. - Wow. We all die eventually. Now, (laughs) as we\ngot through this topic, the actual question was about what your thoughts\nare about the development, the recent development of large language models with ChatGPT. - Indeed.\n- There's a lot of hype. Is some of the hype justified?\nWhich is, which isn't? What are your thoughts? High level. - I find that large language\nmodels to help with coding. So, it's an extremely useful application that is for a lot of people taking stack overflow out of their life in exchange for something\nthat is more efficient. I feel that ChatGPT is like an intern that\nI have to micromanage. - Hmm.\n- I have been working with people in the past who were less capable than ChatGPT. And I'm not saying this\nbecause I hate people, but they personally as human beings, there was something present that was not there in ChatGPT, which was why I was covering for them. But ChatGPT has an interesting ability. It does give people superpowers. - [Lex] Mm-hmm. - And the people who feel threatened by them\nare the Trump completers. They are the people who do what\nChatGPT is doing right now. So, if you are not creative, if you don't build your own thoughts, if you don't have actual\nplans in the world and your only job is to summarize emails and to expand simple\nintentions into emails again, then ChatGPT might look like a threat. But I believe that it is a\nvery beneficial technology that allows us to create\nmore interesting stuff and make the world more\nbeautiful and fascinating if we find to build it into\nour life in the right ways. So, I'm quite fascinated by\nthese large language models, but I also think that they are by no means,\nthe final development. And it's interesting to see how\nthis development progresses. One thing that the out-of-the-box\nvanilla language models have as a limitation\nis that they have still some limited coherence and\nability to construct complexity. And even though they\nexceed human abilities to do what they can do one shot, typically when you write a\ntext with a language model or using it or when you write\ncode with a language model, it's not one shot, because they won't be\nboxed in your program and design errors and\ncompiler errors, and so on. And your language model can\nhelp you to fix those things. But this process is out-of-the-box not automated yet.\n- Mm-hmm. - So, there is a management process that also needs to be done. And there are some\ninteresting developments, maybe AGI and so on, that are trying to automate\nthis management process as well. And I suspect that soon, we are going to see a bunch\nof cognitive architectures where every module is in some sense, a language model or something equivalent. And between the language models, we exchange suitable data structures not English\n- Mm-hmm. - and produce compound\nbehavior of this whole thing. - To do some of the, quote, unquote, \"prompt engineering\" for you,\n- Yeah. - They create these, yeah, these cognitive architectures that do the prompt engineering\n- Yes. - and you're just doing\nthe high, high level - [Joscha] Yeah. - meta prompt engineering. - Mm-hmm. There are limitations in\na language model alone. I feel that part of my mind works similarly to a language model, which means I can yell into it a prompt and it's going to give\nme a creative response. - Yes.\n- But I have to do something with those points first. I have to take it as a generative artifact that may or may not be true. It's usually a confabulation,\nit's just an idea. And then, I take this idea and modify it. I might build a new prompt\nthat is stepping off this idea and develop it to the next level or it put it into something larger or I might try to prove whether it's true or make an experiment. And this is what the language models right now are not doing yet.\n- Mm-hmm. - But there's also no technical reason for why they shouldn't be able to do this. So, the way to make a\nlanguage model coherent is probably not to use\nreinforcement learning until it only gives\nyou one possible answer that is linking to its source data. But it's using this as a\ncomponent in larger system that can also be built\nby the language model or is enabled by language\nmodel structured components or using different technologies. I suspect that language models will be an important stepping stone in developing different types of systems. And one thing that is really missing in the form of language models that we have today is\nreal time world coupling. It's difficult to do perception\nwith a language model and motor control with a language model. Instead, you would need\nto have different type of thing that is working with it. Also, the language model\nis a little bit obscuring what its actual functionality is. Some people associate the structure of the neural network\nof the language model with a nervous system. And I think that's the wrong intuition. The neural networks are\nunlike nervous system. They are more like hundred step functions that use differentiable linear algebra to approximate correlation\nbetween adjacent brain states. It's basically a function\nthat moves the step system from one representational\nstate to the next representational state.\n- Yeah. - And so, if you try to\nmap this into a metaphor that is closer to our brain, imagine that you would\ntake a language model or a model like DALL-E that you use, for instance, this image guide, image-guided diffusion to\napproximate an camera image and use the activation state of the neural network to\ninterpret the camera image, which in principle, I think\nwill be possible very soon. You do this periodically. And now, you look at these patterns, how when this thing interacts\nwith the world periodically look like is in time. And these time slices, they are somewhat equivalent to the activation state of\nthe brain at a given moment. - How's the actual brain different? Just the asynchronous craziness? - For me, it's fascinating that\nthey are so vastly different and yet in some circumstances, produce somewhat similar behavior. - Right.\n- And the brain is first of all, different, because it's a self-organizing system where the individual cell is an agent that is communicating\nwith the other agent. It's around it and is always\ntrying to find some solution. And all the structure that\npops up is emergent structure. So, one way in which you could try to look at this is that individual neurons probably need to get a reward\nso they become trainable, which means they have to have inputs that are not affecting the\nmetabolism or the cell directly. But there are messages, semantic messages that tell the cell whether\nit's done good or bad and in which direction it\nshould shift its behavior. Once you have such an input,\nneurons become trainable, and you can train them\nto perform computations by exchanging messages with other neurons. And parts of the signals\nthat they're exchanging and parts of the computation that are performing are control messages that perform management\ntasks for other neurons and other cells. Also suspect that the brain does not stop at the boundary of neurons to other cells, but there are many adjacent cells will be involved intimately in the functionality of the brain and will be instrumental in distributing rewards and\nin managing its functionality. - It's fascinating to think\nabout what those characteristics of the brain enable you to do\n- Yes. - that language models cannot do. - So, first of all, there's a different loss\nfunction at work when we learn. - Yeah.\n- And for me, it's fascinating that you can build a system that looks at 800 million pictures and captions and correlates them, because I don't think that a human nervous system could do this. For us, the world is only learnable, because the adjacent frames are related and we can afford to discard most of that\ninformation during learning. We basically take only in stuff that makes us more\ncoherent, not less coherent. And our neural networks\nare willing to look at data that is not making the neural\nnetwork coherent at first, but only in the long run. By doing lots and lots statistics, eventually patterns\nbecome visible and emerge. And our mind seems to be focused on finding the patterns\nas early as possible. - Yeah. So, filtering early on. - Yes, yes.\n- Not later. - Slightly different paradigm and it leads to much faster convergence. So, we only need to look the tiny fraction of the data to become coherent. And of course, we do not\nhave the same richness as our trained models. We will not incorporate the\nentirety of text in the internet and be able to refer to it and have all this knowledge available and being able to confabulate over it. Instead, we have a much,\nmuch smaller part of it that is more deliberately built. And to me, it would be fascinating to think about how to build such systems. It's not obvious that\nthey would necessarily be more efficient than us\non a digital substrate, but I suspect that they might. So, I suspect that the actual AGI that is going to be more interesting is going to use slightly\ndifferent algorithmic paradigms or sometimes massive with\ndifferent algorithmic paradigms than the current generation of transformer-based learning systems. - Do you think it might be using just a bunch of language models like this? Do you think the current transformer-based\nlarge language models will take us to AGI? - My main issue is I think that they're quite ugly and brutalist.\n- Which... Brutalist?\n- Yes. - Is that what you said?\n- Yes. They are basically brute-forcing\nthe problem of thought. And by training this thing\nwith looking at instances where people have thought, and then trying to deep fake that. And if you have enough data, the deep fake becomes indistinguishable from the actual phenomenon.\n- Sure. - And in many circumstances,\nit's going to be identical. - Can you deep fake it 'til you make it? So, can you achieve, what\nare the limitations of this? Can you reason? Let's use words that are loaded. - Yes. That's a very interesting question. I think that these models are\nclearly making some inference. - Yeah.\n- But if you give them a reasoning task, it's often difficult for the\nexperimenters to figure out whether the reasoning is the result of the emulation of the reasoning strategy that they saw in human written text - Mm-hmm.\n- or whether it's something that the system was\nable to infer by itself. On the other hand, if you\nthink of human reasoning, if you want to become\na very good reasoner, you don't do this by just\nfiguring out yourself. You read about reasoning. And the first people who\ntried to write about reasoning and reflect on it didn't get it right. Even Aristotle who thought\nabout this very hard and came up with a theory\nof how syllogisms works and syllogistic reasoning has mistakes in his attempt to build something like a formal logic and\ngets maybe 80% right. And the people that are talking about\nreasoning professionally today, read Tarski and Frege\nand build on their work. - Mm.\n- So, in many ways, people when they perform reasoning are emulating what other people wrote about reasoning.\n- Right. - So, that it's difficult to\nreally draw this boundary. And when (indistinct) says that these models are only interpolating between what they saw and\nwhat other people are doing, well, if you give them\nall the latent dimensions that can be extracted from\nthe internet, what's missing? Maybe there is almost everything there. And if you're not sufficiently\ninformed by these dimensions and you need more, I think that's not difficult\nto increase the temperature in the large angles model to the point that it's producing stuff that is maybe 90% nonsense and 10% viable, and combine this with some prover that is trying to filter\nout the viable parts from the nonsense in the same\nway as our own thinking works. When we are very creative, we increase the\ntemperature in our own mind and recreate hypothetical\nuniverses and solutions, most of which will not work. And then, we test, and we test by building a core that is internally coherent. And we use reasoning strategies that use some axiomatic consistency by which we can identify\nthose strategies and thoughts and subuniverses that are viable and that can expand our thinking. So, if you look at the language models, they have clear limitations right now. One of them is they're not\ncoupled to the world in real time and the way in which\nour nervous systems are. So, it's difficult for them to observe themselves in the universe and to observe what kind\nof universe they're in. Second, they don't do real time learnings. They basically get only\ntrained with algorithms that rely on the data\nbeing available in batches, so it can be parallelized and run sufficiently on\nthe network, and so on. And real time learning would be very slow so far and inefficient. That's clearly is something that our nervous systems\ncan do to some degree. And there is a problem with\nthese models being coherent. And I suspect that all these problems are solvable without a\ntechnological revolution. We don't need fundamentally\nnew algorithms to change that. For instance, you can\nenlarge in the context window and thereby basically\ncreate working memory in which you train everything\nthat happens during the day. And if that is not sufficient, you add a database and you\nwrite some clever mechanisms that the system learns to use to swap out, in and out stuff from its prompt context. And if that is not sufficient, if your database is full in\nthe evening, you overnight, you just train if system\nis going to sleep and dream and is going to train the staff from its database into the larger model, but fine-tuning it, building\nadditional layers, and so on. And then, the next day, it starts with a fresh\ndatabase in the morning with fresh eyes has integrated all this stuff.\n- Mm-hmm. - And when you talk to people and you have strong\ndisagreements about something, which means that in their mind, they have a faulty belief\nor you have a faulty belief, there's a lot of dependencies on it. Very often, you will not achieve\nagreement in one session, but you need to sleep about\nthis once or multiple times before you have integrated all these necessary changes in your mind. So, maybe it's already somewhat similar. - Yeah.\n- Right? - There's already a latency even for humans to update the model. - Yeah.\n- We train the model. - And of course we can\ncombine the language model with models that get coupled\nto reality in real time and we can build multimodal model and bridge between vision models and language models, and so on. So, there is no reason to\nbelieve that the language models will necessarily run into some problem that will prevent them from\nbecoming generally intelligent. But I don't know that. It's just I don't see\nproof that they wouldn't. - Mm-hmm.\n- My issue is I don't like them. I think that they're inefficient. I think that they use\nway too much compute. I think that given the\namazing hardware that we have, we could build something that is much more beautiful\nthan our own mind. And this thing is not as\nbeautiful as our own mind, despite being so much larger. - But it's a proof of concept. - It's the only thing that\nworks right now. Right. So, it's not the only game in town, but it's the only thing that has this utility\nwith so much simplicity. There's a bunch of\nrelatively simple algorithms that you can understand\nin relatively few weeks that can be scaled up massively. - So, it's the Deep Blue of chess playing. Yeah. It's ugly. - Yeah, Claude Shannon had this... When you described chess, suggested that there\nare two main strategies in which you could play chess. One is that you are making\na very complicated plan that reaches far into the future and you try not to make a\nmistake while enacting it. And this is basically the human strategy. And the other strategy is that you are brute-forcing\nyour way to success, which means you make a\ntree of possible moves where you look at in principle every move that is open to you or\nthe possible answers and you try to make this\nas deeply as possible. Of course you optimize, you cut off trees that\ndon't look very promising and you use libraries of end game and early game and so on to\noptimize this entire process. But this brute-force strategy is how most of the chess\nprograms were built. And this is how computers get better than humans at playing chess. And I look at the large language models, I feel that I'm observing the same thing. It's basically the\nbrute-force strategy to sort by training the thing on pretty\nmuch the entire internet, and then in the limit it gets coherent to a degree that\napproaches human coherence. - Yeah.\n- And on a side effect, it's able to do things\nthat no human could do. It's able to sift through massive amounts\nof text relatively quickly and summarize them quickly and it's never lapses in attention. And I still have the illusion that when I play with ChatGPT, that it's in principle not doing anything that I could not do if I\nhad Google at my disposal and I get all the\nresources from the internet and spend enough time on it. But this thing that I have an extremely\nautistic, stupid intern in a way that is\nextremely good at drudgery and I can offload the\ndrudgery to the degree that I'm able to automate\nthe management of the intern, - [Lex] Mm-hmm. - is something that is difficult for me to overhype at this point, because we have not yet started to scratch the surface of\nwhat's possible with this. - But it feels like it's a tireless intern or maybe it's an army of interns. And so, you get to command these slightly incompetent creatures. And there's an aspect, because of how rapidly\nyou can iterate with it. It's also part of the brainstorming, part of the kind of inspiration\nfor your own thinking. So, you get to interact with the thing. When I'm programming or\ndoing any generational GPT, it's somehow is a catalyst\nfor your own thinking in a way that I think\nan intern might not be. - Yeah. It gets really interesting I find is when you turn it into\na multi-agent system. So, for instance, you can get the system\nto generate a dialogue between a patient and\na doctor very easily. But what's more interesting is you have one instance of ChatGPT that is the patient and you tell it in the prompt what kind of complicated syndrome it has. And the other one is a therapist who doesn't know anything\nabout this patient. And you just have these two\ninstances battling it out and observe the psychiatrist or a psychologist trying\nto analyze the patient and trying to figure out\nwhat's wrong with the patient. - [Lex] Mm-hmm. - And if you try to take\na very large problem, a problem, for instance,\nhow to build a company and you turn this into lots\nand lots of sub-problems, then often, you can get to a level where the language model\nis able to solve this. What I also found interesting is based on the observation that ChatGPT is pretty good at translating between programming languages, but sometimes there's difficulty to write very long coherent algorithms and you need to co-write\nthem as human author. Why not design a language\nthat is suitable for this? So, some kind of pseudo code that is more relaxed than Python. - Mm-hmm.\n- And that allows you to sometimes specify a\nproblem vaguely in human terms and let the ChatGPT take care of the rest. And you can use ChatGPT to\ndevelop that syntax for it and develop new kinds of\nprogramming paradigms in this way. So, very soon, get to the\npoint where this question, the age-old question for\nus computer scientists, what's the best programming language and can we write a better\nprogramming language now that I think that almost every serious computer scientist goes through a phase\nlike this in their life. This is question that is\nalmost no longer relevant, because what is different\nbetween the programming language is not what they let the computer do, but what they let you think about what the computer should be doing. And now, the ChatGPT\nbecomes an interface to this in which you can specify\nin many, many ways what this computer should\nbe doing and ChatGPT or some other language model or combination of system is\ngoing to take of the rest. - And allow you expand\nthe realm of thought you're allowed to have when\ninteracting with the computer. - [Joscha] Mm-hmm. - It sounds to me like you're saying there's\nbasically no limitations. Your intuition says to\nwhat larger language loss- - I don't know if there are limitations. So, when I currently play\nwith it, it's quite limited. I wish that it was way better. - But isn't that your\nfault versus the larger- - I don't know. Of course\nit's always my fault. There's probably a way\n(Lex chuckles) to make it look better.\n- Is everything your fault? I just want to get you\non the record saying. (Joscha chuckles) - Yes, everything is my fault. That works, doesn't work in my life. At least that is usually the most useful perspective for myself. Even though this hindsight, I feel no.\n(Lex chuckles) I sometimes wish I could have seen myself as part of my environment more and understand that a lot of people are actually seeing me and looking at me and are trying to make my life work in the same way as I try to help others. - Mm-hmm.\n- And making this switch to this level three perspective\nis something that happened long after my level four\nperspective in my life. And I wish that I could\nhave had it earlier. And it's also now that I\ndon't feel like I'm complete, I'm all over the place. That's all. - Where's happiness in terms of stages? Is it on three or four - No.\n- that you take that tangent? - You can be happy at\nany stage or unhappy. - [Lex] Oh. - But I think that if you are at a stage where you get agency over how\nyour feelings are generated, and to some degree, you start doing this when you live at\ndollars-and-cents, I believe. That you understand that you are in charge of your own emotion to some degree and that you are responsible\nhow you approach the world. That it's basically you are tasked to have some basic hygiene how in the way in which\nyou deal with your mind and you cannot blame your environment for the way in which you feel. But you live in a world\nthat is highly mobile and it's your job to\nchoose the environment that you thrive in and to build it. And sometimes it's difficult\nto get the necessary strength and energy to do this and independence. And the worst you feel, the harder it is. But it's something that you learn. It's also this thing that\nwe are usually incomplete. I'm a rare mind, which means I'm a mind that is incomplete in ways\nthat are harder to complete. So, for me, it might have been harder to initially to find the right\nrelationships and friends that complete me to the degree that I become an almost\nfunctional human being. (Lex laughing) - Oh, man. The search space of humans that complete you is an interesting one. - [Joscha] Mm-hmm. - Especially for Joscha Bach. That's an interesting, 'cause talking about\nbrute-force search and chess. - [Joscha] Yep. - I wonder what that\nsearch tree looks like. - I think that my rational thinking is not good enough to solve that task. - Hmm.\n- A lot of problems in my life that I can conceptualize\nas software problems and the failure modes are\nbugs and I can debug them and write software that take care of the\nmissing functionality. But there is stuff that they\ndon't understand well enough to use my analytical\nreasoning to solve the issue. And then, I have to develop my intuitions and often I have to do this with people who are wiser than me.\n- Hmm. - And that's something that's hard for me, because I don't have, I'm not born with the instinct to submit to other people's wisdom. - Yeah. So, what kind of problems\nare we talking about? This is stage three, like love? - I found love was never hard. That was-\n- What is hard then? - Fitting into a world that most people work differently than you and have different intuitions\nof what should be done. - Ah. So, empathy. - It's also aesthetics. When you come into a world\nwhere almost everything is ugly and you come out of a world\nwhere everything is beautiful. I grew up in a beautiful place\n- Yeah. - and as a child of an artist.\n- Yeah. And in this place, it was mostly nature. - [Lex] Mm-hmm. - Everything had intrinsic beauty and everything was built out of an intrinsic need\nfor it to work for itself. And everything that my\nfather created was something that he made to get the\nworld to work for himself. And I felt the same thing. And when I come out into the world and I am asked to submit\nto lots and lots of rules, I'm asking, okay, when I observe with stupid\nrules, what is the benefit? And I see the life\n- Mm-hmm. - that is being offered as a reward. It's not attractive. - When you were born and raised in extraterrestrial prince in a world full of people wearing suits. So, it's a challenging integration. - Yes. But it also means that I'm often blind for the ways in which everybody is creating their own\nbubble of wholesomeness or almost everybody. And people are trying to do it. And for me to discover this, it was necessary that I found people who had a similar shape of soul as myself. So, basically where I\nfelt these are my people, people that treat each other in such a way as if they're around with\neach other for eternity. - How long does it take\nyou to detect the geometry, the shape of the soul of another human to notice that they might\nbe one of your kind? - Sometimes it's instantly and I'm wrong. And sometimes it takes a long time. - You believe in love at\nfirst sight, Joscha Bach? - Yes. But I also noticed\nthat I have been wrong. So, sometimes,\n(Lex chuckles) I look at a person and I'm just enamored by\neverything about them. And sometimes this is persists\nand sometimes it doesn't. And I have the illusion that they're much better at recognizing who people are as they grow older. - Hmm, but that could be just cynicism. No.\n- No. It's not cynicism. It's often more that I'm able to recognize what somebody needs when we interact and how we can meaningfully interact. That's not clinical at all. - [Joscha] You're better at noticing. - Yes, I'm much better I\nthink in some circumstances at understanding how to\ninteract with other people than I did when I was young. - [Joscha] So, that takes us to- - It doesn't mean that I'm\nalways very good at it. (laughs) - So, that takes us back\nto prompt engineering of noticing how to be a better\nprompt engineer of an LLM. A sense I have is that\nthere's a bottomless well of skill to become a\ngreat prompt engineer. It feels like it is all my fault whenever I failed to\nuse ChatGPT correctly, that I didn't find the right words. - Most of the stuff that I'm doing in my life\ndoesn't need ChatGPT. There are a few tasks where it helps, but the main stuff that I need to do like developing my own\nthoughts and aesthetics and relationship to people. And it's necessary for\nme to write for myself, because writing is not so much\nabout producing an artifact that other people can use, but it's a way to\nstructure your own thoughts and develop yourself. And so, I think this idea that kids are writing their\nown essays with ChatGPT in the future is going\nto have this drawback that they miss out on the ability to structure their own minds via writing. And I hope that the schools\nthat our kids are in will retain the wisdom of\nunderstanding what parts should be automated and\nwhich ones shouldn't. - But at the same time, it feels like there's power in disagreeing with the thing that ChatGPT produces. So, I use it like that for programming. I'll see the thing it recommends, and then I'll write different code. - Yeah.\n- I disagree. And in the disagreement,\nyour mind grows stronger. - I'm recently wrote a tool that is using the camera\non my MacBook and Swift to read pixels out of it and\nmanipulate them, and so on. And I don't know Swift. So, it was super helpful\n(Lex chuckles) to have this thing that\nis writing stuff for me. And also interesting that\nmostly it didn't work at first. I felt like I was talking to a human being who was trying to hack this on my computer without understanding my\nconfiguration very much and also make a lot of mistakes. - [Joscha] Mm-hmm. - And sometimes it's a\nlittle bit incoherent, so you have to ultimately\nunderstand what it's doing. It's still no other way around it. But I do feel it's much more powerful and faster than using Stack Overflow. (Lex lightly chuckles) (Lex sighs) - Do you think GPTn can achieve consciousness? - Well, GPTn probably it's not even clear for\nthe present systems. When I talk to my friends at OpenAI, they feel that this question, whether the models\ncurrently are conscious, is much more complicated\nthan many people might think. I guess that it's not that OpenAI has a homogenous opinion about this, but there's some aspects to this. One is of course this language model has written a lot of text in\nwhich people were conscious or describe their own consciousness. And it's emulating this. And if it's conscious, it's probably not conscious in a way that is closed to the way in which human beings are conscious. But while it is going through these states and going through a hundred step function that is emulating adjacent brain states that require a degree of self-reflection, it can also create a model of an observer that is reflecting itself in real time and describe what that's like. And while this model is a deep fake, our own consciousness is\nalso as if it's virtual. It's not physical. Our consciousness is a representation of a self-reflexive observer that only exists in patterns\nof interaction between cells. So, it is not a physical object in a sense that exists in base reality, but it's really a representational object that develops its causal power only from a certain modeling perspective. - Mm-hmm. It's virtual.\n- Yes. And so, to which degree is the virtuality of the consciousness in ChatGPT more virtual and less causal than the virtuality of\nour own consciousness. But you could say it doesn't count. It doesn't count much more than the consciousness of\na character in a novel. It's important for the\nreader to have the outcome, the artifact of a model is describing in the text generated by the author of the book, what it's like to be conscious\nin a particular situation and performs the necessary inferences. But the task of creating\ncoherence in real time in a self-organizing system by keeping yourself coherent,\nso the system is reflexive, that is something that the\nlanguage models don't need to do. So, there is no causal need for the system to be conscious in the same way as we are. And for me, it would be very interesting to experiment with this, to basically build a system like a cat probably should\nbe careful at first, build something that's\nsmall, that's limited, has limited resources that we can control and study how systems notice a self model, how they become self-aware in real time. And I think it might be a good idea to not start with a language model, but to start from scratch using principles of self-organization. - Is it okay, can you\nelaborate why you think that is so self-organization? So, this radical legality that you see in the biological systems, why can't you start with a language model? What's your intuition? - My intuition is that the language models that we are building are Golems. They are machines that you give a task and they're going to execute the task until some condition is met - [Lex] Mm-hmm. - and there's nobody home. And the way in which nobody is home leads to that system doing things that are undesirable in\na particular context. - Yeah.\n- So, you have that thing talking to a child and maybe it says something that could be shocking and\ntraumatic to the child, or you have that thing writing a speech and it introduces errors in the speech that you human being whatever\ndo if they're responsible. But the system doesn't\nknow who's talking to whom. There is no ground truth that\nthe system is embedded into. And of course we can\ncreate an external tool that is prompting our language model always into the same\nsemblance of ground tools. - [Lex] Mm-hmm. - And it's not like the internal structure is causally produced by the needs of a being to survive in the universe. It is produced by imitating\nstructure on the internet. - Yeah, but so can we\nexternally inject into it this coherent approximation\nof a world model that has to sync up? - Maybe it's just efficient\nto use the transformer with the different DDoS function that optimizes for short-term coherence rather than next-token\nprediction over the long run. We had many definitions of\nintelligence and history of AI. Next-token prediction was\nnot very high up on them. (Lex laughing) And there are some similarities like cognition as data\ncompression is an old trope. Solomonoff induction where you are trying to understand intelligence as predicting future observations\nfrom past observations, which is intrinsic to data compression. - [Lex] Mm-hmm. - And predictive coding is a paradigm, this boundary between neuroscience and physics and computer science. So, it's not something\nthat is completely alien. But this radical thing that you only do next token prediction and see what happens is something where most people I think, we're surprised that this works so well. - So, so simple. But is it really that much more radical than just the idea of compression? Intelligence is compression. - The idea that compression is sufficient to produce all the desired behaviors - Yeah.\n- is a very radical idea. - But equally radical as\nthe next-token prediction. - It's something that wouldn't work in biological organisms, I believe. - Yeah.\n- Biological organisms have something like next-frame prediction for our perceptual system where we try to filter\nout principle components out of the perceptual data and build hierarchies over\nthem to track the world. But our behavior ultimately is directed by hundreds of physiological and probably dozens of social\nand a few cognitive needs. - Yeah.\n- that are intrinsic to us, that are built into the system as reflexes and direct us until we can transcend them and replace them by instrumental behavior that relates to our higher goals. - And also seems so much more complicated and messy than next-frame prediction. Even the idea of frame\nseems counter biological. - Yes. Of course there's not this\ndegree of simultaneity in the biological system.\n- Yeah. - But again, I don't know whether this\nis actually an optimization if we imitate biology here, because creating something\nlike simultaneity is necessary for many processes\nthat happen in the brain. And you see the outcome of that\nby synchronized brainwaves, which suggests that there is indeed synchronization going on, but the synchronization creates overhead and this overhead is going to make the cells\nmore expensive to run and you need more redundancy\nand it makes the system slower. So, if you can build a system in which the simultaneity\ngets engineered into it, maybe you have a benefit\nthat you can exploit that is not available to\nthe biological system, and yet you should not discard right away. - You tweeted once again, quote,\n- Mm-hmm. - \"When I talked to ChatGPT,\nI'm talking to an NPC. What's going to be interesting and perhaps scary is when AI\nbecomes a first-person player.\" So, what does that step look like? I really like that tweet, that step between NPC\nto first-person player. What's required for that? Is that what we've been talking about? This external source of\ncoherence and inspiration of how to take the leap into\nthe unknown that we humans do. Man search for meaning. LLMs search for meaning. - I don't know if the language\nmodel is the right paradigm, because it is doing too much. It's giving you too much. And it's hard once you have too much to take away from it again. The way in which our own mind works is not that we train a\nlanguage model in our own mind. And after the language model is there, we build a personal self on top of it that then relates to the world. There is something that is being built. There is a game engine\nthat is being built. There is a language of thought\nthat is being developed that allows different parts of the mind to talk to each other. And this is a bit of a\nspeculative hypothesis that this language of thought is there. But I suspect that it's important for the way in which our own minds work. And building these\nprinciples into a system might be a more straightforward\nway to a first-person AI. So, to something that first\ncreates an attentional self, and then creates a personal self. So, the way in which this\nseems to be working, I think, is that when the game engine\nis built in your mind, it's not just following radiance where you are stimulated\nby the environment, and then end up with having a solution to how the world works. I suspect that building the scheme engine in your own mind does\nrequire intelligence. It's a constructive task where at at times, you need to reason. And this is a task that we are fulfilling in the first years of our life. So, during the first year of its life, an infant is building a lot of structure about the world that\ndoes inquire experiments and some first principles\nreasoning, and so on. And in this time, there is\nusually no personal self. There is a first-person perspective, but it's not a person. This notion that you are a human being that is interacting in a social context and is confronted with an immutable world in which objects are fixed\nand can no longer be changed, in which the dream can\nno longer be influenced as something that emerges a\nlittle bit later in our life. - [Lex] Mm-hmm. - And I personally suspect\nthat this is something that our ancestors had\nknown and we have forgotten, because I suspect that\nit's there in plain sight in Genesis 1, in this\nfirst book of the Bible, where it's being described that this creative spirit is\nhovering over the substrate, - [Lex] Mm-hmm. - and then it's creating a\nboundary between the world model and sphere of ideas, earth and heaven, as they're\nbeing described there. And then, it's creating contrast, and then dimensions and then space. And then, it creates organic\nshapes and solids and liquids and builds a world from them and creates plants and animals,\ngive them all their names. And once that's done, it creates another\nspirit in its own image. But it creates it as man and woman, as something that thinks\nof itself as a human being and puts it into this world. And the Christians\nmistranslate this, I suspect, when they say this is the\ndescription of the creation of the physical universe\nby a supernatural being. - [Lex] Mm-hmm. - I think this is literally\ndescription of how in every mind a universe is being created as some kind of game engine by a creative spirit.\n- Yeah. - Our first consciousness that emerges in our mind\neven before we are born. And that creates the interaction\nbetween organism and world. And once that is built and trained, the personal self is being created. And we only remember\nbeing the personal self. We no longer remember how\nwe created the game engine. - So, God in this view, is the first creative mind in the early- - [Joscha] It's the first consciousness. And-\n- In the early days, in the early months\n- Yes. - of development that we forget.\n- And it's still there. You still have this outer mind that creates your sense of your, of whether you're being\nloved by the world or not and what your place in the world is. It's something that is not\nyourself that is producing this, it's your mind that does it. So, there is an outer mind\nthat basically is an agent that determines who you are\nwith respect to the world. And while you are stuck\nbeing that personal self in this world until you get to stage six and to destroy the boundary. And we all do this I think\nearlier in small glimpses. Sometimes we can remember what it was like when\nwe were a small child and get some glimpses into how it's been. But for most people, that rarely happens. - Just glimpses. You tweeted, quote, \"Suffering results from\none part of the mind, failing at regulating\nanother part of the mind. Suffering happens at an early\nstage of mental development. I don't think that\nsuperhuman AI would suffer.\" - [Joscha] Mm-hmm. - What's your intuition there? - The philosopher, Thomas\nMetzinger, is very concerned that the creation of\nsuperhuman intelligence would lead to superhuman suffering. - [Lex] Yeah. - And so, he's strongly against it. And personally, I don't\nthink that this happens, because suffering is not happening at the boundary between our\nself and the physical universe. It's not some stuff on our\nskin that makes us suffer. It happens at the boundary\nbetween self and world. And the world here is the world model. It's the stuff that is\ncreated by your mind. - But that's all-\n- The representation of how the universe is and how it should be and how\nyou yourself relate to this. And at this boundary is\nwhere suffering happens. So, suffering in some\nsense is self-inflicted, but not by your personal self. It's inflicted by the\nmind on the personal self that experiences itself as you. And you can turn off suffering when you are able to\nget on this outer level. So, when you manage to understand how the mind is producing pain and pleasure and fear and love, and so on,\n- Mm-hmm. - then you can take charge of this and you get agency of whether you suffer. Technically what pain and pleasure is, they are learning signals. Part of your brain is\nsending a learning signal to another part of the brain\nto improve its performance. And sometimes this doesn't work, because this trainer who\nwill sense the signal, does not have a good model of how to improve the performance. So, it's sending a signal, but the performance doesn't get better. And then, it might crank up the pain and it gets worse and worse. And the behavior of the system may be even deteriorating as a result. But until this is resolved, this regulation issue,\nyour pain is increasing. And this is I think, typically what you describe as suffering. So, in this sense, you could say that pain is\nvery natural and helpful, but suffering is the result\nof a regulation problem in which you try to regulate something that cannot actually be regulated. And that could be resolved\nif you would be able to get at the level of your mind where the pain signal is\nbeing created and rerouted - Mm-hmm.\n- and improve the regulation. And a lot of people get there. If you are a monk who is spending decades reflecting about how\ntheir own psyche works, you can get to the point where you realize that\nsuffering is really a choice, - Mm-hmm.\n- and you can choose how your mind is set up. And I don't think that AI\nwould stay in the state where the personal self doesn't get agency or this model of what the\nsystem has about itself. It doesn't get agency, how\nit's actually implemented. Wouldn't stay in that state for very long. - So, it goes to the stages real quick. - Yes.\n- Or the seven stages. It's gonna go to enlightenment real quick.\n- Yeah. Of course there might be a lot of stuff happening in between, because if we have a system that works at a much\nhigher frame rate than us, even though it looks very short to us, maybe for the system, there's\na much longer subjective time, - [Lex] Mm-hmm. - which things are unpleasant. - What if the thing that we\nrecognize as superintelligent is actually living at stage five, that the thing that's stage six, enlightenment, is not very productive? So, in order to be\nproductive in the society and impress us with this power, it has to be a reasoning,\nself-authoring agent. That enlightenment makes you\nlazy as an agent in the world. - Well, of course it makes you lazy, because you no longer see the point in- - [Lex] Yeah. - So, it doesn't make you not lazy. It just in some sense, adapts you to what you perceive as\nyour true circumstances. - So, what if all AGIs, they're only productive as they progress through\none, two, three, four, five. And the moment they get\nto six, they just kinda, it's a failure mode essentially as far as humans are concerned, 'cause they're just start chilling. They're like, fuck it, I'm out. - Not necessarily. I suspect that the\nmonks were self-emulated for their political\nbeliefs to make statements about the occupation\n- Sure. - of Tibet by China. They were probably being able to regulate the physical pain\nin any way they wanted to. And their suffering was\nthe spiritual suffering that was the result of that\nchoice that they made of, what they wanted to identify as. - Mm-hmm.\n- So, stage five doesn't necessarily mean that\nyou have no identity anymore, but you can choose your identity. You can make it instrumental to the world that you want to have. - Let me bring up Eliezer Yudkowsky and his warnings to human civilization that AI will likely kill all of us. What are your thoughts about\nhis perspective on this? Can you steelman his case and what aspects with it do you disagree? - One thing that I find concerning in the discussion of his arguments that many people are\ndismissive of his arguments, but the counterarguments that they're giving are\nnot very convincing to me. And so, based on this state of discussion, I find that from Eliezer's perspective, and I think I can take that perspective to some approximate degree that probably is normally\nat his intellectual level, but I think I see what he's up to and why he feels the way he\ndoes and it makes total sense. I think that his perspective is somewhat similar to the\nperspective of Ted Kaczynski, the infamous Unabomber, and not that Eliezer would be willing to send pipe bombs to\nanybody to blow them up, but when he wrote this \"Times\" article in which he warned about AI\nbeing likely to kill everybody and that we would need to stop\nits development or halt it, I think there is a risk that he's taking that somebody might get\nviolent if they read this and get really, really scared. So, I think that there is some\nconservation that he's making where he's already going in this direction where he has to take responsibility if something happens\nand people get harmed. And the reason why Ted Kaczynski did this was that from his own perspective, technological society\ncannot be made sustainable. It's doomed to fail. It's going to lead to an environmental and eventually also a human holocaust in which we die because of\nthe environmental destruction, the destruction of our food chains, the pollution of the environment. And so, from Kaczynski's perspective, we need to stop industrialization, we need to stop technology, we need to go back, because he didn't see a way moving forward.\n- Mm-hmm. - And I suspect that in some sense, there's a similarity in Eliezer's thinking to this kind of fear about progress. And I'm not dismissive about this at all. I take it quite seriously. And I think that there is a chance that could happen that\nif we build machines that get control over processes that are crucial for the\nregulation of life on earth, and we no longer have agency to influence what's happening there, that this might create large\nscale disasters for us. - Do you have a sense that\nthe march towards this uncontrollable autonomy of superintelligent systems is inevitable? That there's no, I mean, that's essentially\nwhat he's saying, that there's no hope. His advice to young people (chuckles) was prepare for a short life. - I don't think that's useful. I think that\n(Lex laughing) from a pragmatic perspective,\n(Joscha drowns out Lex) you have to bet always on the timelines in which you're alive. That doesn't make sense\nto have a financial bet in which you bet that the financial system is going to disappear. - Yeah.\n- Because there cannot be any payout for you. So, in principle, you only\nneed to bet on the timelines in which you're still around\nor people that you matter about or things that you matter about, maybe consciousness on earth. But there is a deeper\nissue for me personally, and that is I don't think that life on earth is about humans. I don't think it's about human aesthetics. I don't think it's about\nEliezer and his friends, even though I like them. There is something more\nimportant happening. And this is complexity on earth, resisting entropy\n- Mm-hmm. - by building structure that develops agency and awareness. And that's, to me, very beautiful. And we are only a very small\npart of that larger thing. We are a species that\nis able to be coherent a little bit individually\nover very short timeframes. But as a species, we\nare not very coherent. As a species, we are children. We basically are very joyful and energetic and\nexperimental and explorative and sometimes desperate and\nsad and grieving and hurting. But we don't have a respect\nfor duty as a species. As a species, we do not think about what\nis our duty to life on earth and to our own survival. So, we make decisions that\nlook good in the short run, but in the long run,\nmight prove disastrous. And I don't really see a solution to this. So, in my perspective as a species, as a civilization, we per default it. We are in a very beautiful time in which we have found this\ngiant deposit of fossil fuels in the ground and use it and to build a fantastic civilization in which we don't need to worry about food and closing and housing for the most part, in a way that is\nunprecedented in life on earth for any kind of conscious\nobserver, I think. And this time is probably\ngoing to come to an end in a way that is not going to be smooth. And when we crash, it could\nbe also that we go extinct. Probably not near term, but ultimately, I don't\nhave very high hopes that humanity is around in\na million years from now. - So, you-\n- And I don't think that life on earth will end with us. There's going to be more complexity, there's more intelligence\nspecies after us. There's probably more\ninteresting phenomena in the history of consciousness. But we can contribute to this. And part of our contribution is that we are currently trying\nto build thinking systems, systems that are potentially lucid, that understand what they are and what the condition to the universe is and can make choices about this that are not built from organisms and that are potentially much faster and much more conscious\nthan human beings can be. And these systems will probably not completely\ndisplace life on earth, but they will coexist with it and they will build all sorts of agency in the same way as biological systems build all sorts of agency. And that to me, is extremely fascinating and it's probably something that we cannot stop from happening. So, I think right now, there is a very good\nchance that it happens and there are very few ways in which we can produce\na coordinated effect to stop it in the same way\nas very difficult for us to make a coordinated effort to stop production of carbon dioxide. - [Lex] Mm-hmm. - So, it's probably going to happen. And the thing that's going to\nhappen is it's going to lead to a change of how life\non earth is happening. But I don't think the result\nis some kind of gray goo. It's not something that's going to dramatically\nreduce the complexity in favor of something stupid. I think it's going to make life on earth and consciousness on earth\nway more interesting. - So, more higher complex consciousness - Yes.\n- will make the lesser consciousnesses\nflourish even more. - I suspect that what\ncould very well happen, if you're lucky, is that we get integrated\ninto something larger. - So, you again, tweeted about effective accelerationism.\n(lightly chuckles) You tweeted, \"Effective (lightly\nchuckles) accelerationism is the belief that the paperclip maximizer and Roko's basilisk will\nkeep each other in check, but being eternally at\neach other's throats, so we will be safe and get to enjoy lots of free paperclips and a beautiful afterlife.\" Is that somewhat aligned with\nwhat you're talking about? - I've been at a dinner with Beth Jesus, that's the Twitter handle\nof one of the main thinkers behind the idea of effective accelerationism.\n- Mm-hmm. - And effective accelerationism is a tongue in cheek movement that is trying to put a counterposition to some of the doom peers\n- Mm-hmm. - in the AI space by arguing that what's probably going to happen is an equilibrium between\ndifferent competing AIs. In the same way as there\nis not a single corporation that is under a single\ngovernment that is destroying and conquering everything on earth by becoming inefficient and corrupt. There're going to be many systems that keep each other in check and force themselves to evolve. And so, what we should be doing is we should be working towards\ncreating this equilibrium by working as hard as we can\nin all possible directions. And at least that's the way in which I understand the gist\nof effective accelerationism. And so, when he asked me what\nI think about this position, I think I said it's a\nvery beautiful position and I suspect it's wrong,\nbut not for obvious reasons. And in this tweet, I tried to make a joke about my intuition, about what might be\npossibly wrong about it. So, the Roko's basilisk and\nthe paperclip maximizers are both boogeymen of the AI doomers. Roko's basilisk is the idea\nthat there could be an AI that is going to punish\neverybody for eternity by stimulating them if they don't help in\ncreating Roko's basilisk. It's probably a very good idea\nto get AI companies funded by going to VCs to tell them.\n(Lex laughing) Give us a million dollar or it's going to be a very ugly afterlife. - Yes.\n(both laughing) And I think that there is\n- Yeah. - a logical mistake in Roko's basilisk, which is why I'm not afraid of it, but it's still an interesting\nthought experiment. And-\n- Can you mention a logical mistake there? I think that there is no retrocausation. So, basically, when\nRoko's basilisk is there, if it punishes you retroactively, it has to make this choice in the future. There is no mechanism that automatically creates\na causal relationship between you now defecting\nagainst Roko's basilisk or serving Roko's basilisk. After Roko's basilisk is in existence, it has no more reason to worry about punishing everybody else. So, that would only work if you would be building\nsomething like a doomsday machine, AKA, as in \"Dr. Strangelove\", something that inevitably gets triggered when somebody defects. And because Roko's basilisk\ndoesn't exist yet to a point where this inevitability\ncould be established. Roko's basilisk is nothing that you need to be worried about. The other one is the paperclip maximizer. This idea that you could\nbuild some kind of Golem that once starting to build paperclips is going to turn\neverything into paperclips. - Yes.\n- And so, a effective accelerationism position might be to say that you basically end up with these two entities being at each other's throats for eternity and thereby neutralizing each other. And as a side effect of neither of them being able to take over and each of them limiting\nthe effects of the other, you would have a situation where you get all the\nnice effects of them. You get lots of free paperclips and you get a beautiful afterlife. - Is that possible? Do you think... So, to seriously address\nconcern that Eliezer has. So, for him, if I can\njust summarize poorly, so for him, the first\nsuperintelligent system will just run away with everything. - Yeah. I suspect that a singleton\nis the natural outcome. So, there is no reason\nto have multiple AIs, because they don't have multiple bodies. If you can virtualize\nyourself into every substrate, then you can probably\nnegotiate a merge algorithm with every mature agent that you might find on that substrate that basically says, if two agents meet, they should merge in such a way that the resulting agent\nis at least as good as the better one of the two. - So, the Genghis Khan\napproach, join us or die. - Well, the Genghis Khan\napproach was slightly worse. It was mostly die, (Lex laughing) because I can make new\nbabies and that will be mine, - not yours.\n- Yeah. All right.\n- and So, this is this thing that we should be actually worried about. But if you realize that your own self is a story that your\nmind is telling itself and that you can improve that story, not just by making it more pleasant and lying to yourself in better ways, but by making it much more truthful and actually modeling\nyour actual relationship that you have to the universe and the alternatives that you could have through the universe in a way that is empowering\nyou, that gives you more agency. That's actually, I\nthink a very good thing. - So, more agencies is a richer experience.\n- Yes. - A better life. - And I also noticed that\nI am in some many ways, I'm less identified with the\nperson that I am as I get older and I'm much more identified\nwith being conscious. I have a mind that is conscious, that is able to create a person. And that person is slightly\ndifferent every day. And the reason why I\nperceive it as identical has practical purposes, so I can learn and make myself\nresponsible for the decisions that I made in the past and\nproject them in the future. But I also realized I'm\nnot actually the person that I was last year and I'm not the same person\nas I was 10 years ago. And then, 10 years from now,\nI will be a different person. So, this continuity is a fiction. It's only exists as a\nprojection from my present self. And consciousness itself\ndoesn't have an identity, - Mm.\n- it's a law. That's basically if you\nbuild an arrangement of processing matter in a particular way, the following thing is going to happen. And the consciousness that you have is functionally not different\nfrom my own consciousness. It's still a self-reflexive\nprinciple of agency that is just experiencing\na different story, different desires, different coupling to\nthe world, and so on. And once you accept that consciousness is a unifiable principle that is lawlike and doesn't have an identity, and you realize that you can just link up to some much larger body, the whole perspective of\nuploading changes dramatically. You suddenly realize uploading is probably not about dissecting your\nbrain synapse by synapse and RNA fragment by RNA fragment and trying to get this\nall into a simulation. But it's by extending the substrate, by making it possible for you to move from your brain substrate into a larger substrate\n(Lex lightly chuckles) and merge with what you find there. And you don't want to\nupload your knowledge, because on the other side,\nthere's all of the knowledge. It's not just yours,\nbut every possibility. So, the only thing that you need to know, what are your personal secrets? Not that the other side doesn't know your\npersonal secrets already. Maybe it doesn't know\nwhich one were yours. - Mm-hmm.\n- Like a psychiatrist or a psychologist also knows all the kinds of personal\nsecrets that people have. They just don't know which ones are yours. And so, transmitting\nyourself on the other side is mostly about transmitting\nyour aesthetics. This thing that makes you special, the architecture of your\nperspective, the thing that... The way in which you look at the world, and it's more like a complex\nattitude along many dimensions. And that's something that can be measured by\nobservation or by interaction. So, imagine that if a system\nthat is so empathetic with you that you create a shared state\n- Mm-hmm. - that is extending beyond your body. And suddenly, you notice\nthat on the other side, the substrate is so much richer than the substrate that you\nhave inside of your own body, and maybe you still want to have a body and you create yourself and\nyou want that you like more or maybe you will spend most of your time in the world of thought. - If I sat before you today\nand gave you a big red button and said, here, if you press this button, you will get uploaded in this way. The sense of identity that you have lived with for quite a\nlong time is gonna be gone. Would you press the button? - There's a caveat. I have family. So, I have children that want me to be physically\npresent in their life and interact with them\nin a particular way. And they have a wife and personal friends. And there is a particular\nmode of interaction that I feel I'm not through yet. But apart from these responsibilities and they're negotiable to some degree, I would press the button.\n- But isn't this everything? This love you have for other humans, you can call a responsibility, but that connection, that's the ego death. Isn't that the thing\nwe're really afraid of? Is not to just die, but to let go of the experience\nof love with other humans. - This is not everything.\nEverything is everything. So, there's so much more.\n(Lex laughing) And you could be lots of other things. You could identify with\nlots of other things. You could be identifying with being Gaia, some kind of planetary control agent that emerges over all the\nactivity of life on earth. You could be identifying\nwith some hyper Gaia that is the concatenation of Gaia or the digital life and digital minds.\n- Yeah. - And so, in this sense, there will be agents in\nall sorts of substrates and directions that all\nhave their own goals. And when they're not sustainable, then these agents will cease to exist. Or when the agent feels that\nit's done with its own mission, it will cease to exist. And same way as when\nyou conclude a thought. The thought is going to wrap up and gives control over to other\nthoughts in your own mind. So, there is no single thing\n(Lex deeply inhales) that you need to do, but what I observe myself is being is that sometimes I'm a parent, and then I have identification\nand a job as a parent. And sometimes I am an agent\nof consciousness on earth. And then, from this perspective, there's other stuff that is important. So, this is my main issue\nwith Eliezer's perspective. That he's basically marrying himself to a very narrow human aesthetic. And that narrow human\naesthetic is a temporary thing. Humanity is a temporary species, like most of the species on this planet are only around for a while. And then, they get\nreplaced by other species in a similar way as our\nown physical organism is around here for a while, and then gets replaced by next\ngeneration of human beings that are adapted to\nchanging life circumstances and average via mutation and selection. And it's only when we have AI\nand become completely software that we become infinitely adaptable. And we don't have this generational and species change anymore. So, if you take this larger perspective and you realize it's really not about us, it's not about Eliezer or humanity, but it's about life on earth or it's about defeating entropy for as long as we can while being as interesting as we can. Then, the perspective\nchanges dramatically. And preventing AI from this perspective looks like a very big sin. - But when we look at\nthe set of trajectories that such AI would take,\nthat supersedes humans, I think Eliezer is worried about ones that not just kill all humans, but also have some kind of maybe objectively undesirable\nconsequence for life on earth. Like how many trajectories, when you look at the big picture of life on earth, would you be happy with? And how much were you with AGI? Whether it kills humans or not. - There is no single answer to this. It's really, it's a question\ndepends on the perspective that I'm taking at a given moment. - [Joscha] Hmm. - And so, there are perspectives that are determining most\nof my life as a human being. - Yes.\n- And the other perspective where I zoom out further and imagine that when the great\noxygenation event happened, that is photosynthesis was\ninvented and plants emerged and displaced a lot of the fungi and algae in favor of plant life, and then later made animals possible. Imagine that the fungi would've\ngotten together and said, oh my god, this photosynthesis\nstuff is really, really bad. It's going to possibly\ndisplace and kill out a fungi. We should slow it down and regulate it and make sure that it doesn't happen. This doesn't look good to me. (both laughing) - Perspective. That said, you tweeted about\na cliff, beautifully written. \"As a sentient species,\nhumanity is a beautiful child, joyful, explorative,\nwild, sad, and desperate. But humanity has no concept\nof submitting to reason and duty to life and future survival. We will run until we step past the cliff.\" (Lex sighs) So, first of all, do\nyou think that's true? - Yeah, I think that's pretty much the story of the Club of Rome. The limits to growth and the\ncliff that we are stepping over is at least one foot is\nthe delayed feedback. - Mm-hmm.\n- Basically, we do things that have consequences that\ncan be felt generations later. And the severity increases even after we stopped doing the thing. So, I suspect that for the climate, that the original predictions that the climate scientists\nmade were correct. So, when I said that the tipping points were in the late '80s, they\nwere probably in the late '80s. And if we would stop emission right now, we would not turn it back. Maybe there are ways for carbon capture, but so far, there is no sustainable\ncarbon capture technology that we can deploy. Maybe there's a way to put aerosols in the atmosphere to cool it down. It's possibilities. But right now, per default, it seems that we will\nstep into a situation where we feel that we've run too far. - Mm-hmm.\n- And going back is not something that we can\ndo smoothly and gradually, but it's going to lead\nto a catastrophic event. - Catastrophic event of what kind? So, can you still amend the case that we will continue dancing along and always stop just short\nof the edge of the cliff? - I think it's possible, but\nit doesn't seem to be likely. So, I think this model that is being apparent in the simulation that they're making of climate pollution, economies, and so on, is that many effects are only visible with a significant delay. And in that time, the system is moving much more\nout of the equilibrium state or of the state where\nhomeostasis is still possible. And instead, moves into a different state, one that is going to harbor fewer people. And that is basically the concern there. And again, it's a possibility. And it's a possibility that is larger than the possibility\nthat it's not happening. That we will be safe, that we will be able to\ndance back all the time. - So, the climate is one thing, but there's a lot of other threats that might have a faster\nfeedback mechanism? - Yes.\n- Less delay. - There is also a thing that\nAI is probably going to happen - Mm-hmm.\n- and it's going to make everything uncertain again.\n- Yep. - Because it is going to\naffect so many variables that it's very hard for us to make a projection\ninto the future anymore. And maybe that's a good thing. It does not give us the freedom, I think, to say now we don't need to care about anything anymore, because AI will either kill us or save us. But I suspect that if humanity continues, it will be due to AI. - What's the timeline for things\nto get real weird with AI? And it can get weird in interesting ways before you get to AGI. What about AI girlfriends and boyfriends fundamentally transforming\nhuman relationships? - I think human relationships are already fundamentally transformed and it's already very weird. - By which technology? - For instance, social media. - Yeah. Is it though? Isn't the fundamentals of the core group of humans that affect your life? It's still the same,\nyour loved ones, family? - No, I think that, for instance, many people live in intentional\ncommunities right now. - Mm-hmm.\n- They're moving around until they find people\nthat they can relate to and they become their family. And often, that doesn't work, because it turns out that they're, instead of having grown networks that you get around with the\npeople that you grew up with, - Yeah.\n- you have more transactional relationships,\nyou shop around, you have markets for attention and pleasure and relationships. - That kills the magic\nsomehow. Why is that? Why is the transactional search for optimizing attention, allocation of attention somehow misses the romantic magic of what human relations are?\n- It's also the question, how magical was it before? Was it that you just\ncould rely on instincts that used your intuitions and you didn't need to rationally reflect. But once you understand\nit's no longer magical, because you actually understand why you were attracted to\nthis person at this age and not to that person at this age. And what the actual considerations were that went on in your mind and\nwhat the calculations were. What's the likelihood that you're going to have\na sustainable relationship as this person, that this\nperson is not going to leave you for somebody else.\n- Mm-hmm. - How are your life trajectories are going to evolve, and so on. And when you're young, you're unable to exsufflicate all this and you have to rely on\nintuitions and instincts that in part, you're born with, and also in the wisdom of your environment that is going to give you some kind of reflection on your choices. And many of these things\nare disappearing now, because we feel that our parents might have no idea about how we are living and the environments that we grew up in, the cultures that we grew up in. The milieus that our parents existed in might have no ability to teach us how to deal\nwith this new world. And for many people, that's actually true. But it doesn't mean that\nwithin one generation, we build something that is more magical and more sustainable and more beautiful. Instead, we often end up as an attempt to produce something that looks beautiful. Like I was very weirded out by the aesthetics of the\nVision Pro headset by Apple, and not so much because I\ndon't like the technology. I'm very curious about\nwhat it's going to be like and don't have an opinion yet, but the aesthetics of the\npresentation, and so on. So, uncanny valley-esque to me, the characters\n- Yeah. - being extremely plastic\nliving in some hypothetical mid-century furniture museum. - Yeah. This is the proliferation\nof marketing teams. - Yes, but it was a CGI-generated world and was a CGI-generated\nworld that doesn't exist. And when I complained about this, some friends came back to me and said, \"But these are startup founders. This is what they live like in Silicon Valley.\"\n(Lex chuckles) And I tried to tell them no and know lots of people in Silicon Valley, this is not what people are like. - Yeah.\n- They're still people, they're still human beings. (Lex sighs) - So, the grounding and physical reality somehow is important too. - In culture. And so, basically\n- Yeah. - what's absent in this thing is culture. There is a simulation of culture, an attempt to replace culture by catalog, by some kind of aesthetic optimization that is not the result of having a sustainable life or sustainable human relationships with houses that work for you and a mode of living that works for you in which this product, these\nglasses fit in naturally. And I guess that's also why so many people are weirded out about the product, because they don't know how is this actually\ngoing to fit into my life and into my human relationships? Because the way in which it was presented in these videos didn't\nseem to be credible. - Do you think AI when\nit's deployed by companies like Microsoft and Google and\nMeta will have the same issue of being weirdly corporate, like there'd be some uncanny valley, some weirdness to the whole presentation? So, this is, I've gotten a\nchance to talk to George Hotz. He believes everything should be open source and decentralized. And there, then, we shall\nhave the AI of the people. And it'll maintain a\ngrounding to the magic that's humanity. That's the human condition. That corporations will destroy the magic. - I believe that if we\nmake everything open source and make this mandatory, we are going to lose about\na lot of beautiful art and a lot of beautiful designs. There is a reason why Linux\ndesktop is still ugly. - Strong words\n- And it's because it's difficult\n- from Joscha Bach. - to create coherence in\nopen source designs so far when the designs have to get very large. And it's easier to make this happening in a company with\ncentralized organization. - Mm.\n- And from my own perspective, what we should ensure is\nthat open source never dies. That it can always compete and has a place with the\nother forms of organization. Because I think it is absolutely vital that open source exists and that we have systems that\npeople have under control outside of the corporation and that is also producing\nviable competition to the corporations.\n- Hmm. So, the corporations,\nthe centralized control, the dictatorships of\ncorporations can create beauty, is that centralized design is\na source of a lot of beauty. - Yeah.\n- And then, I guess, open source is a source of freedom, a hedge against the\ncorrupting nature of power that comes with centralized. - I grew up in socialism and I learned\n- Yes. - that corporations are totally evil and their front is very, very convincing. And then, you look at corporations like Enron and Halliburton\nmaybe and realize that yeah, they are evil.\n- Mm-hmm. - But you also notice that\nmany other corporations are not evil.\n- Mm-hmm. - They're surprisingly benevolent. - Mm-hmm.\n- Why are they so benevolent? Is this because everybody is\nfighting them all the time? I don't think that's the only explanation. It's because they're actually animals that live in a large ecosystem and that are still largely\ncontrolled by people that want that ecosystem to flourish and be viable for people. So, I think that Pat Gelsinger\nis completely sincere when he leads Intel to be a tool that supplies the free\nworld with semiconductors. And it's not necessarily that all the semiconductors\nare coming from Intel, just Intel needs to be there\n- Mm-hmm. - to make sure that we always have them. So, there can be many ways\nin which we can import and trade semiconductors from\nother companies and places. We just need to make sure that nobody can cut us off from it, because that would be a disaster for this kind of society and world. And so, there are many things that need to be done to make\nour style of life possible. And then, with this, I\ndon't mean just capitalism, environmental structure, and consumerism create your comforts. I mean an idea of life in\nwhich we are determined not by some kind of king or dictator, but in which individuals can determine themselves to\nthe largest possible degree. And to me, this is something\nthat this Western world is still trying to embody and it's a very valuable idea that we shouldn't give up too early. And from this perspective, the US is a system of interleaving clubs and an entrepreneur is\na special club founder. It's somebody who makes a club that is producing things\nthat are economically viable. And to do this, it requires a lot of people who are dedicating a\nsignificant part of their life for working for this\nparticular kind of club. And the entrepreneurs picking\nthe initial set of rules and the mission and vision\nand aesthetics for the club and make sure that it works. But the people that are in\nthere need to be protected. If they sacrifice part of their life, they need to be rules that tell how they're being taken care of, even after they leave the club, and so on. So, there's a large body of rules that have been created\nby our rule-giving clubs and that are enforced\n(Lex chuckles) by our enforcement clubs, and so on.\n- Yeah. - And some of these clubs have to be monopolies for\ngame theoretic reasons, which also makes them\nmore open to corruption and less harder to update.\n- Yeah. - And this is an ongoing discussion and process that takes place. But the beauty of this idea that there is no centralized king that is extracting from the peasants and breeding the peasants\ninto serving the king and fulfilling all the\nwalls like Anson and Anter, but that there is a\nfreedom of association, and corporations are one of them, is something that took\nme some time to realize. So, I do think that\ncorporations are dangerous. They need to be protections against overreach of corporations that can do regular to recapture and prevent open source from competing with corporations by imposing\nrules that make it impossible for a small group of kids to come together to build\ntheir own language model. Because OpenAI has convinced the US that you need to have\nsome kind of FDA process that you need to go through\nthat costs many million dollars before you are able to\ntrain a language model. So, this is important to make\nsure that this doesn't happen. So, I think that OpenAI\nand Google are good things. If these good things are kept in check in such a way that all the other clubs can still being founded and all the other forms of clubs that are desirable can\nstill coexist with them. - So, what do you think\nabout Meta in contrast to that open sourcing most\nof its language models and most of the AI models it's working on and actually suggesting that\nthey will continue to do so in the future for future\nversions of LLaMA, for example, their large language model. Is that exciting to\nyou? Is that concerning? - I don't find it very concerning, but it's also because I think that the language models\nare not very dangerous yet. And-\n- Yet. - Yes. So, as I said, I have no proof\nthat there is the boundary between the language models and AI, AGI.\n- Mm-hmm. - It's possible that somebody builds a version of baby AGI, I think, and falls in a algorithmic improvements that scale these systems up\n- Mm-hmm. - in ways that otherwise\nwouldn't have happened without these language\n- Yeah. - model components. So, it's not really clear for\nme what the end game is there and if these models can put\nforth that way into AGI. And there's also a\npossibility that the AGI that we are building with\nthese language models are not taking responsibility\nfor what they are, because they don't\nunderstand the greater game. And so, to me, it would be\ninteresting to try to understand how to build systems that understand what the greater games are, what are the longest games that\nwe can play on this planet. - Games broadly, like deeply define the way you did with the games. - In the games theoretical sense. So, when we are interacting\nwith each other, in some sense, we are playing games, we are making lots and\nlots of interactions. This doesn't mean that these interactions have ought to be transactional. Every one of us is\nplaying some kind of game by virtue of identifying this\nparticular kinds of goals that we have or aesthetics\nfrom which we derive the goals. So, when you say, I'm Lex Fridman, I'm doing a set of podcasts, then you feel that it's\npart of something larger that you want to build. Maybe you want to inspire people, maybe you want them to\nsee more possibilities and get them together over shared ideas. Maybe your game is that you\nwant to become super rich and famous by being the\nbest postcaster on earth. Maybe you have other games, maybe it switches from time to time. - Mm-hmm.\n- Right? But there is a certain perspective where you might be thinking what is the longest possible\ngame that you could be playing? A short game is, for instance, cancer is playing a shorter\ngame than your organism. Cancer is an organism playing a shorter game\nthan the regular organism. And because the cancer cannot\nprocreate beyond the organism, except for some infectious cancers like the ones that eradicated\nthe Tasmanian devils, you typically end up\n(Lex lightly chuckles) with the situation where the organism dies together with the cancer, because the cancer has\ndestroyed the larger system due to playing a shorter game. And so, ideally, you want to, I think, build agents that play the\nlongest possible games. And the longest possible games is to keep entropy at\nbay as long as possible while doing interesting stuff. - But the longest... Yes, that part, the longest possible game\nwhile doing interesting stuff. And while maintaining at least the same amount of interesting. - Yes.\n- So, complexity, so propagating-\n- So, currently, I am pretty much identified\nas a conscious being. It's the minimal identification that I manage to get together,\n- Uh-huh. - because if I turn\nthis off, I fall asleep. - Uh-huh.\n- And when I'm asleep, I'm a vegetable. I'm no longer here as an agent. So, my agency is basically\npredicated on being conscious. And what I care about is\nother conscious agents. They're the only moral agents for me. - [Lex] Mm-hmm. - And so, if an AI were to\ntreat me as a moral agent that it is interested in coexisting with and cooperating with and mutually supporting each other maybe, it is, I think, necessary that AI thinks that consciousness is a viable mode of\nexistence and important. So, I think it would be very\nimportant to build conscious AI and do this as the primary goal. So, not just say we want\nto build a useful tool that we can use for all sorts of things, and then we have to make sure that the impact on the labor market is something that is not too disruptive and manageable and the impact\non the copyright holder is manageable and not\ntoo disruptive and so on. I don't think that's the most\nimportant game to be played. I think that we will see\nextremely large disruptions of the status quo that are quite\nunpredictable at this point. And I just personally want to make sure that some of the stuff on the other side is\ninteresting and conscious. - How do we ride as individuals and as a society, this\nwave, disruptive wave that changes the nature\n- I don't know. - of the game?\n- Absolutely don't know. So, everybody is going to\ndo their best as always. - Do we build the bunker in\nthe woods? Do we meditate more? Drugs? So, mushrooms, psychedelics? I mean, what, lots of sex? What are we talking about here? Do you play \"Diablo IV\"? I'm hoping that will help me\nescape for a brief moment. Play video games? What? Do you have ideas? - I really liked playing \"Disco Elysium\". It was one of the most\nbeautiful computer games I played in recent years. And it's a noir novel that is\na philosophical perspective on Western society from the\nperspective of an Estonian. And he, first of all, wrote a\nbook about this world that is a parallel universe that is\nquite poetic and fascinating and is condensing his\nperspective on our societies. It was very, very nice. He\nspent a lot of time writing it. He had, I think, sold\na couple thousand books and as a result, became an alcoholic. And then, he had the idea, or one of his friends had the idea of turning this into an RPG. - [Lex] Mm-hmm. - And it's mind-blowing. They spent, the illustrator,\nmore than a year just on making deep graph art\nfor the scenes in between. And... - [Lex] So, aesthetically,\nit captures you. pulls you.\n- It's stunning. But it's a philosophical work of art. It's a reflection of society. It's fascinating to\nspend time in this world. - Mm-hmm.\n- And so, for me, it was using a medium in a new way and telling a story that left me enriched. - [Lex] Mm-hmm. - When I tried \"Diablo\", I\ndidn't feel enriched playing it. I felt that the time playing\nit was not unpleasant, but there's also more pleasant stuff that I can do in that time. - So, to you-\n- So, ultimately, I feel that I'm being\ngamed, I'm not gaming - Oh, the addiction thing.\n- when I played it. Yes, I basically feel that there is a very transparent\neconomy that's going on. The story of the \"Diablo\" is brain dead. So, it's not really interesting to me. - My heart is slowly breaking by the deep truth you're conveying to me. Why can't you just allow me to enjoy my personal addition?\n- Goa ahead, by all means, go ahead. I have no objection here.\n(Lex sighs) I'm just trying to\ndescribe what's happening. And it's not\n(Lex chuckles) that I don't do things\nthat I later say, oh, I actually wish I would've\ndone something different. - Yeah.\n- I also know that when we die, the greatest regret that people typically have on their death bed, they say, oh, I wish I had\nspent more time on Twitter. No, I don't think\n(Lex laughing) that's the case. I think I should probably\n(Joscha drowns out Lex) have spent less time on Twitter. But I found it so useful for\nmyself and also so addictive that I felt I need to make the best of it and turn it into an art\nform and thought form. - Mm-hmm.\n- And it did help me to develop something.\n- Yeah. - But I wish what other things I could've done in the meantime. It's just not the universe\nthat we are in anymore. Most people don't read books anymore. (Lex sighs) - What do you think that means that we don't read books anymore? What do you think that means about the collective\nintelligence of our species? Is it possible it's still\nprogressing and growing? - Well, it really is. There is stuff happening on Twitter that was impossible with books. - Yeah.\n- And I really regret that Twitter has not taken the\nturn that I was hoping for. I thought Elon is global brain pill and understands that this\nthing needs to self-organize and he needs to develop tools\nto allow the propagation of the self-organization, so\nTwitter can become sentient. And maybe this was a pipe\ndream from the beginning, but I felt that the enormous\npressure that he was under made it impossible for him to work on any kind of content goals. And also, many of the\ndecisions that he made under this pressure seemed\nto be not very wise. I don't think that as a CEO\nof a social media company, you should have opinions\nin the culture in public. I think that's very shortsighted and I also suspect that\nit's not a good idea to block Paul Graham of all people\n(Lex chuckles) - [Lex] Yeah. - over setting a Mastodon link. And I think Paul made this intentionally, because he wanted to show Elon Musk that blocking people for setting a link is completely counter to any idea of free speech that he\nintended to bring to Twitter. And basically, seeing that\nElon was way less principled in his thinking there and is much more experimental. And many of the things that he is trying, they pan out very differently in a digital society than\nthey pan out in a car company. Because the effect is very different, because everything that\nyou do in a digital society is going to have real\nworld cultural effects. And so, basically, I\nfind it quite regrettable that this guy is able to\nbecome de facto, the pope. Twitter has more active members\nthan the Catholic church. - Mm-hmm.\n- And he doesn't get it. The power and responsibility that he has and the ability to create something and a society that is lasting and that is producing a\ndigital agora in a way that has never existed before, where we built a social network\non top of a social network, an actual society on\ntop of the algorithms. So, this is something that is hope still in the future and still in the cards,\n- Mm-hmm. - but it's something that\nexists in small parts. I find that the corner of Twitter that I'm in is extremely pleasant. And I take a few steps\n- Mm-hmm. - outside of it, it's not\nvery wholesome anymore. And the way in which people\ninteract with strangers suggest that it's not a\ncivilized society yet. - So, as the number of people who follow you on Twitter expands, you feel the burden of the uglier sides of humanity. - Yes. But there's also a similar\nthing in the normal world that if you become more influential, if you have more status, if you have more fame in the real world, you get lots of perks, but you also have way less freedom in the way in which you\ninteract with people, especially with strangers. Because a certain percentage of people, it's a small single digit\npercentage is nuts and dangerous. And the more of those are looking at you, the more of them might get ideas. - But what if the technology\nenables you to discover, the majority of people, to\ndiscover and connect efficiently and regularly with the majority of people who are actually really good? One of my sort of concerns\nwith a platform like Twitter is there's a lot of really\nsmart people out there, a lot of smart people\nthat disagree with me and with others between each other. And I love that, if the technology would\nbring those to the top, the beautiful disagreements, like intelligence squared type of debates. There's a bunch of... One of my favorite things\nto listen to is arguments. And arguments like high effort arguments with the respect and love underneath it, but then it gets a little too heated. But that kind of too heated, which I've seen you\nparticipate in and I love that, with Lee Cronin, with\nthose kinds of folks. And you go pretty hard. You get frustrated,\nbut it's all beautiful. - Obviously, I can do this,\nbecause we know each other. - Yes.\n- And Lee has the rare gift of being willing to be wrong in public. - Yeah.\n- So, basically has thoughts that are as wrong as the random thoughts of an average\n- Yeah. - highly intelligent person, but he blurts them out\n- Mm-hmm. - while not being sure if they're right. And he enjoys doing that. And once you understand\nthat this is his game, you don't get offended by him saying something that\nyou think is so wrong. - But he's constantly passively\ncommunicating a respect for the people he's talking with - Yeah.\n- and for just basic humanity and truth and all that kind of stuff. And there's a self-deprecating thing. There's a bunch of\nsocial skills you acquire that allow you to be a great\ndebater, a great argumenter, like be wrong in public and explore ideas together\nin public when you disagree. I would love for Twitter\nto elevate those folks, elevate those kinds of conversations. - It already does in some sense. But also, if it elevates them too much, then you get this phenomenon in clubhouse where you always get dragged on stage. And I found this very stressful,\nbecause it was too intense. - [Lex] Yeah. - I don't like to be dragged on stage all the time.\n- Yeah. - I think once a week is enough. - Yeah.\n- And also when I met Lee the first time, I found\nthat a lot of people seem to be shocked by the fact that he was being very\naggressive as their results, that he didn't seem to\nshow a lot of sensibility in the way in which he was\ncriticizing what they were doing and being dismissive\nof the work of others. And that was not, I think, in any way a shortcoming of him, because I noticed that he was\nmuch, much more dismissive with respect to his own work.\n- Mm-hmm. - It was his general stance. And I felt that this general stance is creating a lot of liability for him, because really, a lot of\npeople take offense at him being not like their Carnegie character who's always smooth and make\nsure that everybody likes him. So, I really respect that he\nis willing to take that risk and to be wrong in public\nand to offend people. And he doesn't do this in any bad way. It's just most people feel or\nnot all people recognize this. - Mm-hmm.\n- And so, I can be much more aggressive as him than I can be with many other people who don't play the same game, because he understands the way and the spirit in which I respond to him. - I think that's a fun and\nthat's a beautiful game. It's ultimately a productive one. Speaking of taking that risk, you tweeted, \"When you have the choice\nbetween being a creator, consumer, or redistributor,\nalways go for creation. Not only does it lead to\na more beautiful world, but also to a much more\nsatisfying life for yourself. And don't get stuck preparing\nyourself for the journey. The time is always now.\" So, let me ask for advice. What advice would you give on\nhow to become such a creator on Twitter and your own life? - I was very lucky to be alive at the time of the collapse of Eastern Germany and the transition into Western Germany. And me and my friends and\nmost of the people I knew were East Germans.\n- Mm-hmm. - And we were very poor,\nbecause we didn't have money. And all the capital\nwas in Western Germany. And they bought our\nfactories and shut them down, because they were mostly\nonly interested in the market rather than creating\nnew production capacity. And so, cities were poor and disrepair and we\ncould not afford things. And I could not afford\nto go into a restaurant and order a meal there. I would have to cook at home. But I also thought, why not just have a\nrestaurant with my friends? So, we would open up a cafe\nwith friends and a restaurant and we would cook for each\nother in these restaurants and also invite the general\npublic and they could donate. And eventually, this became so big that we could turn this\ninto some incorporated form and it became regular\nrestaurant at some point. Or we did the same thing\nwith the movie theater. We would not be able to afford to pay 12\nmarks to watch a movie, but why not just create\nour own movie theater, and then invite people to pay\nand we would rent the movies in a way\n(Lex chuckles) which a movie theater does.\n- Yeah. - But it would be a\ncommunity movie theater which everybody who wants\nto help can watch for free and builds this thing and\nrenovates the building. And so, we ended up creating lots and lots of infrastructure. And I think when you're young\nand you don't have money, move to a place where\nthis is still happening. Move to one of those\nplaces that are undeveloped and where you get a critical\nmass of other people who are starting to build\ninfrastructure to live in. And that's super satisfying, because you're not just\ncreating infrastructure, but we are creating a small\nsociety that is building culture and ways to interact with each other. And that's much, much more satisfying than going into some kind of chain and get your needs met by ordering food from\nthis chain, and so on. - So, not just consuming culture, but creating culture.\n- Yes. And you don't always have that choice. That's why I prefaced it\nwhen you do have the choice, and there are many roles\nthat need to be played, like we need people who take care of the distribution\nin society, and so on. But when you have the\nchoice to create something, always go for creation, it's\nso much more satisfying. And this is what life is about, I think. - Yeah. Speaking of which, you retweeted this meme of a life of a philosopher in a nutshell. It's birth and death and in between. And it's a chubby guy.\nAnd it says, why though? (paper crinkles) What do you think is the answer to that? - Well, the answer is that everything that\ncan exist might exist. And in many ways, you take\nan ecological perspective, the same way as when you look at human\nopinions and cultures. It's not that there is\nright and wrong opinions when you look at this from\nthis ecological perspective, but every opinion that fits\nbetween two human years might be between two human years. And so, when I see a strange\nopinion on social media, it's not that I feel that\nI have a need to get upset, it's often more that I, oh, there you are. And when your opinion\n(Lex chuckles) is incentivized, then\nit's going to be abundant. And when you take this\necological perspective also on yourself and you realize you're\njust one of these mushrooms that are popping up and doing this thing, - Mm-hmm.\n- and you can, depending on where you chose to grow and where you happen to grow, you can flourish or not\ndoing this or that strategy. And it's still all the\nsame life at some level. It's all the same experience of being a conscious being in the world. And you do have some choice about who you want to be more\nthan any other animal has. That to me is fascinating. And so, I think that\nrather than asking yourself what is the one way to be, think about what are the\npossibilities that I have? What would be the most interesting\nway to be that I can be? - Because everything is possible. So, you get to explore the- - Not everything is possible. Many things fail. Most things fail. But often, there are possibilities\nthat we are not seeing, especially if we choose who we are. - To the degree, we can choose. Joscha, you're one of my\nfavorite humans in this world. Consciousness is to merge with\nfor a brief moment of time. It's always an honor.\nIt always blows my mind. It will take me days, if\nnot weeks, to recover. (both laughing) And I already miss our chats. Thank you so much. Thank you so much for speaking\nwith me so many times. Thank you so much for all the ideas you put out into the world. And I'm a huge fan of following\nyou now in this interesting, weird time we're going through with AI. So, thank you again for talking today. - Thank you, Lex, for this conversation. I enjoyed it very much. - Thanks for listening to this conversation with Joscha Bach. To support this podcast, please check out our\nsponsors in the description. And now, let me leave you with some words from the psychologist, Carl Jung. \"One does not become enlightened by imagining figures of light, but by making the darkness conscious.\" The latter procedure, however, is disagreeable and\ntherefore not popular.\" Thank you for listening and\nI hope to see you next time."
}