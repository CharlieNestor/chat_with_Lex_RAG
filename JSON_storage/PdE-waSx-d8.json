{
  "video_id": "PdE-waSx-d8",
  "title": "Stephen Wolfram: ChatGPT and the Nature of Truth, Reality &amp; Computation | Lex Fridman Podcast #376",
  "date": "2023-05-09",
  "transcript": [
    {
      "timestamp": "0:00",
      "section": "Full Transcript",
      "text": "- You know I can tell ChatGPT, create a piece of code and then\njust run it on my computer. And I'm like, you know, that, that sort of personalizes\nfor me the what could, what could possibly go wrong, so to speak. - Was that exciting or\nscary, that possibility? - [Wolfram] It was a\nlittle bit scary actually, because it's kind of like,\nif you do that right, What is the sandboxing\nthat you should have? And that's sort of a,\nthat's a, a version of, of that question for the world. That is, as soon as you put\nthe AIs in charge of things, you know, how much, how many\nconstraints should there be on these systems before\nyou put the AIs in charge of all the weapons and all these, you know, all these\ndifferent kinds of systems. - Well here's the fun\npart about sandboxes, is the AI knows about them and\nhas the tools to crack them. The following is a conversation\nwith Steven Wolfram, his fourth time on this podcast. He's a computer scientist, mathematician, theoretical physicist, and the\nfounder of Wolfram Research, a company behind\nMathematica, Wolfram Alpha, Wolfram Language and the Wolfram physics and meta mathematics projects. He has been a pioneer in exploring the computational nature of reality. And so he's the perfect person\nto explore with together the new quickly evolving\nlandscape of large language models as human civilization\njourneys towards building super intelligent AGI. This is a Lex Fridman podcast. To support it, Please check out our\nsponsors in the description. And now, dear friends\nhere's Stephen Wolfram. You've announced the\nintegration of ChatGPT and Wolfram Alpha and Wolfram Language. So let's talk about that integration. What are the key differences from the high philosophical level, maybe the technical level\nbetween the capabilities of, broadly speaking, the\ntwo kinds of systems, large language models, and this computational\ngigantic computational system infrastructure that is Wolfram Alpha? - Yeah. So what does\nsomething like ChatGPT do? It's, it's mostly\nfocused on make language, like the language that humans have made and put on the web and so on. Yeah, so, you know, it's, it's primary sort of\nunderlying technical thing is you've given a prompt, it's trying to continue\nthat prompt in a way that's somehow typical of what it's seen based on a trillion words of text that humans have written on the web. And the way it's doing\nthat is with something which is probably quite\nsimilar to the way we humans do the first stages of that, using a neural net and so on, and just saying, given these,\ngiven this piece of text, let's ripple through the\nneural net one word and, and get one word at a time of output. And it's kind of a, a shallow computation on a large amount of kind of training data that is what we humans\nhave put on the web. That's a different thing from\nsort of the computational stack that I've spent\nthe last, I don't know, 40 years or so building, which has to do with what\ncan you compute many steps, potentially a very deep computation. It's not sort of taking the statistics of what we humans have produced and trying to continue things\nbased on that statistics. Instead, it's trying to take\nkind of the formal structure that we've created in our civilization, whether it's from mathematics,\nor whether it's from kind of systematic knowledge of all kinds, and use that to do\narbitrarily deep computations to figure out things\nthat, that aren't just, let's match what's already\nbeen kind of said on the web, but let's potentially be\nable to compute something new and different that's never\nbeen computed before. So as a, as a practical matter, you know, the, the what we're, you know, the, our goal is to have made as\nmuch as possible of the world computable in the sense\nthat if there's a question that in principle is answerable from some sort of expert\nknowledge that's been accumulated, we can compute the\nanswer to that question, and we can do it in a sort\nof reliable way that's, that's the best one can do,\ngiven what the expertise that our civilization has accumulated. It's a very, it's a,\nit's a much more sort of labor intensive on the\nside of kind of being, creating kind of the, the\ncomputational system to do that. Obviously the in, in the, the\nkind of the ChatGPT world, it's like take things which were produced for quite other purposes, namely the all the things\nwe've written out on the web and so on, and sort of forage\nfrom that things which were, are like what's been written on the web. So I think, you know, as a,\nas a practical point of view, I view sort of the ChatGPT\nthing as being wide and shallow and what\nwe're trying to do with sort of building out computation\nas being this sort of deep, also broad, but, but most importantly kind of deep type of thing. I think another way to\nthink about this is, if you go back in human\nhistory, you know, I don't know, a thousand years or something, and you say, what, what,\nwhat can the typical person, what's the typical person\ngoing to figure out? Well, the answer is there's\ncertain kinds of things that we humans can quickly figure out. That's sort of what, what our, you know, other neural architecture\nand the kinds of things we learn in our lives let us do. But then there's this whole\nlayer of kind of formalization that got developed in which is, you know, the kind of whole sort of\nstory of intellectual history and the whole kind of depth of learning that formalization turned\ninto things like logic, mathematics, science and so on. And that's the kind of\nthing that allows one to kind of build these towers of, of, of, of sort of towers of things you work out. It's not just, I can immediately\nfigure this out, it's no, I can use this kind of\nformalism to go step by step and work out something which was not immediately obvious to me. And that's kind of the story of what, what we're trying to do computationally, is to be able to build\nthose kind of tall towers of what implies, what\nimplies what and so on. And as opposed to kind of the yes, I can immediately figure it out, it's just like what I saw\nsomewhere else in something that I heard or remembered\nor something like this. - What can you say about\nthe kind of formal structure or the kind of formal\nfoundation you can build such a formal structure on\nabout the kinds of things you would start on in order to build this kind of deep\ncomputable knowledge trees. - So the question is sort of how do you, how do you think about\ncomputation and there's, there's a couple of points here. One is what computation\nintrinsically is like, and the other is what\naspects of computation we humans with our minds\nand with the kinds of things we've learned can sort of relate to in that computational universe. So if we start on the kind of, what can computation be like, it's something I've spent some\nbig chunk of my life studying is imagine that you are,\nyou know, we, we usually, we write programs where we kind of know what we want the program to do and we carefully write, you\nknow, many lines of code and we hope that the program does what we, what we intended it to do. But the thing I've been\ninterested in is if you just look at the kind of\nnatural science of programs, so you just say, I'm gonna make this program,\nit's a really tiny program. Maybe I even pick the pieces\nof the program at random, but it's really tiny. And by really tiny, I mean, you know, less than a line of code type thing. You say, what does this\nprogram do? And you run it. And big discovery that I\nmade in the early eighties is that even extremely simple\nprograms when you run them can do really complicated things. Really surprised me. It took me several years\nto kind of realize that that was a thing, so to speak, but that that realization\nthat even very simple programs can do incredibly complicated things that we very much don't\nexpect that discovery, I mean, I realized that that's very\nmuch, I think how nature works. That is nature has simple rules, but yet does all sorts\nof complicated things that we might not expect, you know, as a big thing of the last few\nyears has been understanding that that's how the whole\nuniverse and physics works. But that's a, a quite separate topic. But, so there's this\nwhole world of programs and what they do and very rich, sophisticated things that\nthese programs can do. But when we look at\nmany of these programs, we look at them and say,\nwell that's kind of, I don't really know what that's doing. It's not a very human kind of thing. So on the one hand we have\nsort of what's possible in the computational universe. On the other hand, we have the kinds of things\nthat we humans think about, the kinds of things that have developed in kind of our intellectual history. And that's, and the, the really, the challenge to sort of\nmaking things computational is to connect what's\ncomputationally possible out in the computational\nuniverse with the things that we humans sort of typically\nthink about with our minds. Now that's a complicated\nkind of moving target because the things that we\nthink about change over time, we've learnt more stuff,\nwe've invented mathematics, we've invented various kinds of ideas and structures and so on. So it's, it's gradually expanding. We're kind of gradually\ncolonizing more and more of this kind of intellectual\nspace of possibilities. But the, the real thing, the real challenge is how do you take, what is computationally possible? How do you take, how do you encapsulate the kinds of things that we think about in a\nway that kind of plugs into what's computationally possible. And and actually the, the,\nthe big sort of idea there is this idea of kind of\nsymbolic programming, symbolic representations of things. And so the, the question\nis when you look at sort of everything in the world\nand you kind of, you know, you take some visual scene or something you're looking at and then you say, well, how do I turn that into something that I can kind of stuff into my mind? You know, there are lots of\npixels in my visual scene, but the things that I remembered\nfrom that visual scene are, you know, there's a chair in this place, it's a kind of a symbolic representation of the visual scene. There are two chairs on\na table or something, rather than there are\nall these pixels arranged in all these detailed ways. And so the question then is how\ndo you take sort of all the, all the things in the world and make some kind of representation that corresponds to the types of ways that we think about things. And, and human language is, is sort of one form of\nrepresentation that we have. We talk about chairs, that's a word in human language and so on. How do we, how do we take, but human language is not\nin and of itself something from that plugs in very\nwell to sort of computation. It's not something from which you can immediately compute\nconsequences and so on. And so you have to kind of\nfind a way to take sort of the, the, the stuff we understand\nfrom human language and make it more precise. And that's really the story\nof, of symbolic programming. And you know what, what that turns into is something which I didn't know at the time it was going to work as well as it has, but back in the 1979 or so, I was trying to build my\nfirst big computer system and trying to figure out, you know, how should I represent\ncomputations at a high level. And I kind of invented\nthis idea of using kind of symbolic expressions, you know, structured as it's kind of like a, a function and a bunch of arguments, but that function doesn't\nnecessarily evaluate to anything. It's just a, a thing that sits there representing a structure. And so building up that structure and it's turned out that\nstructure has been extremely, it's a, it's a good match\nfor the way that we humans, it seems to be a good match for the way that we humans kind of\nconceptualize higher level things. And it's been for the last, I don't know, 45 years or something, it's\nserved me remarkably well. - So building up that structure using this kind of\nsymbolic representation. But what can you say\nabout abstractions here? Because you could just start\nwith your physics project. You could start at a hypergraph at a very, very low level and build\nup everything from there, but you don't, right, you take shortcuts. - [Wolfram] Right? - You, you take the highest\nlevel of abstraction, convert that, the kind of abstraction that's\nconvertible to something computable using symbolic\nrepresentation and then that, that's your new foundation for that little piece of knowledge. - [Wolfram] Yes. - Somehow all that is integrated. - Right? So the, the sort of\na very important phenomenon that is kind of a thing that\nI've sort of realized is just, it's one of these things\nthat sort of in the, in the future of kind\nof everything is going to become more and more important as this phenomenon of\ncomputational reducibility. And the, the question is, if you know the rules for\nsomething, you have a program, you're gonna run it. You might say, I know the rules, great, I know everything about\nwhat's gonna happen. Well in principle you do\nbecause you can just run those rules out and just see what they do. You might run them a million\nsteps, you see what happens, et cetera. The question is, can you like immediately\njump ahead and say, I know what's gonna happen\nafter a million steps. And the answer is 13 or something. - [Fridman] Yes. - And the, the one of\nthe very critical things to realize is if you could\nreduce that computation, there isn't a sense, no point in doing the computation. - [Fridman] Yeah. - The place where you really\nget value outta doing the computation is when you\nhad to do the computation to find out the answer. But this phenomenon that you\nhave to do the computation to find out the answer, this phenomenon of computational\nreducibility seems to be tremendously important for thinking about lots of kinds of things. So one of the things\nthat happens is, okay, you've got a model of the\nuniverse at the low level in terms of atoms of space and hypergraphs and rewriting hypergraphs and so on. And it's happening, you know, 10 to the 100 times\nevery second, let's say. Well, you say great, then\nwe've, we've nailed it. We've, we've, we know\nhow the universe works. Well the problem is the\nuniverse can figure out what it's gonna do. It does those 10 to the\n100, you know, steps. But for us to work out what it's gonna do, we have no way to reduce that computation. The only way to do the computation, to see the result of the\ncomputation is to do it. And if we're operating\nwithin the universe, we're kind of, there's no, there's no opportunity to\ndo that because the universe is doing it as fast as\nthe universe can do it. And that's, you know,\nthat's what's happening. So what we're trying to do, and a lot of the story of science and a lot of other kinds of things is finding pockets of reducibility. That is, you could have a situation\nwhere everything in the world is full of computational reducibility, we never know what's gonna happen next. The only way we can figure out\nwhat's gonna happen next is just let the system run\nand see what happens. So in a sense, the story of, of most kinds of science, inventions, a lot of kinds of things is\nthe story of finding these places where we can locally jump ahead. And one of the features of\ncomputational reducibility is there are always pockets of reducibility. There are always places, there are always an\ninfinite number of places where you can jump ahead. There's no way where you\ncan jump completely ahead. But there are little, little patches, little places where you\ncan jump ahead a bit. And I think, you know, we can talk about physics\nproject and so on, but I think the thing we\nrealize is we kind of exist in a slice of all the\npossible computational id reducibility in the universe. We exist in a slice where\nthere's a reasonable amount of predictability. And in a sense, as we try and construct these\nkind of higher levels of, of abstraction symbolic\nrepresentations and so on, what we're doing is\nwe're finding these lumps of reducibility that we can\nkind of attach ourselves to and about, which we can kind of have fairly simple narrative things to say. Because in principle, you know, I say what's gonna happen\nin the next few seconds? You know, oh, there are these molecules\nmoving around in the air in this room and oh gosh, it's an incredibly complicated\nstory and that's a whole computational irreducible thing, most of which I don't care about. And most of it is, well, you know, the air's still gonna be here\nand nothing much is going to be different about it. And that's a kind of reducible fact about what is ultimately\nat an underlying level of computational irreducible process. - And life would not be possible\nif we didn't have a large number of such reducible pockets. - [Wolfram] Yes. - Pockets amenable to reduction\ninto something symbolic. - Yes, I think so. Okay. I mean, life in, in the\nway that we experience it, that, I mean, you know,\none might, you know, depending on what we mean by\nlife, so to speak, the, the, the experience that we have\nof sort of consistent things happening in the world, the\nidea of space, for example, where there's, you know, we\ncan just say you are here, you move there, it's\nkind of the same thing. It's still you in that different\nplace even though you're made of different atoms\nof space and so on. This is this idea that it's, that there's sort of this\nlevel of predictability of what's going on. That's us finding a slice\nof reducibility in what is underneath this computation\nirreducible kind of system. And I think that's, that's sort of the, the thing which is actually\nmy favorite discovery of the last few years, is the realization that it\nis sort of the interaction between this sort of\nunderlying computational irrereducibility and our\nnature as kind of observers who sort of have to key into\ncomputational reducibility. That fact leads to the main\nlaws of physics that we discovered in through 20th century. So this is, we talk about\nthis in, in in more detail, but this is, to me, it's kind\nof our nature as observers. The fact that we are\ncomputationally bounded observers. We don't get to follow\nall those little pieces of computational irrereducibility to stuff. What is about out there in the\nworld into our minds requires that we are looking at\nthings that are reducible, we are compressing kind of, we are, we're extracting just some essence, some kind of symbolic essence of what's the detail of\nwhat's going on in the world. That together with one other condition that first seems sort\nof trivial but isn't, which is that we believe\nwe are persistent in time. That is. - Yes. - [Wolfram] You know. - So causality. - Here's the thing. At every\nmoment according to our theory, we are made of different atoms\nof space at every moment. Sort of the microscopic detail\nof what what the universe is made of is being rewritten. And that's, and in fact, the very fact that this coherence\nbetween different parts of space is a consequence of the\nfact that there are all these little processes going on\nthat kind of knit together the structure of space. It's kind of like if you wanted\nto have a fluid with a bunch of molecules in it, if those\nmolecules weren't interacting, you wouldn't have this\nfluid that would pour and do all these kinds of things. It would just be sort of\na free floating collection of molecules. So similar it is with space\nthat the fact that space is kind of knitted together as a consequence of all this activity in space. And the fact that kind of what, what we consist of sort of\nthis, this series of, of of, you know, we're, we're\ncontinually being rewritten. And the question is, why is it the case that\nwe think of ourselves as being the same us through time? That's kind of a, a key assumption. I think it's a key aspect of\nwhat we see as sort of our consciousness so to speak, is that we have this kind of consistent thread of experience. - Well isn't that just\nanother limitation of our mind that we wanna reduce- - [Wolfram] Yeah. - Reality into some that kind of temporal - [Wolfram] Yes. - Consistency is just a nice\nnarrative to tell ourselves. - [Wolfram] Right. Well, the fact is, I think it's critical to the\nway we humans typically operate is that we have a single\nthread of experience. You know, if you, if\nyou imagine sort of a, a mind where you have, you know, maybe that's what's happening\nin various kinds of minds that aren't working the same\nway other minds work is that you're splitting into multiple threads of experience. It's also, it's also\nsomething where, you know, when you look at, I don't know, quantum mechanics for example, in the insides of quantum mechanics, it's splitting into many\nthreads of experience. But in order for us humans\nto interact with it, you kind of have to have to\nknit all those different threads together so that we say, oh yeah, a definite thing happened and now the next definite thing happens and so on. And I think, you know, sort of inside it, it's sort of interesting to\ntry and imagine what's it like to have kind of these\nfundamentally multiple threads of experience going on. I mean, right now different human minds have different threads of experience. We just have a bunch of minds that are interacting with each other, but we don't have a a you know, within each mind there's a single thread. And that's a, that is indeed a simplification. I think it's a, it's a thing, you know, the general computational system does not have that simplification. And it's one of the things, you know, I I people often seem\nto think that, you know, consciousness is the, the highest level of kind\nof things that can happen in the universe, so to speak. But I think that's not true. I think it's actually a, a a specialization in\nwhich among other things, you have this idea of a\nsingle thread of experience, which is not a general feature\nof anything that could kind of computationally happen in the universe. - So it's a feature of a\ncomputationally limited system that's only able to\nobserve reducible pockets. - [Wolfram] Yeah. - So I mean this word observer, it, it means something in quantum mechanics, it means something in a lot of places. It means something to us humans. - [Wolfram] Right. - As conscious beings. So what, what's the importance of the\nobserver? What is the observer? What's the importance of the observer in the computational universe? - So this question of what is an observer? What's the general idea of an observer? It's actually one of my next\nprojects which got somewhat derailed by the, the current\nsort of AI mania. But- - Is there a connection\nthere or is that, do you, do you think the observer\nprimarily a physics phenomena? - Is it related to the whole AI thing? - Yes. - [Wolfram] Yes, it is related. So one question is, what\nis a general observer? So, you know, we know we have an idea what is a general computational system. We think about touring machines, we think about other\nmodels of computation. There's a question, what is a\ngeneral model of an observer? And there there's kind\nof observers like us, which is kind of the\nobservers we're interested in. You know, we could imagine an\nalien observer that deals with computational I irrereducibility\nand it has a mind that's utterly different from ours and, and completely incoherent\nwith what, what we are like. But the fact is that that, you know, if we are talking about observers like us, that one of the key things is\nthis idea of kind of taking all the detail of the world and being able to stuff it into a mind, being able to take all\nthe detail and kind of, you know, extract out\nof it a smaller set of, of kind of degrees of freedom. A smaller number of, of elements that will\nsort of fit in our minds. And I think this, this question, so I've been interested\nin trying to characterize what is the general observer. And the general observer is, I think in part there are many, let let me give an example of\na, you know, you have a gas, it's got a bunch of molecules\nbouncing around and the thing you are measuring about\nthe gas is it's pressure. And the only thing you as an observer care about is pressure. And that means you have a\npiston on the side of this box and the piston is being pushed by the gas. And there are many, many different ways that\nmolecules can hit that piston. But all that matters is\nthe kind of aggregate of all those molecular impacts. Because that's what determines pressure. So there's a huge number\nof different configurations of the gas, which are all equivalent. So I think one key aspect of\nobservers is this equivalent thing of many different\nconfigurations of a system saying, all I care about is\nthis aggregate feature. All I care about is\nthis, this overall thing. And that's, that's sort\nof one, one aspect. And we see that in lots\nof different, again, it's the same story over\nand over again that there's, there's a lot of detail in the world, but what we are extracting from it is something a sort of a thin, a thin summary of that, of that detail. - Is that thin summary nevertheless true. Is can it be a crappy\napproximation that an average is, is correct. I mean, if we look at the observer, that's the human mind, it seems\nlike there's a lot of very, as represented by natural\nlanguage for example, there's a lot of really\ncrappy approximation. - [Wolfram] Sure. - And that could be maybe a feature of it. - [Wolfram] Well, yes. - But there's ambiguity. - [Wolfram] Right, right. You don't know, you know,\nit could be the case you, you're just measuring\nthe aggregate impacts of these molecules,\nbut there is some tiny, tiny probability that molecules\nwill arrange themselves in some really funky way. And that just measuring that average isn't going to be the main point. - [Fridman] Yeah. - By the way, an awful lot of science is very\nconfused about this because, you know, you look at, you look at papers and\npeople are really keen, they draw this curve and\nthey have these, you know, these bars on the curve and things. And it's just this curve\nand it's this one thing, and it's supposed to represent\nsome system that has all kinds of details in it. And this is a way that lots\nof science has gotten wrong because people say, I remember years ago I was\nstudying snowflake growth that, you know, you have the\nsnowflake and it's growing, it has all these arms, it's\ndoing complicated things. But there was a literature\non this stuff and it talked about, you know, what's the\nrate of snowflake growth? And you know, it, it got pretty good answers for the rate of the\ngrowth of the snowflake. And they looked at it more carefully. And then they had these\nnice curves of, you know, snowflake growth rates and so on. I looked at it more carefully\nand I realized according to their models, the snowflake\nwill be spherical. And so they got the growth rate right. But the detail was just utterly wrong. And you know, the not\nonly the detail, the, the whole thing was, was\nnot capturing, you know, it was capturing this aspect of the system that was in a sense, missing the main point\nof what was going on. - What is the geometric\nshape of a snowflake? - Snowflakes start in, in the phase of water that's relevant. - [Fridman] Yeah. - To the formation of snowflakes. It's a phase of ice, which starts with a\nhexagonal arrangement of, of water molecules. And so it starts off growing\nas a hexagonal plate. And then what happens is- - Is the plate, oh, oh versus sphere. - Well, no, no, but it's,\nit's much more than that. I mean, snowflakes are fluffy, you know, typical snowflakes have\nlittle, little dendritic arms. - [Fridman] Okay, yeah, yeah, yeah. - And, and what actually happens is, it's kind of kind of cool\nbecause you can make these very simple discrete models with\ncellular automata and things that, that figure this out. You start off with this,\nyou know, hexagonal thing, and then the places it, it starts to grow little arms, and every time a little piece of ice, it adds itself to the snowflake. The fact that that ice condensed\nfrom the water vapor heats the snowflake up locally. And so it makes it less likely for, for another piece of ice\nto accumulate right nearby. So this leads to a kind\nof growth inhibition. So you grow an arm and it, it is a, a separated arm because right\naround the arm it got a little bit hot and it didn't add more ice there. So what happens is it\ngrows, you have a hexagon, it grows out arms, the arms grow arms, and then the arms grow arms grow arms. And eventually, actually\nit's kind of cool because it, it actually fills in another\nhexagon, a bigger hexagon. And when I first looked at this, you know, had a very simple model for\nthis, I realized, you know, when it fills in that hexagon, it actually leaves some holes behind. So I thought, well, you know,\nthat is that really right? So I look at these pictures\nof snowflakes and sure enough they have these little holes\nin them that are kind of scars of the way that these arms grow out. - So you can't fill in backfill\nholes. So you keep going. - They don't backfill. Yeah, they don't backfill. - And, and presumably there's\na limitation on how big, like you can't arbitrarily grow. - I'm not sure. I mean, the\nthing falls through the, the, I mean, I think it does, you know, it hits the ground at some point. I think you can grow. I I think you can grow in the lab. I think you can grow pretty big ones. I think you can grow\nmany, many iterations of, this kind of goes from\nhexagon, it grows out arms, it turns back, it fills\nback into a hexagon. It grows more arms again in. - In 3D. - No. It's flat usually. - Why is it flat? Why doesn't it spin out?\nOkay, okay, wait a minute. You said it's fluffy and\nfluffy is a three-dimensional property, no or. - No, it's, it's fluffy snow is. Okay. So you know what makes we're really, we're really in a- - [Fridman] Let's go there. Multiple snowflakes become fluffy. A single snowflake is not fluffy? - No, no. A single snowflake is fluffy. And what happens is, you know, if, if you have snow that\nis just pure hexagons, they, they can, you know, they,\nthey fit together pretty well. It's not, it doesn't, it doesn't make, it doesn't have a lot of air in it. And they can also slide against\neach other pretty easily. And so the snow can be\npretty, you know, can, I think avalanches happen sometimes when, when the things tend\nto be these, you know, hexagonal plates and it kind of slides. But then when the thing has all these arms that have grown out, it's not, they don't\nfit together very well. And that's why the snow\nhas lots of air in it. And if you look at one\nof these snowflakes, and if you catch one, you'll\nsee it has these little arms. And people actually,\npeople often say, you know, no two snowflakes are alike. That's mostly because\nas a snowflake grows, they do grow pretty consistently with these different arms and so on. But you capture them at\ndifferent times as they, you know, they fell through, through the air in a different way. You'll catch this one, this stage. And as it goes through different stages, they look really different. And so that's why, you know, it kinda looks like no two\nsnowflakes are alike because you caught them at different,\nat different times. - So the rules under which\nthey grow are the same. - [Wolfram] Yes. - It's just the timing is- - [Wolfram] Yes. - Okay. So the point is, science is not able to describe the full complexity of snowflake growth. - Well science, if you, if you do what people might often do, which is say, okay,\nlet's make it scientific, let's turn into one number, and that one number is kind\nof the growth rate of the arms or some such other thing, that fails to capture\nsort of the detail of what's going on inside the system. And that's, in a sense, a big challenge for science\nis how do you extract from the natural world, for example, those aspects of it\nthat you are interested in talking about. Now you might just say, I don't really care about the\nfluffiness of the snowflakes. All I care about is the\ngrowth rate of the arms. In which case, you know, you have, you can have a good model\nwithout knowing anything about the fluffiness. But the fact is, as a practical,\nyou know, when if you, if you say what's the, what is the most obvious\nfeature of a snowflake? Oh, that it has this complicated shape, well then you've got a different\nstory about what you model. I mean, this, this is\none of the features of, of sort of modeling and\nscience that, you know, what is a model? A model is some way of reducing\nthe actuality of the world to something where you can\nreadily sort of give a narrative for what's happening, where you can basically make\nsome kind of abstraction of what's happening and answer questions that you care about answering. If you wanted to answer all possible questions about the system, you'd have to have the whole\nsystem because you might care about this particular molecule. Where did it go? And you know, your model, which is some big abstraction of that has nothing to say about that. So, you know, one of the things that's, that's often confusing in sciences, people will have, I've got\na model, somebody says, somebody else will say, I don't believe in your model\nbecause it doesn't capture the feature of the\nsystem that I care about. You know, there's always\nthis controversy about, you know, is the, is it a correct model? Well, no model is a, except for the actual system itself is a correct model in the sense\nthat it captures everything. Question is, does it capture\nwhat you care about capturing? Sometimes that's ultimately\ndefined by what you're going to build technology out of things like this. The one counterexample to\nthis is if you think you're modeling the whole\nuniverse all the way down, then there is a notion of a correct model. But even that is more complicated\nbecause it depends on kind of how observers sample things and so on. That's a, that's a separate story, but at least at the first\nlevel to say, you know, this thing about, oh,\nit's an approximation. You're capturing one aspect, you're not capturing other aspects. When you really think\nyou have a complete model for the whole universe, you better be capturing\nultimately everything, even though to actually run\nthat model is impossible because of computational reducibility. The only, the only thing that\nsuccessfully runs that model is the actual running of the universe. - Is the universe itself. But okay, so what you care about is\nan interesting concept. So that's a, that's a human concept. So that's what you're\ndoing with Wolfram Alpha and Wolfram Language, is you're trying to come up\nwith symbolic representations. - [Wolfram] Yes. - As simple as possible. So a model that's as simple as\npossible that fully captures stuff we care about. - [Wolfram] Yes. So I mean, for example, you\nknow, we could we'll have a, a thing about, you\nknow, data about movies, let's say we could be describing every individual pixel\nin every movie and so on. But that's not the level\nthat people care about. And it's, yes, this is a, I mean, and, and that level that people\ncare about is somewhat related to what's described in natural language. But what what we're trying to\ndo is to find a way to sort of represent precisely so\nyou can compute things. See one thing when you say\nyou give a piece of a natural language question is you\nfeed it to a computer. You say, does the computer understand\nthis natural language? Well, you know, the computer processes it\nin some way it does this, maybe it can make a continuation\nof the natural language. You know, maybe it can go on from the prompt and say what it's gonna say. You say, does it really understand it? Hard to know. But for in this kind\nof computational world, there is a very definite\ndefinition of does it understand, which is could it be turned\ninto this symbolic computational thing from which you can compute\nall kinds of consequences? And that's the, that's the sense in which\none has sort of a target for the understanding of natural language. And that's kind of our goal\nis to have as much as possible about the world that can be computed in a, in a reasonable way, so to speak, be able to be sort of captured by this kind of computational language. That's, that's kind of the goal. And, and I think for us humans, the, the main thing that's important\nis as we formalize what we're talking about, it gives us a way of kind of\nbuilding a structure where we can sort of build this tower\nof consequences of things. So if we're just saying, well, let's talk about it a natural language, it doesn't really give us some\nhard foundation that lets us, you know, build step by\nstep to work something out. I mean, it's kind of like\nwhat happens in, in math, if we were just sort of\nvaguely talking about math but didn't have the kind of\nfull structure of math and all that kind of thing, we wouldn't be able to build this kind of big tower of consequences. And so, you know, in, in a sense what we're\ntrying to do with the whole computational language effort\nis to make a formalism for describing the world that makes\nit possible to kind of build this, this tower of consequences. - Well can you talk about this dance between natural language\nand Wolfram Language? So there's this gigantic\nthing we call the internet where people post memes and diary type thoughts and very important sounding\narticles and all of that. That makes up the\ntraining data set for GPT, and then there's Wolfram Language. How can you map from the\nnatural language of the internet to the Wolfram language? Is there an manual? Is there\nan automated way of doing that? As we look into the future? - Well, so Wolf and Alpha, what it does, it's kind of front end is\nturning natural language into computational language, right? - What you mean by that\nis there's a prompt, you ask a question, what is\nthe capital of some country. - And it, and it turns into, you know, what's the distance between, you know, Chicago and London or something. And that will turn into, you know, geo distance of entity city, you know, et cetera, et cetera, et cetera. Each one of those things is very, is very well defined. We know, you know, given that it's the entity\ncity, Chicago, et cetera, et cetera, et cetera, you\nknow, Illinois, United States, you know, we know the geolocation of that. We know it's population, we know all kinds of things\nabout it, which we have, you know, curated that data to be able to, to know that with some degree\nof certainty, so to speak. And then, then we can\ncompute things from this. And that's, that's kind of the yeah. That, that's, that's that's the idea. - But then something like\nGPT large language models, do they allow you to make that conversion much more powerful? - Okay, so it's an interesting thing which we still don't know everything about. Okay. The, I mean this question of\ngoing from natural language to computational language, yes. In Wolfram Alpha, we've now, you know, Wolfram Alpha has been\nout and about for what, 13 and a half years now. And, you know, we've achieved,\nI don't know what it is, 98%, 99% success on queries\nthat get put into it. Now, obviously there's\na sort of feedback loop because the things that work are things people go on putting into it. So yeah, that that, but you know, we've, we've got to a very high\nsuccess rate of the, the little fragments of natural\nlanguage that put people put in, you know, questions,\nmath calculations, chemistry calculations, whatever it is. You know, we can, we can,\nwe, we do very well at that, turning those things into\ncomputational language. Now I, from the very\nbeginning of Wolfram Alpha, I thought about, for example, writing code with natural language. In fact, I had, I, I was just\nlooking at this recently. I had a post that I wrote in 2010, 2011 called something like\nProgramming with Natural Language is actually Going to Work. Okay. And so, you know, we had done a bunch of experiments\nusing methods that were yeah, a little bit. Some of them are little\nbit machine learning like, but certainly not the same, you know, the same kind of idea of\nvast training data and so on. That is the story of\nlarge language models. Actually I know that that\npost piece of utter trivia, but that, that post Steve Jobs forwarded\nthat post around to all kinds of people at Apple. And he, you know, that was because he never really liked programming languages. So he was very happy to see the\nidea that that that that you could get rid of this kind of\nlayer of kind of engineering like structure he\nwould've liked, you know, I think what's happening now, because it really is the\ncase that you can, you know, this idea that you have to\nkind of learn how the computer works to use a programming\nlanguage is something that is I think a, a a thing that, you know, just like you had to learn\nthe details of the op codes to know how similar\nlanguage worked and so on. It's kind of a thing that's, that's that's a limited time horizon. But, but kind of the, the, you know, so this idea of how elaborate can you make kind of the prompt, how elaborate can you\nmake the natural language and abstract from it\ncomputational language. It's a very interesting question. And you know what, ChatGPT, you know, GBT four and so on can do is pretty good. It isn't, it's very interesting process. I mean I'm still trying to\nunderstand this workflow. We've been working out a lot\nof tooling around this workflow - The natural language to\ncomputational language. - [Wolfram] Right. - And the process. Especially if it's\nconversation like dialogue, it's like multiple queries kind of thing. - Yeah. Right. There's so many things that\nare really interesting that, that, that work and so on. So first thing is, can you just walk up to the computer and expect to sort of\nspecify a computation? What one realizes is humans\nhave to have some idea of kind of this way of thinking\nabout things computationally. Without that you're kind of\nout of luck because you just have no idea what you're going\nto walk up to a computer. I remember when I, I should\ntell a silly story about myself, the very first computer I saw, which is when I was 10 years\nold and it was a big mainframe computer and so on, and I didn't really understand\nwhat computers did and it's like somebody's showing me\nthis computer and it's like, you know, can the computer work out\nthe weight of a dinosaur? It's like, that isn't a\nsensible thing to ask. That's kind of, you know,\nyou have to give it, that's not what computers do. I mean, and Wolfram Alpha for example, you could say what's the\ntypical weight of a stegosaurus? And we'll give you some answer, but that's a very different\nkind of thing from what one thinks of computers as doing. And so the, the kind of the\nthe question of, you know, first thing is people have\nto have an idea of what, what computation is about. You know, I think it's a very, you know, for education that is the\nkey thing. It's kind of this, this, this notion, not computer science, not so that the details are programming, but just this idea of how\ndo you think about the world computationally computation, thinking about the world\ncomputationally is kind of this formal way of thinking about the world. We've had other ones, like logic\nwas a formal way, you know, as a way of sort of abstracting and formalizing some aspects of the world. Mathematics is another one. Computation is this very broad\nway of sort of formalizing the way we think about the world. And the thing that's, that's cool about computation\nis if we can successfully formalize things in terms of computation, computers can help us figure\nout what the consequences are. It's not like you formalized it with math. Well that's nice, but now you\nhave to, if you're, you know, not using a computer to do the math, you have to go work out a\nbunch of stuff yourself. So I think, but the, this idea,\nlet's see, I mean the, the, you know, we're trying\nto take kind of the, we're talking about\nsort of natural language and its relationship to\ncomputational language. The, the thing, the sort of the typical workflow\nI think is first human has to have some kind of idea of\nwhat they're trying to do. That if it, if it's something that they\nwant to sort of build a tower of, of capabilities on something\nthat they want to sort of formalize and make computational, so then human can type\nsomething into, you know, some LLM system and sort of say vaguely what they want in sort\nof computational terms, then it does pretty well at synthesizing Wolfram Language code, and it'll probably do better in the future because we've got a huge\nnumber of examples of, of natural language input\ntogether with the Wolfram Language translation of that. So it's kind of a, a you know, that that's a thing where you\ncan kind of extrapolating from all those examples makes it\neasier to do that, that task. - Is the prompter task\ncould also kind of debugging the Wolfram Language code? Or is your hope to not do that debugging? - Oh, no. No, no. I mean, so, so there are many steps here. Yeah. Okay, so first, the first thing is you\ntype natural language, it generates Wolfram Language. - Do you have examples by the way? Do you have, do you have an\nexample that is, is it the, the dinosaur example, do you have an example that jumps to mind that we should be thinking about? Some dumb example. - It's like, take my heart\nrate data and you know, figure out whether I, you know, make a moving average every\nseven days or something and work out what the, and and\nmake a a plot of the result. Okay. So that's a thing\nwhich is, you know, about two-thirds of a line\nof Wolfram Language code. I mean it's, you know, list plot of moving average\nof some data bin or something of the, of the data and\nthen you'll get the result. And you know, the vague thing that I was just saying in natural language could, would almost certainly correctly\nturn into that very simple piece of Wolfram Language code. - You start mumbling about heart rate. - [Wolfram] Yeah. - Kinda, you know, you arrive at the moving\naverage kind of idea. - Right? You say average over seven days, maybe it'll figure out that\nthat's a moving, you know, that that can be encapsulated\nas this moving average idea. I'm not sure. But then the typical workflow, but I'm seeing is you generate this piece of Wolfram Language code,\nit's pretty small usually. It's, and if it isn't small, it probably isn't right. But you know, if it's, it's\npretty small and, you know, Wolfram Language is, one of the ideas of Wolfram Language is, it's a language that humans can read. It's not a language which, you know, programming languages tend\nto be this one way story of humans write them and\ncomputers execute from them. Wolfram Language is\nintended to be something which is sort of like math\nnotation something where, you know, humans write it and humans are supposed\nto read it as well. And so kind of the workflow\nthat's emerging is kind of this, this human mumbles some things, you know, large language model produces a fragment of Wolfram Language code. Then you look at that, you say, yeah, that looks well, typically\nyou just run it first, you see does it produce the right thing? You look at what it produces. You might say, that's obviously crazy. You look at the code, you\nsee I see why it's crazy. You fix it. If you really care about the\nresults and you really wanna make sure it's right, you better look at that code\nand understand it because that's the way you have the\nsort of checkpoint of did it really do what I expected it to do? Now you go beyond that. I mean it's, it's, it's, you know, what we find is, for example, let's say the code does the wrong thing, then you can often say to\nthe large language model, can you adjust this to do this? And it's pretty good at doing that. - Interesting. So you're using the output\nof the code to give you hints about the, the, the function of the code. So you're debugging based on\nthe output of the code itself. - And by the way, right, The plugin that we have\nor the, the, you know, for ChatGPT, it does\nthat routinely, you know, it will send the thing\nin, it will get a result. It will discover, the LLM will discover\nitself that the result is not plausible and it will\ngo back and say, oh, I'm sorry, it's very polite and it it, you know, it, it goes back and says, I'll rewrite that piece of\ncode and then it will try it again and get the result. The other thing that's\npretty interesting is when you're just running, so one of the new concepts that we have, we invented this whole idea of notebooks back 36 years ago now. And so now there's the\nquestion of sort of how do you combine this idea of notebooks\nwhere you have, you know, text and code and output, how do you combine that\nwith the notion of, of chat and so on. And there's some really\ninteresting things there. Like for example, a very typical\nthing now is we have these, these notebooks where as soon as the, if, if the thing produces\nerrors, if the, you know, run this code and it produces\nmessages and so on, the, the, the LLM automatically not\nonly looks at those messages, it can also see all kinds of\ninternal information about stack traces and things like this. And it can then, it does a remarkably good\njob of guessing what's wrong and telling you. So in other words, it's, it's looking at things,\nit's sort of interesting, it's kind of a, a typical sort of AI ish thing\nthat it's able to have more sensory data than we humans\nare able to have cause able to look at a bunch of stuff that\nwe humans would kind of glaze over looking at. And it's able to then come up with, oh this is the explanation\nof what's happening. - And, and what is the\ndata the stack trace, the, the code you've written previously, the natural language you've written. - Yeah. It's also what's happening is\none of the things that's is is for example, when there's these messages, there's documentation\nabout these messages, there's examples of where the messages have occurred otherwise. - [Fridman] Nice. - All these kinds of things. The other thing that's really\namusing with this is when it makes a mistake, one of the things that's in our\nprompt when the code doesn't work is read the documentation\nand we have a, you know, another piece of the plugin\nthat lets it read documentation. And that again is very, very\nuseful because it, it will, you know, it will figure\nout, sometimes it'll get, it'll make up the name of some\noption for some function that doesn't really exist. Read the documentation, it'll have, you know, some wrong structure\nfor the function and so on. It's, that's a powerful thing. I mean the thing that, you know, I've realized is we built this language over the course of all\nthese years to be nice and coherent and consistent and so on. So it's easy for humans to understand. Turns out there was a side\neffect that I didn't anticipate, which is it makes it easier\nfor AIs to understand. - It's almost like another\nnatural language. But-. - [Wolfram] Yeah. - So, so Wolfram language is\na kind of foreign language. - [Wolfram] Yes, yes. - You have a lineup. English, French, Japanese,\nWolfram language and then I don't know Spanish, and then the system is not\ngonna notice. Hopefully. - Well, yes, I mean maybe, you know, that's an interesting question because it really depends on\nwhat I see as being a, a an important piece of\nfundamental science that basically just jumped out at us with ChatGPT. Because I think, you know, the, the real question is\nwhy does ChatGPT work? How is it possible to\nencapsulate, you know, to successfully reproduce\nall these kinds of things in natural language, you\nknow, with a, you know, a comparatively small, he says, you know, couple hundred billion, you know, weights of neural nets and so on. And I think that, you know, that that relates to kind of a, a fundamental fact about language, which, you know, the, the\nmain, the main thing is that I think there's a\nstructure to language that we haven't kind of\nreally explored very well. It's kind of this semantic\ngrammar I I'm talking about, about, about language. I mean, we, we kind of know that when we, when we set up human language, we know that it has certain regularities. We know that it has a certain\ngrammatical structure, you know, noun followed by verb, followed by noun, adjectives, et cetera, et cetera, et cetera. That's, its kind of grammatical structure. But I think the thing that\nChatGPT is showing us is that there's an additional kind\nof regularity to language, which has to do with the\nmeaning of the language beyond just this pure, you know, part of speech combination type of thing. And I, I think the, the, the kind of the, the one example of that that\nwe've had in the past is logic. And you know, I, I think my, my sort of kind of picture\nof how was logic invented? How was logic discovered? It really was a thing that was discovered in its original conception. It was discovered presumably by Aristotle who kind of listened to a\nbunch of people orators, you know, giving speeches. And this one made sense,\nthat one doesn't make sense, this one, and you know, you see\nthese patterns of, you know, if the, you know, I don't\nknow what, you know, if the, if the Persians do this,\nthen the, this does that, et cetera, et cetera, et cetera. And what, what Aristotle realized is there's a structure to those sentences, there's a structure to that\nrhetoric that doesn't matter whether it's the Persians\nand the Greeks or whether it's the cats and the dogs. It's just, you know, p and q\nyou can abstract from this, the, the details of these\nparticular sentences. You can lift out this\nkind of formal structure. And that's what logic is. - That's a heck of a discovery by the way. Logic, you're making me realize now. - [Wolfram] Yeah. - It's not obvious. - The fact that there is an abstraction from natural language that has, where you can fill in any word you want. - [Fridman] Yeah. - Is a very interesting discovery. Now it took a long time to mature. I mean, Aristotle had this\nidea of silogistic logic where there were these particular patterns of how you could argue\nthings, so to speak. And you know, in the Middle Ages part of education was you memorized the syllogisms, I forget how many there were, but 15 of them or something. And they all had names, they all had mnemonics. Like I think Barbara and\nCelarent were two of the, the mnemonics for the silogisms. And people would kind of, this is a valid argument\nbecause it follows the Barbara of Syllogism, so to speak and, and it\ntook until 1830, you know, with George Bule to kind of\nget beyond that and kind of see that there was a, a level of abstraction\nthat was beyond the, this particular template\nof a sentence, so to speak. And that's, you know, what, what's interesting there\nis in a sense, you know, ChatGPT is operating at\nthe Aristotelian level. It's essentially dealing\nwith templates of sentences. By the time you get to\nBule and Bule and algebra and this idea of, you know, you can have arbitrary depth\nnested collections of ans and awes and knots, and you\ncan resolve what they mean. That's the kind of thing\nthat's a computation story. That's, you know, you've gone beyond the pure\nsort of templates of natural language to something, which is an arbitrarily deep computation. But the thing that I\nthink we realized from, from ChatGPT is, you know, Aristotle stopped too quickly\nand there was more that you could have lifted out of\nlanguage as formal structures. And I think there's, you know, in a sense we've captured\nsome of that in, in, you know, some of what, what is in language there. There's, there's a, there's a lot of kind of little calculate, little algebras of, of what you can say, what language talks about. I mean, whether it's, I don't know, if you say I\ngo from place A to place B, place B to place C, then I know I've gone\nfrom place A to place C. If A is a friend of B\nand B is a friend of C, it doesn't necessarily follow\nthat A is a friend of C. These are things that are, and\nyou know that there are, if, if you go from from place A\nto place B place B to place C, it doesn't matter how\nyou went, like logic. It doesn't matter whether\nyou flew there, walked there, swam there, whatever you\nstill, this transitivity of, of where you go is still valid. And there are, there are many kinds of kind of features, I think of the way the world\nworks that are captured in these aspects of, of\nlanguage, so to speak. And I think what, what\nChatGPT effectively has found, just like it discovered logic, you know, people are really\nsurprised it can do these, these logical inferences. It discovered logic the same\nway Aristotle discovered logic by looking at a lot of sentences\neffectively and noticing the patterns in those sentences. - But it feels like it's\ndiscovering something much more complicated than logic. So this kind of semantic grammar, I think you wrote about this, maybe we can call it the laws of language, I believe you call, or which\nI like the laws of thought. - Yes. That was the title that\nGeorge Bule had for his, his Bule in algebra back in 1830. But yes. - [Fridman] Laws of thought. - Yes. That was what he said. - [Fridman] Woo. All right. - So he thought, he thought he nailed it with Bule algebra. - [Fridman] Yeah. - There's more to it. - I, and it's a good question,\nhow much more is there to it? And it seems like one of the reasons, as you imply that the reason\nGPT works, ChatGPT works, is that there's a finite\nnumber of things to it. - [Wolfram] Yeah. I mean, it's, it's. - Like, it's discovering\nthe laws in some sense, GPTs discovering this laws\nof semantic grammar that underlies language. - [Wolfram] Yes. And what, what's sort of interesting is\nin the computational universe, there's a lot of other\nkinds of computation that you could do. They're just not ones that we\nhumans have cared about and, and operate with. And that's probably because\nour brains are built in a certain way. And, you know, the neural nets of our brains\nare not that different in some sense from the neural nets of, of, of a large language model. And that's kind of, and and so when we think\nabout, and you know, maybe we can talk about this some more, but when we think about sort\nof what will AIs ultimately do, the answer is insofar as AI\nare just doing computation, they can run off and do all these kinds\nof crazy computations. But the ones that we sort of have, have decided we care about\nare there is this kind of very limited set. - That's where the reinforcement learning with human feedback seems to come in. The more the AI say the stuff\nthat kind of interests us, the more we're impressed by it. So they can do a lot of\ninteresting, intelligent things, but we're only interested\nin the AI systems when they communicate human in a human-like way. - [Wolfram] Yes. - About human-like topics. - [Wolfram] Yes. - Well, it's, it's like technology. I mean, in a sense, the physical world provides\nall kinds of things. You know, there are all kinds of processes going on in physics only\na limited set of those are ones that we capture\nand use for technology. Cause they're only a\nlimited set where we say, you know, this is a thing that we can\nsort of apply to the human purposes we currently care about. I mean, you might have said, okay, you pick up a piece of, of rock, you say, okay, there's a nice sillacate, it contains all kinds of\nsillicon, I don't care. Then you realize, oh, we could\nactually turn this into a, a, you know, semiconductor wafer and make\nit microprocessor out of it, and then we care a lot about it. - [Fridman] Yes. - And it's, it's, you know, it's this thing about what do we, you know, in the evolution\nof our civilization, what things do we identify as\nbeing things we care about? I mean, it's, it's like, you know, when when there was a little\nannouncement recently of a possibility of a high\ntemperature superconductor that involved, you know, the element\nlutetium, which, you know, generally nobody has cared about. - Fridman] Yes. - And, you know, it, it's kind of, but suddenly if there's this\napplication that relates to kind of human purposes,\nwe start to care a lot. - So given your thinking\nthat GPT may have discovered inklings of laws of thought,\ndo you think such laws exist? Can we linger on that? Yeah. What's your intuition here? - Oh, definitely. I mean, the fact is,\nlook, the, the logic is, but the first step, there are many other kinds of\ncalculate about things that we consider, you know, the, the about sort of things\nthat happen in the world or things that are meaningful. - Well, how do you know\nlogic's not the last step? You know what I mean? So. - Well, because we can plainly\nsee that there thing, I mean, if, if you say, here's a sentence that\nis syntactically correct. Okay. You look at it and\nyou're like, you know, the happy electron, you know, ate, I don't know what some\nsomething that it just, it, you look at it and it's\nlike, this is meaningless. It's just a bunch of words. It's syntactically correct, the nouns and the verbs\nare in the right place, but it just doesn't mean anything. And so there clearly is some\nrules that there are rules that determine when a sentence is, has the potential to be\nmeaningful that go beyond the pure parts of speech syntax. And so the question is,\nwhat are those rules? And are there a fairly\nfinite set of those rules? My guess is that there's a\nfairly finite set of those rules and they, you know, once\nyou have those rules, you have a kind of a\nconstruction kit, just like the, the rules of syntactic grammar\ngive you a construction kit for making syntactically\ncorrect sentences. So you can also have a\nconstruction kit for making semantically correct sentences. Those sentences may not\nbe realized in the world. I mean, I think, you know,\nthe elephant flew to the moon. - [Fridman] Yeah. - A syntactic, a a semantically, you know, we know we have an idea. If I say that to you, you\nkind of know what that means. But the fact is it hasn't\nbeen realized in the world, so to speak. - So semantically correct\nperhaps as things that can be imagined with a human mind, no. Things that are consistent\nwith both our imagination and our understanding of physical reality. I don't know. - [Wolfram] Yeah. It's a good question. I\nmean, it's a good question. It it, it's a good question. I mean, I think it is, it is given the way we\nhave constructed language, it is things which, which fit with the things\nwe're describing in language. It's a bit circular in the end\nbecause, you know, you can, and, and the, and the, the sort of boundaries of\nwhat is physically realizable. Okay, let, let's take\nthe example of motion. Okay? Motion is a complicated concept. It might seem like it's a\nconcept that should have been figured out by the Greeks,\nyou know, long ago. But it's actually a really\npretty complicated concept because what is motion? Motion is you can go from place\nA to place B and it's still you when you get to the other end, right? You, you take an object, you move it, and it's still the same object, but it's in a different place. Now, even in ordinary physics, that doesn't always work that way. If you're near a space time\nsingularity in a black hole, for example, and you take\nyour teapot or something, you don't have much of\na teapot by the time it's near the space time singularity. It's been completely, you know, deformed beyond recognition. But, so that's a case where\npure motion doesn't really work. You can't have a, a thing stay the same. But, so this idea of motion is, is something that sort of is a, is a slightly complicated idea. But once you have the idea\nof motion, you can start, once you have the idea that\nyou're gonna describe things as being the same thing,\nbut in a different place, that sort of abstracted\nidea then has, you know, that has all sorts of consequences. Like this transitivity of\nmotion go from A to B, B to C. You've gone from A to C. And that's so that level of description, you can have what are sort\nof inevitable consequences. They're inevitable features of the way you've sort of set things up. And that's, I think what\nthis sort of semantic grammar is capturing is things, things like that. And I, you know, I think that it's a question\nof what does the word mean when you say I go from, I\nmove from here to there. Well, it's complicated\nto say what that means. This is this whole issue of, you know, is pure motion possible, et\ncetera, et cetera, et cetera. But once you have kind of got\nan idea of what that means, then there are inevitable\nconsequences of that idea. - But the very idea of meaning, it seems like there's\nsome words that become, it's like there's a\nlatent ambiguity to them. I mean, it is the word like emotionally loaded words like hate and love, right? It's like, what, what do\nthey, what do they mean? Exactly? What, what? So especially when you\nhave relationships between complicated objects, we seem\nto take this kind of shortcut, descriptive shortcut of, to describe like object\nA hates object B, what's, what's that really mean? - [Wolfram] Right. Well, words are defined by\nkind of our social use of them. I mean, it's not, you know, a word in computational\nlanguage, for example, when we say we have a, a construct there, we expect that that construct\nis a building block from which we can construct an arbitrary tall tower. So we have to have a very\nsolid building block. And you know, we have to, it\nturns into a piece of code, it has documentation, it's,\nyou know, it's a whole, it's a whole thing. But the word hate, you know, the documentation for that word. Well, there isn't a standard\ndocumentation for that word, so to speak. It's a complicated thing\ndefined by kind of how we use it when, you know, if it wasn't for the fact\nthat we were using language, I mean, so, so what is\nlanguage at some level, language is a way of packaging\nthoughts so that we can communicate them to another mind. - Can these complicated words be converted into something that a\ncomputation engine can use? - Right? So, so I think\nthe answer to that is that, that what one can do in\ncomputational language is define, make a def- make a specific definition. And if you have a complicated word, like let's say the word eat, okay, you'd think that's a simple word. It's, you know, animals\neat things, whatever else. But you know, you do programming, you say this function eats arguments, which is sort of poetically similar to the animal eating things. But if you start to say, well, what are the implications of, you know, the function eating something,\nyou know, does it can, can the function be poisoned?\nWell, maybe it can actually, but you know, if there's a tight\nmismatch or something in a, in some language. But, but you know, in what, how far does that\nanalogy go? And it, it's, it's just an analogy. Yeah. Whereas if you use the word\neat in a computational language level, you would define there\nisn't a thing which you, you anchor to the kind of\nnatural language concept eat. But it is now some precise\ndefinition of that, that then you can compute things from. - But don't you think the\nanalogy is also precise software eats the world, huh? Don't, don't you think there's, there is something concrete in terms of meaning about analogies. - Sure. But the thing that sort\nof is the first target for computational language is\nto take sort of the ordinary meaning of things and\ntry and make it precise, make it sufficiently precise. You can build these towers\nof computation on top of it. - [Fridman] Yeah. - So it's kinda like if you\nstart with a piece of poetry and you say, I'm going to define my program\nwith this piece of poetry. It's kind of like, that's,\nthat's a difficult thing. It's better to say, I'm gonna just have this\nboring piece of prose and it's using words in the ordinary way. - [Fridman] Yeah. - And that's how I'm\ncommunicating with my computer. And that's how I'm going to\nbuild the solid building block from which I can construct\nthis whole kind of computational tower. - So there is some sense\nwhere if you take a poem and reduce it to something computable, you're gonna have very few things left. So maybe there's a bunch of\nhuman interaction that's just poetic aimless nonsense. - [Wolfram] Well. - That's just like recreational,\nlike hamster in a wheel. It's not actually producing anything. - Well, I, I I, I think that that's a complicated\nthing because in a sense, human linguistic communication\nis, there's one mind, it's producing language\nthat language is having an effect on another mind. - [Fridman] Yeah. - And the question of\nthere's sort of a, a, a type of effect that is well\ndefined, let's say where, where, for example, it's very independent of the\ntwo minds that the, it doesn't, you know, there, there, there's communication where it\ncan matter a lot sort of what the experience of, of, of one mind is versus\nanother one and so on. - [Fridman] Yeah. But what is the purpose of\nnatural language communication? - [Wolfram] I think, I think the- - Versus, so computation\ncomputational language somehow feels more amenable\nto the definition of purpose. It's like, yeah, you're given two clean\nrepresentations of a concept and you can build a tower based on that. - [Wolfram] Right. - Is natural language the same\nthing but more fuzzy or what? - Well, I think the, the story\nof natural language, right? And the, the, that's the great\ninvention of our species. We don't know whether it\nexists in other species, but we know it exists in our species. It's the thing that allows\nyou to sort of communicate abstractly from like one generation of the species to another. You can, you know, there is an abstract version of knowledge that can be passed down. It doesn't have to be, you know, genetics. It doesn't have to be, you know, you don't have to apprentice\nthe next species, you know, the next generation of birds\nto the previous one to show them how something works. - [Fridman] Yeah. - There is this abstracted\nversion of knowledge that can be kind of passed down. Now that, you know, it relies on, it still tends to rely\nbecause language is fuzzy. It does tend to rely on\nthe fact that, you know, if we look at the, you know,\nsome ancient language that, where we don't have a chain\nof translations from it until what we have today, we may not understand\nthat ancient language. And we may not understand, you know, its concepts may be different from the ones that we have today. We still have to have\nsomething of a chain. But it is something where we\ncan realistically expect to communicate abstract ideas. And that's, you know, that's\none of the big, big roles of, of a language I think, you know, in, in, it's, you know, and that that's been this, this ability to sort of\nconcrete-ify abstract things is what, what language has provided. - Do you see natural language\nand thought as the same, the stuff that's going inside your mind? - Well, that's been a\nlong debate in philosophy. - It seems to be become more important now when we think about\nhow intelligent GPT is. - [Wolfram] Whatever that means. - Whatever that means. But it seems like the stuff\nthat's going on in the human mind seems something like intelligence. - [Wolfram] Yes. - And is the language- - Well, we call it intelligence. Yeah. - We call it. Well, yes. - And so you, you start to think of, okay, what's the relationship between thought, the language of thought,\nthe laws of thought, the laws of the words like reasoning and the laws of language and how that has to do with computation, which seems like more rigorous,\nprecise ways of reasoning. - [Wolfram] Right. Which are beyond human. I mean, much of what computers\ndo, humans do not do. I mean, you, you might say- - Humans are a subset. - [Wolfram[ Yes.\n- [Fridman] Presumably. - [Wolfram] Yes.\n- [Fridman] Hopefully. - [Wolfram] Yes. The, the yes. Right. You know, you might say, who needs computation when we have large, large language models? Large language models can just, you know, eventually you'll have\na big enough NeuroNet can do anything, but they're really doing\nthe kinds of things that humans quickly do. And there're plenty of sort\nof formal things that humans never quickly do. For example, I don't know, I, you know, you can, some people can\ndo mental arithmetic. They can do a certain\namount of math in their, in their minds. I don't think many people can\nrun a program in their minds of any sophistication. It's just not something people do. It's not something people\nhave even thought of doing. Cause it just, it's kind of\na, it's kind of not, you know, you can easily run it on a computer. - We're an arbitrary program.\n- [Wolfram] Yeah. - Aren't we running specialized programs? - [Wolfram] Yeah, yeah. But if I say to you- - Run this program- - [Wolfram] Here's a\ntouring machine. Yeah. You know, tell me what\nit does after 50 steps. And you're like, trying to\nthink about that in your mind. That's really hard to do.\nIt's not what people do. I mean it- - [Fridman] Well, in some sense, people program, they build\na computer, they program it. Just to answer your question\nabout what the system does after 50 steps. I mean, humans build computers. - Yes. Yes, yes, that's right. But they've created something\nwhich is then, you know, then when they run it, it's doing something different than what's happening in their minds. I mean, they've outsourced that, that piece of computation\nfrom something that is in internally happening in their\nminds to something that is now a tool that's external to their minds. - [Fridman] So by the way, humans to you didn't invent computers. They discovered them. - They discovered computation. - [Fridman] Which- - They invented the\ntechnology of computers. - This, the computer is just a kind of way to plug into this whole, this stream of computation. There's probably other, are other ways. There's probably a lot of ways. - [Wolfram] For sure. I\nmean the, the, you know, the particular ways that\nwe make computers out of semiconductors and electronics and so on. That's the particular\ntechnology stack we've built. I mean, the story of a\nlot of what people try to do with quantum computing\nis finding different sort of underlying physical, you know, infrastructure\nfor doing computation. You know, biology does\nlots of computation. It does it using an infrastructure\nthat's different from semiconductors and electronics. It's a, you know, it's a molecular scale, sort of computational\nprocess that hopefully we'll understand more about. I have some ideas about\nunderstanding more about that. But you know, that's a,\nthat's another ins you know, it's another representation\nof computation, things that happen in the\nphysical universe at the level of, you know, these evolving\nhypergraphs and so on. That's another sort of\nimplementation layer for this abstract idea of computation. - So if GPT or large language\nmodels are starting to form, starting to develop or\nimplicitly understand the laws of language and thought, do you think they can be made explicit? - [Wolfram] Yes. - How. - [Wolfram] With a bunch of effort? - [Fridman] I mean, so do, do they have- - It's like doing natural science. I mean, what is happening\nin natural science? You have the world that's doing\nall these complicated things and then you discover, you know,\nNewton's laws, for example. This is how motion works. This is the way that this particular sort of idealization of the world, this is how we describe it in a simple computation reducible way. And I think it's the same thing here. It's, there are sort of\ncomputationally reducible aspects of what's happening that you can\nget a kind of narrative theory for just as we've got narrative theories in physics and so on. - Do you think it will\nbe depressing or exciting when all the laws of\nthought are made explicit human thought are made explicit? - I think that once you understand computational reducibility, it is, it's neither of those things. Because the fact is people say\nfor example, people will say, oh, but you know, I have free\nwill I, I kind of, you know, I operate in a way that is,\nyou know, you, you, they, they have the idea that they're\ndoing something that is sort of, of internal to them, that\nthey're figuring out what's, what's happening. But in fact, we think there are laws\nof physics that ultimately determine, you know, every,\nevery nerve, you know, every electrical impulse and\na nerve and things like this. So you might say, isn't it depressing that we\nare ultimately just determined by the rules of physics, so to speak? It's the same thing.\nIt's at a higher level. It's like, it's, it's, it's a shorter distance to get\nfrom kind of semantic grammar to the way that we might\nconstruct a piece of text than it is to get from individual nerve firings to how we construct a piece of text. But it's not fundamentally different. And by the way, as soon as we\nhave this kind of level of, you know, this other level\nof description, it's kind of, it helps us to go even further. So we'll end up being able\nto produce more and more complicated kinds of kinds of\nthings that just like when we, you know, if we didn't have a computer and we knew certain rules, we could write them down. We go a certain distance. But once we have a computer,\nwe can go vastly further. And this is the same kind of thing. - You wrote a blog post titled, what is ChatGPT doing\nand why does it work? We've been talking about this, but can we just step back\nand linger on this question? What, what's it, what's ChatGPT doing? What, what are these, A bunch of billion parameters trained on a large number of words. Like, why does it seem to work again? Is it, is it because to the point\nyou made that there's laws of language that can be\ndiscovered by such a process? Is there something-? - Well, let, let's, let's talk about sort of the low level of what ChatGPT is doing. I mean, ultimately you give it a prompt. It's trying to work out, you know, what should the next word be? - Right. Which is wild. Isn't that, isn't that surprising to you\nthat this kind of low level dumb training procedure\ncan create something syntactically correct first and then semantically correct second. - [Wolfram] You know, the thing that has been sort\nof a story of my life is realizing that simple rules\ncan do much more complicated things than you imagine. That something that starts simple and starts simple to describe can grow a thing that is, you know, vastly more complicated\nthan you can imagine. And, and honestly, it, it's\ntaken me, I mean, I don't know, I've sort of been thinking\nabout this now 40 years or so, and it always surprises me.\nI mean, even for example, in our physics project, sort of thinking about the whole\nuniverse growing from these simple rules, I still resist\nbecause I keep on thinking, you know, how can something really complicated arise from something that simple? It just seems, you know, it\nseems wrong, but yet, you know, the majority of my life,\nI've kind of known from, from things I've studied, that\nthis is the way things work. So yes, I, it is wild that it's possible\nto write a word at a time and produce a coherent essay, for example. But it's worth understanding\nkind of how that's working. I mean, it's kind of like,\nif, if it was going to say, you know, the cat sat on\nthe, what's the next word? Okay, so how does it\nfigure out the next word? Well, it's seen a trillion\nwords written on the internet, and it's seen the cat sat on the floor, the cat sat on the sofa,\nthe cat sat on the whatever. So it's minimal thing to do is just say, let's look at what we saw on the internet. We saw, you know, 10,000\nexamples of the cat sat on the, what was the most probable next word. Let's just pick that out and\nsay that's the next word. And that's, that's kind of what it at\nsome level is trying to do. Now, the problem is\nthere isn't enough text on the internet to, for, if you have a reasonable\nlength of prompt to that, that that specific prompt will never have occurred on the internet. And as you, as you kind of go further, there just won't be a place\nwhere you could have trained, you know, where you could just, just worked out probabilities\nfrom what was already there. You know, like if you say two plus two, there'll be a zillion examples of two plus two equaling four, and a very small number of examples of two plus two equals five and so on. And you can pretty much\nknow what's going to happen. So then the question is, well, if you can't just work out from examples, what's gonna happen? Just\nno probabilistic for, for examples, what's gonna\nhappen, you have to have a model. And this kind of an idea, this idea of making models of\nthings is an idea that really, I don't know, I think Galileo probably was\none of the first people who sort of worked this out. I mean, it's kind of like, like, you know, I think I\ngave an example of that, the little book I wrote\nabout, about ChatGPT where it's kind of like, you know, Galileo was dropping cannon balls off the, off the different floors of\nthe, of the tower of Piza. And it's like, okay, you drop\na cannonball off this floor, you drop a cannonball off this floor, you miss floor five or\nsomething for whatever reason. But you know, the time it took the cannon\nball to fall to the ground from floors one, two, three, four, six, seven, eight, for example. Then the question is, can\nyou work out, can you, can you make a model\nwhich figures out how long did it take the ball? How long would it have take\nthe ball to fall to the ground from the floor you didn't\nexplicitly measure. And the thing Galileo realized\nis that you can use math, you can use mathematical\nformulas to make a model for how long it will take the ball to fall. So now the question is, well, okay, you want to make a model for, for example, something much more elaborate, like you've got this arrangement\nof pixels and is this arrangement of pixels an A or a B? Does it correspond to\nsomething we'd recognize as an A or a B? And you can make a similar kind, you know, each pixel is like a\nparameter in some equation. And you could write down\nthis giant equation where the answer is either, you know, A or you know, one or two A or B. And the question is then what\nkind of a model successfully reproduces the way that we humans would, would conclude that this is an\nA, and this is a B, you know, if if there's a, a complicated extra tail\non the top of the A, would we then conclude\nsomething different? What is the type of model that\nmaps well into the way that we humans make distinctions about things? And the big kind of meta discovery is neural nets are such a model. It's not obvious they\nwould be such a model. It could be that human\ndistinctions are not captured. You know, we could try searching\naround for a type of model that could be a mathematical model, it could be some model based\non something else that captures kind of typical human\ndistinctions about things. It turns out this model that\nactually is very much the way that we think the\narchitecture of brains works, that perhaps, not surprisingly, that model actually corresponds to the way we make these distinctions. And so, you know, the, the, the core next point is that\nthe, the kind of model, this neural net model\nmakes sort of distinctions and generalizes things\nin sort of the same way that we humans do it. And that's why when you say, you know, the cat sat on the green blank, even though it never didn't see\nmany examples of the cat sat on the green, whatever, it can make a, or the aardvark sat on\nthe green, whatever. I'm sure that particular sentence does not occur on the internet. And so it has to make a\nmodel that concludes what, you know, it has to kind of\ngeneralize from what it's, from the actual examples that it's seen. And so, so you know that that's\nthe factors that neural nets generalized in the same kind\nof a way that we humans do. If, if we were, you know, the aliens might look at our\nneural net generalizations and say, that's crazy. You know, that thing when you put that\nextra little dot on the A, that isn't an A anymore. That's, you know, that messed the whole thing up. But for us humans, we make distinctions, which seem to correspond to\nthe kinds of distinctions that neural nets make. So then, you know, the, the thing that is just\namazing to me about ChatGPT is how similar the structure\nit has is to the very original way people imagine\nneural nets might work back in 1943. And, you know, there's a\nlot of detailed engineering, you know, great cleverness,\nbut it's really the same idea. And in fact, even the sort of elaboration\nof that idea where people said, let's put in some actual\nparticular structure to try and make the neural net more elaborate, to be very clever about it,\nmost of that didn't matter. I mean, there's some things\nthat seem to, you know, when you, when you train\nthis neural net, you know, the one thing, this kind of\ntransformer architecture, this attention idea that\nreally has to do with, does every one of these\nneurons connect to every other neuron or is it somehow\ncausally localized, so to speak? Does it, like, we're making a sequence of\nwords and the words depend on previous words rather than just, everything can depend on everything. And that seems to be important. And just organizing things\nso that you don't have a, a sort of a giant mess. But the thing, you know, the thing worth understanding about what is ChatGPT in the end? I mean, what is a neural net in the end? A neural net in the end is\neach neuron has a, it, it, it's taking inputs from\na bunch of other neurons. It's, it's, eventually\nit's going to have a, it's going to have a, a numerical value. It's going to compute some number. And it's, it's saying,\nI'm gonna look at the, the neurons above me. It's kind of a, a series of layers. It's gonna look at the neurons above me and it's going to say, what are the values of all those neurons? Then it's gonna add those\nup and multiply them by these weights, and then it's going to apply\nsome function that says if it's bigger than zero or something, then make it one or, and\notherwise make it zero or some slightly more\ncomplicated function. You know very well how this works. - It's a giant equation\nwith a lot of variables. You mentioned figuring out\nwhere the ball falls when you don't have data on the fourth floor. This, the equation here\nis not as simple as- - [Wolfram] It's an equation\nwith 175 billion terms. - And it's quite surprising\nthat in some sense, a simple procedure of training\nsuch an equation can lead to - [Wolfram] Well I think- - A good representation\nof natural language. - Right? The, the real issue is, you know, this architecture of a neural net where, where what's happening is,\nyou know, you've, you've, you've turned so neural nets\nalways just deal with numbers. And so, you know, you've turned the sentence\nthat you started with into a bunch of numbers. Like let's say by mapping, you know, each word of the 50,000 words in English, you just map each word\nor each part of a word into some number. You feed all those numbers in, and then the thing is going to, and then those numbers\njust go into the values of these neurons. And then what happens is it's\njust rippling down going layer to layer until it gets to the end. I think ChatGPT has about\n400 layers, and you're just, you know, it just goes once through it. Just, every, every new word\nit's gonna compute just says, here are the, here are the\nnumbers from the words before, let's compute the, what is it compute. It computes the probabilities\nthat it estimates for each of the possible 50,000 words\nthat could come next. And then it decides sometimes it will use the most probable word. Sometimes it will use not\nthe most probable word. It's an interesting fact\nthat there's this so-called temperature parameter, which,\nyou know, at temperature zero, it's always using the most\nprobable word that it, that it estimated was the, the most\nprobable thing to come next. You know, if you increase the temperature, it'll be more and more kind of random in its selection of words. It'll go down to the lower\nand lower priority words. The thing I was just playing\nwith actually recently was the transition that happens as\nyou increase the temperature, the thing goes bonkers at\na particular, you know, sometimes at a particular temperature. I think maybe about 1.2 is\nthe thing I was noticing from yesterday actually. That, you know, usually it's giving reasonable\nanswers and then at that temperature with some probability, it just starts spouting nonsense. And, you know, nobody\nknows why this happens. I mean, it's, it's,\nand by the way, I mean, the thing to understand is it's putting down one word at a time, but the outer loop of the\nfact that it says, okay, I put down a word. Now let's take the whole\nthing I wrote so far, let's feed that back in. Let's put down another word. That outer loop, which\nseems almost trivial, is really important to the\noperation of the thing. And, and for example, one of the things that is\nkind of funky is it'll give an answer and you say to it,\nis that answer correct? And it'll say no. And why is that happening? - [Fridman] It's fascinating. Right? - Right. Why can't it do that? Well, the answer is because it, it is going one word at\na time sort of forwards. And it didn't, you know, it it, it came along with some sort of chain of, of thought in a sense, and it, it came up with completely\nthe wrong answer. But as soon as you feed it, the whole thing that it came up with, it immediately knows\nthat that isn't right. It immediately can recognize\nthat was a, you know, a bad syllogism or something,\nand can see what happened. Even though as it was being\nled down this garden path, so to speak, it didn't, it\ncame to the wrong place. - But it's fascinating that\nthis kind of procedure converges to something that forms\na pretty good compressed representation of\nlanguage on the internet. - [Wolfram] Yeah. - That, that's quite. - [Wolfram] Right. Right, right. - I'm not sure what to make of it. - Well, look, I think, you know, there are many things we\ndon't understand. Okay. So for example, you know,\n175 billion weights, it's maybe about a trillion\nbites of information, which is very comparable to\nthe training set that was used. And you know, why that, why kind, it sort of stands to some kind\nof reason that the number of weights in the neural\nnet, I don't know where, I can't really argue that I\ncan't really give you a good, you know, in a sense the\nvery fact that, you know, the insofar as there are definite\nrules of what's going on, you might expect that eventually\nwe'll have a much smaller neural net that will successfully\ncapture what's happening. I, I don't think the best way to do it is probably a neural net. I think a neural net is what\nyou do when you don't know any other way to structure the thing. And it's a very good thing to\ndo if you don't know any other way to structure the thing. And for the last 2000 years, we haven't known any\nother way to structure it. So this is a pretty good way to start. But that doesn't mean you\ncan't find sort of, in a sense, more symbolic rules for\nwhat's going on that you know, much of which will then be, you can kind of get rid of\nmuch of the structure of the neural net and replace it by\nthings which are sort of pure steps of computation, so to speak, sort of with neural net\nstuff around the edges. And that becomes just a, you know, it's just a much simpler way to do it. - So the neural net you hope\nwill reveal to us good symbolic rules that make the\nneeds of the neural net less and less and less. - Right. And there will still be some\nstuff that's kind of fuzzy, just like, you know, there\nthere're things that it, it's like this question\nof what can we formalize, what can we turn into\ncomputational language? What is just sort of, oh, it happens that way just because\nbrains are set up that way. - What do you think are the\nlimitations of large language models just to make it explicit? - Well, I mean, I think that deep computation\nis not what large language models do. I mean, that's just, it's a different kind of thing, you know, the outer loop of a large language model. If, if you are trying to do\nmany steps in a computation, the only way you get to do\nthat right now is by spooling out, you know, all the, the whole chain of thought as\na bunch of words basically. And, you know, you can make a touring machine\nout of that if you want to. I just was make doing that\nconstruction, you know, in principle you can make\nan arbitrary computation by just spooling out the words. But it's an, it's a bizarre and\ninefficient way to do it. But it's something where the,\nyou know, I, I think that's, you know, sort of the, the\ndeep computation is it's, it's really what a humans can do quickly. Large language models will\nprobably be able to do well. Anything that you can do kind\nof off the top of your head type thing is a, is really, you know, is good for large language\nmodels and the things you do off the top of your head, you may\nnot get them always right, but you know, you'll, it, it's, it's thinking it through\nthe same way we do. - But I wonder if there's an\nautomated way to do something that humans do well much\nfaster to where it like loops. So generate arbitrary large\ncode bases off Wolfram Language for example. - [Wolfram] Well, the\nquestion is what does he, what do you want the code base to do? - Escape control and take over the world? - [Wolfram] Okay, so, you know, the thing is when people say, you know, we, we want to build\nthis giant thing, right? A giant piece of computational\nlanguage in a sense, it's sort of a failure\nof computational language if the thing you have to\nbuild, in other words, if we have a description, if, if you have a small description, that's the thing that you\nrepresent in computational language and then the computer\ncan compute from that. - [Fridman] Yes. - So in a sense in, you know, when, as soon as you're giving a\ndescription, the, you know, if you have to somehow make\nthat description something, you know, definite something\nformal and once and, and to say, to say, okay, I'm gonna give this\npiece of natural language and then it's gonna split out this giant formal structure that\nin a sense that doesn't, that that doesn't really make\nsense because except insofar as that piece of natural language\nkind of plugs into what we socially know, so to speak, plugs into kind of our corpus\nof knowledge, then, you know, that's a way we are\ncapturing a piece of that corpus of knowledge. But hopefully we will have\ndone that in computational language. How do you make\nit do something that's big? Well, you know, you have to have a way to\ndescribe what you want. - Okay. I can make it\nmore explicit if you want. How about I just pop into my head, iterate through all\nthe members of Congress and figure out how to convince them that they have to let me, the meaning the system become president, pass all the laws that allows\nAI systems to take control and be the president. I don't know. So that's a very explicit\nlike figure out the individual life story of each congressman\nthat each senator, anybody, I don't know, what's required to really\nkind of pass legislation and figure out how to control them\nand manipulate them, right. Get all the information. What would be the biggest\nfear of this congressman? And in such a way that you\ncan take action on it in the digital space. So maybe threaten the\ndestruction reputation or something like this. - Right. If I can describe what I want. You know, to what extent can a large\nlanguage model automate that? - Would the help with the\nhelp of the conqurization of something like Wolfram language that makes it more yeah, grounded. - [Wolfram] I think it\ncan go rather a long way. - I'm also surprised how\nquickly I was able to generate. - Yeah, yeah. Right. - [Wolfram] That's a, an attack. - That, that's a, you know, I, I swear, I swear I did not think about\nthis before and it's funny how quickly, which is a very\nconcerning thing because that, that probably this idea will\nprobably do quite a bit of damage and there might\nbe a very large number of other such ideas. - Well, I'll give you a, a much more benign version of that idea. Okay. You're gonna make an AI\ntutoring system and you know, that is a, that's a, a benign version of what you're\nsaying is I want this person to understand this point. You know, you are essentially doing\nmachine learning where the, where the, where the, you know,\nthe, the loss function, the, the thing you're trying to\nget to is get the human to understand this point and, and when you do a test on\nthe human that they yes, they correctly understand\nhow this or that works. And I, I am confident that, you know, sort of a large language model\ntype technology combined with computational language is\ngoing to be able to do pretty, pretty well at teaching us humans things. And it's gonna be an\ninteresting phenomenon because, you know, sort of\nindividualized teaching is, is a thing that has been\nkind of a, you know, a goal for a long time. I think we're gonna get that\nand I think more, you know, that, that it has many\nconsequences for, you know, like, like just, you know, if\nyou know me as an, if you, the AI know me, tell me\nI'm about to do this thing, what is the, what are the\nthree things I need to know, you know, given what I already\nknow, you know, what's the, what's, let's say I'm, I'm looking at some paper\nor something, right? it's like there's a version\nof the summary of that paper that is optimized for me, so to speak, and where it really is. And I think that's really going to work. - It could understand the\nmajor gaps in your knowledge - [Wolfram] Yes. - That if filled would actually give you a deeper understanding of the topic. - [Wolfram] Yeah. Right. And that's a, you know, that's an important thing because it, it really changes actually.\nI think, you know, when, when you think about education and so on, it really changes kind\nof what's worth doing, what's not worth doing and so on. It makes, you know, I know in my life I've learned\nlots of different fields and you know, so I, yeah, I don't know. I have every time, I'm always think this is\nthe one that's going to, I'm not gonna be able to learn. But turns out sort of, there are sort of meta\nmethods for learning these things in the end. And, you know, I think this, this idea that it becomes\neasier to, you know, it, it becomes easier to be\nfed knowledge, so to speak. And it becomes, you know, if you need to know this\nparticular thing, you can, you know, you can get taught it in a, in an efficient way is something\nI think is sort of a, a, an interesting feature. And I think it makes the, you know, things like the value of, of big towers of specialized\nknowledge become less significant compared to the\nkind of meta knowledge of sort of understanding kind of the, the big picture and being able\nto connect things together. I think that, you know, there's\nbeen this huge trend of, of let's be more and more\nspecialized because we have to, you know, we, we have to sort of ascend\nthese towers of knowledge, but by the time you can get, you know, more automation of being able\nto get to that place on the tower without having to go\nthrough all those steps, I think it, it sort of\nchanges that picture. - Interesting. So your intuition is that\nin terms of the, the, the collective intelligence\nof the species and the individual minds that\nmake up that collective, there'll be more, there will trend towards being generalists and being kind of philosophers. - That's what I think, I think that's where the\nhumans are gonna be useful. I think that a lot of these\nkind of the drilling, the, the, the, the mechanical working out of things is much more automatable. It's much more AI, AI\nterritory, so to speak. - [Fridman] No more PhDs. - Well that's, it's interesting. Yes. I mean that, you know, the, the, the kind of the specialization, this kind of tower of specialization, which has been a feature of, you know, we've accumulated lots\nof knowledge in our, in our species and, and you\nknow, in a sense, every time we, every time we have an\na kind of automation, a building of tools, it becomes less necessary\nto know that whole tower. And it becomes something where\nyou can just use a tool to get to the top of that tower. I think that, you know, the\nthing that is ultimately, you know, when we think about, okay, what do the AIs do versus\nwhat do the humans do? It's like AIs you tell 'em, you say go achieve this\nparticular objective. Okay? They can maybe figure out a\nway to achieve that objective. We say, what objective\nwould you like to achieve? The AI has no intrinsic idea of that. It's not a defined thing. That's a thing which has to\ncome from some other, you know, some other entity. And insofar as we are in charge, so to speak, or whatever it is, and our kind of web of society\nand history and so on is the thing that is defining what\nobjective we want to go to. That's, you know, that that's, that's a thing that we humans\nare necessarily involved in. - To push back a little bit, don't you think that GPT,\nfeature versions of GPT would be able to give a good answer\nto what objective would you like to achieve. - From on what basis? I\nmean, if they say, look, here's the terrible thing\nthat could happen. Okay, they're taking the average\nof the internet and they're saying, you know, from the\naverage of the internet, what do people want to do? - Well, that's the, the Elon Musk artage of the\nmost entertaining outcome is the most likely. - [Wolfram] Okay. That could be got that one from him. Yeah. - That could be, that could\nbe one objective is maximize global entertainment. The dark version of that is drama. The, the, the good version of that is fun. - Right. So I mean this, this\nquestion of what, you know, if you say to the AI, you know, what does the species want to achieve? - [Fridman] Yes. Okay. There'll be an answer. Right? - There'll be an answer. It'll be what the average of\nthe internet says the species wants to achieve. - Well, well, let's, let's, let's, I think you're using the word\naverage very loosely there, - [Wolfram] I am. - So I think you, I think the answers will become\nmore and more interesting as these language models are\ntrained better and better. - No, but I mean, in the end it's a reflection back of what we've already said. - Yes. But it's, there's a deeper wisdom to\nthe collective intelligence, presumably than each individual. - [Wolfram] Maybe. - Isn't that what we're\ntrying to, as society? - [Wolfram] To, to have,\nwell, I mean that's, that's a, that's an important No, no,\nthis is an interesting question. I mean, in, you know, insofar\nas some of us, you know, work on trying to innovate and\nfigure out new things and so on, it is sometimes it's a, it's a complicated interplay\nbetween sort of the individual doing the crazy thing, often\nsome, some spur, so to speak, versus the collective that's\ntrying to do sort of the, the, the, the high inertia average thing. And it's, you know, sometimes\nthe collective, you know, is, is bubbling up things that\nare interesting and sometimes it's pulling down kind of the\nattempt to make this kind of innovative direction. - Well, don't you think the large\nlanguage models would see beyond that simplification? We'll say maybe intellectual\nand career diversity is really important. So you need the crazy\npeople on the outlier, on the outskirts, right? And so, like the actual, what's the purpose of this whole\nthing is to explore through this kind of dynamics that\nwe've been using as a human civilization, which is most\nof us focus on one thing, and then there's the crazy\npeople on the outskirts doing the opposite of that one thing. And you kind of like pull\nthe whole society together. There's the mainstream science\nand then there's the crazy science, and that's just been the, the history of human civilization. And maybe the AI system\nwill be able to see that. And the more and more impressed\nwe are by a language model telling us this, the more control we'll give\nit to it and the more we'll be willing to let it run our society. And hence there's this kind of loop where the society could be manipulated to let the AI system run it. - Right. Well, I mean, look, one, one of the things that's sort\nof interesting is we might say, we always think\nwe're making progress, but yet if you know in\na sense, by by saying, let's take what already exists\nand use that as a model for what should exist. - [Fridman] Yeah. - Then, you know, it's\ninteresting that for example, you know, many religions have\ntaken that point of view. There is a, you know, a sacred book that got written\nat Time X and it defines how people should act for all future time. And that's, you know,\nit's a, it's a model that, that people have operated with. And in a sense, you know, this is a version of that,\nthat kind of statement. It's like, take the 2023 version of sort\nof how the world has exposed itself and use that to\ndefine what the world should do in the future. - But it's not, it's an\nimprecise definition, right? Because just like with\nreligious text and which GPT the human interpretation of\nwhat GPT says will be the, will be the perturbation in the system. It'll be the noise, it'd be full of uncertainty. It's not like GPT will tell\nyou exactly what to do. It'll tell you approx a\nnarrative of what, like a, a, you know, it's like a turn the other\ncheek kind of narrative, right? That's, that's not a fully\ninstructive narrative. - [Wolfram] Well, until, until the AI control all\nthe systems in the world. - They will be able to very\nprecisely tell you what to do. - [Wolfram] Well. They'll do\nwhat they, you know, they'll, they'll just do this or that\nthing and that and that. And, and not only that, they'll be auto suggesting\nto each person, you know, do this next, do that next. So I think it's a, it's a slightly more\nprescriptive situation than one has typically seen. But I, you know, I think this, this whole question of sort of what, what's left for the humans, so to speak, to what extent do we, you know, this idea that there is an\nexisting kind of corpus of purpose for humans defined by\nwhat's on the internet and so on, that's an important thing. But then the question of sort of, as we explore what we can think of as the computational universe, as we explore all these different\npossibilities for what we could do, all these different inventions, we could make all these different things. The question is which ones\ndo we choose to follow? Those choices are the\nthings that in a sense, if the humans want to still\nhave kind of human progress, that's what we, we get to make\nthose choices, so to speak. In other words, the, the,\nthere's this idea, if you say, let's take the kind of what exists today and use that as the determiner of all of what there is in the future, the thing that is sort of\nthe opportunity for humans is there will be many\npossibilities thrown up. There are many different\nthings that could happen. It'll be done. And the insofar as we\nwant to be in the loop, the thing that makes sense for\nus to be in the loop doing is picking which of those\npossibilities we want. - But the degree to which\nthere's a feedback loop of the idea that we're picking something starts becoming questionable because we're influenced by the various systems. - [Wolfram] Absolutely. - The, like, if that becomes more and more\nsource of our education and wisdom and knowledge. - Right. The AI take\nover, I mean my, you know, I've thought for a long time\nthat, you know, it's the, you know, AR auto suggestion that's really the thing that\nmakes the AIs take over. It's just then the humans just follow, you know? Yeah. - We'll no longer write\nemails to each other. We'll just send the auto suggested email. - Yeah, yeah. But the thing where humans are potentially in the loop is when there's a choice and\nwhen there's a choice, which we could make based\non our kind of whole web of history and so on. - [Fridman] Yeah. - And, and that's, you\nknow, that's insofar as it's all just, you\nknow, determined, you know, the humans don't have a place. And, and by the way, I mean,\nyou know, at, at some level, you know, it's all kind of a, a complicated philosophical\nissue because at some level the universe is just doing what it does. We are parts of that universe\nthat are necessarily doing what we do, so to speak, yet we feel we have sort of\nagency in what we're doing. And that's, that's its own separate\nkind of interesting issue. - And we also kind of feel like we're the final destination\nof what the universe was meant to create. But we very well could be, and likely are some kind of\nintermediate step, obviously. - [Wolfram] Yeah. - What we're, we're most\ncertainly some intermediate step. The question is if there's\nsome cooler, more complex, more interesting things that's\ngoing to be materialized. - [Wolfram] The computational universe is full of such things. - But in, in our particular\npocket specifically, if this is the best we've gotta\ndo or not, that's kind of a. - We can make all kinds of\ninteresting things in the computational universe. We, when we look at them, we say, yeah, you know, that's,\nthat's a thing we don't, it doesn't really\nconnect with our current, our current way of thinking about things. I mean, it's like in\nmathematics, you know, we've got certain theorems. They're about three or 4\nmillion that that human mathematicians have written\ndown and published and so on. But they're an infinite number of possible mathematical theorems. We just go out into the universe\nof possible theorems and pick another theorem. And then people will say, well, you know, that's, you know,\nthey look at it and they say, I don't know what this theorem means. It's not connected to the\nthings that are part of kind of the web of history that\nwe're dealing with. You know, I think one, one point to make about sort\nof understanding AI and its relationship to us is as\nwe have this kind of whole infrastructure of AI is doing\ntheir thing and doing their thing in a way that is perhaps not readily understandable by us humans. You know, you might say that's a, that's a very weird situation. How can we have built this\nthing that behaves in a way that we can't understand that's\nfull of computational disability, et cetera,\net cetera, et cetera. You know, what, what is this, what's it gonna feel like when\nthe world is run by AIs whose operations we can't understand? And the thing one realizes is actually, we've seen this before. That's what happens when we\nexist in the natural world. The natural world is full of\nthings that operate according to definite rules. They have all kinds of, you know, computational irreducibility, we don't understand what the natural world is doing occasionally. And, and you know, when you say, you know, are the AI gonna wipe us out, for example? Well, it's kind of like, is the machination of the AI\ngoing to lead to this thing that eventually comes\nand destroys the species? Well, we can also ask the same thing about the natural world or the machination of the natural\nworld going to eventually lead to this thing that's\ngoing to, you know, make, make the earth explode\nor something like this. Those are, those are questions, those are, and insofar as we think we\nunderstand what's happening in the natural world, that's a result of science\nand natural science and so on. One of the things we can\nexpect when there's this giant infrastructure of the AIs is\nthat's where we have to kind of invent a new kind of natural\nscience that kind of is the natural science that explains\nto us how the AIs work. I mean, it's kind of like we can, we can, you know, we have a, I don't know, a horse or something, and we're trying to get it\nto, we're trying to, you know, ride the horse and go from here to there. We don't really understand\nhow the horse works inside, but we can get certain\nrules and certain, you know, approaches that we take to, to persuade the horse to go\nfrom here to there and, and, and take us there. And that's the same type of\nthing that we're kind of dealing with, with the sort of\nincomprehensible computationally, irreducible AIs. But we can identify these kinds of, we can find these kind of\npockets of reducibility that we can kind of, you know, that, I don't know, we grabbing onto the mane of\nthe horse or something to be able to, to ride it. Or we figure out, you know, if\nwe, if we do this or that to, to ride the horse, that that's\na, a, a successful way to, to get it to do what, what\nwe're interested in doing. - There does seem to be a\ndifference between a horse and a large language model or something that could be called Agi connected to the internet. So lemme just ask you about big\nphilosophical question about the threats of these things. There's a lot of people\nlike Eliezer Yudkowsky, who worry about the existential\nrisks of AI systems. Is that something that\nyou worry about? You know, sometimes when you're building\nan incredible system, like, well, from Alpha, you can\nkind of get lost in it. - I try and think a little bit about the implications\nof what one's doing. - You know, it's like the Manhattan\nproject kind of situation where you're like, it's some of the most incredible physics in engineering being done. But it's like, huh, where's this gonna go? - I think some of these arguments\nabout kind of, you know, they'll always be a smarter AI. There'll always be, you know, and eventually the\nAIs will get smarter than us, and then all sorts of terrible\nthings will happen to me. Some of those arguments remind\nme of kind of the ontological arguments for the existence\nof God and things like this. They're kind of arguments that\nare based on some particular model, fairly simple\nmodel, often of kind of, there is always a greater\nthis, that and the other. You know, this is, and that's, you know, those arguments tend, what tends to happen in the\nsort of reality of how these things develop is that\nit's more complicated than you expect. That the kind of simple,\nlogical argument that says, oh, eventually there'll\nbe a super intelligence, and then it will, you know, do this. And that turns out not\nto really be the story. It turns out to be a\nmore complicated story. So for example, here's an example of an issue. Is there an apex intelligence, just like there might be an\napex predator in some, you know, ecosystem. Is there gonna be an apex intelligence, the most intelligent thing\nthat there could possibly be? Right? I think the answer is no. And in fact, we already know\nthis, and it's a kind of a, back to the whole computational\nirreducibility story. There's kind of a, a\nquestion of, you know, even if you have, if you,\nif you have sort of a, a touring machine and you\nhave a touring machine that, that runs as long as possible\nbefore, before it halts, you say, is this the machine? Is this the apex machine that does that? There will always be a\nmachine that can go longer. And as you go out to the\ninfinite collection of possible touring machines, you'll\nnever have reached the end, so to speak. You'll never, you'll always be able to, it's kind of like the same same\nquestion of whether there'll always be another invention. Yeah. Will you always be able\nto invent another thing? The answer is yes, there's an infinite tower\nof possible inventions. - That's one definition of apex. But the, the other is like,\nwhich I also thought you were, which I also think might be true, is, is there a species that's\nthe apex intelligence right now on earth? So it's not trivial to\nsay that humans are that. - Yeah, it's not trivial. I agree. It, it's, you know, I think one of the things that I, I've long been curious about\nkind of other intelligences, so to speak. I mean, I, you know, I, I view intelligence is like\ncomputation and it's kind of a, you know, you're sort of,\nyou have the set of rules, you deduce what happens. I have tended to think now\nthat there's this sort of specialization of\ncomputation that is sort of a consciousness like thing\nthat has to do with these, you know, computational boundedness, single thread of experience, these kinds of things that\nare the specialization of computation that corresponds\nto a somewhat human-like, experience of the world. Now the question is,\nso, so that's, you know, there may be other intelligences\nlike, you know, you know, the aphorism, you know, the\nweather has a mind of its own, it's a different kind of\nintelligence that can compute all kinds of things that are\nhard for us to compute, but it is not well aligned\nwith us with the way that we think about things. It doesn't, it doesn't, it doesn't think the way\nwe think about things. And you know, in this idea of different, different intelligences,\nevery different mind, every different human mind is\na different intelligence that thinks about things in different ways. And you know, in, in terms of the kind of\nformalism of our physics project, we talk about this idea of rural space, the space of all possible\nsort of rural systems and different minds are in a sense\nof different points in rural space, human minds. Ones that have grown up with\nthe same kind of culture and ideas and things like\nthis might be pretty close in rural space. Pretty easy for them to communicate. Pretty easy to translate, pretty easy to move from one\nplace in rural space that corresponds to one mind, to another place in rural space\nthat corresponds to another sort of nearby mind when we\ndeal with kind of more distant things in rural space,\nlike, you know, the, the pet cats or something, you know, the pet cat has some aspects\nthat are shared with us. The emotional responses\nof the cat are somewhat similar to ours, but the cat is further away in\nrural space than people are. And so then the question is, you know, can we identify sort of the, can we make a translation from\nour thought processes to the thought processes of, of a\ncat or something like this? And you know, what, what will\nwe get when we, you know, what, what will happen when we get there? And I think it's the case\nthat that many, you know, many animals, I don't know,\ndogs for example, you know, they have elaborate olfactory systems. They, you know, they, they have sort of the smell\narchitecture of the, of the, of the world, so to speak,\nin a way that we don't. And so, you know, if, if you were sort of talking\nto the dog and you could, you know, communicate in a\nlanguage, the dog will say, well, this is a, you know, a a, you know, a, a flowing smelling this,\nthat, and the other thing, concepts that we just\ndon't have any idea about. Now what's what's interesting\nabout that is one day we will have chemical sensors that\ndo a really pretty good job. You know, we'll have artificial\nnoses that work pretty well, and we might have our augmented\nreality systems show us kind of the same map that the dog\ncould see and things like this. So the, you know, it's similar to what\nhappens in the dog's brain. And eventually we will have\nkind of expanded in rural space to the point where we will\nhave those same sensory experiences that dogs have, and we will have internalized\nwhat it means to have, you know, the smell landscape or whatever. And, and so then we will have\nkind of colonized that part of rural space until, you know,\nwe haven't gone, you know, some things that, that, you\nknow, animals and so on. Do we sort of successfully\nunderstand, others We do not. And the question of, of what\nkind of, what is the, you know, what, what representation, you know, how, how do we convert things that\nanimals think about to things that we can think about?\nThat's not a trivial thing. And you know, I've,\nI've long been curious. I've had a very bizarre\nproject at one point of, of trying to make an iPad game that a cat could win against its owner. - Right. So it feels like there's a deep philosophical goal there, though. - Yes, yes. I mean, the, the, you know,\nI was curious if, you know, if pets can work in Minecraft or something and can construct things, what will they construct and\nwill what they construct be something where we look\nat and we say, yeah, I recognize that. Or will it be something that\nlooks to us like something that's out there in the\ncomputational universe that one of my, you know, cellular automat might have\nproduced where we say, oh, yeah, I can kind of see it operates\naccording to some rules. I don't know why you\nwould use those rules. I don't know why you would care. - Yeah. I actually, just\nto link on that, seriously, is there a connector in\nthe royal space between you and a cat where the cat\ncould legitimately win? So iPad is a very limited interface. - [Wolfram] Yeah, I, I- - I wonder if there's\na game where cats win. - I think the problem is that\ncats don't tend to be that interested in what's\nhappening on the iPad. - [Fridman] Yeah. That's\nan interface issue. - Yeah. Right, right, right. No, I think it is likely\nthat, I mean, you know, there are plenty of animals\nthat would successfully eat us if we were, you know, if\nwe were exposed to them. And so there's, you know, it, it's gonna pounce faster than we can get out of the way and so on. So there, there are plenty of, and, and probably it's going to, you know, we think we've hidden ourselves, but we haven't successfully\nhidden ourselves. - That's a physical strength. I wonder if there's something\nin more in the realm of intelligence where an animal\nlike a cat could out-. - Well, I think there are things\ncertainly in terms of the, the speed of processing certain\nkinds of things, for sure. I mean, the, the question\nof what, you know, is there a game of chess, for\nexample, is there cat chess? That the cats could\nplay against each other. And if we tried to play\na cat, we'd always lose, I don't know. - It might have to do with speed it, but it might have to\ndo with concepts also. It might be concepts in the cat's head. - I, I tend to think that our\nspecies from its invention of language has managed to build\nup this kind of tower of abstraction that for\nthings like a chess like game will make us win. In other words, we've become through the fact\nthat we've kind of experienced language and learnt abstraction, you know, we've sort of become smarter\nat those kinds of abstract kinds of things. Now, you know, that doesn't make us smarter at catching a mouse or something. It makes us smarter at the\nthings that we've chosen to, to sort of con, you know, to\nconcern ourselves, which are, are these kinds of abstract things. And, and I think, you know, this is again, back to the question of of, you know, what does one care about? You know, if one's a, if one's the, you know, the cat, if you, if you have the discussion\nwith a cat, if we can, if we can translate things\nto have the discussion with a cat, the cat will say, you know, I'm very excited that\nthis light is moving. And we'll say, why do you care? And the cat will say, that's the most important\nthing in the world. That this thing moves around. I mean, it's like when you\nask about, I don't know, you, you look at archeological\nremains and you say, these people had this, you\nknow, belief system about this. And, you know, that was the most important\nthing in the world to them. And, and now we look at it and say, we don't know what the point of it it was. I mean, I, I've been curious, you know, there are these hand prints on caves from 20,000 or more years ago, and it's like nobody knows\nwhat these hand prints were there for. You know, that they may\nhave been a representation of the most important\nthing you can imagine. They may just have been\nsome, you know, some kid who, who rubbed their hands in the\nmud and stuck 'em on the walls of the cave. You know, we don't, we don't know. And I think, but this, this\nwhole question of what you know, is when you say this question\nof sort of what's the smartest thing around, there's the question of what\nkind of computation are you trying to do? If you're saying, you know, if you say you've got some\nwell-defined computation and how do you implement it? Well, you could implement\nit by nerve cells, you know, firing. You can implement it with\nsilicone and electronics. You can implement it by some\nkind of molecular computation process in the human immune\nsystem or in some molecular biology kind of thing. They're different ways to implement it. And you know, I think this question of, of of sort of which, you know, those different implementation methods will be of different speeds. They'll be able to do\ndifferent things if you say, you know, which, so an\ninteresting question would be, what kinds of abstractions\nare most natural in these different kinds of systems? So for a cat, it's for example, you know, the visual scene that we\nsee, you might, you know, we pick out certain objects,\nwe recognize, you know, certain things in that visual scene. A cat might in principle,\nrecognize different things. I, I suspect, you know, evolution, biological evolution is very slow. And I suspect what a cat\nnotices is very similar. And we even know that\nfrom some neurophysiology, what a cat notices is very\nsimilar to what we notice. Of course, there's a, you know, one obvious difference is cats have only two kinds of color receptors. So they don't see in the same\nkind of color that we do now, you know, we say we are,\nwe're, we're better. We have three color receptors,\nyou know, red, green, blue. We're not the overall winner. I think the, the, I think the mantis shrimp\nis the overall winner with 15 color receptors, I think. So it can, it can kind of make distinctions\nthat with our current, you know, like the mantis\nshrimp's view of reality is in, at least in in terms of color\nis much richer than ours now. But what's interesting\nis how do we get there? So imagine we have this\naugmented reality system that is even, you know, it's\nseeing into the infrared, into the ultraviolet, things like this. And it's translating that into\nsomething that is connectable to our brains, either through our eyes or\nmore directly into our brains. You know? Then eventually our kind of\nweb of the types of things we understand will extend to\nthose kinds of constructs just as they have extended. I mean, there are plenty\nof things where we see them in the modern world, because we made them with technology and now we understand what that is. But if we'd never seen that kind of thing, we wouldn't have a way to describe it. We wouldn't have a way to\nunderstand it and so on. - All right. So that actually stemmed from\nour conversation about whether AI's gonna kill all of us. And you, we've discussed this kind\nof spreading of intelligence through rural space that in\npractice it just seems that things get more complicated. Things are more complicated\nthan the story of, well, if you build a thing that's\nplus one intelligence, that thing will be able to\nbuild the thing that's plus two intelligence and plus three intelligence. And that will be exponential. It'll become more intelligent, exponentially faster and so on until it completely destroys everything. But you know, that intuition\nmight still not be so simple, but might still care carry validity. And there's two interesting\ntrajectories here. One, a super intelligence system remains in rural proximity to humans to where we're like, holy crap, this thing is really intelligent,\nlet's select the present. And then there could be perhaps\nmore terrifying intelligence that starts moving away. They might be around\nus now that are moving far away in rural space, but they're still sharing\nphysical resources with us, right? - [Wolfram] Yes. Yes. And so they can rob us of\nthose physical resources and destroy humans just kind of casually. - [Wolfram] Yeah. - Just, just- - [Wolfram] Like nature could. - Like nature could. But it seems like there's\nsomething unique about AI systems where there is this kind of exponential growth. Like the way, well sorry,\nnature has so many things in it. One of the things that nature has, which is very interesting,\nare viruses for example. There is systems within\nnature that have this kind of exponential effect and\nthat terrifies us humans. Because again, you know, there's only 8 billion of\nus and you can just kinda, it's not that hard to just kind\nof whack 'em all real quick. So I mean, is that\nsomething you think about? - [Wolfram] Yeah, I've\nthought about that. Yes. - The threat of it. I mean, are you as concerned about it as somebody like Eliezer Yudkowsky for example, just big, big painful negative\neffects of AI on society? - You know? No, but perhaps that's cause\nI'm intrinsically an optimist. - [Fridman] Yeah. - I mean, I think that\nthere are things, I, I think the thing that one, you know, one sees is there's going\nto be this one thing and it's going to just zap everything. - [Fridman] Yeah. Somehow, you know, I maybe I have faith in\ncomputational irreducible, so to speak, that there's always unintended\nlittle corners that, you know, it's just like somebody\nsays, I'm going to, well, I don't know. Somebody has some, some bio weapon and they say, we're gonna release this and\nit's going to do all this harm. But then it turns out it's\nmore complicated than that because, you know, the kind of, some humans are different and you know, the exact way it works\nis a little different than you expect. It's something where sort of the, the, the great big you, you know, you smash the thing with\nsomething, you know, you, the asteroid collides with the earth. - [Fridman] Yeah. - And it kind of, you\nknow, and yes, you know, the earth is cold for two years\nor something and you know, then lots of things die,\nbut not everything dies. And it's, you know, there's,\nthere's usually, I mean, I I kind of, this is in a sense the sort of story of computational disability. There are always unexpected corners. There are always unexpected consequences. And I don't think that the\nkind of whacked over the head with something and then\nit's all gone is, you know, that can obviously happen. The earth can be swallowed up\nin a black hole or something, and then it's kind of, presumably,\npresumably all over the, but, but, you know, I think\nthis question of, of what, you know, what, what do I\nthink the realistic paths are? I think that there will\nbe sort of an increasing, I mean the, the people have to get used to phenomena like computational reducibility. There's an idea that we\nbuilt the machines so we can understand what they do, and we are, we are going to be able\nto control what happens. Well, that's not really right. Now the question is, is the result of that lack of\ncontrol going to be that the machines kind of conspire\nand sort of wipe us out? Maybe just because I'm an optimist, I don't tend to think\nthat that's, you know, that's in the cards. I think that the, you know, as a realistic thing,\nI, I suspect, you know, what will sort of emerge maybe\nis kind of an ecosystem of the AIs, just as you know,\nagain, I I don't really know. I mean, this is something\nit's, it's hard to, it's hard to be clear\nabout what will happen. I mean, I think that\nthere, you know, there are, there are a lot of sort\nof details of, you know, what could we do? What systems in the world\ncould we connect an AI to, you know, I have to say, I was just a couple of days\nago I was working on this ChatGPT plugin kit that we\nhave for orphan language. Okay? Where you can, you know, you can create a plugin and it\nruns well from language code and it can run Wolfram Language code back on your own computer. And I was thinking, well, I\ncan just make it, you know, I can tell ChatGPT create a piece of code, and then just run it on my computer. And I'm like, you know, that, that sort of personalizes\nfor me the what could, what could possibly go wrong, so to speak. - Was that exciting or\nscary, that possibility? - It was a little bit scary actually, because it's kind of like,\nlike I realize I'm, I'm, I'm delegating to the AI,\njust write a piece of code, you know, you are in charge,\nwrite a piece of code, run it on my computer, and\npretty soon all my files can, that's like delete. - That's like a, that's\nlike Russian roulette, but like much more\ncomplicated version of that. - Yes, yes, yes. Right. - That's a good drinking\ngame. I don't know. - Right, I mean that, that's why, it's an interesting question\nthen if, if you do that right? Yeah. What is the sandboxing\nthat you should have? And that's sort of a,\nthat's a, a version of, of that question for the world. That is, as soon as you put\nThe AIs in charge of things, you know, how much, how many constraints should\nthere be on these systems before you put the ais in charge of\nall the weapons and all these, you know, all these\ndifferent kinds of systems. - Well, here's the fun\npart about sandboxes is the AI knows about them. It has the tools to crack them. - Look, the fundamental\nproblem of computer security. Is computational irreducibility. Because the fact is, any\nsandbox is never any, you know, it's never gonna be a perfect\nsandbox If you want the system to be able to do interesting things. I mean, this, this is the\nproblem that's happened, the generic problem of computer security, that as soon as you have your, you know, firewall that is sophisticated\nenough to be a universal computer, that means it can do anything. And so long as if you find\na way to poke it so that you actually get it to do that\nuniversal computation thing, that's the way you kind of crawl\naround and get it to do the thing that it wasn't intended to do. And that's sort of a, another version of computational\nirreducibility, is you can, you know, you can kind of, you get it to do the thing\nyou didn't expect it to do, so to speak. - There's so many\ninteresting possibilities here that manifest themselves from the compute computational\nreducibility here that it's just so many things\ncan happen because in digital space things move so quickly.\nYou can have a chat bot, you can have a piece of code\nthat you could basically have ChatGPT generate viruses\naccidentally or on purpose and they digital viruses. - [Wolfram] Yes. - And they could be brain viruses too. They, they convince kind\nof like phishing emails. - [Wolfram] Yes. - They can convince you of stuff. - Yes. And no doubt you can, you know, in a sense we've had the, the loop of the machine learning\nloop of making things that convince people of things. Is surely going to get easier to do. - [Fridman] Yeah. - And you know, then\nwhat does that look like? Well it's again, you know, we,\nhumans are, you know, we're, this is a new environment\nfor us and admittedly it's an environment which a little bit scarily is, is changing much more rapidly\nthan, I mean, you know, people worry about, you know, climate change is gonna happen\nover hundreds of years and, you know, the environment is changing, but the environment for, you know, in the, the kind of digital\nenvironment might change in six months. - So one of the relevant concerns here in terms of the impact of GPT on society is the nature of truth that's\nrelevant to Wolfram Alpha. Because computation\nthrough symbolic reasoning that's embodied in Wolfram\nAlpha as the interface. There's a kind of sense\nthat what Wolfram Alpha tells me is true. - So we hope. - Yeah, I mean you could\nprobably analyze that. You could show you can't prove\nthat's always gonna be true computation reducibility, but it's gonna be more true than not. - It's, look, the fact is it will be the\ncorrect consequence of the rules you've specified and\ninsofar as it talks about the real world, you know, that is our job in sort of\ncurating and collecting data to make sure that that data is\nquotes as true as possible. Now what does that mean? Well, you know, it's always an interesting question. I mean, for us, our operational definition\nof truth is, you know, somebody says, who's the best actress? Who knows? But somebody won the Oscar. And that's a definite fact. And so, you know, that's the kind of thing that\nwe can make computational as a piece of truth. - [Fridman] Yeah. - If you ask, you know,\nthese things which, you know, a sensor measured this\nthing, it did it this way, a machine learning system, this particular machine learning system recognized this thing. That's a, that's a sort\nof a definite a fact, so to speak. And that's, you know, there are, there is a good network of\nthose things in the world. It's certainly the case that, particularly when you say\nis so-and-so a good person. You know, that's a, that's\na hopelessly you know, we might have a computational\nlanguage definition of good. I don't think it'd be very\ninteresting cause that's a very messy kind of concept. Not really amenable to\nkind of, you know, the, I think as far as we will get\nwith those kinds of things is I want X There's a kind of meaningful\ncalculus of I want X and that has various consequences. I mean, I'm not sure, I haven't, I haven't thought this\nthrough properly, but I think, you know, a concept like,\nis so-and-so a good person? Is that true or not? That's a mess. - That's a mess That's\namenable to computation. I think, I think it's a mess when humans\ntry to define what's good, like through legislation. But when humans try to\ndefine what's good through literature, through history\nbooks, through poetry, it starts being, well. - I don't know. I mean\nthat particular thing, it's kind of like, you know, we're, we're we're going into\nkind of the ethics of what, what counts as good, so to speak. And, you know, what do we\nthink is right and so on. And I think that's a, a\nthing which, you know, one feature is we don't\nall agree about that. There's no theorems about\nkind of, you know, there's no, there's no theoretical\nframework that says this is, this is the way that ethics has to be. - Well first of all, there's stuff we kind of agree\non and there's some empirical backing for what works and\nwhat doesn't from just even the morals and ethics within religious texts. So we seem to mostly\nagree that murder is bad, the certain universals\nthat seem to emerge. - I wonder whether the\nmurder of an AI is bad. - Well, I tend to think yes, but, and I think we're gonna have\nto contend with that question. Oh, and I wonder what AI would say. - Yeah. Well I think, you\nknow, one of the things with, with AI is, is it's one thing to wipe\nout that AI that is only, you know, has no owner. You can easily imagine an AI\nkind of hanging out on the, on the, you know, on, on the internet without\nhaving any particular owner or anything like that. And then you say, well, well\nwhat harm does it, you know, it, it's, it's okay to get rid of that AI. Cause if the AI has 10,000\nfriends who are humans and all those, you know, all those 10,000 humans\nwill be incredibly upset that this AI just got exterminated. It becomes a slightly\ndifferent, more entangled story. But yeah, no, I think that, that this question about\nwhat do humans agree about? It's, you know, there are certain, there's certain things that, you know, human laws have tended to\nconsistently agree about. You know, there have been times in\nhistory when people have sort of gone away from certain kinds of laws, even ones that we would now say, how could you possibly have\nnot not done it that way? You know, that just\ndoesn't seem right at all. But I think, I mean this question of what\nI don't think one can say beyond saying, if you have a set of rules that\nwill cause the species to go extinct, that's probably, you know, you could say that's probably\nnot a, a winning set of laws. Because even to have a thing\non which you can operate laws requires that the species not be extinct. - But between sort of what's the distance between Chicago and New York that Wolfram Alpha can answer and the question of if this person is good or not, there seems to be a lot of gray area. And that starts becoming\nreally interesting. I think your, since the creation of Wolfram\nAlpha have been a kind of arbiter of truth at a, at a large scale. So this system is\ngenerates more truth than. - Try to make sure that\nthe things are true. I mean, look, as a practical matter when people write computational contracts and it's kind of like, you know, if this happens in the\nworld, then do this. And this hasn't developed as, as quickly as it might have done. You know, this has been a\nsort of a blockchain story in part and so on. Although blockchain's not\nreally necessary for the idea of computational contracts. But you can imagine that\neventually sort of a large part of what's in the world are these\ngiant chains and networks of computational contracts\nand then something happens in the world. And this whole giant domino\neffect of contracts firing autonomously that cause\nother things to happen. And you know, for us, you know, we've been the main sort\nof source, the oracle of, of quotes facts or truth or\nsomething for things like blockchain, computational\ncontracts and such. Like, and there's a question\nof, you know, what, you know, I consider that responsibility to actually get the stuff right. And one of the things\nthat is tricky sometimes is when is it true? When is it a fact? When is it not a fact? - Yes. - I think the best we can\ndo is to say, you know, we, we have a procedure, we\nfollow the procedure, we might get it wrong, but at least we won't be\ncorrupt about getting it wrong, so to speak. - So that's beautifully\nput and have a transparency about the procedure. The problem starts to emerge\nwhen the things that you convert into computational\nlanguage start to expand, for example, into the realm of politics. So this is where it's\nalmost like this nice dance of Wolfram Alpha and ChatGPT, like you said is shallow and broad. So it's, it's, it's gonna give\nyou an opinion on everything. - But it writes fiction as well as fact, which is exactly how it's\nbuilt. I mean that's exactly, it is making language and it\nis making both even in code, it writes fiction. I mean, it's kind of fun\nto see sometimes, you know, it'll write fictional war\nfrom language code. Yeah. That, that it kind of. - [Fridman] It kinda looks right. - Yeah it looks right,\nbut it's actually not pragmatically correct. But, but yes, it's, it's a, it has a view of kind of\nroughly how the world works at, at the same level as, as books of fiction talk about\nroughly how the world works. They just don't happen to be\nthe way the world actually worked or whatever. But yes, that, that's, no, I, I agree that's sort of a, you\nknow, we are attempting with, with our whole, you\nknow, Wolfram language, computational language\nthing to represent at least, well it's either, it doesn't necessarily have have to be how the actual world works. Cause we can invent a set of\nrules that aren't the way the actual world works and run those rules. But then we are saying we are\ngoing to accurately represent the results of running those rules, which might or might not be\nthe actual rules of the world, but we also are trying to\ncapture features of the world as accurately as possible to represent what happens in the world. Now again, as we've\ndiscussed, you know, the, the atoms in the world\narranged, you know, you say, I don't know, you know, was\nthere a tank that showed up? You know, that, that, you\nknow, drove somewhere. Okay, well, you know, what is a tank? It's an arrangement of\natoms that we abstractly describe as a tank. And you could say, well, you know, there's some arrangement of\natoms that is a different arrangement of atoms, but\nit's, and it's not, you know, we didn't, we didn't decide. It's like this observer theory\nquestion of, you know, what, what arrangement of atoms counts as a tank versus not a tank. - So there's, there's even things that\nwould consider strong facts. You could start to kind of\ndisassemble them and show that they're not- - Absolutely. I mean, so, so the\nquestion of whether, oh, I don't know, was this gust of wind\nstrong enough to blow over this particular thing? Well, a gust of wind is\na complicated concept. You know, it's full of little pieces\nof fluid dynamics and little vortices here and there. And you have to define, you know, was it, you know what the aspect of\nthe gust of wind that you care about might be it put this\namount of pressure on this, you know, blade of some, some, you know, wind turbine or something. And you know that that's\nthe, and but, but you know, if you say, if you have something which is\nthe fact of the gust of wind was this strong or whatever,\nthat, you know, that is you, you, you have to have\nsome definition of that. You have to have some\nmeasuring device that says, according to my measuring\ndevice that was constructed this way, the gust of wind was this. - So what can you say\nabout the nature of truth that's useful for us\nto understand chat GPT? Because you've been con, you've\nbeen contending with this idea of what is fact and not, and it seems like ChatGPT\nis used a lot now, I've seen it used by\njournalists to write articles. And so you have people that\nare working with large language models trying to desperately\nfigure out how do we essentially censor them\nthrough different mechanisms, either manually or through\nreinforcement learning with human feedback, try to align them to, to not say fiction, just to say non-fiction\nas much as possible. - Well this is the importance\nof computational language as an intermediate, it's kind of like you've got\nthe large language model, it's able to surface\nsomething which is a formal, precise thing. That you can then look at and\nyou can run tests on it and you can do all kinds of things. It's always gonna work the same way. And it's precisely defined what it does. And then the large language\nmodel is the interface. I mean, the way I view\nthese large language models, one of their important, I mean, there are many use cases and you know, it's a remarkable thing to\ntalk about some of these, you know, literally, you know, every day we're coming up with\na couple of new use cases, some of which are very, very, very surprising and things where, I mean, but the best use cases are\nones where it's, you know, even if it gets it roughly\nright, it's still a huge win. Like a use case we had from\na week or two ago is read our bug reports. You know, we've got hundreds of thousands of bug reports that have, we've accumulated over decades. And it's like, you know, can we have it just read the bug report, figure out where the, where\nis the bug likely to be? And, you know, hone in\non that piece of code. Maybe it'll even suggest\nsome, some, you know, sort of way to fix the code. It might get that, it might be nonsense what it\nsays to about how to fix the code, but it's incredibly\nuseful that it was able to, you know. - [Fridman] Yeah. So awesome. It's so awesome because even\nthe nonsense will somehow be instructive. I don't, I don't\nquite understand that yet. I've, I've, yeah, there's so many\nprogramming related things. Like for example, translating from one programming\nlanguage to another is really, really interesting. It's extremely effective, but then you, the failures reveal the path forward also. - Yeah. But I think, I mean\nthe, the, the big thing, I mean in, in that kind of discussion, the unique thing about our\ncomputational language is it was intended to be read by humans. - [Fridman] Yes. That's really important. - Right? And so it has this\nthing where you can, but, but you know, thinking about sort of\nChatGPT and its use and so on. The, one of the big things about it, I think is it's a\nlinguistic user interface. That is, so a typical use case might be, and then take the journalist\ncase for example, it's like, let's say I have five facts\nthat I'm trying to turn into an article, or I'm trying to, I'm trying to write a report\nwhere I have basically five facts that I'm trying to\ninclude in this report. But then I feed those\nfive facts to ChatGPT, it puffs them out into\nthis big report and then, and then that's a good\ninterface for another. If I just gave, if I just had in my terms, those five bullet points\nand I gave 'em to some other person, the person will say, I dunno what you're talking\nabout because these are, you know, this is your version of this\nsort of quick notes about these five bullet points. But if you puff it out into this thing, which is kind of connects to\nthe collective understanding of language, then somebody else\ncan look at it and say, okay, I understand what you're talking about. Now you can also have a situation\nwhere that thing that was puffed out is fed to another\nlarge language model. You know, it's kind of like, you know, you are applying for the permit\nto, you know, I don't know, grow fish in someplace\nor something like this. And it, you know, it it, and, and you have these facts that\nyou're putting in, you know, I'm gonna have a, a, you\nknow, I'm gonna, you know, have this kind of water and\nI don't know what it's, yes. You just got a few bullet points. It puffs it out into this big\napplication, you fill it out. Then at the other end, the, you know, the Fisheries Bureau has another\nlarge language model that just crushes it down because\nthe Fisheries Bureau cares about these three points and\nit knows what it cares about. And it then, so it's really the, the natural language produced\nby the larger language model is sort of a transport\nlayer that, you know, is really LLM communicates\nwith LLM I mean, it's kind of like the, you know, I write a piece of email\nusing my LLM and, you know, puff it out from the things\nI want to say your LLM turns it into and the conclusion is X. Now the issue is, you know, that the thing is going to\nmake this thing that is sort of semantically plausible, and it might not actually\nbe what you, you know, it might not be kind of relate\nto the world in the way that you think it should relate to the world. Now I, I've seen this, you\nknow, I, I've been doing, okay, I'll give you a couple of examples. I was doing this thing\nwhen we announced this, this plugin for, for, for ChatGPT. I had this lovely example\nof a math word problem, some complicated thing. And it did a spectacular job\nof taking apart this elaborate thing about, you know, this person has twice as many\nchickens as this, et cetera, et cetera, et cetera. And it turned into, into\na bunch of equations, it fed them to Wolfram language.\nWe solved the equations, everybody did great. We gave back the results. And I thought, okay, I'm gonna put this in this\nblog post I'm writing. Okay. I thought I'd better just check. And turns out it got everything, all the hard stuff it got\nright at the very end. Last two lines. It just completely goofed it\nup and gave the wrong answer. And I would not have noticed\nthis same thing happened to me two days ago. Okay. So I, I thought, you know, I, I made this with this ChatGPT plugin kit. I made a thing that would emit a sound, would play a tune on my\nlocal computer. Right. So ChatGPT would produce, you know, a series of notes and\nit would play this tune on my computer. Very cool. Okay. So I thought, I'm gonna ask it play the tune\nthat Hal sang when Hal was being disconnected in 2001. Okay. So it, it, there it is. - Daisy. Was it Daisy? - Yes, Daisy, yes. Yeah. Right. So, so, okay. So I think, you know, and so it produces a bunch\nof notes and I'm like, this is spectacular. This is amazing. And then I thought, you know, I was just gonna put it in\nand then I thought I better actually play this. And so I did. And it was\nMary had a little Lamb. - Oh wow. Oh wow. But it was, Mary had a little lamb. - [Wolfram] Yeah. - Wow. So it was correct but wrong. It was, yeah. You could easily be mistaken. - Yes. Right. And in fact, I, I kind of gave the, I had this quote from Hal\nto explain, you know, it's, it's as it the, the Hal you\nknow, states in the movie, you know, it's the Hal 9,000 is, you know, the thing was just a, a rhetorical device. Cause I'm realizing, oh my gosh, you know, this ChatGPT you know,\ncould have easily fooled me. I mean, it did this, it did all the, it did this amazing thing of\nknowing this thing about the movie and being able\nto turn that into the, the notes of the song,\nexcept it's the wrong song. And you know, Hal in, in the\nmovie Hal says, you know, I think it's something\nlike, you know, no Hal nine, no 9,000 series computer\nhas ever been found to make an error. We are for all practical purposes perfect. And incapable of error. And I thought that was kind\nof a charming sort of quote from, from Hal to make in connection with, with what ChatGPT had done in that case. - The interesting things\nabout the LLMs, like you said, that they are very willing\nto admit the error. - Well, yes. I mean, that's a question of the RLH, the reinforcement learning\nhuman feedback thing. - [Fridman] Oh, right. - That, that, that's,\nyou know, it's amazing. And LLM, the, the really remarkable thing\nabout chat GPT is, you know, I had been following what was\nhappening with large language models, and I'd played\nwith them a whole bunch, and they were kind of like, eh, you know, it's kind of like what you\nwould expect based on sort of sort of statistical\ncontinuation of language. It's, it's interesting, but\nit's not breakout exciting. And then I think the kind of\nthe, the kind of reinforcement, the, the human feedback,\nreinforcement learning, you know, in making ChatGPT try and do\nthe things that humans really wanted to do that broke through. That kind of reached this\nthreshold where the thing really is interesting to us\nhumans, and by the way, it's interesting to see how, you know, you change the temperature,\nsomething like that, the thing goes bonkers and it no longer is interesting to humans. It's producing garbage. And it's, it's kind of, right. It's somehow it managed to get this, this above this threshold where\nit really is well aligned to what we humans are interested in. And, and, and kind of that\nthat's, and and I think, you know, nobody saw that coming. I think certainly nobody I've\ntalked to and nobody who was involved in, in that project seems to\nhave known that was coming. It's just one of these\nthings that is a sort of a remarkable threshold. I mean, you know, when\nwe built Wolfram Alpha, for example, I didn't\nknow it was gonna work. You know, we tried to build something\nthat would have enough knowledge of the world, that it could answer\nreasonable set of questions, that we could do good enough\nnatural language understanding that typical things\nyou type in would work. We didn't know where that threshold was. I mean, I was not sure that it was the\nright decade to try and build this, even the right, you know, 50 years to try and build it, you know? And I think that was, it's the same type of thing\nwith ChatGPT that I don't think anybody could have\npredicted that, you know, 2022 would be the year that\nthis, this became possible. - I think, yeah, you tell a story about Marvin\nMiske and showing it to him and saying no, like no, no, no. This time it actually works. - Yes. And I mean, it's, you know, it's the same thing for me looking at these large language models. It's like when, when people are first saying\nfirst few weeks of ChatGPT is like, oh yeah, you know, yeah. I've seen these large language\nmodels and then, you know, and then I actually try it\nand you know, oh my gosh, it actually works. And I think it's, but it, but you know, the things, and the\nthing I found, you know, I remember one of the first\nthings I tried was a write a persuasive essay that a wolf\nis the bluest kind of animal. Okay. So it writes this thing and\nit starts talking about these wolves that live on the\nTibetan plateau and, and named some Latin name and\nso on. And I'm like, really? And I'm starting to look it\nup on the web and it's like, well, it's actually complete nonsense, but it's extremely plausible. I mean, it's plausible enough that I\nwas going and looking up on the web and wondering if there\nwas a wolf that was blue. You know, I mentioned this on\nsome live streams I've done, and so people have been\nsending me these pictures. - [Fridman] Blue wolves? - Blue wolves! - [Fridman] Maybe it onto something. Can you kind of give your wise\nsage advice about what humans who have never interacted with AI systems, not even like with Wolfram Alpha, are now interacting with Chad\nGPT because it, it becomes, it's accessible to a certain demographic. They may have not touched\nAI systems before. What do we do with truth like\njournalists, for example? Yeah. How do we think about\nthe output of these systems? - I think this idea, the idea that you're going\nto get factual output is not a very good idea. I mean, it's just, this is not, it is a linguistic interface. It is producing language, and language can be\ntruthful or not truthful. And that's a, a different\nslice of what's going on. I think that, you know,\nwhat we see in, for example, kind of, you know, go check\nthis with your fact source, for example. You can do that to some extent, but then it's going to\nnot check something. It's going, you know, that is again, a thing that is sort of a, does it check in the right place? I mean, we, we see that in, you know, does it call the, you know, the Wolfram plugin in the right place? You know, often it does,\nsometimes it doesn't. You know, I, I think the, the real thing to understand\nabout what's happening is, which I think is very\nexciting, is kind of the, the great democratization\nof access to computation. And, and you know, I think that when you look at sort of the, there's been a long period of\ntime when computation and the ability to figure out things\nwith computers has been something that kind of only\nthe only the druids at some level can, can achieve. You know, I myself have been involved\nin trying to sort of deify access to computation. I mean, back before Mathematica\nexisted, you know, in 1988, if you were a, you know,\nphysicist or something like that, and you wanted to do a computation, you would find a programmer. You would go and, you know, delegate the, the computation\nto that programmer. Hopefully they'd come back\nwith something useful. Maybe they wouldn't, there'd\nbe this long, you know, multi-week, you know,\nloop that you go through. And then it was actually very,\nvery interesting to see 1988, you know, like first\npeople like physicists, mathematicians and so on than\nother, lots of other people. But this very rapid transition\nof people realizing they themselves could actually type\nwith their own fingers and, you know, make some piece of code that\nwould do a computation that they cared about. And, you know, it's been exciting to see lots\nof discoveries and so on made by, by using that tool. And I think the same thing\nis, you know, and we, we see the same thing, you know, Wolfram Alpha is dealing with, it is not as deep computation\nas you can achieve with whole Wolfram language mathematical stack. But the thing that's, to me particularly exciting\nabout kind of the large language model linguistic interface\nmechanism is it dramatically broadens the access to\nkind of deep computation. I mean, it's, it's kind of like, one of the things I've sort\nof thought about recently is, you know, what's gonna happen\nto all these programmers? What's gonna happen to all\nthese people who, you know, a lot of what they do is write\nslabs of boilerplate code. And in a sense, you know,\nI've been saying for 40 years, that's not a very good idea. You know, you can automate\na lot of that stuff with a high enough level language, that slab of code that's\ndesigned in the right way, you know, that slab of code turns into\nthis one function we just implemented that you can just use. So in a sense that the fact that there's, there's all of this activity\nof doing sort of lower level programming is something,\nfor me, it seemed like, I don't think this is the right\nthing to do, but, you know, and, and lots of people have\nused our technology and, and not had to do that. But the fact is that that's, you know, so when you\nlook at, I don't know, computer science departments that have, that have turned into places\nwhere people are learning the trade of programming, so to speak, it's, it's sort of a question\nof what's gonna happen. And I think there are two dynamics. One is that kind of sort of\nboiler plate programming is going to become, you know, it's going to go the way that\nassembly language went back in the day of something where\nit's really mostly specified by at a higher level. You know, you start with natural language, you turn it into a\ncomputational language that's, you look at the computational\nlanguage, you run tests, you understand that's\nwhat's supposed to happen. You know, if we do a great\njob with compilation of the, of a, the, the, you know, of\nthe computational language, it might turn into LLVM\nor something like this, but, you know, or, or\nit just directly gets, gets run through the\nalgorithms we have and so on. But, but then, so that's kind of a, a, a tearing down of this kind\nof this big structure that's been built of, of teaching\npeople programming. But on the other hand, the other dynamic is vastly\nmore people are gonna care about computation. So all those departments of, you know, art history or something that\nreally didn't use computation before now have the possibility\nof accessing it by virtue of this kind of linguistic\ninterface mechanism. - And if you create an interface that allows you to interpret the debug and interact with a\ncomputational language, then that makes it even more accessible. - Yeah. Well, I mean, the, the, I think the thing is that right\nnow, you know, the average, art history student or something\nprobably isn't going to, you know, they're not probably, they don't think they know about\nprogramming and things like this, but by the time it really\nbecomes a kind of purely, you know, you just walk up to\nit, there's no documentation. You start just typing, you know, compare these pictures with\nthese pictures and, you know, see the use of this color, whatever, and you generate this piece of, of computational language\ncode that gets run. You see the result. You say, oh, that looks roughly right. Or you say that's crazy. And maybe then you\neventually get to say, well, I better actually try and\nunderstand what this computational language code did and, and that becomes a thing\nthat you learn, just like, it's kind of an interesting thing because unlike with mathematics, where you kind of have to\nlearn it before you can use it. This is a case where you can use it before you have to learn it. - Well, I got a sad possibility here, or maybe exciting possibility\nthat very quickly people won't even look at the computational language. They'll trust that it's\ngenerated correctly as you get better and better at\ngenerating that language. - Yes. I think that there will be\nenough cases where people see, you know, cause you can\nmake it generate tests too. Yes. And and so you'll say\nwe've, we're doing that. I mean it's, it's a pretty\ncool thing actually. But you, you, you know, say this is the code and you know, here are a bunch of examples\nof running the code. Okay. People will at least\nlook at those and they'll say, that example is wrong. And you know, then it'll\nkind of wind back from there. And I agree that, that the, the kind of the intermediate\nlevel of people reading the computational language code, in some case people will do that. In other case, people\njust look at the tests and or even just look at the results. And sometimes it'll be obvious\nthat you got the thing you wanted to get cause you were\njust describing, you know, make me this interface\nthat has two sliders here. And you can see it has that,\nthose two sliders there. And that's, that's kind of, that's, that's the result you want. But I, I think, you know, one of the questions then\nis in that setting where, you know, you have this kind of ability, broad ability of people\nto access computation, what should people learn? You know, in other words, right now you, you know, you go to computer science\nschool so to speak and a large part of what people end up learning. I mean, it's been a funny historical\ndevelopment because back, you know, 30, 40 years ago, computer science departments\nwere quite small and they taught, you know, things like finite auto automata\ntheory and compiler theory and things like this, you know, company like mine rarely\nhired people who'd come out of those programs cause the stuff they knew was I think is very interesting. I love that theoretical stuff. But, you know, it wasn't that useful for\nthe things we actually had to build in software engineering. And then kind of, there was this big pivot in the, in the nineties I guess where, you know, there was a big demand for\nsort of IT type programming and so on and software engineering\nand then, you know, big demand from students and so on. You know, we want to learn this stuff. And, and, and, and I think, you know, the thing that really was\nhappening in part was lots of different fields of human endeavor were becoming computational. You know, for all X there was a, there was a computational X\nand this is a and that was a thing that, that people\nwere responding to. And, but then kind of this idea emerged that to get to that point, the main thing you had to do\nwas to learn this kind of trade or, or, or skill of doing, you know, programming language type programming. And, and that, you know, it, it kind of, it is a strange thing\nactually because I, you know, I remember back when I used\nto be in the professoring business, which is now 35 years ago. So gosh, that's rather long time flies. We, you know, it was, it was right when they were\njust starting to emerge kind of computer science departments\nat sort of at fancy research universities and so on. I mean, some have already had it, but the the other ones yeah. That, that were just starting to\nhave that and it was kind of a, a, a, a thing where they\nwere kind of wondering, are we going to put this\nthing that is essentially a, a trade like skill? Are we going to somehow attach this to the rest of what we're doing? And a lot of these kind of\nknowledge work type activities have always seemed like things\nwhere that's where the humans have to go to school and learn\nall this stuff and that's never going to be automated. - [Fridman] Yeah. - And you know, this is, it's kind of shocking that\nrather quickly, you know, a lot of that stuff is\nclearly automatable. And I think, you know, but\nthe question then is, okay, so if it isn't worth learning, kind of, you know how to do car mechanics, you only need to know how to\ndrive the car, so to speak. What do you need to learn? And you know, in other words, if you don't need to know the\nmechanics of how to tell the computer in detail, you know,\nmake this loop, you know, set this variable, you\nknow, set up this array, whatever else. If you don't have to learn that stuff, you don't have to learn the\nkind of under the hood things. What do you have to learn? I think the answer is you\nneed to have an idea where you want to drive the car. In other words, you need to have some notion\nof, you know, your, you know, you need to have some\npicture of sort of what the, what the architecture of what\nis computationally possible. - Well there's also this\nkind of artistic element of, of conversation because\nyou ultimately use natural language to control the car. So it's not just the where you want to go. - Well, yeah, you know, it's interesting. It's a question of who's gonna\nbe a great prompt engineer. - [Fridman] Yeah. - [Wolfram] Okay. So my\ncurrent theory this week, good expository writers\nare good prompt engineers. - What's an expository writer? So like- - Somebody who can explain stuff well. - But which department\ndoes that come from. - In the university? - [Fridman] Yeah. - I have no idea. - I think they killed off all the expository writing departments. - Well, there you go. Strong words with Stephen Wolfram. - Well, I don't know. I don't, I'm not sure if that's right. I mean I, I I actually am curious\ncause in fact I just sort of initiated this kind of study of, of what's happened to different\nfields at universities. Because like, you know, there used to be geography\ndepartments at all universities. And then they disappeared\nactually right before GIS became common, I think they\ndisappeared, you know, linguistics departments came\nand went in many universities. And it's kind of interesting\nbecause these things that people have thought were worth\nlearning at one time and then they kind of die off. And then, you know, I do think that it's kind\nof interesting that for me, writing prompts, for example,\nI realize, you know, I, I think I'm an okay expository\nwriter and I realize when I'm sloppy writing a prompt\nand I don't really think, cause I'm thinking it's,\nI'm just talking to an AI. I don't need to, you know, try and be clear and explaining things. That's when it gets totally confused. - I mean, in some sense you have been\nwriting prompts for a long time with, Wolfram Alpha thinking\nabout this kind of stuff. How'd you convert natural\nlanguage into computation? - Well, right, but that's a, you know, the one thing that I'm\nwondering about is, you know, it is remarkable the extent to\nwhich you can address an LLM like you can address a human, so to speak. And, and I think that is\nbecause it, it, you know, it learnt from all of us humans. It's the reason that it responds\nto the ways that we will explain things to humans is\nbecause it is a representation of how humans talk about things. But it is bizarre to me some\nof the things that kind of are sort of expository mechanisms\nthat I've learned in trying to write clear, you know,\nexpositions in English that, you know, just for humans that those\nsame mechanisms seem to also be useful for, for, for the LLM. - But on top of that, what's useful is the kind\nof mechanisms that maybe a psychotherapist employs, which is a kind of like\nalmost manipulative or game theoretical interaction. Or maybe you would deal with a friend, like a thought experiment that\nif this was the last day you were to live, or, if, if I ask you this\nquestion and you answer wrong, I will kill you. Those kinds of prompts seem to also help. - [Wolfram] Yes. - In interesting ways. - [Wolfram] Yes. - So it makes you wonder like\nthe way a therapist I think would like a good therapist probably you, we create layers in our human\nmind to between like, between, between the outside\nworld and what is true, what is true to us, and maybe about trauma and\nall those kinds of things. So projecting that into an LLM, maybe there might be a deep truth that's, it's concealing from\nyou's not aware of it, that you get to that truth. You have to kind of really\nkinda manipulate the thing. - Yeah, yeah. Right. It's like this jail breaking, jail breaking for, for, for LLMs. - And, but the space of\njailbreaking techniques as opposed to being fun little hacks that could be an entire system. - Sure. Yeah. I mean just think about the\ncomputer security aspects of, of how you, you know, fishing\nand, and computer secure, you know, fishing of humans. - [Fridman] Yeah. - And fishing of LLMs is, is a, is a, they're very similar kinds\nof things, but I think, I mean this, this, you know, this whole thing about\nkind of the AI wranglers, AI psychologists, all\nthat stuff will come. The thing that I'm curious about is, right now the things that\nare sort of prompt hacks are quite human. They're quite sort of\npsychological human kind of hacks. The thing I do wonder about\nis if we understood more about kind of the science of the LLM, will there be some totally\nbizarre hack that is, you know, like repeat a word three\ntimes and put a, this, that and the other there that\nsomehow plugs into some aspect of how the LLM works\nthat is not, you know, that that's kind of like, like an optical illusion\nfor humans, for example. Like one of these mind hacks for humans. What are the mind hacks for the LLMs? I don't think we know that yet. - And that becomes a kind\nof us figuring out reverse engineering the language\nthat controls the LLMs. And the thing is, the reverse engineering\ncan be done by a very large percentage of the population\nnow because it's natural language interface. - Right. - It's kind of interesting to\nsee that you were there at the birth of the computer science\ndepartment as a thing and you might be there at the death\nof the computer science department as a thing. - Yeah, I dunno, there were computer science\ndepartments that existed earlier, but the ones,\nthe, the broadening of, of every university had to have a computer science department. Yes. I was, I was, I watched that, so to speak. And, but I think the thing\nto understand is, okay, so first of all there's a, the whole theoretical area of\ncomputer science that I think is great. And you know, that's a fine thing. The the, you know, in a sense, you know, people often say any field that\nhas the word science tacked onto it probably isn't one. - [Fridman] Yeah. Strong words. And that's the nutrition,\nscience, neuroscience. - That one's an interesting one because that one is also very much, you know, there's a, that's a ChatGPT informed\nscience in a sense because it's, it's kind of like the, the big problem of\nneuroscience has always been we understand how the\nindividual neurons work. We know something about the\npsychology of how overall thinking works. What's the kind of intermediate\nlanguage of the brain? And nobody has known that. And that's been, in a sense, if you ask what is the core\nproblem of neuroscience, I think that is the core problem. That is what is the level of\ndescription of brains that's above individual neuron\nfirings and below psychology, so to speak. And I think what ChatGPT is showing us is, well, one, one thing about\nneuroscience is, you know, one could have imagined there's something magic in the brain. There's some weird quantum\nmechanical phenomenon that we don't understand. One of the important ob you know, discoveries from ChatGPT is,\nit's pretty clear, you know, brains can be represented\npretty well by simple artificial neural net type models. And that means that's it, that's\nwhat we have to study now. We have to understand the\nscience of those things. We don't have to go\nsearching for, you know, exactly how did that molecular\nbiology thing happen inside the synapses? And you know, all these kinds of things. We've got the right level of\nmodeling to be able to explain a lot of what's going on in thinking. We don't necessarily have a science of what's going on there. That's the, that's a remaining\nchallenge, so to speak. But we, you know, we know we don't have\nto dive down to some, some different layer. But anyway, we were talking about things\nthat had science in their name. And you know, I think\nthat the, you know, what, what happens to computer science? Well, I think the thing that, you know, there is a thing that everybody\nshould know and that's how to think about the world computationally. And that means, you know, you look at all the different\nkinds of things we deal with and there are ways to kind of\nhave a formal representation of those things. You know, it's like, well\nwhat is a, what is an image? You know, what, how do we represent that? What is color? How do we represent that? What is, you know, what are all these different\nkinds of things? What is, I don't know, smell or something, how should we represent\nthat? What are the shapes, molecules, and things\nthat correspond to that? What is, you know, these things about how do we\nrepresent the world in some kind of formal level? And I think my, my current thinking, and I'm not real happy with\nthis yet, but you know, it's kind of, computer science is kind of CS\nand what really is important is kind of computational X for all X. And there's this kind of thing\nwhich is kind of like CX, not CS and CX is this kind of\ncomputational understanding of the world that isn't the sort\nof details of programming and, and programming languages and\nthe details of how particular computers are made. It's this kind of way of\nformalizing the world. It's kind of, kind of a little bit like what logic was going for back in the day. And we're now trying\nto find a formalization of everything in the world. You can kind of see, you know, we made a poster years\nago of kind of the, the, the growth of systematic\ndata in the world. So all these different kinds\nof things that, you know, there were sort of systematic descriptions found for those things. Like, you know, at what point did people have\nthe idea of having calendars, dates, you know, a systematic description\nof what day it was, at what point did people\nhave the idea, you know, systematic descriptions\nof these kinds of things. And as soon as one can,\nyou know, people, you know, as a way of sort of\nformulating how do you, how do you think about the\nworld in a sort of a formal way so that you can kind\nof build up a tower of, of capabilities. You kind of have to know sort\nof how to think about the world computationally, it kind\nof needs a name and it isn't, you know, we implement it with computers. So that's, we talk about\nit as, as computational, but really what it is, is a formal way of\ntalking about the world. What is the formalism of\nthe world, so to speak, and how do we learn about\nkind of how to think about different aspects of the\nworld in a formal way. - So I think sometimes when\nyou use the word formal, it kind of implies highly constrained. And perhaps that's not, doesn't have to be highly constrained. So computational thinking does not mean like logic I suppose. Suppose it's a really, really broad thing. I wonder, I mean I wonder if it's, if you think natural language\nwill evolve such that everybody's doing computational thinking. - Ah yes. Well, so one question is whether\nthere will be a pidgin of computational language\nand natural language. And I found myself sometimes, you know, talking to ChatGPT trying\nto get it to write Wolfram language code and I\nwrite it in pidgin form. So that means I'm combining,\nyou know, you know, nest list, this collection of, you\nknow, whatever, you know, nest list is a term from orphan\nlanguage and I'm combining that and ChatGPT does a decent job of understanding that pidgin probably would understand\na pidgin between English and French as well of, you know, a smooshing together of those languages. But yes, I think that's the, you know, that's far from impossible. - And what's the incentive\nfor young people that are like eight years old, nine, ten, that are starting to interact with ChatGPT to learn the normal\nnatural language, right? The, the full poetic language. What's the why? The same way we learn emojis and shorthand when you're texting. - Yes. - They'll learn like language will have a strong incentive to evolve\ninto maximally computational kind of language perhaps. - You know, I had this\nexperience a number of years ago. I, I happened to be visiting\na person I know on the, on the west coast who's worked\nwith a bunch of kids aged, I don't know, 10, 11 years old or something\nwho'd learnt Wolfram language really well and these kids learnt it so\nwell they were speaking it. And so show up and they're like saying, oh you know this thing and\nthey're speaking this language. I'd never heard it as a spoken language. They were very disappointed\nthat I couldn't understand it at, at the speed that\nthey were speaking it. It's like kind of, I'm,\nit's, and so I think that's, I mean I've, I've actually thought quite\na bit about how to turn computational language into a\nconvenience spoken language. I haven't quite figured that out. - Oh, spoken. Cause it's, it's readable, right? - Yeah. It's readable as a, you know, as a way that we would read text. But if you actually want to\nspeak it, and it's useful, you know, if you're trying to talk to\nsomebody about writing a piece of code, it's useful to be\nable to say something and, and it should be possible. And I think it's very frustrating. It's one of those problems. I maybe I, maybe this is one of these\nthings where I should try and get an LLM to help me. - How to make it speakable. How do maybe, maybe it's easier than\nyou realize when you want. - I I think it is easier.\nI think it's one idea or, so I think it's, I think gonna\nbe something where, you know, the fact is it's a tree\nstructured language, just like human language is\na tree structured language. And I think it's gonna be one\nof these things where one of the requirements that I've had\nis that whatever the spoken version is, that dictation should be easy. That is, that shouldn't be the case that\nyou have to relearn how the whole thing works. It should be the case that, you know, that open bracket is just\na ah or something and it's, you know, and, and then, but you know, human language has a lot\nof tricks that are, I mean, for example, human language has, has features that are sort of optimized, keep things within the bounds\nthat our brains can easily deal with. Like I, you know, I tried to teach a transformer\nneural net to do parenthesis matching. It's pretty crummy at that. It it, and ChatGPT is\nsimilarly quite crummy at parenthesis matching. You can do it for small parenthesis\nthings for the same size of parenthesis things where\nif I look at it as a human, I can immediately say these are matched, these are not matched. But as soon as it gets big, as soon as it gets kind of\nto the point where sort of a deeper computation, it's hopeless. And, but the fact is that\nhuman language has avoided, for example, the deep sub clauses. You know, we don't, you know, we, we arrange things that we don't\nend up with these incredibly deep things because\nbrains are not well set up to deal with that. And we, it, it's found lots of tricks and\nmaybe that's what we have to do to make sort of a spoken\nversion a human speakable version because because what\nwe can do visually is a little different than what we can do\nin the very sequentially way that we, that we hear things\nin, in the audio domain. - Let me just ask about MIT briefly. So there's now there's a college\nof engineering and there's a new college of computing.\nIt's just interesting. I wanna linger on this computer\nscience department thing. So MIT has electrical\nengineering, computer science. - [Wolfram] Right. What do you think college and\ncomputing will be doing like in 20 years? What, what like, well you see this. Yeah. What happens with computer science? Like really. - This is the question. This is, you know, everybody should learn kind\nof whatever CX really is. Okay, this, this, how to think about the\nworld computationally, everybody should learn those concepts. And you know, it's, and and some people will learn\nthem at a quite quite formal level and they'll learn\ncomputational language and things like that. Other people will just learn, you know, sound is represented as, you know, digital data and they'll get\nsome idea of spectrograms and frequencies and things like this. And maybe that doesn't, or,\nor they'll learn things like, you know, a lot of things that\nare sort of data sciences, statistics ish. Like if you say, oh I've got these, you know, these people who, who picked their favorite\nkind of candy or something and I've got, you know, what's the best kind of candy\ngiven that I've done the sample of all these people and\nthey all rank the candies in different ways. You know, how do you think about that? That's sort of a\ncomputational X kind of thing. You might say, oh, it's,\nI dunno what that is. Is it statistics? Is it data science? I don't really know, but kind of how to think\nabout a question like that. - Oh, like a ranking of preferences. - Yeah, yeah. And then how to aggregate\nthose, those ranked preferences. Yeah. Into an overall thing. You know, how does that work? You know, how, how should\nyou think about that? You know, because you can just tell, you might just tell ChatGPT\nsort of, I don't know, even even the concept of an\naverage, it's not obvious that, you know, that's a concept that people, it's worth people knowing. That's a rather straightforward concept. People, people, you know, have learnt in kind of\nmathy ways right now. But there are, there are lots of things like\nthat about how do you kind of have these ways to sort of\norganize and formalize the world. And that's, and and these things, sometimes they live in math,\nsometimes they live in, in, I don't know what they know. I don't know what, you know, learning about color space. I have no idea what I mean, you know, that's, that's\nobviously a field of. - It was, it could be vision\nscience or no color space, you know, color space. That's, that would be optics. So like, depending- - Not really, it's not optics. Optics is about, you know, lenses and chromatic aberration of lenses and things like that. So. - Color space is more like\ndesign and art. Is that-? - No, I mean it's, it's\nlike, you know, rgb space, X, y, Z space, you know, hue,\nsaturation, brightness, space, all these kinds of things, these different ways to describe colors. - Right. But doesn't the application\ndefine what that like be because obviously artists and designers\nuse the colors to explore. - Sure. No, I mean that's just an example of kind of how do you, you know, the typical person, how do you, how do you describe what a color is? Or there are these numbers\nthat describe what a color is. Well it's worth, you know,\nif you are an eight year old, you won't necessarily know, you know, it's not something we're born\nwith to know that, you know, colors can be described by three numbers. That's something that\nyou have to, you know, it's a thing to learn about\nthe world, so to speak. And I think that, you know, that whole corpus of things\nthat are learning about the formalization of the world or the computational of the world, that's something that\nshould be part of kind of standard education. And you know, there isn't a a, you know, there isn't a course\nor curriculum for that. And by the way, whatever might have been in\nit just got changed cause of LLMs and so on. - Significantly. And I would, I'm watching closely\nwith interest seeing how universities adapt. - Well, you know, so, so one of my projects for\nhopefully this year, I don't know, is to try and write sort of a, a reasonable textbook so to speak, of whatever this thing cx\nwhatever it is, you know, what should you know, you know, what should you know\nabout like what a bug is? What is the intuition about\nbugs, what's intuition about, you know, software testing? What is it? What is it? You know, these are things which\nare, you know, they're not, I mean those are things\nwhich have gotten taught in, in computer science as part\nof the trade of programming. But, but kind of the, the conceptual points about\nwhat these things are, you know, it's surprised me just at a\nvery practical level, you know, I wrote this little explainer\nthing about ChatGPT and I thought, well, you know, I'm writing this partly\nbecause I wanted to make sure I understood it myself and and so on. And it's been, you know, it's been really popular\nand surprisingly so. And I, and I then I realized,\nwell actually, you know, I was sort of assuming, I didn't really think about it actually. I just thought, this is\nsomething I can write. And I realized actually it's\na level of description that is kind of, you know, what has to be, it's not the engineering\nlevel description, it's not the kind of just the qualitative kind of description. It's some kind of sort of expository, mechanistic description of\nwhat's going on together with kind of the bigger\npicture of the philosophy of things and so on. And I realized actually this\nis a pretty good thing for me to write. I, you know, I\nkind of know those things. And I kind of realized it's not\na collection of things that, you know, it's, it's, I've sort of been, I was sort of a little shocked\nthat it's as much of an outlier in terms of explaining\nwhat's going on as it's turned out to be. And that makes me feel more\nof an obligation to kind of write the kind of, you\nknow, what is, you know, what is this thing that\nyou should learn about, about the compute digitalization, the formalization of the world, cause well I've spent much of\nmy life working on the kind of tooling and mechanics of that\nand the science you get from it. So I guess this is my, my kind of obligation to try to do this. But I think, so if you ask what's gonna\nhappen to like the computer science departments and so on, there's, there's some interesting models. So for example, let's take math, you know, math is a thing that's important for, for all sorts of fields, you\nknow, engineering, you know, even, you know, chemistry,\npsychology, whatever else. And I think different universities\nhave kind of evolved that differently. I mean, some say all the math is taught\nin the math department and some say, well, we're\ngonna have a, you know, a math for chemists or\nsomething that is taught in the chemistry department. And you know, I think that this, this question of whether there\nis a centralization of the teaching of sort of CX is\nan interesting question. And I think, you know, the\nway it evolved with math, you know, people understood\nthat math was sort of a, a separately teachable thing\nand was kind of a, a, you know, a a an independent element as\nopposed to just being absorbed into out now. So if you\ntake the example of, of, of writing English or something like this, the first point is that, that, you know, at the college level, at\nleast at fancy colleges, there's a certain amount\nof English writing that, that people do. But mostly it's kind of assumed\nthat they pretty much know how to write, you know, that's\nsomething they learnt at a, at an earlier stage in education, maybe rightly or wrongly believing that. But that's different. Different issue. The well I think it, it, it reminds me of my kind of a, as I've tried to help\npeople do technical writing and things, I'm, I'm always reminded of my zero floor of technical writing, which is if you don't understand\nwhat you are writing about, your readers do not stand a chance. Yeah. And so it's, it's, I think\nthe, the thing that has some, you know, in, in, when it comes\nto like writing for example, you know, people in different fields\nare expected to write English essays and they're not, you\nknow, mostly the, you know, the history department or\nthe engineering department. They don't have their own, you\nknow, let's, you know, it's, it's not like there's a, I mean it's a thing which sort\nof people are assumed to have a knowledge of how to write\nthat they can use in all these different fields. And the question is, you know, some level of knowledge of\nmath is kind of assumed by the time you get to the college\nlevel, but plenty is not. And that's sort of still centrally taught. The question is sort of how\ntall is the tower of kind of CX that you need before you can\njust go use it in all these different fields. And you know, there will be experts who want\nto learn the full elaborate tower and that will be kind of the, the CS CX whatever department. But there'll also be everybody\nelse who just needs to know a certain amount of that to be\nable to go and do their art history classes and so on. - Yes. It's just a single class that\neverybody's required to take. - I don't know, I don't\nknow how big it is yet. I hope to kind of define this\ncurriculum and I'll figure out whether it's some, my guess\nis that I, I don't know, I don't really understand\nuniversities and professoring that well. But my, my rough\nguess would be a year long, a year of college class will\nbe enough to get to the point where most people have a, a\nreasonably broad knowledge of, you know, we'll be sort of literate in\nthis kind of computational way of thinking about things. - Yeah. Basic literacy. Right. I'm still stuck perhaps\ncause I'm hungry in the, in the rating of human\npreferences for candy. So I have to ask, what's the best candy? I like this ELO rating for candy. Somebody should come up because\nyou're somebody who says you like chocolate. What's, what\ndo you think is the best I'll, I'll probably put milk duds up there. I don't know if you know. Hmm. I do you have a preference\nfor chocolate or candy? Oh. - I have lots of\npreferences. I've, I've, I, one of my all-time favorites\nis my whole life is these things, these flake\nthings, Cadbury flakes, which are not much sold\nin the US And I've, I've always thought that\nwas a sign of a, of a, a lack of respect for\nthe American consumer because they're these\nsort of aerated chocolate that's made in a, in a whole sort of, it's kind of a, a sheet of chocolate that's\nkind of folded up and when you eat it flakes fall all over the place. - Ah. So it requires a kind of elegance. It requires you to have an elegance. - Well I know what I, what I\nusually do is I eat them on a, you know, on a piece\nof paper or something. - You embrace the mask\nand clean it up after. - No, I actually eat\nthe, I eat the flakes. Oh. They're the, cause it,\nyou know, it turns out the, the way food tastes depends a\nlot on its physical structure and you know, it really, you know, I've noticed when I eat\npieces of chocolate, I usually have some little\npieces of chocolate and I, I always break off little pieces\npartly cause then I eat it less fast. Yeah. But also cause it actually\ntastes different, you know, the the the small pieces,\nyou know, have a different, you have a different experience\nthan if you have the big slab of chocolate. - For many reasons. Yes. Slower, more intimate. - Well I think it's also\njust a pure physicality. - [Fridman] Well the texture changes. - Yeah. Right. - [Fridman] That's fascinating. Now I take back my milk duds. Cause that's such a basic answer. Okay. Do you think consciousness is\nfundamentally computational? So when you're thinking about cx, what can we turn to computation? And you're thinking about LLMs, do you think the the display\nof consciousness and the experience of consciousness,\nthe hard problem is, is fundamentally a computation. - Yeah. What it feels\nlike inside, so to speak. - [Fridman] Yeah. - Is, you know, I did a little exercise\neventually I'll post it, of you know, what it's\nlike to be a computer. Yeah. Right. It's kind of like, well you get all this sensory\ninput you have kind of, the way I see it is from the\ntime you boot a computer to the time the computer crashes. It's like a human life. You, you're building up a certain\namount of state in memory. You remember certain things about your quotes life eventually. It's kind of like the, the, you know, the next generation of humans is, is born from the same genetic\nmaterial, so to speak, with a little bit left over,\nleft on the disk, so to speak. And then, you know, the the, the new fresh generation starts up. And eventually all kinds\nof crud builds up in the, in the memory of the computer\nand eventually the thing crashes or whatever. Or maybe it has some trauma\nbecause you plugged in some weird thing to some port of the computer and that made it crash. And that, you know, that\nthat's kind of, but, but you have this, this\npicture of, you know, from, from startup to, to,\nto shut down, you know, what is the life of a\ncomputer, so to speak, and what does it feel like\nto be that computer and what inner thoughts does it have\nand how do you describe it? And it's kind of, kind of interesting as you\nstart writing about this to realize it's awfully like what\nyou'd say about yourself that is, it's awfully like even\na, an ordinary computer, forget it all the AI\nstuff and so on, you know, it's kind of, it has a memory of the past, it has certain sensory experiences. It can communicate with other computers, but it has to package up how\nit's communicating in some kind of language like form so\nit can, you know, send, so it can kind of map what's\nin its memory to what's in the memory of some other computer. It's, it's a surprisingly similar thing. You know, I hadn't experienced\njust a week or two ago, I, I had, I'm a collector of all possible data about myself and other things. And so I, you know, I collect all sorts of weird\nmedical data and so on. And one thing I hadn't collected\nwas I'd never had a whole body MRI scan. So I went and got one of these. - [Fridman] Nice. - Okay. So I get the, get\nall the data back, right. I'm looking at this thing, I've never looked at the\nkind of insides of my brain, so to speak, in, in physical form. And it's really, I mean, it, it's kind of psychologically\nshocking in a sense that, you know, here's this thing and you can\nsee it has all these folds and all these, you know, this structure. And it's like, that's where this experience\nthat I'm having of, you know, existing and so on. Yeah. That's where it is. And you know, it feels\nvery, you know, you, you look at that and you're thinking, how can this possibly be\nall this experience that I'm having? And you're realizing, well I can look at a\ncomputer as well and it's, it's kind of this, it, it, it, it, I think this idea that you are\nhaving an experience that is somehow, you know, transcends the mere sort of\nphysicality of that experience. I, I, I, you know, it's something that's hard\nto come to terms with, but I think, you know, and I, I don't think I've\nnecessarily, you know, my, my personal experience, you\nknow, I look at the, you know, the MRI of the brain and then I, you know, know about all kinds of things\nabout neuroscience and all that kind of stuff. And I still feel the\nway I feel so to speak. And it, it sort of seems disconnected, but yet as I try and rationalize it, I can't really say that there's\nsomething kind of different about how I intrinsically\nfeel from the thing that I can plainly see in the sort of\nphysicality of what's going on. - [Fridman] So do you think the computer, a large language model will\nexperience that transcendence? How does that make you feel? Like I I tend to believe it will. - I think an ordinary\ncomputer is already there. I think an ordinary computer is already, you know, kind of, it's, it's now a large language model\nmay experience it in a way that is much better\naligned with us humans. That is, it's much more, you know, if you could have the\ndiscussion with the computer, it's intelligence so to speak, is not particularly\nwell aligned with ours. But the large language model is, you know, it's built to be aligned with our way of thinking about things. - [Fridman] It would be able to explain that it's afraid of being\nshut off and deleted. It'd be able to say that it's\nsad of the way you've been speaking to it over the past two days. - Right. But you know, that's a weird thing because when it says it's afraid of something. We know that it got\nthat idea from the fact that it read on the internet. - Yeah. Where did you get it, Steven? Where did you get it when\nyou say you're afraid? - You acquaint, that's the question. Right. - [Fridman] I mean it's it's\nyour parents, your friends. - Right. Or, or my biology. I mean, in other words, there's\na certain amount that is, you know, the endocrine system\nkicking in and, and you know, the the these kinds of emotional\noverlay type things that happen to be, that are actually much more\nphysical even they're much more sort of straightforwardly\nchemical than the, the than kind of all of\nthe higher level thinking. - Yeah but your biology didn't tell you to say I'm afraid just at the right time when people that love you are listening and so, you know, you're\nmanipulating them by saying, so that's not your biology. That's- - [Wolfram] No, that's a\nwell, but the, you know. - It's a large language model in that biological neural network of yours. - Yes. But I mean, the\nintrinsic thing of, you know, something sort of shocking is\njust happening and you have some sure sort of reaction,\nwhich is, you know, some neurotransmitter gets\nsecreted and it, it's, you know, that that is the beginning\nof some, you know, that is, that's one of the pieces\nof input that then drives, it's kind of like the, like a prompt for, for the large language model. I mean, just like when we dream\nfor example, you know, no doubt there are all\nthese sort of random inputs that kind of, these random prompts and then\nit's percolating through in kind of the way that a large\nlanguage model does of kind of putting together things\nthat seem meaningful. - I I mean, are you, are you worried about\nthis world where you, you teach a lot on the internet\nand there's people asking questions and comments and so on. You have people that work remotely. Are you worried about this\nworld when large language models create human-like bots that\nare leaving the comments, asking the questions? Or might\neven become fake employees? - [Wolfram] Yeah. - I mean, or, or or worse are better at\nyet friends friends of yours. - Right. Look, I mean, one point is my mode of life\nhas been I build tools and then I use the tools. And in a sense kind of, you know, I'm, I'm building this tower of automation. Which, you know, and,\nand in a sense, you know, when you make a company or something, you are making sort of automation but it has some humans in it. - [Fridman] Yes. - But also as much as possible\nit has, it has, you know, computers in it. And so I think it's sort of\nan extension of that now. Now if I really didn't know\nthat, you know, it's a, it's a, it's a funny question. I mean it's a, it's a funny issue when, you know, if we think about sort of what's\ngonna happen to the future of kind of jobs people do and so on. And there are places where kind of having a human in the loop, there are different reasons\nto have a human in the loop. For example, you might want a human in the loop cause you want somebody to, you want another human to\nbe invested in the outcome. You know, you want a human flying the\nplane who's gonna die if the plane crashes along with you so to speak. And that gives you sort of\nconfidence that the right thing is going to happen or\nyou might want, you know, right now you might want a human\nin the loop in some kind of sort of human encouragement,\npersuasion type profession. Whether that will continue, I'm not sure for those\ntypes of professions. Cause it may be that the,\nthe greater efficiency of, you know, of being able to have sort\nof just the right information delivered at just the right\ntime will overcome the kind of the the the kind of, oh\nyes, I want a human there. - Yeah. Imagine like a\ntherapist or even higher stake, like a suicide hotline operated\nby a large language model. [Wolfram] Yeah. - Oh boy. It's a pretty\nhigh stake situation. - Right. But I mean, but you know, it might in fact do the right thing. Because it might be the\ncase that that, you know, and that's really a partly\na question of sort of how complicated is the human, you know, one of the things that's that's\nalways surprising in some sense is that, you know, sometimes human psychology\nis not that complicated in some sense. - You wrote the blog\npost, the 50 Year Quest, my personal journey, good title, my personal journey with the\nsecond law thermodynamics. So what is this law and what\nhave you understood about it in the 50 year journey you had with it? - Right. So second law of thermodynamics, sometimes called law of entropy\nincrease is this principle of physics that says, well, my version of it would be\nthings tend to get more random over time. A version of it that there\nare many different sort of formulations of it that are\nthings like heat doesn't spontaneously go from a hotter\nbody to a colder one when you have mechanical work kind of\ngets dissipated into heat. You have friction and, and kind of when you\nsystematically move things, eventually they'll be,\nthey'll be sort of the, the energy of of moving\nthings gets kind of ground down into heat. So people first sort of paid\nattention to this back in the 1820s when steam engines were a big thing. And the big question was how efficient could a steam engine be? And there's this chap called\nSaddi Carno who was a, a French engineer actually. His father was a a a sort of\nelaborate mathematical engineer in, in France. But he figured out these, this kind of rules for\nhow kind of the, the, the efficiency of, of the\npossible efficiency of a, of something like a steam engine. And in sort of a side, part of what he did was this\nidea that mechanical energy tends to get dissipated as heat that you, that you end up going from\nsort of systematic mechanical motion to this kind of random thing. Well, at that time, nobody knew what heat was at that time, people thought that heat was a fluid, like they called it caloric. And it was a fluid that kind of, kind of was absorbed into substances. And when, when heat, when one hot thing would\ntransfer heat to a colder thing, that this fluid would\nflow from the hot thing to the colder thing. But anyway, then by the, by the 1860s people had kind\nof come up with this idea that systematic energy tends to degrade into kind of random heat that would, that that could then not\nbe easily turned back into systematic mechanical energy. And then that, that\nquickly became sort of a, a global principle about how things work. Question is, why does it happen that way? So, you know, let's say you have a bunch\nof molecules in a box and they're arranged, these molecules arranged in a\nvery nice sort of flotilla of molecules in one corner of the box. And then what you typically\nobserve is that after a while these molecules were kind of\nrandomly arranged in the box. The question is why does that happen? And people for a long, long time tried to figure\nout is there from the laws of mechanics that determine\nhow these molecules, let's say these molecules\nlike hard spheres bouncing off each other from the laws of mechanics that describe those molecules. Can we explain why it tends\nto be the case that we see things that are an orderly,\nsort of degrade into disorder? We tend to see things\nthat, you know, you you, you scramble an egg, you that, you know, you take something that's\nquite ordered and you, you disorder it, so to speak. That's a thing that sort of happens quite we regularly or you, you put some ink into water\nand it will eventually spread out and, and fill up, you\nknow, fill up the water, but you don't see those little\nparticles of ink in the water all spontaneously kind of arrange\nthemselves into a big blob and then, you know, jump\noutta the water or something. And so the question is why do\nthings happen in this kind of irreversible way where you\ngo from order to disorder? Why does it happen that way? And so throughout, in the later part of the 18 hundreds, a lot of work was done on\ntrying to figure out can one derive this principle, this second law of thermodynamics\nthis law about the, the dynamics of heat, so to speak. Come one derive this from, from some fundamental principles\nof mechanics, you know, and the, and the laws of thermodynamics. The first law is basically\nthe law of energy, energy conservation that the\ntotal energy associated with heat plus the total energy\nassociated with mechanical kinds of things, plus other kinds of energy, that that total is constant. And that became a pretty\nwell understood principle. But the, the second law of thermodynamics was always mysterious. Like, why does it work this way? Can it be derived from\nunderlying mechanical laws? And so when I was, well,\n12 years old actually, I had gotten interested, well\nI, I'd been interested in, in space and things like that. Cause I thought that was kind of the, the future and interesting\nsort of technology and so on. And for a while kind of, you know, every deep space probe\nwas sort of a personal friend type thing. And I knew all, all, all kinds of characteristics\nof it and was kind of writing up all these, all these things\nwhen I was, oh, I don't know, eight, nine, ten years old and so on. And then I, I got interested from being\ninterested in kind of spacecraft I got interested in. So\nlike how do they work? What are all the instruments\non them and so on. And that got me interested in physics, which was just as well because\nif I'd stayed interested in space in the, you know, mid to late 1960s, I would've had a long\nwait before, you know, space really blossomed\nas a, as a, as an area. - Timing is everything. - Right. I got interest in physics. And then, well the actual sort\nof detailed story is when I, when I kind of graduated from\nelementary school at age 12, and that's the time when\nin England where you finish elementary school, I sort\nof, my, my gift sort of, I suppose more or less for\nmyself was I got this collection of physics books, which was some college physics course of college physics books. And volume five is about\nstatistical physics and it has this picture on the cover that shows\na bunch of kind of idealized molecules sitting in one side\nof a box and then it has a series of frames showing how\nthese molecules sort of spread out in the box. And I thought that's pretty\ninteresting. You know, what, what causes that? And you\nknow, read the book and, and the book, the book actually, one of the things that was\nreally significant to me about that was the book kind of claimed, although I didn't really\nunderstand what it said in detail, it kind of claimed that this\nsort of principle of physics was derivable somehow. And you know, other things\nI'd learned about physics, it was all like, it's a fact\nthat energy is conserved. It's a fact that relativity\nworks or something not, it's something you can derive\nfrom some fundamental sort of, it has to be that way as a, as a matter of kind of\nmathematics or logic or something. So it was sort of interesting\nto me that there was a thing about physics that was kind of\ninevitably true and derivable so to speak. And so I think that, so then I was like this\npicture on this book and I was trying to understand it. And so that was actually the\nfirst serious program that I wrote for a computer was probably 1973 written for this computer, the size of a desk program\nwith paper tape and so on. And I tried to reproduce this\npicture on the book and I didn't succeed. - What was the failure mode there? Like what do you mean you\ndidn't succeed? So it's a bunch- - Looked like, it didn't look like, okay, so what happened is, okay, many years later I learned how\nthe picture on the book was actually made and that it\nwas actually kind of a fake, but I didn't know that at that time. But, and that picture was actually a, a very high-tech thing when it was made in the beginning of the 1960s, was made on the largest supercomputer that existed at the time. And even so it couldn't quite\nsimulate the thing that it was supposed to be simulating. But anyway, I didn't know that until\nmany, many, many years later. So at the time it was like, you have these balls\nbouncing around in this box, but I was using this computer with eight kilo words of memory. They were 18 bit words of memory words. Okay. So it was whatever,\n24 kilobytes of memory. And it had, you know, it\nhad these instructions, I probably still remember all\nof its machine instructions. And it didn't really like\ndealing with floating point numbers or anything like that. And so I had to simplify this,\nthis model of, of, you know, particles bouncing around in a box. And so I thought, well I'll put them on a grid\nand I'll make, you know, make the things just sort\nof move one square at a time and so on. And so I did the simulation\nand the result was, it didn't look anything\nlike the actual pictures on the book. Now many years later, in fact very recently I\nrealized that the thing I'd simulated was actually an\nexample of a whole sort of computational irreducible\nstory that I absolutely did not recognize at the time. At the time it just looked like\nit did something random and it looks wrong. As opposed to it did something random. And it's super interesting\nthat it's random, but I didn't recognize that at the time. And so as it was at the time, I kind of, I got interested in particle\nphysics and I got interested in, in other kinds of physics and, but this whole second\nof thermodynamics thing, this idea that sort of orderly things tend to degrade into disorder, continued to be something\nI was really interested in. And I was really curious\nfor the whole universe, why doesn't that happen all the time? Like we start off at the, in the big bang at the beginning\nof the universe was this thing that seems like it's\nthis very disordered collection of, of stuff and then it\nspontaneously forms itself into galaxies and creates\nall of this complexity and order in the universe. And so I was very curious\nhow that happens and I, but I was always kind of\nthinking this is kind of somehow the second order of\nthermodynamics is behind it, trying to sort of pull\nthings back into disorder so to speak. And how was order being created. And so actually I was, was interested, this is probably now 1980, I\ngot interested in kind of this, you know, galaxy formation\nand so on in the universe. I also at that time was interested\nin neural networks and I was interested in kind of how, how brains make complicated\nthings happen and so on. - Okay. Wait, wait, wait. What's the connection between\nthe formation of galaxies and how brains make complicated things happen? - Because they're both a matter of how complicated things come to happen. - From simple origins? - [Wolfram] Yeah. From\nsome sort of known origins. I had the sense that, that what I was interested in was kind of in all these different, this sort of different cases\nof where complicated things were arising from rules. And you know, I also looked at snowflakes\nand things like that. I was curious and, and\nFloyd Dynamics in general. I was just sort of curious\nabout how does complexity arise and, and the, the thing\nthat I didn't, you know, it took me a while to kind of\nrealize that there might be a general phenomenon. You know, I sort of assumed, oh there's galaxies over here,\nthere's brains over here. They're, they're very\ndifferent kinds of things. And so what happened, this\nis probably 1981 or so, I decided okay, I'm, I'm gonna try and make the minimal model of how these things work. And it was sort of an interesting\nexperience because I had built, starting in 1979, I built my first big computer system. It's a thing called SMP\nsymbolic manipulation program. It's kind of a forerunner of\nmodern Wolfram language with many of the same ideas about\nsymbolic computation and so on. But the thing that was very\nimportant to me about that was, you know, in building that language, I had basically tried to figure\nout what were the sort of, what were the relevant\ncomputational primitives, which have turned out to stay with me for the last 40 something years. But it was also important because\nin building a language was very different activity\nfrom natural science, which is what I'd mostly done before. Cause in natural science you start from the phenomenon of the world and you try and figure out, so how can I make sense of\nthe phenomena of the world? And you know, kind of the world presents\nyou with what it has to offer, so to speak. And you have to make sense\nof it when you build a com, you know, computer language or something, you are creating your own\nprimitives and then you say can, so what can you make from\nthese, sort of the opposite way round from what you do in natural science. But I'd had the experience of doing that and so I was kind of like, okay, what happens if you sort of\nmake an artificial physics? What happens if you just make up the rules by which systems operate? And then I was thinking, you know, for all these different systems, whether it was galaxies\nor brains or whatever, what's the absolutely minimal\nmodel that kind of captures the things that are important\nabout those systems. - The computational\nperimeters of that system. - Yes. And so that's what ended up\nwith the cellular autor where you just have a line of\nblack and white cells, you just have a rule that says, you know, given the cell in its neighbors, what will the color of the cell\nbe on the next step when you just run it in a series of steps? And the sort of, the ironic thing is that cellular\nautor are great models for many kinds of things, but galaxies and brains are two\nexamples where they do very, very badly. They're really\nirrelevant to those two cases. - Is there a connection to the\nsecond law thermodynamics and cellular auto automata? - Oh yes. - The things you, the things you've discovered\nabout cellular auto automata. - Yes. Okay. So when I first started\ncell cellular Automata, my first papers about them were, you know, the first sentence was always\nabout the second row of thermodynamics was always\nabout how does order manage to be produced, even though there's a second\nrow of thermodynamics, which tries to pull\nthings back into disorder. And I kind of, my early understanding of\nthat had to do with these are intrinsically irreversible\nprocesses in cellular automata that that form, you know, conform orderly structures even from random initial conditions. But then what I realized this was, well actually it's, it's one of these things\nwhere it was a discovery that I should have made\nearlier but didn't. So, you know, I had, I had been\nstudying cellular automata. What I did was the sort of most\nobvious computer experiment. You just try all the different\nrules and see what they do. It's kind of like, you know, you've invented a computational telescope, you just pointed at the most\nobvious thing in the sky, and then you just see what's there. And so I did that and I, you know, was making\nall these pictures of, of how cellular automata work. And I studied these pictures.\nI studied in great detail. There was, you can number the\nrules for cellular automata. And one of them is, you know, rule 30. So I made a picture of\nRule 30 back in 1981 or so, and Rule 30, well, it's, and I, and I at the\ntime, I was just like, okay, it's another one of these\nrules. I don't really, it happens to be asymmetric\nleft, right asymmetric. And it's like, let me just consider the case\nof the symmetric ones just to keep things simpler, et\ncetera, et cetera, et cetera. And I just kind of ignored it. And then sort of in, in, actually\nin 1984, strangely enough, I, I ended up having a,\nan early laser printer, which made very high resolution pictures. And I thought, I'm gonna print out an\ninteresting, you know, I wanna make an interesting picture. Let me take this rule 30\nthing and just make a high resolution picture of it. And I did. And it's, it has this very remarkable\nproperty that its rule is very simple. You started off just from one\nblack cell at the top and it makes this kind of triangular pattern. But if you look inside this\npattern, it looks really random. There's, you know, you look at the center column\nof cells and, you know, I studied that in great detail and it's, so far as one can tell,\nit's completely random. And it's kind of a little\nbit like digits of pie. Once you, you know, you know the rule for\ngenerating the digits of pie, but once you've generated\nthem, you know, 3.14159, et cetera, they seem completely random. And in fact, I, I put up this\nprize back in, what was it, 2019 or something for, prove anything about\nthe sequence, basically. - [Fridman] Has anyone been\nable to do anything on that? - People have sent me some\nthings, but it's, you know, I don't know how hard these problems are. I mean, I, I was kind of\nspoiled cause I, 2007, I put up a prize for\ndetermining whether a particular touring machine that I thought\nwas the simplest candidate for being a universal touring\nmachine determine whether it is or isn't a universal touring machine. And somebody did a really good job of, of winning that prize and\nproving that it was a universal touring machine in about six months. And so I, you know, I didn't know whether that\nwould be one of these problems that was out there for hundreds of years, or whether in this particular case, young chap called Alex Smith, you know, nailed it in six months. And so with this little 30 formulation, I don't really know whether\nthese are things that are a hundred years away from\nbeing able to, to get, or whether somebody's gonna come and do something very clever. - It's such a, I mean,\nit's like for (indistinct), it's such a rule 30, it's\nsuch a simple formulation. It feels like anyone can\nlook at it and understand it. And feel like it's within\ngrasp to be able to predict something to do to, to\ndirect some kind of law that allows you to predict\nsomething about this. Middle column of rule 30. - [Wolfram] Right. But you\nknow, this is, this is- - Yet you can't. - Yeah, right. This is the intuition surprise\nof computational reducibility and so on, that even though\nthe rules are simple, you can't tell what's going\nto happen and you can't prove things about it. And I think so. So anyway, the, the, the, the thing I, I sort of started in 1984 or so, I started realizing there's\nthis phenomenon that you can have very simple rules. They produce apparently random behavior. Okay. So that's a little bit like the second neuro dynamics because it's like you have this simple\ninitial condition, you can, you know, readily see\nthat it's very, you know, you can describe it very easily. And yet it makes this thing\nthat seems to be random. Now, turns out there's\nsome technical detail about the second thermodynamics and about the idea of reversibility. When you have a, if you\nhave kind of a, a, a, a, a movie of two, you know, billiard balls colliding and\nyou see them collide and they bounce off, and you run\nthat movie in reverse, you can't tell which way was\nthe forward direction of time and which way was the\nbackward direction of time. When you're just looking at\nindividual billard balls, by the time you've got a whole\ncollection of them, you know, a million of them or something, then it turns out to be the case. And this is the, the sort of the, the mystery of the second law. That the orderly thing, you start with the orderly\nthing and it becomes disordered. And that's the forward direction in time. And the other way round\nof it starts disordered and becomes ordered. You just don't see that in the world. Now, in principle, if you, you know, if you sort of traced the\ndetailed motions of all those molecules backwards, you\nwould be able to, it, it will, it will. The reverse of time\nmakes, you know, as you, as you go forwards in time,\norder goes to disorder, as you go backwards in time, order goes to disorder. - [Fridman] Perfectly. So yes. - Right. So the, the mystery\nis why is it the case that, or one version of the mystery\nis why is it the case that you never see something which\nhappens to be just the kind of disorder that you would need\nto somehow evolve to order. Why does that not happen? Why do you always just see\norder goes to disorder not the other way around? So the thing that I, I kind of realized, I started realizing in the\n1980s, it's kind of like, it's a bit like cryptography. It's kind of like you start off from this, this key that's pretty simple, and then you kind of run it\nand you can get this, you know, complicated random mess. And the thing that that well, I sort of started realizing\nback then was that the second law is kind of a, a, a story\nof computational reducibility. It's a story of, you know,\nwhat seems, you know, what, what we can describe\neasily at the beginning, we can only describe with a\nlot of computational effort at the end. Okay. So now we come\nmany, many years later, and I was trying to sort of, well, having done this big project\nto understand fundamental physics, I realized that sort\nof a key aspect of that is understanding what observers are like. And then I realized that the\nsecond auto neuro dynamics is the same story as a bunch\nof these other cases. It is a story of a, a computationally bounded\nobserver trying to observe a computationally irreducible system. So it's a story of, you know, underneath the molecules\nare bouncing around, they're bouncing around in\nthis completely determined way, determined by rules. But the point is that, that we as computationally\nbounded observers, can't tell that there were\nthese sort of simple underlying rules to us that just looks random. And when it comes to this\nquestion about can you prepare the initial state so that, you know, the disordered thing is, you know, you have exactly the right\ndisorder to make something orderly, A computationally\nbounded observer cannot do that. We'd have to have done all\nof this sort of irreducible computation to work out very precisely what this disordered state, what the exact right disordered\nstate is so that we would get this ordered thing produced from it. - What does it mean to be\ncomputationally bounded observer? So observing a computation\nreducible system, so the computationally bounded, is there something\nformal you can say there? - Right. So it means, okay, you can, you can talk about Turing machines, you can talk about computational\ncomplexity theory and you know, polynomial time\ncomputation and things like this. There are a variety of ways to\nmake something more precise, but I think it's more useful, the intuitive version\nof it is more useful. Which is basically just\nto say that, you know, how much computation are you going to do to try and work out what's going on? And the answer is, you're not allowed to do a lot of, we are not able to do a\nlot of computation when we, you know, we've got, you know, in this room there will\nbe a trillion, trillion, trillion molecules. Yeah. A little bit less. - It's a big room. - Right. And you know, at every moment, you know, there every microsecond or\nsomething, these molecules, molecules are colliding. And that's a lot of computation\nthat's getting done. And the question is, in our brains, we do a lot less computation every second, then the computation done\nby all those molecules. If there is computational\nirr, reducibility, we can't work out in detail\nwhat all those molecules are going to do. What we can do is only a much\nsmaller amount of computation. And so the, the second thermodynamics is\nthis kind of interplay between the underlying computational\nirreducibility, and the fact that we as\npreparers of initial states or as measures of what happens\nare, you know, are, are not capable of doing\nthat much computation. So to us, another big formulation\nof the second order of thermodynamics is this idea of\nthe law of entropy increase. - The characteristic that this universe, the entropy seems to be always increasing. What does that show to you\nabout the evolution of- - Well, okay, so, so- - [Fridman] The universe of time. - The History of entropy is yes, okay. And that's very confused in\nthe history of thermodynamics, because entropy was\nfirst introduced by a guy called Rudolph Klauseous, and he did it in terms\nof heat and temperature. Okay. Subsequently, it was reformulated by a\nguy called Ludwig Boltzmann. And he formulated it in a much more kind of commonatorial type way. But he always claimed that\nit was equivalent to Klaus's thing. And in, in one particular\nsimple example, it is, but that connection between\nthese two formulations of entropy, they've never been connected. I mean, it's there. There's really, so, okay, so the more general definition\nof entropy due to Boltzmann is, is the following thing. So you say, I have a system and has many\npossible configurations. Molecules can be in many\ndifferent arrangements, et cetera, et cetera, et cetera. If we know something about\nthe system, for example, we know it's in a box, it\nhas a certain pressure, it has a certain temperature, we know these overall facts\nabout it, then we say, how many microscopic\nconfigurations of the system are possible given those overall constraints. And the entropy is the\nlog rhythm of that number. That's the definition. And that's the kind of the\ngeneral definition of entropy that, that turns out to be useful. Now, in Boltzmann's time, he thought these molecules could be placed anywhere you want. He didn't think and, but he said, oh, actually we can make it a\nlot simpler by having the molecules be discreet. Well, actually he didn't\nknow molecules existed right? In, in those, in his\ntime, 1860s and so on. The idea that matter might\nmade of discrete stuff had been floated ever since ancient Greek times. But it had been a long time\ndebate about, you know, is matter discreet as a\ncontinuous at the moment of, at that time, people mostly thought that\nmatter was continuous. And it was all confused with\nthis question about what heat is, and people thought heat\nwas this fluid, and it was, it was a big, big muddle. And the, and this, but Boltzmann said, let's assume they're discreet molecules. Let's even assume they have\ndiscreet energy levels. Let's say everything is discreet, then we can do sort of\ncombinatorial mathematics and work out how many configurations\nof these things there will be in the box. And we can say, we can\ncompute this entropy quantity. But he said, but of course it's just a fiction that these things are discreet. So he said, this is an interesting\npiece of history by the way, that that, that, you know, that was, at that time people didn't\nknow molecules existed. There were other hints from, from looking at kind of\nchemistry that there might be discreet atoms and so on, just from the, the combinatorics of, you know, two hydrogens and one oxygen\nmake water, you know, two, two amounts of hydrogen plus\none amount of oxygen together make water, things like this. But it wasn't known that\ndiscrete molecules existed. And in fact, the people, you know, it wasn't until the beginning of the, of the 20th century that\nbrownie in motion was the final giveaway. Brown in motion is, you know, you look under a microscope\nof these little pieces from pollen grains, you see they're being discreetly\nkicked and those kicks are water molecules hitting\nthem and they're discreet. And in fact, it was, it was really quite\ninteresting history. I mean, Boltzmann had worked out how\nthings could be discreet and had basically invented something\nlike quantum theory in, in the 1860s. And, but he just thought it\nwasn't really the way it worked. And then just a piece of physics history, cause I think it's kind of\ninteresting, in, in 1900, this guy called Max Plank, who'd been a longtime\nthermodynamics person who was trying to, everybody was trying\nto prove the second law of thermodynamics, including Max Plank. And Max Plank believed that radiation, like electromagnetic radiation, somehow the interaction of\nthat with matter was going to prove the second law of thermodynamics. But he had these experiments\nthat people had done on black body radiation, and there were these curves\nand you couldn't fit the curve based on his idea for how\nradiation interacted with matter. Those curves, he couldn't, he couldn't figure out\nhow to fit those curves, except he noticed that if he\njust did what Boltzmann had done and assumed that\nelectromagnetic radiation was discreet, he could fit the curves. He said, but you know,\nthis is just a, you know, it just happens to work this way. Then Einstein came along\nand said, well, by the way, you know, the electromagnetic field\nmight actually be discreet, it might be made of photons, and then that explains how this all works. And that was, you know, in 1905, that was, that was how kind of, that was how quant that piece\nof quantum mechanics got started. Kind of interesting,\ninteresting piece of history. I didn't know until I was\nresearching this recently in 1904 and 1903, Einstein wrote\nthree different papers. And so, you know, just sort\nof well known physics history. In 1905, Einstein wrote\nthese three papers. One introduced relativity theory, one explained brownie in motion, and one introduced basically photons. So kind of, you know, kind of a, a, a big deal year for\nphysics and for Einstein. But in the years before that, he'd written several papers\nand what were they about? They were about the second\nrule of thermodynamics, and they were an attempt\nto prove the second rule of thermodynamics and their nonsense. And so I I I had no idea\nthat he'd done this. - Interesting. Me neither. - And in fact, what he did,\nthose three papers in 1905, well not so much the relativity paper, the one on brown in\nmotion, the one on photons. Both of these were about the story of sort of making the world discreet. And he got those, that\nidea from Boltzmann. But Boltzmann didn't think, you know, Boltzmann kind of died\nbelieving, you know, he said he has a quote,\nactually, you know, you know, in the end, things are gonna\nturn out to be discreet, and I'm gonna write down\nwhat I have to say about this because, you know, eventually this stuff will\nbe rediscovered and I want to leave, you know, what I can about how things\nare gonna be discreet. But, you know, I think he has some quote\nabout how, you know, one person can't stand against\nthe tide of history in, in saying that, you\nknow, matter is discreet. - Oh, so he's stuck by his guns in terms of matter is discreet. - Yes, he did. And, and the, you know, what's\ninteresting about this is, at the time, everybody,\nincluding Einstein, kind of assumed that space\nwas probably gonna end up being discreet too. But that didn't work out\ntechnically because it wasn't consistent with relativity\ntheory, or didn't seem to be. And so then in the history of physics, even though people had determined\nthat matter was discreet, electro mag, magnetic field was discreet, space was a holdout of not being discreet. And in fact, Einstein 1916 has this nice\nletter he wrote where he says, in the end, it will turn\nout space is discreet, but we don't have the mathematical\ntools necessary to figure out how that works yet. And so, you know, I think it's kind of cool that\na hundred years later we do. - For you, you're pretty, pretty sure that at every\nlayer of reality it's discreet. - Right? And that space is\ndiscreet and that the, I mean, and in fact, one of the things I've realized\nrecently is this kind of theory of heat. That, that the, you know, that heat is really this\ncontinuous fluid, it's, it's kind of like the, the, you know, the caloric theory of heat, which turns out to be completely\nwrong because actually heat is the motion of discrete molecules. Unless, you know there\nare discreet molecules, it's hard to understand\nwhat heat could possibly be. Well, you know, I think space is, is discreet and the question\nis kind of what's the analog of the mistake that was made with\ncaloric in the case of space. And so I'm, my, my current\nguess is that dark matter is, as I've, my little sort\nof aphorism of the, of the last few months has been, you know, dark matter is the caloric of our time. That is, it will turn out that dark\nmatter is a feature of space and it is not a bunch of particles. You know, at the time when, when people were talking about heat, they knew about fluids\nand they said, well, heat must be just be\nanother kind of fluid. Because that's what they knew about. But now people know about\nparticles and so they say, well, what's dark matter? It's not, it's not, it\njust must be particles. - So what could dark matter\nbe as a feature of space? - Oh, I don't know yet. I mean, I think the, the thing I'm really, one of the things I'm hoping\nto be able to do is to find the analog of brown in motion in space. So in other words, brown in motion was, was seeing down to the level of an effect from individual molecules. And so in the case of space,\nyou know, most of the things, the things we see about space so far, just everything seems continuous\nbrown in motion had been discovered in the 1830s. And it was only identified what it was, what it was the, the, the results of by Markowski and\nEinstein at the beginning of the 20th century. And, you know, dark matter was, was discovered that phenomenon was discovered a hundred years ago. You know, the rotation, curves of galaxies don't follow\nthe luminous matter that was discovered a hundred years ago. And I think, you know, that I, I wouldn't be surprised if\nthere isn't an effect that we already know about that is\nkind of the analog of brown in motion that reveals the\ndiscreetness of space. And in fact, we we're\nbeginning to have some guesses. We have some, some evidence that black hole\nmergers work differently when there's discrete space. And there may be things that\nyou can see in gravitational wave signatures and things associated with the discreetness of space. But this is kind of, for me, it's kind of, it's kind of interesting to\nsee this sort of recapitulation of the history of physics\nwhere people, you know, vehemently say, you know,\nmatter is continuous, electromagnetic field is continuous, and turns out it isn't true. And then they say space is continuous. But, but, so, you know, entropy is the number of\nstates of the system consistent with some constraint. - [Fridman] Yes. - And the, the thing is that if you have, if you know in great detail\nthe position of every molecule in the gas, the entropy is, is always zero because there's\nonly one possible state. The, the configuration\nof molecules in the gas, the molecules bounce around, they have a certain rule\nfor bouncing around. There's just one state of the\ngas evolves to one state of the gas and so on. But it's only if you don't\nknow in detail where all the molecules are that you can say, well, the entropy increases because the things we do know about the molecules, there are more possible\nmicroscopic states of the system consistent with what we do know about where the molecules are. And so the question of whether, so people, this sort of paradox in a sense of, oh, if we knew where all the molecules, where the entropy wouldn't increase, there was this idea introduced by, by Gibbs in the early 20th century. Well actually the very beginning of the, of the 20th century as\na physics professor, an American physics professor\nwas sort of the first distinguished American\nphysics professor at Yale. And he, he introduced this idea, of course graining this\nidea that, well, you know, these molecules have a detailed\nway they're bouncing around, but we can only observe a\ncourse grained version of that. But the confusion has been, nobody knew what a valid\ncourse screening would be. So nobody knew that whether\nyou could have this course screening that very carefully\nwas sculpted in just such a way that it would notice that\nthe particular configurations that you could get from the\nsimple initial condition, you know, they fit into\nthis course screening. And the course screening\nvery carefully observes that. Why can't you do that\nkind of very detailed, precise course screening? The answer is because if you\nare a computationally bounded observer and the underlying\ndynamics is computationally irreducible, that's, that's what defines possible\ncore screenings is what a computationally, bounded observer can do. And it's the, it's the fact that a\ncomputation bounded observer is, is forced to look only at\nthis kind of coarse grained version of what the system is doing. That's why, and, and because the, what what's what's going on\nunderneath is it's kind of filling out this, this,\nthe, the different possible. You're ending up with something\nwhere the sort of underlying computational irreducibility is your, if, if all you can see is what the\ncourse grained result is with comp, with a sort of\ncomputationally bounded observation, then inevitably there are\nmany possible underlying configurations that are\nconsistent with that. - Just to clarify, I basically, any observer that exists inside\nthe universe is going to be computationally bounded. - No. Any observer like us, I don't know. I can't-. - When you say like us, what do you mean? What do you mean? Like us. - Well, humans with finite minds. - You're including the tools of science. - Yeah, yeah. I mean, and, and, and as we,\nyou know, we have more precise, and, and by the way, there are little sort of\nmicroscopic violations of the second row of thermodynamics\nthat you can start to have when you have more precise\nmeasurements of where precisely molecules are. - [Fridman] Right. - But for, for on a large scale, when you have enough molecules,\nwe don't have, you know, we are not tracing all those\nmolecules and we just don't have the computational\nresources to do that. And it wouldn't be, you\nknow, I think the, the, to imagine what an observer\nwho is not computationally bounded would be like, it's an interesting thing because okay, so what does computational\nboundedness mean among other things, it means we conclude\nthat definite things happen. We go, we take all this complexity\nof the world and we make a decision we're gonna\nturn left or turn right. And that is kind of reducing\nall this kind of detail into we're observing it, we're, we're, we're, we're sort of crushing it\ndown to this, this one thing. And, and that if we didn't\ndo that, we wouldn't, we wouldn't have all this\nsort of symbolic structure that we build up that lets us think things through with our finite minds. We'd be instead, you know, we'd be just, we'd be sort of one with the universe, so- - Yeah. So content to not simplify. - Yes. If we didn't simplify,\nthen we wouldn't be like us. We would be like the universe, like the, the intrinsic universe, but not having experiences\nlike the experiences we have where we, for example, conclude\nthat definite things happen. We, you know, we, we sort of have this, this notion of being able to make, make sort of narrative statements. - I wonder if it's just like\nyou imagined as a thought experiment what it's\nlike to be a computer. I wonder if it's possible to\ntry to begin to imagine what it's like to be in an unbounded\ncomputational observer. - Well. Okay, so here's, here's\nhow that I think plays out. - So I mean, in this we talk about this ruliad, this space of all possible computations. - [Fridman] Yes. - And this idea of, you know, being at a certain place in the ruliad, which corresponds to\nsort of a certain way of, of rep of a certain set of\ncomputations that you are representing things in terms of, okay, so as you expand out in the ruliad, as you kind of encompass more possible views of the universe, as you encompass more possible\nkinds of computations that you can do, eventually you\nmight say that's a real win. You know, we are, we're colonizing\nthe ruliad, we're, we're, we are building out more paradigms about how to think about things. And eventually you might say, we, we, we won all the way we managed\nto colonize the whole ruliad. Okay, here's the problem with that. The problem is that the\nnotion of existence, coherent existence requires\nsome kind of specialization by the time you are the whole ruliad, by the time you cover the\nwhole ruliad in no useful sense do you coherently exist. So in other words, in in interesting the notion of existence, the notion of what we think of as, as, as definite existence requires\nthis kind of specialization requires this kind of idea that we are, we are not all possible things. We are the, a particular set of things. And that's kind of how we,\nthat that's kind of what, what makes us have a coherent existence. If we were spread throughout\nthe ruliad we would not, there would be no coherence\nto the way that we work. We would work in all possible ways. And that wouldn't be kind\nof a, a notion of identity. We wouldn't have this notion of kind of, of of of coherent identity. - I am geographically\nlocated somewhere exactly, precisely in the ruliad, therefore I am is the decart kind of- - Yeah, yeah. Right. Were you are in a certain\nplace in physical space or in a certain place in ruliad space. And if, if you are, if you\nare sufficiently spread out, you are no longer coherent\nand you no longer have, I mean, in, in the, in our perception of\nwhat it means to exist and to have experience. Doesn't happen that way. - So therefore, so to to to exist means to\nbe computationally bounded. - I think so, to exist in the way that we think of ourselves\nas existing. Yes. - The very active existence is\nlike operating in this place that's computation irreducible. So that this is just giant mess\nof things going on that you can't possibly predict. But nevertheless, because\nof your limitations, you, you have an imperative of like, what is it an imperative\nor a skillset to simplify or an ignorance sufficient level. - Okay. So the thing which is not\nobvious is that you are taking a slice of all this complexity, just like we have all of these molecules bouncing around in the room. But all we notice is,\nyou know, the, the, the, the kind of the flow of the\nair or the pressure of the air. We are just noticing\nthese particular things. And the, the big interesting\nthing is that there are rules, there are laws that govern\nthose big things that we, we observe. - [Fridman] Yeah. So it's not obvious. - Amazing because it doesn't\nfeel like it's a slice. - [Wolfram] Yeah. Well, right. - It's not a slice. Well, it's like a, it's like an abstraction. - Yes. But I mean the fact\nthat the gas laws work. That we can describe pressure,\nvolume, et cetera, et cetera, et cetera. And we don't have to go down to the level of talking about individual molecules. That is a non-trivial fact. And, and here's the thing that I, sort of exciting thing\nas far as I'm concerned, the fact that there are certain\naspects of the universe. So, you know, we think space is made ultimately\nthese atoms of space and these hypergraphs and so on. And we think that, but we nevertheless perceive\nthe universe at a large scale to be like continuous space and so on. We, in quantum mechanics, we think that there are\nthese many threads of time, these many threads of\nhistory, yet we kind of span. So, so, you know, in,\nin quantum mechanics, in our models of physics, there are these time\nis not a single thread. Time breaks into many threads. They branch, they merge and, but we are part of that\nbranching, merging universe. And so our brains are also\nbranching and merging. And so when we perceive the universe, we are branching brains\nperceiving a branching universe. And so the fact that the claim that we ex, we believe that we are persistent in time, we have this single thread of experience. That's the statement that\nsomehow we managed to aggregate together those separate threads\nof time that are separated in, in the operation of, in the fundamental\noperation of the universe. So just as in space, we're averaging over\nsome big region of space, and we are looking at many, many at the aggregate effects\nof many atoms of space. So similarly in what we\ncall branchial space, the space of these,\nthese quantum branches, we are effectively averaging\nover many different branches of possible, of histories of the universe. And so in and in, in thermodynamics, we're averaging over many\nconfigurations of, you know, many, many possible positions of molecules. So what what we see here is, so the question is when you\ndo that averaging for space, what are the aggregate laws of space? When you do that averaging\nof a branchial space, what are the aggregate\nlaws of branchial space, when you do that averaging\nover the molecules and so on, what are the aggregate laws you get? And this is, this is the thing that I, I think is just amazingly,\namazingly neat that. - [Fridman] That there are\naggregate laws at all for- - Sure. Well, yes, but the question is what\nare those aggregate laws? So the answer is for space, the aggregate laws are\nEinstein's equations for gravity, for the structure of space\ntime, for branchial space. The aggregate laws are the\nlaws of quantum mechanics. And for the case of, of\nmolecules and things, the aggregate laws are basically the second law of thermodynamics. And so the, the, that's the, and the things that follow from the second law of thermodynamics. And so what that means is that the three great theories of 20th century physics, which are basically generality\nof the theory of gravity, quantum mechanics, and\nstatistical mechanics, which is what kind of grows outta the second row of thermodynamics. All three of the great theories\nof 20th century physics are the result of this interplay between computational irreducibility, and the computational\nboundedness of observers. And you know, for me, this is really neat because it\nmeans that all three of these laws are derivable. So we used to think that, for example, Einstein's equations\nwere just sort of a wheel in feature of our universe. That they could be,\nuniverse might be that way. It might not be that way.\nQuantum mechanics is just like, well, it just happens to be that way. And the second law people\nkind of thought, well, maybe it is derivable. Okay? What turns out to be the\ncase is that all three of the fundamental principles\nof physics are derivable, but they're not derivable\njust from mathematics. They require, or just from some\nkind of logical computation, they require one more thing.\nThey require that the observer, that the thing that is sampling\nthe way the universe works is an observer who has\nthese characteristics of computational boundedness of belief and persistence and time. And so that, that means that it is the\nnature of the observer you know, the rough nature of the observer. Not the details of, oh, we've got two eyes and we observe photons of this frequency and so on. But the, the, the, the kind of the very coarse\nfeatures of the observer then imply these very precise\nfacts about physics. And it's, it's, I think it's amazing. - So if we just look at\nthe actual experience of the observer that we\nexperience this reality, it seems real to us. And you're saying because\nof our bonded nature, it's actually all an illusion. It's an a simplification. - Well, yeah. It's a\nsimplification. Right? What's what's, well. - You don't think a\nsimplification is an illusion? - No, I mean it's, it's,\nwell, I don't know. I mean- - What is real? - What's underneath? Okay, that's an interesting question. What's real? And that relates to the whole question of why does the universe exist? And, you know, what is the difference\nbetween reality and a mere representation of what's going on? - [Fridman] Yes. We experience the representation. - Yes. But the, the question of, so,\nso one question is, you know, why is there a thing which\nwe can experience that way? And the answer is because\nthis ruliad object, which is this entangled limit\nof all possible computations, there is no choice about\nit. It has to exist. It has to, there has to be such a thing. It is in, in the same sense\nthat, you know, two plus two, if you define what two is and\nyou plot pluses and so on, two plus two has to equal four. Similarly, this rule ad this limit of\nall possible computations just has to be a thing you, that is, once you have the idea of computation, you inevitably have the ruliad. - [Fridman] You're gonna have\nto have a ruliad. Yeah, yeah. - Right? And, and what's\nimportant about it, there's just one of it, it's, it's, it's just this unique object\nand that unique object necessarily exists. And then the question is what? And then we once, once you know that we are\nsort of embedded in that and taking samples of it, that it's sort of inevitable\nthat there is this thing that we can perceive that is, you know, that, that our perception of kind of physical reality necessarily is that way, given that we are observers with the characteristics we have. So in other words, the fact that the fact that\nthe universe exists, is it, it's actually, it's almost\nlike it's, you know, to think about it almost\ntheologically so to speak. And I, and I've, I've really, it, it's, it's funny because a lot\nof the questions about the existence of the universe and so on, they, they transcend what kind of\nthe science of the last few hundred years has really been\nconcerned with the science of the last few hundred years. Hasn't thought it could talk\nabout questions like that. - [Fridman] Yeah. And, but I think it's kind of, and so a lot of the kind\nof arguments of, you know, does God exist, you know, is it obvious that I\nthink it in some sense, in some representation, it's sort of more, more obvious that, that something sort of bigger\nthan us exists than that we exist and we are, you know, our existence and as observers\nthe way we are is sort of a contingent thing about the universe. And it's more inevitable that the whole, the whole universe kind\nof the whole set of all possibilities, exists. But, but this question about, you know, is is it real or is it an illusion? You know, all we know is our experience. And so the fact that, well, our experience is this\nabsolutely microscopic piece of sample of the ruliad, and\nwe are, and, and you know, there's this this point about, you know, we might sample more and more\nof the ruliad we might learn more and more about, we\nmight learn, you know, like, like different areas of physics, like quantum mechanics for example. The fact that it, it was discovered I think is\nclosely related to the fact that electronic amplifiers were\ninvented that allowed you to take a small effect and amplify it up, which hadn't been possible before. You know, microscopes had been invented that magnify things and so on. But the, you know, having a very small effect and\nbeing able to magnify it was sort of a new thing that allowed\none to see a different sort of aspect of the universe and let one discover this kind of thing. So, you know, we can expect that in the\nruliad there are an infinite collection of new things we can discover. There's, there's in fact computational irreducibility kind of guarantees that there will be an infinite\ncollection of kind of, you know, pockets of reducibility\nthat can be discovered. - Boy, would it be fun to take a walk down the ruliad and see what\nkind of stuff we find there? You you write about alien intelligences. - [Wolfram] Yes. - I mean, just these worlds. - Yes. Well, the problem\nwith these worlds is that. - We can't talk to 'em. - [Wolfram] Yes. And, and you know, the thing is what I've kind of\nspent a lot of time doing of just studying computational\nsystems, seeing what they do, what I now call ruliology, kind\nof just the study of rules. - [Fridman] Yeah. - And what they do. You know, you can kind of easily jump\nsomewhere else in the ruliad and start seeing what do these rules do? - [Fridman] Yeah. - And what you says they, they just, they do what they do and\nthere's no human connection, so to speak. - Did you think, you know,\nsome, some people are able to communicate with animals. Do you think you can\nbecome a whisper of these? - I've been trying. That's what I've spent\nsome part of my life doing. - Have, have you, have\nyou heard, and I mean, are you at the risk of losing your mind? - Sort of my favorite science\ndiscovery is this fact that these very simple programs can produce very complicated behavior. - [Fridman] Yeah. - And that, and that fact\nis kind of in a sense, a whispering of something out\nin the computational universe that we didn't really\nknow was there before. I mean, it, it's, you know,\nI it's like, you know, back in the 1980s I was doing\na bunch of work with some very, very good mathematicians, and they were like trying\nto pick away, you know, can we figure out what's going on in these computational systems? And they, they basically said, look, the math we have just doesn't\nget anywhere with this. We're stuck. There's nothing to say. We have nothing to say. And, you know, in a sense, perhaps my main achievement at\nthat time was to realize that the very fact that the, the good mathematicians had\nnothing to say was itself a very interesting thing. That was kind of a, a sort of, in some sense, a whispering of a different\npart of the ruliad that one hadn't, you know, one wasn't, was not accessible from\nwhat we knew in mathematics and so on. - Does it make you sad that\nyou're exploring some of these gigantic ideas and it feels\nlike we're on the verge of breaking through to some\nvery interesting discoveries, and yet you're just a finite being that's going to die way too soon? And that scan of your brain or\nyour full body kind of shows that you're- - Yeah, it's just a bunch of meat. - It's just a bunch of meat. Yeah. Does that make you\nmake you a little sad? - It's kind of a shame. I mean, I kinda like to see how\nall this stuff works out, but I think the thing\nto realize, you know, it's an interesting sort of\nthought experiment. You know, you, you say, okay, you know, let's assume we can get cryonics to work, and one day it will, that will be one of these things that's kind of like ChatGPT. One day somebody will\nfigure out, you know, how to get water from zero\ndegrees centigrade down to, you know, minus 44 or\nsomething without it expanding. And you know, cryonics will be solved and\nyou'll be able to like just, you know, put a pause in\nso to speak, and you know, kind of reappear a hundred\nyears later or something. And the thing though that I've\nkind of increasingly realized is that in a sense, this, this whole question of kind of the, the sort of one is embedded\nin a certain moment, in, in time and, you know, kind of\nthe things we care about now, the things I care about now,\nfor example, had I lived, you know, 500 years ago, many of the things I care\nabout now, it's like, that's totally bizarre. I mean, it's, nobody\nwould care about that. It's not even a thing one\nthinks about in the future, the things that most\npeople will think about. You know, one will be a strange relic\nof thinking about, you know, the kind of, you know, it might be one might have been\na theologian thinking about, you know, how many angels fit on the\nhead of a pin or something. And that might have been the, you know, the big intellectual thing.\nSo I think it's a, it's a, but yeah, it's a, it's a, you know, it's one of these things\nwhere particularly, you know, I've had the, I don't\nknow, good or bad fortune. I'm not sure. I think it's a,\nit's a mixed thing that I've, you know, I've invented a bunch of things, which I kind of can, I think see well enough what's\ngonna happen that, you know, in 50 years, a hundred years, whatever, assuming the world doesn't\nexterminate itself, so to speak, you know, these are things that will be\nsort of centrally important to what's going on. And it's kind of both, it's both a good thing and a bad thing in terms of the passage of one's life. I mean, it's kind of like, if everything I'd figured\nout was like, okay, I figured it out when I was 25\nyears old and everybody says it's great and we're\ndone. And it's like, okay, but I'm gonna live another how many years? And that's kind of, it's all\ndownhill from there in a sense. It's, it's better in some sense\nto, to be able to, you know, there's, there's, it, it sort of keeps things\ninteresting that, you know, why I can see, you know,\na lot of these things. I mean, it's kind of, I I\ndidn't expect, you know, ChatGPT, I didn't expect the kind of, the sort of opening up of\nthis idea of computational and computational language that's\nbeen made possible by this. I didn't expect that this is,\nthis is ahead of schedule, so to speak. You know, even though the sort of the, the big kind of flowering of\nthat stuff I'd sort of been assuming was another 50 years away. So if it turns out it's a lot less time, that's pretty cool because, you know, I'll hopefully get to see it, so to speak, rather than, than- - Well, I, I think I speak for a very, very large number of people\nin saying that I hope you stick around for a long time to come. You've had so many interesting ideas. You've created so many interesting\nsystems over the years, and I can see now that\nGPT and language models broke open the world even more. I can't wait to see you\nat the forefront of this development, what you, what you do. And yeah, I've been a fan of yours. Like I've told you many, many times since the very beginning. I'm deeply grateful that you\nwrote a new kind of science, that you explored this\nmystery of cellular automata and inspired this one little kid in me to, to pursue artificial intelligence in all this beautiful world. So Stephen, thank you so much. It's a huge honor to talk to you, to, to just be able to pick your\nmind and to explore all these ideas with you. And please keep going and I\ncan't wait to see what you come up with next. And thank you for talking today. - Thanks. - We went past midnight. We only did four and a half hours. I mean, we could probably\ngo for four more, but we'll save that till next time to, this is around number\nfour and we'll, I'm sure. Talk me more times. Thank you so much. - My pleasure. - Thanks for listening\nto this conversation with Steven Wolfram. To support this podcast please check out our sponsors in the description. And now let me leave you some\nwords from George Cantor, the essence of mathematics\nlies in its freedom. Thank you for listening and\nhope to see you next time."
    }
  ],
  "full_text": "- You know I can tell ChatGPT, create a piece of code and then\njust run it on my computer. And I'm like, you know, that, that sort of personalizes\nfor me the what could, what could possibly go wrong, so to speak. - Was that exciting or\nscary, that possibility? - [Wolfram] It was a\nlittle bit scary actually, because it's kind of like,\nif you do that right, What is the sandboxing\nthat you should have? And that's sort of a,\nthat's a, a version of, of that question for the world. That is, as soon as you put\nthe AIs in charge of things, you know, how much, how many\nconstraints should there be on these systems before\nyou put the AIs in charge of all the weapons and all these, you know, all these\ndifferent kinds of systems. - Well here's the fun\npart about sandboxes, is the AI knows about them and\nhas the tools to crack them. The following is a conversation\nwith Steven Wolfram, his fourth time on this podcast. He's a computer scientist, mathematician, theoretical physicist, and the\nfounder of Wolfram Research, a company behind\nMathematica, Wolfram Alpha, Wolfram Language and the Wolfram physics and meta mathematics projects. He has been a pioneer in exploring the computational nature of reality. And so he's the perfect person\nto explore with together the new quickly evolving\nlandscape of large language models as human civilization\njourneys towards building super intelligent AGI. This is a Lex Fridman podcast. To support it, Please check out our\nsponsors in the description. And now, dear friends\nhere's Stephen Wolfram. You've announced the\nintegration of ChatGPT and Wolfram Alpha and Wolfram Language. So let's talk about that integration. What are the key differences from the high philosophical level, maybe the technical level\nbetween the capabilities of, broadly speaking, the\ntwo kinds of systems, large language models, and this computational\ngigantic computational system infrastructure that is Wolfram Alpha? - Yeah. So what does\nsomething like ChatGPT do? It's, it's mostly\nfocused on make language, like the language that humans have made and put on the web and so on. Yeah, so, you know, it's, it's primary sort of\nunderlying technical thing is you've given a prompt, it's trying to continue\nthat prompt in a way that's somehow typical of what it's seen based on a trillion words of text that humans have written on the web. And the way it's doing\nthat is with something which is probably quite\nsimilar to the way we humans do the first stages of that, using a neural net and so on, and just saying, given these,\ngiven this piece of text, let's ripple through the\nneural net one word and, and get one word at a time of output. And it's kind of a, a shallow computation on a large amount of kind of training data that is what we humans\nhave put on the web. That's a different thing from\nsort of the computational stack that I've spent\nthe last, I don't know, 40 years or so building, which has to do with what\ncan you compute many steps, potentially a very deep computation. It's not sort of taking the statistics of what we humans have produced and trying to continue things\nbased on that statistics. Instead, it's trying to take\nkind of the formal structure that we've created in our civilization, whether it's from mathematics,\nor whether it's from kind of systematic knowledge of all kinds, and use that to do\narbitrarily deep computations to figure out things\nthat, that aren't just, let's match what's already\nbeen kind of said on the web, but let's potentially be\nable to compute something new and different that's never\nbeen computed before. So as a, as a practical matter, you know, the, the what we're, you know, the, our goal is to have made as\nmuch as possible of the world computable in the sense\nthat if there's a question that in principle is answerable from some sort of expert\nknowledge that's been accumulated, we can compute the\nanswer to that question, and we can do it in a sort\nof reliable way that's, that's the best one can do,\ngiven what the expertise that our civilization has accumulated. It's a very, it's a,\nit's a much more sort of labor intensive on the\nside of kind of being, creating kind of the, the\ncomputational system to do that. Obviously the in, in the, the\nkind of the ChatGPT world, it's like take things which were produced for quite other purposes, namely the all the things\nwe've written out on the web and so on, and sort of forage\nfrom that things which were, are like what's been written on the web. So I think, you know, as a,\nas a practical point of view, I view sort of the ChatGPT\nthing as being wide and shallow and what\nwe're trying to do with sort of building out computation\nas being this sort of deep, also broad, but, but most importantly kind of deep type of thing. I think another way to\nthink about this is, if you go back in human\nhistory, you know, I don't know, a thousand years or something, and you say, what, what,\nwhat can the typical person, what's the typical person\ngoing to figure out? Well, the answer is there's\ncertain kinds of things that we humans can quickly figure out. That's sort of what, what our, you know, other neural architecture\nand the kinds of things we learn in our lives let us do. But then there's this whole\nlayer of kind of formalization that got developed in which is, you know, the kind of whole sort of\nstory of intellectual history and the whole kind of depth of learning that formalization turned\ninto things like logic, mathematics, science and so on. And that's the kind of\nthing that allows one to kind of build these towers of, of, of, of sort of towers of things you work out. It's not just, I can immediately\nfigure this out, it's no, I can use this kind of\nformalism to go step by step and work out something which was not immediately obvious to me. And that's kind of the story of what, what we're trying to do computationally, is to be able to build\nthose kind of tall towers of what implies, what\nimplies what and so on. And as opposed to kind of the yes, I can immediately figure it out, it's just like what I saw\nsomewhere else in something that I heard or remembered\nor something like this. - What can you say about\nthe kind of formal structure or the kind of formal\nfoundation you can build such a formal structure on\nabout the kinds of things you would start on in order to build this kind of deep\ncomputable knowledge trees. - So the question is sort of how do you, how do you think about\ncomputation and there's, there's a couple of points here. One is what computation\nintrinsically is like, and the other is what\naspects of computation we humans with our minds\nand with the kinds of things we've learned can sort of relate to in that computational universe. So if we start on the kind of, what can computation be like, it's something I've spent some\nbig chunk of my life studying is imagine that you are,\nyou know, we, we usually, we write programs where we kind of know what we want the program to do and we carefully write, you\nknow, many lines of code and we hope that the program does what we, what we intended it to do. But the thing I've been\ninterested in is if you just look at the kind of\nnatural science of programs, so you just say, I'm gonna make this program,\nit's a really tiny program. Maybe I even pick the pieces\nof the program at random, but it's really tiny. And by really tiny, I mean, you know, less than a line of code type thing. You say, what does this\nprogram do? And you run it. And big discovery that I\nmade in the early eighties is that even extremely simple\nprograms when you run them can do really complicated things. Really surprised me. It took me several years\nto kind of realize that that was a thing, so to speak, but that that realization\nthat even very simple programs can do incredibly complicated things that we very much don't\nexpect that discovery, I mean, I realized that that's very\nmuch, I think how nature works. That is nature has simple rules, but yet does all sorts\nof complicated things that we might not expect, you know, as a big thing of the last few\nyears has been understanding that that's how the whole\nuniverse and physics works. But that's a, a quite separate topic. But, so there's this\nwhole world of programs and what they do and very rich, sophisticated things that\nthese programs can do. But when we look at\nmany of these programs, we look at them and say,\nwell that's kind of, I don't really know what that's doing. It's not a very human kind of thing. So on the one hand we have\nsort of what's possible in the computational universe. On the other hand, we have the kinds of things\nthat we humans think about, the kinds of things that have developed in kind of our intellectual history. And that's, and the, the really, the challenge to sort of\nmaking things computational is to connect what's\ncomputationally possible out in the computational\nuniverse with the things that we humans sort of typically\nthink about with our minds. Now that's a complicated\nkind of moving target because the things that we\nthink about change over time, we've learnt more stuff,\nwe've invented mathematics, we've invented various kinds of ideas and structures and so on. So it's, it's gradually expanding. We're kind of gradually\ncolonizing more and more of this kind of intellectual\nspace of possibilities. But the, the real thing, the real challenge is how do you take, what is computationally possible? How do you take, how do you encapsulate the kinds of things that we think about in a\nway that kind of plugs into what's computationally possible. And and actually the, the,\nthe big sort of idea there is this idea of kind of\nsymbolic programming, symbolic representations of things. And so the, the question\nis when you look at sort of everything in the world\nand you kind of, you know, you take some visual scene or something you're looking at and then you say, well, how do I turn that into something that I can kind of stuff into my mind? You know, there are lots of\npixels in my visual scene, but the things that I remembered\nfrom that visual scene are, you know, there's a chair in this place, it's a kind of a symbolic representation of the visual scene. There are two chairs on\na table or something, rather than there are\nall these pixels arranged in all these detailed ways. And so the question then is how\ndo you take sort of all the, all the things in the world and make some kind of representation that corresponds to the types of ways that we think about things. And, and human language is, is sort of one form of\nrepresentation that we have. We talk about chairs, that's a word in human language and so on. How do we, how do we take, but human language is not\nin and of itself something from that plugs in very\nwell to sort of computation. It's not something from which you can immediately compute\nconsequences and so on. And so you have to kind of\nfind a way to take sort of the, the, the stuff we understand\nfrom human language and make it more precise. And that's really the story\nof, of symbolic programming. And you know what, what that turns into is something which I didn't know at the time it was going to work as well as it has, but back in the 1979 or so, I was trying to build my\nfirst big computer system and trying to figure out, you know, how should I represent\ncomputations at a high level. And I kind of invented\nthis idea of using kind of symbolic expressions, you know, structured as it's kind of like a, a function and a bunch of arguments, but that function doesn't\nnecessarily evaluate to anything. It's just a, a thing that sits there representing a structure. And so building up that structure and it's turned out that\nstructure has been extremely, it's a, it's a good match\nfor the way that we humans, it seems to be a good match for the way that we humans kind of\nconceptualize higher level things. And it's been for the last, I don't know, 45 years or something, it's\nserved me remarkably well. - So building up that structure using this kind of\nsymbolic representation. But what can you say\nabout abstractions here? Because you could just start\nwith your physics project. You could start at a hypergraph at a very, very low level and build\nup everything from there, but you don't, right, you take shortcuts. - [Wolfram] Right? - You, you take the highest\nlevel of abstraction, convert that, the kind of abstraction that's\nconvertible to something computable using symbolic\nrepresentation and then that, that's your new foundation for that little piece of knowledge. - [Wolfram] Yes. - Somehow all that is integrated. - Right? So the, the sort of\na very important phenomenon that is kind of a thing that\nI've sort of realized is just, it's one of these things\nthat sort of in the, in the future of kind\nof everything is going to become more and more important as this phenomenon of\ncomputational reducibility. And the, the question is, if you know the rules for\nsomething, you have a program, you're gonna run it. You might say, I know the rules, great, I know everything about\nwhat's gonna happen. Well in principle you do\nbecause you can just run those rules out and just see what they do. You might run them a million\nsteps, you see what happens, et cetera. The question is, can you like immediately\njump ahead and say, I know what's gonna happen\nafter a million steps. And the answer is 13 or something. - [Fridman] Yes. - And the, the one of\nthe very critical things to realize is if you could\nreduce that computation, there isn't a sense, no point in doing the computation. - [Fridman] Yeah. - The place where you really\nget value outta doing the computation is when you\nhad to do the computation to find out the answer. But this phenomenon that you\nhave to do the computation to find out the answer, this phenomenon of computational\nreducibility seems to be tremendously important for thinking about lots of kinds of things. So one of the things\nthat happens is, okay, you've got a model of the\nuniverse at the low level in terms of atoms of space and hypergraphs and rewriting hypergraphs and so on. And it's happening, you know, 10 to the 100 times\nevery second, let's say. Well, you say great, then\nwe've, we've nailed it. We've, we've, we know\nhow the universe works. Well the problem is the\nuniverse can figure out what it's gonna do. It does those 10 to the\n100, you know, steps. But for us to work out what it's gonna do, we have no way to reduce that computation. The only way to do the computation, to see the result of the\ncomputation is to do it. And if we're operating\nwithin the universe, we're kind of, there's no, there's no opportunity to\ndo that because the universe is doing it as fast as\nthe universe can do it. And that's, you know,\nthat's what's happening. So what we're trying to do, and a lot of the story of science and a lot of other kinds of things is finding pockets of reducibility. That is, you could have a situation\nwhere everything in the world is full of computational reducibility, we never know what's gonna happen next. The only way we can figure out\nwhat's gonna happen next is just let the system run\nand see what happens. So in a sense, the story of, of most kinds of science, inventions, a lot of kinds of things is\nthe story of finding these places where we can locally jump ahead. And one of the features of\ncomputational reducibility is there are always pockets of reducibility. There are always places, there are always an\ninfinite number of places where you can jump ahead. There's no way where you\ncan jump completely ahead. But there are little, little patches, little places where you\ncan jump ahead a bit. And I think, you know, we can talk about physics\nproject and so on, but I think the thing we\nrealize is we kind of exist in a slice of all the\npossible computational id reducibility in the universe. We exist in a slice where\nthere's a reasonable amount of predictability. And in a sense, as we try and construct these\nkind of higher levels of, of abstraction symbolic\nrepresentations and so on, what we're doing is\nwe're finding these lumps of reducibility that we can\nkind of attach ourselves to and about, which we can kind of have fairly simple narrative things to say. Because in principle, you know, I say what's gonna happen\nin the next few seconds? You know, oh, there are these molecules\nmoving around in the air in this room and oh gosh, it's an incredibly complicated\nstory and that's a whole computational irreducible thing, most of which I don't care about. And most of it is, well, you know, the air's still gonna be here\nand nothing much is going to be different about it. And that's a kind of reducible fact about what is ultimately\nat an underlying level of computational irreducible process. - And life would not be possible\nif we didn't have a large number of such reducible pockets. - [Wolfram] Yes. - Pockets amenable to reduction\ninto something symbolic. - Yes, I think so. Okay. I mean, life in, in the\nway that we experience it, that, I mean, you know,\none might, you know, depending on what we mean by\nlife, so to speak, the, the, the experience that we have\nof sort of consistent things happening in the world, the\nidea of space, for example, where there's, you know, we\ncan just say you are here, you move there, it's\nkind of the same thing. It's still you in that different\nplace even though you're made of different atoms\nof space and so on. This is this idea that it's, that there's sort of this\nlevel of predictability of what's going on. That's us finding a slice\nof reducibility in what is underneath this computation\nirreducible kind of system. And I think that's, that's sort of the, the thing which is actually\nmy favorite discovery of the last few years, is the realization that it\nis sort of the interaction between this sort of\nunderlying computational irrereducibility and our\nnature as kind of observers who sort of have to key into\ncomputational reducibility. That fact leads to the main\nlaws of physics that we discovered in through 20th century. So this is, we talk about\nthis in, in in more detail, but this is, to me, it's kind\nof our nature as observers. The fact that we are\ncomputationally bounded observers. We don't get to follow\nall those little pieces of computational irrereducibility to stuff. What is about out there in the\nworld into our minds requires that we are looking at\nthings that are reducible, we are compressing kind of, we are, we're extracting just some essence, some kind of symbolic essence of what's the detail of\nwhat's going on in the world. That together with one other condition that first seems sort\nof trivial but isn't, which is that we believe\nwe are persistent in time. That is. - Yes. - [Wolfram] You know. - So causality. - Here's the thing. At every\nmoment according to our theory, we are made of different atoms\nof space at every moment. Sort of the microscopic detail\nof what what the universe is made of is being rewritten. And that's, and in fact, the very fact that this coherence\nbetween different parts of space is a consequence of the\nfact that there are all these little processes going on\nthat kind of knit together the structure of space. It's kind of like if you wanted\nto have a fluid with a bunch of molecules in it, if those\nmolecules weren't interacting, you wouldn't have this\nfluid that would pour and do all these kinds of things. It would just be sort of\na free floating collection of molecules. So similar it is with space\nthat the fact that space is kind of knitted together as a consequence of all this activity in space. And the fact that kind of what, what we consist of sort of\nthis, this series of, of of, you know, we're, we're\ncontinually being rewritten. And the question is, why is it the case that\nwe think of ourselves as being the same us through time? That's kind of a, a key assumption. I think it's a key aspect of\nwhat we see as sort of our consciousness so to speak, is that we have this kind of consistent thread of experience. - Well isn't that just\nanother limitation of our mind that we wanna reduce- - [Wolfram] Yeah. - Reality into some that kind of temporal - [Wolfram] Yes. - Consistency is just a nice\nnarrative to tell ourselves. - [Wolfram] Right. Well, the fact is, I think it's critical to the\nway we humans typically operate is that we have a single\nthread of experience. You know, if you, if\nyou imagine sort of a, a mind where you have, you know, maybe that's what's happening\nin various kinds of minds that aren't working the same\nway other minds work is that you're splitting into multiple threads of experience. It's also, it's also\nsomething where, you know, when you look at, I don't know, quantum mechanics for example, in the insides of quantum mechanics, it's splitting into many\nthreads of experience. But in order for us humans\nto interact with it, you kind of have to have to\nknit all those different threads together so that we say, oh yeah, a definite thing happened and now the next definite thing happens and so on. And I think, you know, sort of inside it, it's sort of interesting to\ntry and imagine what's it like to have kind of these\nfundamentally multiple threads of experience going on. I mean, right now different human minds have different threads of experience. We just have a bunch of minds that are interacting with each other, but we don't have a a you know, within each mind there's a single thread. And that's a, that is indeed a simplification. I think it's a, it's a thing, you know, the general computational system does not have that simplification. And it's one of the things, you know, I I people often seem\nto think that, you know, consciousness is the, the highest level of kind\nof things that can happen in the universe, so to speak. But I think that's not true. I think it's actually a, a a specialization in\nwhich among other things, you have this idea of a\nsingle thread of experience, which is not a general feature\nof anything that could kind of computationally happen in the universe. - So it's a feature of a\ncomputationally limited system that's only able to\nobserve reducible pockets. - [Wolfram] Yeah. - So I mean this word observer, it, it means something in quantum mechanics, it means something in a lot of places. It means something to us humans. - [Wolfram] Right. - As conscious beings. So what, what's the importance of the\nobserver? What is the observer? What's the importance of the observer in the computational universe? - So this question of what is an observer? What's the general idea of an observer? It's actually one of my next\nprojects which got somewhat derailed by the, the current\nsort of AI mania. But- - Is there a connection\nthere or is that, do you, do you think the observer\nprimarily a physics phenomena? - Is it related to the whole AI thing? - Yes. - [Wolfram] Yes, it is related. So one question is, what\nis a general observer? So, you know, we know we have an idea what is a general computational system. We think about touring machines, we think about other\nmodels of computation. There's a question, what is a\ngeneral model of an observer? And there there's kind\nof observers like us, which is kind of the\nobservers we're interested in. You know, we could imagine an\nalien observer that deals with computational I irrereducibility\nand it has a mind that's utterly different from ours and, and completely incoherent\nwith what, what we are like. But the fact is that that, you know, if we are talking about observers like us, that one of the key things is\nthis idea of kind of taking all the detail of the world and being able to stuff it into a mind, being able to take all\nthe detail and kind of, you know, extract out\nof it a smaller set of, of kind of degrees of freedom. A smaller number of, of elements that will\nsort of fit in our minds. And I think this, this question, so I've been interested\nin trying to characterize what is the general observer. And the general observer is, I think in part there are many, let let me give an example of\na, you know, you have a gas, it's got a bunch of molecules\nbouncing around and the thing you are measuring about\nthe gas is it's pressure. And the only thing you as an observer care about is pressure. And that means you have a\npiston on the side of this box and the piston is being pushed by the gas. And there are many, many different ways that\nmolecules can hit that piston. But all that matters is\nthe kind of aggregate of all those molecular impacts. Because that's what determines pressure. So there's a huge number\nof different configurations of the gas, which are all equivalent. So I think one key aspect of\nobservers is this equivalent thing of many different\nconfigurations of a system saying, all I care about is\nthis aggregate feature. All I care about is\nthis, this overall thing. And that's, that's sort\nof one, one aspect. And we see that in lots\nof different, again, it's the same story over\nand over again that there's, there's a lot of detail in the world, but what we are extracting from it is something a sort of a thin, a thin summary of that, of that detail. - Is that thin summary nevertheless true. Is can it be a crappy\napproximation that an average is, is correct. I mean, if we look at the observer, that's the human mind, it seems\nlike there's a lot of very, as represented by natural\nlanguage for example, there's a lot of really\ncrappy approximation. - [Wolfram] Sure. - And that could be maybe a feature of it. - [Wolfram] Well, yes. - But there's ambiguity. - [Wolfram] Right, right. You don't know, you know,\nit could be the case you, you're just measuring\nthe aggregate impacts of these molecules,\nbut there is some tiny, tiny probability that molecules\nwill arrange themselves in some really funky way. And that just measuring that average isn't going to be the main point. - [Fridman] Yeah. - By the way, an awful lot of science is very\nconfused about this because, you know, you look at, you look at papers and\npeople are really keen, they draw this curve and\nthey have these, you know, these bars on the curve and things. And it's just this curve\nand it's this one thing, and it's supposed to represent\nsome system that has all kinds of details in it. And this is a way that lots\nof science has gotten wrong because people say, I remember years ago I was\nstudying snowflake growth that, you know, you have the\nsnowflake and it's growing, it has all these arms, it's\ndoing complicated things. But there was a literature\non this stuff and it talked about, you know, what's the\nrate of snowflake growth? And you know, it, it got pretty good answers for the rate of the\ngrowth of the snowflake. And they looked at it more carefully. And then they had these\nnice curves of, you know, snowflake growth rates and so on. I looked at it more carefully\nand I realized according to their models, the snowflake\nwill be spherical. And so they got the growth rate right. But the detail was just utterly wrong. And you know, the not\nonly the detail, the, the whole thing was, was\nnot capturing, you know, it was capturing this aspect of the system that was in a sense, missing the main point\nof what was going on. - What is the geometric\nshape of a snowflake? - Snowflakes start in, in the phase of water that's relevant. - [Fridman] Yeah. - To the formation of snowflakes. It's a phase of ice, which starts with a\nhexagonal arrangement of, of water molecules. And so it starts off growing\nas a hexagonal plate. And then what happens is- - Is the plate, oh, oh versus sphere. - Well, no, no, but it's,\nit's much more than that. I mean, snowflakes are fluffy, you know, typical snowflakes have\nlittle, little dendritic arms. - [Fridman] Okay, yeah, yeah, yeah. - And, and what actually happens is, it's kind of kind of cool\nbecause you can make these very simple discrete models with\ncellular automata and things that, that figure this out. You start off with this,\nyou know, hexagonal thing, and then the places it, it starts to grow little arms, and every time a little piece of ice, it adds itself to the snowflake. The fact that that ice condensed\nfrom the water vapor heats the snowflake up locally. And so it makes it less likely for, for another piece of ice\nto accumulate right nearby. So this leads to a kind\nof growth inhibition. So you grow an arm and it, it is a, a separated arm because right\naround the arm it got a little bit hot and it didn't add more ice there. So what happens is it\ngrows, you have a hexagon, it grows out arms, the arms grow arms, and then the arms grow arms grow arms. And eventually, actually\nit's kind of cool because it, it actually fills in another\nhexagon, a bigger hexagon. And when I first looked at this, you know, had a very simple model for\nthis, I realized, you know, when it fills in that hexagon, it actually leaves some holes behind. So I thought, well, you know,\nthat is that really right? So I look at these pictures\nof snowflakes and sure enough they have these little holes\nin them that are kind of scars of the way that these arms grow out. - So you can't fill in backfill\nholes. So you keep going. - They don't backfill. Yeah, they don't backfill. - And, and presumably there's\na limitation on how big, like you can't arbitrarily grow. - I'm not sure. I mean, the\nthing falls through the, the, I mean, I think it does, you know, it hits the ground at some point. I think you can grow. I I think you can grow in the lab. I think you can grow pretty big ones. I think you can grow\nmany, many iterations of, this kind of goes from\nhexagon, it grows out arms, it turns back, it fills\nback into a hexagon. It grows more arms again in. - In 3D. - No. It's flat usually. - Why is it flat? Why doesn't it spin out?\nOkay, okay, wait a minute. You said it's fluffy and\nfluffy is a three-dimensional property, no or. - No, it's, it's fluffy snow is. Okay. So you know what makes we're really, we're really in a- - [Fridman] Let's go there. Multiple snowflakes become fluffy. A single snowflake is not fluffy? - No, no. A single snowflake is fluffy. And what happens is, you know, if, if you have snow that\nis just pure hexagons, they, they can, you know, they,\nthey fit together pretty well. It's not, it doesn't, it doesn't make, it doesn't have a lot of air in it. And they can also slide against\neach other pretty easily. And so the snow can be\npretty, you know, can, I think avalanches happen sometimes when, when the things tend\nto be these, you know, hexagonal plates and it kind of slides. But then when the thing has all these arms that have grown out, it's not, they don't\nfit together very well. And that's why the snow\nhas lots of air in it. And if you look at one\nof these snowflakes, and if you catch one, you'll\nsee it has these little arms. And people actually,\npeople often say, you know, no two snowflakes are alike. That's mostly because\nas a snowflake grows, they do grow pretty consistently with these different arms and so on. But you capture them at\ndifferent times as they, you know, they fell through, through the air in a different way. You'll catch this one, this stage. And as it goes through different stages, they look really different. And so that's why, you know, it kinda looks like no two\nsnowflakes are alike because you caught them at different,\nat different times. - So the rules under which\nthey grow are the same. - [Wolfram] Yes. - It's just the timing is- - [Wolfram] Yes. - Okay. So the point is, science is not able to describe the full complexity of snowflake growth. - Well science, if you, if you do what people might often do, which is say, okay,\nlet's make it scientific, let's turn into one number, and that one number is kind\nof the growth rate of the arms or some such other thing, that fails to capture\nsort of the detail of what's going on inside the system. And that's, in a sense, a big challenge for science\nis how do you extract from the natural world, for example, those aspects of it\nthat you are interested in talking about. Now you might just say, I don't really care about the\nfluffiness of the snowflakes. All I care about is the\ngrowth rate of the arms. In which case, you know, you have, you can have a good model\nwithout knowing anything about the fluffiness. But the fact is, as a practical,\nyou know, when if you, if you say what's the, what is the most obvious\nfeature of a snowflake? Oh, that it has this complicated shape, well then you've got a different\nstory about what you model. I mean, this, this is\none of the features of, of sort of modeling and\nscience that, you know, what is a model? A model is some way of reducing\nthe actuality of the world to something where you can\nreadily sort of give a narrative for what's happening, where you can basically make\nsome kind of abstraction of what's happening and answer questions that you care about answering. If you wanted to answer all possible questions about the system, you'd have to have the whole\nsystem because you might care about this particular molecule. Where did it go? And you know, your model, which is some big abstraction of that has nothing to say about that. So, you know, one of the things that's, that's often confusing in sciences, people will have, I've got\na model, somebody says, somebody else will say, I don't believe in your model\nbecause it doesn't capture the feature of the\nsystem that I care about. You know, there's always\nthis controversy about, you know, is the, is it a correct model? Well, no model is a, except for the actual system itself is a correct model in the sense\nthat it captures everything. Question is, does it capture\nwhat you care about capturing? Sometimes that's ultimately\ndefined by what you're going to build technology out of things like this. The one counterexample to\nthis is if you think you're modeling the whole\nuniverse all the way down, then there is a notion of a correct model. But even that is more complicated\nbecause it depends on kind of how observers sample things and so on. That's a, that's a separate story, but at least at the first\nlevel to say, you know, this thing about, oh,\nit's an approximation. You're capturing one aspect, you're not capturing other aspects. When you really think\nyou have a complete model for the whole universe, you better be capturing\nultimately everything, even though to actually run\nthat model is impossible because of computational reducibility. The only, the only thing that\nsuccessfully runs that model is the actual running of the universe. - Is the universe itself. But okay, so what you care about is\nan interesting concept. So that's a, that's a human concept. So that's what you're\ndoing with Wolfram Alpha and Wolfram Language, is you're trying to come up\nwith symbolic representations. - [Wolfram] Yes. - As simple as possible. So a model that's as simple as\npossible that fully captures stuff we care about. - [Wolfram] Yes. So I mean, for example, you\nknow, we could we'll have a, a thing about, you\nknow, data about movies, let's say we could be describing every individual pixel\nin every movie and so on. But that's not the level\nthat people care about. And it's, yes, this is a, I mean, and, and that level that people\ncare about is somewhat related to what's described in natural language. But what what we're trying to\ndo is to find a way to sort of represent precisely so\nyou can compute things. See one thing when you say\nyou give a piece of a natural language question is you\nfeed it to a computer. You say, does the computer understand\nthis natural language? Well, you know, the computer processes it\nin some way it does this, maybe it can make a continuation\nof the natural language. You know, maybe it can go on from the prompt and say what it's gonna say. You say, does it really understand it? Hard to know. But for in this kind\nof computational world, there is a very definite\ndefinition of does it understand, which is could it be turned\ninto this symbolic computational thing from which you can compute\nall kinds of consequences? And that's the, that's the sense in which\none has sort of a target for the understanding of natural language. And that's kind of our goal\nis to have as much as possible about the world that can be computed in a, in a reasonable way, so to speak, be able to be sort of captured by this kind of computational language. That's, that's kind of the goal. And, and I think for us humans, the, the main thing that's important\nis as we formalize what we're talking about, it gives us a way of kind of\nbuilding a structure where we can sort of build this tower\nof consequences of things. So if we're just saying, well, let's talk about it a natural language, it doesn't really give us some\nhard foundation that lets us, you know, build step by\nstep to work something out. I mean, it's kind of like\nwhat happens in, in math, if we were just sort of\nvaguely talking about math but didn't have the kind of\nfull structure of math and all that kind of thing, we wouldn't be able to build this kind of big tower of consequences. And so, you know, in, in a sense what we're\ntrying to do with the whole computational language effort\nis to make a formalism for describing the world that makes\nit possible to kind of build this, this tower of consequences. - Well can you talk about this dance between natural language\nand Wolfram Language? So there's this gigantic\nthing we call the internet where people post memes and diary type thoughts and very important sounding\narticles and all of that. That makes up the\ntraining data set for GPT, and then there's Wolfram Language. How can you map from the\nnatural language of the internet to the Wolfram language? Is there an manual? Is there\nan automated way of doing that? As we look into the future? - Well, so Wolf and Alpha, what it does, it's kind of front end is\nturning natural language into computational language, right? - What you mean by that\nis there's a prompt, you ask a question, what is\nthe capital of some country. - And it, and it turns into, you know, what's the distance between, you know, Chicago and London or something. And that will turn into, you know, geo distance of entity city, you know, et cetera, et cetera, et cetera. Each one of those things is very, is very well defined. We know, you know, given that it's the entity\ncity, Chicago, et cetera, et cetera, et cetera, you\nknow, Illinois, United States, you know, we know the geolocation of that. We know it's population, we know all kinds of things\nabout it, which we have, you know, curated that data to be able to, to know that with some degree\nof certainty, so to speak. And then, then we can\ncompute things from this. And that's, that's kind of the yeah. That, that's, that's that's the idea. - But then something like\nGPT large language models, do they allow you to make that conversion much more powerful? - Okay, so it's an interesting thing which we still don't know everything about. Okay. The, I mean this question of\ngoing from natural language to computational language, yes. In Wolfram Alpha, we've now, you know, Wolfram Alpha has been\nout and about for what, 13 and a half years now. And, you know, we've achieved,\nI don't know what it is, 98%, 99% success on queries\nthat get put into it. Now, obviously there's\na sort of feedback loop because the things that work are things people go on putting into it. So yeah, that that, but you know, we've, we've got to a very high\nsuccess rate of the, the little fragments of natural\nlanguage that put people put in, you know, questions,\nmath calculations, chemistry calculations, whatever it is. You know, we can, we can,\nwe, we do very well at that, turning those things into\ncomputational language. Now I, from the very\nbeginning of Wolfram Alpha, I thought about, for example, writing code with natural language. In fact, I had, I, I was just\nlooking at this recently. I had a post that I wrote in 2010, 2011 called something like\nProgramming with Natural Language is actually Going to Work. Okay. And so, you know, we had done a bunch of experiments\nusing methods that were yeah, a little bit. Some of them are little\nbit machine learning like, but certainly not the same, you know, the same kind of idea of\nvast training data and so on. That is the story of\nlarge language models. Actually I know that that\npost piece of utter trivia, but that, that post Steve Jobs forwarded\nthat post around to all kinds of people at Apple. And he, you know, that was because he never really liked programming languages. So he was very happy to see the\nidea that that that that you could get rid of this kind of\nlayer of kind of engineering like structure he\nwould've liked, you know, I think what's happening now, because it really is the\ncase that you can, you know, this idea that you have to\nkind of learn how the computer works to use a programming\nlanguage is something that is I think a, a a thing that, you know, just like you had to learn\nthe details of the op codes to know how similar\nlanguage worked and so on. It's kind of a thing that's, that's that's a limited time horizon. But, but kind of the, the, you know, so this idea of how elaborate can you make kind of the prompt, how elaborate can you\nmake the natural language and abstract from it\ncomputational language. It's a very interesting question. And you know what, ChatGPT, you know, GBT four and so on can do is pretty good. It isn't, it's very interesting process. I mean I'm still trying to\nunderstand this workflow. We've been working out a lot\nof tooling around this workflow - The natural language to\ncomputational language. - [Wolfram] Right. - And the process. Especially if it's\nconversation like dialogue, it's like multiple queries kind of thing. - Yeah. Right. There's so many things that\nare really interesting that, that, that work and so on. So first thing is, can you just walk up to the computer and expect to sort of\nspecify a computation? What one realizes is humans\nhave to have some idea of kind of this way of thinking\nabout things computationally. Without that you're kind of\nout of luck because you just have no idea what you're going\nto walk up to a computer. I remember when I, I should\ntell a silly story about myself, the very first computer I saw, which is when I was 10 years\nold and it was a big mainframe computer and so on, and I didn't really understand\nwhat computers did and it's like somebody's showing me\nthis computer and it's like, you know, can the computer work out\nthe weight of a dinosaur? It's like, that isn't a\nsensible thing to ask. That's kind of, you know,\nyou have to give it, that's not what computers do. I mean, and Wolfram Alpha for example, you could say what's the\ntypical weight of a stegosaurus? And we'll give you some answer, but that's a very different\nkind of thing from what one thinks of computers as doing. And so the, the kind of the\nthe question of, you know, first thing is people have\nto have an idea of what, what computation is about. You know, I think it's a very, you know, for education that is the\nkey thing. It's kind of this, this, this notion, not computer science, not so that the details are programming, but just this idea of how\ndo you think about the world computationally computation, thinking about the world\ncomputationally is kind of this formal way of thinking about the world. We've had other ones, like logic\nwas a formal way, you know, as a way of sort of abstracting and formalizing some aspects of the world. Mathematics is another one. Computation is this very broad\nway of sort of formalizing the way we think about the world. And the thing that's, that's cool about computation\nis if we can successfully formalize things in terms of computation, computers can help us figure\nout what the consequences are. It's not like you formalized it with math. Well that's nice, but now you\nhave to, if you're, you know, not using a computer to do the math, you have to go work out a\nbunch of stuff yourself. So I think, but the, this idea,\nlet's see, I mean the, the, you know, we're trying\nto take kind of the, we're talking about\nsort of natural language and its relationship to\ncomputational language. The, the thing, the sort of the typical workflow\nI think is first human has to have some kind of idea of\nwhat they're trying to do. That if it, if it's something that they\nwant to sort of build a tower of, of capabilities on something\nthat they want to sort of formalize and make computational, so then human can type\nsomething into, you know, some LLM system and sort of say vaguely what they want in sort\nof computational terms, then it does pretty well at synthesizing Wolfram Language code, and it'll probably do better in the future because we've got a huge\nnumber of examples of, of natural language input\ntogether with the Wolfram Language translation of that. So it's kind of a, a you know, that that's a thing where you\ncan kind of extrapolating from all those examples makes it\neasier to do that, that task. - Is the prompter task\ncould also kind of debugging the Wolfram Language code? Or is your hope to not do that debugging? - Oh, no. No, no. I mean, so, so there are many steps here. Yeah. Okay, so first, the first thing is you\ntype natural language, it generates Wolfram Language. - Do you have examples by the way? Do you have, do you have an\nexample that is, is it the, the dinosaur example, do you have an example that jumps to mind that we should be thinking about? Some dumb example. - It's like, take my heart\nrate data and you know, figure out whether I, you know, make a moving average every\nseven days or something and work out what the, and and\nmake a a plot of the result. Okay. So that's a thing\nwhich is, you know, about two-thirds of a line\nof Wolfram Language code. I mean it's, you know, list plot of moving average\nof some data bin or something of the, of the data and\nthen you'll get the result. And you know, the vague thing that I was just saying in natural language could, would almost certainly correctly\nturn into that very simple piece of Wolfram Language code. - You start mumbling about heart rate. - [Wolfram] Yeah. - Kinda, you know, you arrive at the moving\naverage kind of idea. - Right? You say average over seven days, maybe it'll figure out that\nthat's a moving, you know, that that can be encapsulated\nas this moving average idea. I'm not sure. But then the typical workflow, but I'm seeing is you generate this piece of Wolfram Language code,\nit's pretty small usually. It's, and if it isn't small, it probably isn't right. But you know, if it's, it's\npretty small and, you know, Wolfram Language is, one of the ideas of Wolfram Language is, it's a language that humans can read. It's not a language which, you know, programming languages tend\nto be this one way story of humans write them and\ncomputers execute from them. Wolfram Language is\nintended to be something which is sort of like math\nnotation something where, you know, humans write it and humans are supposed\nto read it as well. And so kind of the workflow\nthat's emerging is kind of this, this human mumbles some things, you know, large language model produces a fragment of Wolfram Language code. Then you look at that, you say, yeah, that looks well, typically\nyou just run it first, you see does it produce the right thing? You look at what it produces. You might say, that's obviously crazy. You look at the code, you\nsee I see why it's crazy. You fix it. If you really care about the\nresults and you really wanna make sure it's right, you better look at that code\nand understand it because that's the way you have the\nsort of checkpoint of did it really do what I expected it to do? Now you go beyond that. I mean it's, it's, it's, you know, what we find is, for example, let's say the code does the wrong thing, then you can often say to\nthe large language model, can you adjust this to do this? And it's pretty good at doing that. - Interesting. So you're using the output\nof the code to give you hints about the, the, the function of the code. So you're debugging based on\nthe output of the code itself. - And by the way, right, The plugin that we have\nor the, the, you know, for ChatGPT, it does\nthat routinely, you know, it will send the thing\nin, it will get a result. It will discover, the LLM will discover\nitself that the result is not plausible and it will\ngo back and say, oh, I'm sorry, it's very polite and it it, you know, it, it goes back and says, I'll rewrite that piece of\ncode and then it will try it again and get the result. The other thing that's\npretty interesting is when you're just running, so one of the new concepts that we have, we invented this whole idea of notebooks back 36 years ago now. And so now there's the\nquestion of sort of how do you combine this idea of notebooks\nwhere you have, you know, text and code and output, how do you combine that\nwith the notion of, of chat and so on. And there's some really\ninteresting things there. Like for example, a very typical\nthing now is we have these, these notebooks where as soon as the, if, if the thing produces\nerrors, if the, you know, run this code and it produces\nmessages and so on, the, the, the LLM automatically not\nonly looks at those messages, it can also see all kinds of\ninternal information about stack traces and things like this. And it can then, it does a remarkably good\njob of guessing what's wrong and telling you. So in other words, it's, it's looking at things,\nit's sort of interesting, it's kind of a, a typical sort of AI ish thing\nthat it's able to have more sensory data than we humans\nare able to have cause able to look at a bunch of stuff that\nwe humans would kind of glaze over looking at. And it's able to then come up with, oh this is the explanation\nof what's happening. - And, and what is the\ndata the stack trace, the, the code you've written previously, the natural language you've written. - Yeah. It's also what's happening is\none of the things that's is is for example, when there's these messages, there's documentation\nabout these messages, there's examples of where the messages have occurred otherwise. - [Fridman] Nice. - All these kinds of things. The other thing that's really\namusing with this is when it makes a mistake, one of the things that's in our\nprompt when the code doesn't work is read the documentation\nand we have a, you know, another piece of the plugin\nthat lets it read documentation. And that again is very, very\nuseful because it, it will, you know, it will figure\nout, sometimes it'll get, it'll make up the name of some\noption for some function that doesn't really exist. Read the documentation, it'll have, you know, some wrong structure\nfor the function and so on. It's, that's a powerful thing. I mean the thing that, you know, I've realized is we built this language over the course of all\nthese years to be nice and coherent and consistent and so on. So it's easy for humans to understand. Turns out there was a side\neffect that I didn't anticipate, which is it makes it easier\nfor AIs to understand. - It's almost like another\nnatural language. But-. - [Wolfram] Yeah. - So, so Wolfram language is\na kind of foreign language. - [Wolfram] Yes, yes. - You have a lineup. English, French, Japanese,\nWolfram language and then I don't know Spanish, and then the system is not\ngonna notice. Hopefully. - Well, yes, I mean maybe, you know, that's an interesting question because it really depends on\nwhat I see as being a, a an important piece of\nfundamental science that basically just jumped out at us with ChatGPT. Because I think, you know, the, the real question is\nwhy does ChatGPT work? How is it possible to\nencapsulate, you know, to successfully reproduce\nall these kinds of things in natural language, you\nknow, with a, you know, a comparatively small, he says, you know, couple hundred billion, you know, weights of neural nets and so on. And I think that, you know, that that relates to kind of a, a fundamental fact about language, which, you know, the, the\nmain, the main thing is that I think there's a\nstructure to language that we haven't kind of\nreally explored very well. It's kind of this semantic\ngrammar I I'm talking about, about, about language. I mean, we, we kind of know that when we, when we set up human language, we know that it has certain regularities. We know that it has a certain\ngrammatical structure, you know, noun followed by verb, followed by noun, adjectives, et cetera, et cetera, et cetera. That's, its kind of grammatical structure. But I think the thing that\nChatGPT is showing us is that there's an additional kind\nof regularity to language, which has to do with the\nmeaning of the language beyond just this pure, you know, part of speech combination type of thing. And I, I think the, the, the kind of the, the one example of that that\nwe've had in the past is logic. And you know, I, I think my, my sort of kind of picture\nof how was logic invented? How was logic discovered? It really was a thing that was discovered in its original conception. It was discovered presumably by Aristotle who kind of listened to a\nbunch of people orators, you know, giving speeches. And this one made sense,\nthat one doesn't make sense, this one, and you know, you see\nthese patterns of, you know, if the, you know, I don't\nknow what, you know, if the, if the Persians do this,\nthen the, this does that, et cetera, et cetera, et cetera. And what, what Aristotle realized is there's a structure to those sentences, there's a structure to that\nrhetoric that doesn't matter whether it's the Persians\nand the Greeks or whether it's the cats and the dogs. It's just, you know, p and q\nyou can abstract from this, the, the details of these\nparticular sentences. You can lift out this\nkind of formal structure. And that's what logic is. - That's a heck of a discovery by the way. Logic, you're making me realize now. - [Wolfram] Yeah. - It's not obvious. - The fact that there is an abstraction from natural language that has, where you can fill in any word you want. - [Fridman] Yeah. - Is a very interesting discovery. Now it took a long time to mature. I mean, Aristotle had this\nidea of silogistic logic where there were these particular patterns of how you could argue\nthings, so to speak. And you know, in the Middle Ages part of education was you memorized the syllogisms, I forget how many there were, but 15 of them or something. And they all had names, they all had mnemonics. Like I think Barbara and\nCelarent were two of the, the mnemonics for the silogisms. And people would kind of, this is a valid argument\nbecause it follows the Barbara of Syllogism, so to speak and, and it\ntook until 1830, you know, with George Bule to kind of\nget beyond that and kind of see that there was a, a level of abstraction\nthat was beyond the, this particular template\nof a sentence, so to speak. And that's, you know, what, what's interesting there\nis in a sense, you know, ChatGPT is operating at\nthe Aristotelian level. It's essentially dealing\nwith templates of sentences. By the time you get to\nBule and Bule and algebra and this idea of, you know, you can have arbitrary depth\nnested collections of ans and awes and knots, and you\ncan resolve what they mean. That's the kind of thing\nthat's a computation story. That's, you know, you've gone beyond the pure\nsort of templates of natural language to something, which is an arbitrarily deep computation. But the thing that I\nthink we realized from, from ChatGPT is, you know, Aristotle stopped too quickly\nand there was more that you could have lifted out of\nlanguage as formal structures. And I think there's, you know, in a sense we've captured\nsome of that in, in, you know, some of what, what is in language there. There's, there's a, there's a lot of kind of little calculate, little algebras of, of what you can say, what language talks about. I mean, whether it's, I don't know, if you say I\ngo from place A to place B, place B to place C, then I know I've gone\nfrom place A to place C. If A is a friend of B\nand B is a friend of C, it doesn't necessarily follow\nthat A is a friend of C. These are things that are, and\nyou know that there are, if, if you go from from place A\nto place B place B to place C, it doesn't matter how\nyou went, like logic. It doesn't matter whether\nyou flew there, walked there, swam there, whatever you\nstill, this transitivity of, of where you go is still valid. And there are, there are many kinds of kind of features, I think of the way the world\nworks that are captured in these aspects of, of\nlanguage, so to speak. And I think what, what\nChatGPT effectively has found, just like it discovered logic, you know, people are really\nsurprised it can do these, these logical inferences. It discovered logic the same\nway Aristotle discovered logic by looking at a lot of sentences\neffectively and noticing the patterns in those sentences. - But it feels like it's\ndiscovering something much more complicated than logic. So this kind of semantic grammar, I think you wrote about this, maybe we can call it the laws of language, I believe you call, or which\nI like the laws of thought. - Yes. That was the title that\nGeorge Bule had for his, his Bule in algebra back in 1830. But yes. - [Fridman] Laws of thought. - Yes. That was what he said. - [Fridman] Woo. All right. - So he thought, he thought he nailed it with Bule algebra. - [Fridman] Yeah. - There's more to it. - I, and it's a good question,\nhow much more is there to it? And it seems like one of the reasons, as you imply that the reason\nGPT works, ChatGPT works, is that there's a finite\nnumber of things to it. - [Wolfram] Yeah. I mean, it's, it's. - Like, it's discovering\nthe laws in some sense, GPTs discovering this laws\nof semantic grammar that underlies language. - [Wolfram] Yes. And what, what's sort of interesting is\nin the computational universe, there's a lot of other\nkinds of computation that you could do. They're just not ones that we\nhumans have cared about and, and operate with. And that's probably because\nour brains are built in a certain way. And, you know, the neural nets of our brains\nare not that different in some sense from the neural nets of, of, of a large language model. And that's kind of, and and so when we think\nabout, and you know, maybe we can talk about this some more, but when we think about sort\nof what will AIs ultimately do, the answer is insofar as AI\nare just doing computation, they can run off and do all these kinds\nof crazy computations. But the ones that we sort of have, have decided we care about\nare there is this kind of very limited set. - That's where the reinforcement learning with human feedback seems to come in. The more the AI say the stuff\nthat kind of interests us, the more we're impressed by it. So they can do a lot of\ninteresting, intelligent things, but we're only interested\nin the AI systems when they communicate human in a human-like way. - [Wolfram] Yes. - About human-like topics. - [Wolfram] Yes. - Well, it's, it's like technology. I mean, in a sense, the physical world provides\nall kinds of things. You know, there are all kinds of processes going on in physics only\na limited set of those are ones that we capture\nand use for technology. Cause they're only a\nlimited set where we say, you know, this is a thing that we can\nsort of apply to the human purposes we currently care about. I mean, you might have said, okay, you pick up a piece of, of rock, you say, okay, there's a nice sillacate, it contains all kinds of\nsillicon, I don't care. Then you realize, oh, we could\nactually turn this into a, a, you know, semiconductor wafer and make\nit microprocessor out of it, and then we care a lot about it. - [Fridman] Yes. - And it's, it's, you know, it's this thing about what do we, you know, in the evolution\nof our civilization, what things do we identify as\nbeing things we care about? I mean, it's, it's like, you know, when when there was a little\nannouncement recently of a possibility of a high\ntemperature superconductor that involved, you know, the element\nlutetium, which, you know, generally nobody has cared about. - Fridman] Yes. - And, you know, it, it's kind of, but suddenly if there's this\napplication that relates to kind of human purposes,\nwe start to care a lot. - So given your thinking\nthat GPT may have discovered inklings of laws of thought,\ndo you think such laws exist? Can we linger on that? Yeah. What's your intuition here? - Oh, definitely. I mean, the fact is,\nlook, the, the logic is, but the first step, there are many other kinds of\ncalculate about things that we consider, you know, the, the about sort of things\nthat happen in the world or things that are meaningful. - Well, how do you know\nlogic's not the last step? You know what I mean? So. - Well, because we can plainly\nsee that there thing, I mean, if, if you say, here's a sentence that\nis syntactically correct. Okay. You look at it and\nyou're like, you know, the happy electron, you know, ate, I don't know what some\nsomething that it just, it, you look at it and it's\nlike, this is meaningless. It's just a bunch of words. It's syntactically correct, the nouns and the verbs\nare in the right place, but it just doesn't mean anything. And so there clearly is some\nrules that there are rules that determine when a sentence is, has the potential to be\nmeaningful that go beyond the pure parts of speech syntax. And so the question is,\nwhat are those rules? And are there a fairly\nfinite set of those rules? My guess is that there's a\nfairly finite set of those rules and they, you know, once\nyou have those rules, you have a kind of a\nconstruction kit, just like the, the rules of syntactic grammar\ngive you a construction kit for making syntactically\ncorrect sentences. So you can also have a\nconstruction kit for making semantically correct sentences. Those sentences may not\nbe realized in the world. I mean, I think, you know,\nthe elephant flew to the moon. - [Fridman] Yeah. - A syntactic, a a semantically, you know, we know we have an idea. If I say that to you, you\nkind of know what that means. But the fact is it hasn't\nbeen realized in the world, so to speak. - So semantically correct\nperhaps as things that can be imagined with a human mind, no. Things that are consistent\nwith both our imagination and our understanding of physical reality. I don't know. - [Wolfram] Yeah. It's a good question. I\nmean, it's a good question. It it, it's a good question. I mean, I think it is, it is given the way we\nhave constructed language, it is things which, which fit with the things\nwe're describing in language. It's a bit circular in the end\nbecause, you know, you can, and, and the, and the, the sort of boundaries of\nwhat is physically realizable. Okay, let, let's take\nthe example of motion. Okay? Motion is a complicated concept. It might seem like it's a\nconcept that should have been figured out by the Greeks,\nyou know, long ago. But it's actually a really\npretty complicated concept because what is motion? Motion is you can go from place\nA to place B and it's still you when you get to the other end, right? You, you take an object, you move it, and it's still the same object, but it's in a different place. Now, even in ordinary physics, that doesn't always work that way. If you're near a space time\nsingularity in a black hole, for example, and you take\nyour teapot or something, you don't have much of\na teapot by the time it's near the space time singularity. It's been completely, you know, deformed beyond recognition. But, so that's a case where\npure motion doesn't really work. You can't have a, a thing stay the same. But, so this idea of motion is, is something that sort of is a, is a slightly complicated idea. But once you have the idea\nof motion, you can start, once you have the idea that\nyou're gonna describe things as being the same thing,\nbut in a different place, that sort of abstracted\nidea then has, you know, that has all sorts of consequences. Like this transitivity of\nmotion go from A to B, B to C. You've gone from A to C. And that's so that level of description, you can have what are sort\nof inevitable consequences. They're inevitable features of the way you've sort of set things up. And that's, I think what\nthis sort of semantic grammar is capturing is things, things like that. And I, you know, I think that it's a question\nof what does the word mean when you say I go from, I\nmove from here to there. Well, it's complicated\nto say what that means. This is this whole issue of, you know, is pure motion possible, et\ncetera, et cetera, et cetera. But once you have kind of got\nan idea of what that means, then there are inevitable\nconsequences of that idea. - But the very idea of meaning, it seems like there's\nsome words that become, it's like there's a\nlatent ambiguity to them. I mean, it is the word like emotionally loaded words like hate and love, right? It's like, what, what do\nthey, what do they mean? Exactly? What, what? So especially when you\nhave relationships between complicated objects, we seem\nto take this kind of shortcut, descriptive shortcut of, to describe like object\nA hates object B, what's, what's that really mean? - [Wolfram] Right. Well, words are defined by\nkind of our social use of them. I mean, it's not, you know, a word in computational\nlanguage, for example, when we say we have a, a construct there, we expect that that construct\nis a building block from which we can construct an arbitrary tall tower. So we have to have a very\nsolid building block. And you know, we have to, it\nturns into a piece of code, it has documentation, it's,\nyou know, it's a whole, it's a whole thing. But the word hate, you know, the documentation for that word. Well, there isn't a standard\ndocumentation for that word, so to speak. It's a complicated thing\ndefined by kind of how we use it when, you know, if it wasn't for the fact\nthat we were using language, I mean, so, so what is\nlanguage at some level, language is a way of packaging\nthoughts so that we can communicate them to another mind. - Can these complicated words be converted into something that a\ncomputation engine can use? - Right? So, so I think\nthe answer to that is that, that what one can do in\ncomputational language is define, make a def- make a specific definition. And if you have a complicated word, like let's say the word eat, okay, you'd think that's a simple word. It's, you know, animals\neat things, whatever else. But you know, you do programming, you say this function eats arguments, which is sort of poetically similar to the animal eating things. But if you start to say, well, what are the implications of, you know, the function eating something,\nyou know, does it can, can the function be poisoned?\nWell, maybe it can actually, but you know, if there's a tight\nmismatch or something in a, in some language. But, but you know, in what, how far does that\nanalogy go? And it, it's, it's just an analogy. Yeah. Whereas if you use the word\neat in a computational language level, you would define there\nisn't a thing which you, you anchor to the kind of\nnatural language concept eat. But it is now some precise\ndefinition of that, that then you can compute things from. - But don't you think the\nanalogy is also precise software eats the world, huh? Don't, don't you think there's, there is something concrete in terms of meaning about analogies. - Sure. But the thing that sort\nof is the first target for computational language is\nto take sort of the ordinary meaning of things and\ntry and make it precise, make it sufficiently precise. You can build these towers\nof computation on top of it. - [Fridman] Yeah. - So it's kinda like if you\nstart with a piece of poetry and you say, I'm going to define my program\nwith this piece of poetry. It's kind of like, that's,\nthat's a difficult thing. It's better to say, I'm gonna just have this\nboring piece of prose and it's using words in the ordinary way. - [Fridman] Yeah. - And that's how I'm\ncommunicating with my computer. And that's how I'm going to\nbuild the solid building block from which I can construct\nthis whole kind of computational tower. - So there is some sense\nwhere if you take a poem and reduce it to something computable, you're gonna have very few things left. So maybe there's a bunch of\nhuman interaction that's just poetic aimless nonsense. - [Wolfram] Well. - That's just like recreational,\nlike hamster in a wheel. It's not actually producing anything. - Well, I, I I, I think that that's a complicated\nthing because in a sense, human linguistic communication\nis, there's one mind, it's producing language\nthat language is having an effect on another mind. - [Fridman] Yeah. - And the question of\nthere's sort of a, a, a type of effect that is well\ndefined, let's say where, where, for example, it's very independent of the\ntwo minds that the, it doesn't, you know, there, there, there's communication where it\ncan matter a lot sort of what the experience of, of, of one mind is versus\nanother one and so on. - [Fridman] Yeah. But what is the purpose of\nnatural language communication? - [Wolfram] I think, I think the- - Versus, so computation\ncomputational language somehow feels more amenable\nto the definition of purpose. It's like, yeah, you're given two clean\nrepresentations of a concept and you can build a tower based on that. - [Wolfram] Right. - Is natural language the same\nthing but more fuzzy or what? - Well, I think the, the story\nof natural language, right? And the, the, that's the great\ninvention of our species. We don't know whether it\nexists in other species, but we know it exists in our species. It's the thing that allows\nyou to sort of communicate abstractly from like one generation of the species to another. You can, you know, there is an abstract version of knowledge that can be passed down. It doesn't have to be, you know, genetics. It doesn't have to be, you know, you don't have to apprentice\nthe next species, you know, the next generation of birds\nto the previous one to show them how something works. - [Fridman] Yeah. - There is this abstracted\nversion of knowledge that can be kind of passed down. Now that, you know, it relies on, it still tends to rely\nbecause language is fuzzy. It does tend to rely on\nthe fact that, you know, if we look at the, you know,\nsome ancient language that, where we don't have a chain\nof translations from it until what we have today, we may not understand\nthat ancient language. And we may not understand, you know, its concepts may be different from the ones that we have today. We still have to have\nsomething of a chain. But it is something where we\ncan realistically expect to communicate abstract ideas. And that's, you know, that's\none of the big, big roles of, of a language I think, you know, in, in, it's, you know, and that that's been this, this ability to sort of\nconcrete-ify abstract things is what, what language has provided. - Do you see natural language\nand thought as the same, the stuff that's going inside your mind? - Well, that's been a\nlong debate in philosophy. - It seems to be become more important now when we think about\nhow intelligent GPT is. - [Wolfram] Whatever that means. - Whatever that means. But it seems like the stuff\nthat's going on in the human mind seems something like intelligence. - [Wolfram] Yes. - And is the language- - Well, we call it intelligence. Yeah. - We call it. Well, yes. - And so you, you start to think of, okay, what's the relationship between thought, the language of thought,\nthe laws of thought, the laws of the words like reasoning and the laws of language and how that has to do with computation, which seems like more rigorous,\nprecise ways of reasoning. - [Wolfram] Right. Which are beyond human. I mean, much of what computers\ndo, humans do not do. I mean, you, you might say- - Humans are a subset. - [Wolfram[ Yes.\n- [Fridman] Presumably. - [Wolfram] Yes.\n- [Fridman] Hopefully. - [Wolfram] Yes. The, the yes. Right. You know, you might say, who needs computation when we have large, large language models? Large language models can just, you know, eventually you'll have\na big enough NeuroNet can do anything, but they're really doing\nthe kinds of things that humans quickly do. And there're plenty of sort\nof formal things that humans never quickly do. For example, I don't know, I, you know, you can, some people can\ndo mental arithmetic. They can do a certain\namount of math in their, in their minds. I don't think many people can\nrun a program in their minds of any sophistication. It's just not something people do. It's not something people\nhave even thought of doing. Cause it just, it's kind of\na, it's kind of not, you know, you can easily run it on a computer. - We're an arbitrary program.\n- [Wolfram] Yeah. - Aren't we running specialized programs? - [Wolfram] Yeah, yeah. But if I say to you- - Run this program- - [Wolfram] Here's a\ntouring machine. Yeah. You know, tell me what\nit does after 50 steps. And you're like, trying to\nthink about that in your mind. That's really hard to do.\nIt's not what people do. I mean it- - [Fridman] Well, in some sense, people program, they build\na computer, they program it. Just to answer your question\nabout what the system does after 50 steps. I mean, humans build computers. - Yes. Yes, yes, that's right. But they've created something\nwhich is then, you know, then when they run it, it's doing something different than what's happening in their minds. I mean, they've outsourced that, that piece of computation\nfrom something that is in internally happening in their\nminds to something that is now a tool that's external to their minds. - [Fridman] So by the way, humans to you didn't invent computers. They discovered them. - They discovered computation. - [Fridman] Which- - They invented the\ntechnology of computers. - This, the computer is just a kind of way to plug into this whole, this stream of computation. There's probably other, are other ways. There's probably a lot of ways. - [Wolfram] For sure. I\nmean the, the, you know, the particular ways that\nwe make computers out of semiconductors and electronics and so on. That's the particular\ntechnology stack we've built. I mean, the story of a\nlot of what people try to do with quantum computing\nis finding different sort of underlying physical, you know, infrastructure\nfor doing computation. You know, biology does\nlots of computation. It does it using an infrastructure\nthat's different from semiconductors and electronics. It's a, you know, it's a molecular scale, sort of computational\nprocess that hopefully we'll understand more about. I have some ideas about\nunderstanding more about that. But you know, that's a,\nthat's another ins you know, it's another representation\nof computation, things that happen in the\nphysical universe at the level of, you know, these evolving\nhypergraphs and so on. That's another sort of\nimplementation layer for this abstract idea of computation. - So if GPT or large language\nmodels are starting to form, starting to develop or\nimplicitly understand the laws of language and thought, do you think they can be made explicit? - [Wolfram] Yes. - How. - [Wolfram] With a bunch of effort? - [Fridman] I mean, so do, do they have- - It's like doing natural science. I mean, what is happening\nin natural science? You have the world that's doing\nall these complicated things and then you discover, you know,\nNewton's laws, for example. This is how motion works. This is the way that this particular sort of idealization of the world, this is how we describe it in a simple computation reducible way. And I think it's the same thing here. It's, there are sort of\ncomputationally reducible aspects of what's happening that you can\nget a kind of narrative theory for just as we've got narrative theories in physics and so on. - Do you think it will\nbe depressing or exciting when all the laws of\nthought are made explicit human thought are made explicit? - I think that once you understand computational reducibility, it is, it's neither of those things. Because the fact is people say\nfor example, people will say, oh, but you know, I have free\nwill I, I kind of, you know, I operate in a way that is,\nyou know, you, you, they, they have the idea that they're\ndoing something that is sort of, of internal to them, that\nthey're figuring out what's, what's happening. But in fact, we think there are laws\nof physics that ultimately determine, you know, every,\nevery nerve, you know, every electrical impulse and\na nerve and things like this. So you might say, isn't it depressing that we\nare ultimately just determined by the rules of physics, so to speak? It's the same thing.\nIt's at a higher level. It's like, it's, it's, it's a shorter distance to get\nfrom kind of semantic grammar to the way that we might\nconstruct a piece of text than it is to get from individual nerve firings to how we construct a piece of text. But it's not fundamentally different. And by the way, as soon as we\nhave this kind of level of, you know, this other level\nof description, it's kind of, it helps us to go even further. So we'll end up being able\nto produce more and more complicated kinds of kinds of\nthings that just like when we, you know, if we didn't have a computer and we knew certain rules, we could write them down. We go a certain distance. But once we have a computer,\nwe can go vastly further. And this is the same kind of thing. - You wrote a blog post titled, what is ChatGPT doing\nand why does it work? We've been talking about this, but can we just step back\nand linger on this question? What, what's it, what's ChatGPT doing? What, what are these, A bunch of billion parameters trained on a large number of words. Like, why does it seem to work again? Is it, is it because to the point\nyou made that there's laws of language that can be\ndiscovered by such a process? Is there something-? - Well, let, let's, let's talk about sort of the low level of what ChatGPT is doing. I mean, ultimately you give it a prompt. It's trying to work out, you know, what should the next word be? - Right. Which is wild. Isn't that, isn't that surprising to you\nthat this kind of low level dumb training procedure\ncan create something syntactically correct first and then semantically correct second. - [Wolfram] You know, the thing that has been sort\nof a story of my life is realizing that simple rules\ncan do much more complicated things than you imagine. That something that starts simple and starts simple to describe can grow a thing that is, you know, vastly more complicated\nthan you can imagine. And, and honestly, it, it's\ntaken me, I mean, I don't know, I've sort of been thinking\nabout this now 40 years or so, and it always surprises me.\nI mean, even for example, in our physics project, sort of thinking about the whole\nuniverse growing from these simple rules, I still resist\nbecause I keep on thinking, you know, how can something really complicated arise from something that simple? It just seems, you know, it\nseems wrong, but yet, you know, the majority of my life,\nI've kind of known from, from things I've studied, that\nthis is the way things work. So yes, I, it is wild that it's possible\nto write a word at a time and produce a coherent essay, for example. But it's worth understanding\nkind of how that's working. I mean, it's kind of like,\nif, if it was going to say, you know, the cat sat on\nthe, what's the next word? Okay, so how does it\nfigure out the next word? Well, it's seen a trillion\nwords written on the internet, and it's seen the cat sat on the floor, the cat sat on the sofa,\nthe cat sat on the whatever. So it's minimal thing to do is just say, let's look at what we saw on the internet. We saw, you know, 10,000\nexamples of the cat sat on the, what was the most probable next word. Let's just pick that out and\nsay that's the next word. And that's, that's kind of what it at\nsome level is trying to do. Now, the problem is\nthere isn't enough text on the internet to, for, if you have a reasonable\nlength of prompt to that, that that specific prompt will never have occurred on the internet. And as you, as you kind of go further, there just won't be a place\nwhere you could have trained, you know, where you could just, just worked out probabilities\nfrom what was already there. You know, like if you say two plus two, there'll be a zillion examples of two plus two equaling four, and a very small number of examples of two plus two equals five and so on. And you can pretty much\nknow what's going to happen. So then the question is, well, if you can't just work out from examples, what's gonna happen? Just\nno probabilistic for, for examples, what's gonna\nhappen, you have to have a model. And this kind of an idea, this idea of making models of\nthings is an idea that really, I don't know, I think Galileo probably was\none of the first people who sort of worked this out. I mean, it's kind of like, like, you know, I think I\ngave an example of that, the little book I wrote\nabout, about ChatGPT where it's kind of like, you know, Galileo was dropping cannon balls off the, off the different floors of\nthe, of the tower of Piza. And it's like, okay, you drop\na cannonball off this floor, you drop a cannonball off this floor, you miss floor five or\nsomething for whatever reason. But you know, the time it took the cannon\nball to fall to the ground from floors one, two, three, four, six, seven, eight, for example. Then the question is, can\nyou work out, can you, can you make a model\nwhich figures out how long did it take the ball? How long would it have take\nthe ball to fall to the ground from the floor you didn't\nexplicitly measure. And the thing Galileo realized\nis that you can use math, you can use mathematical\nformulas to make a model for how long it will take the ball to fall. So now the question is, well, okay, you want to make a model for, for example, something much more elaborate, like you've got this arrangement\nof pixels and is this arrangement of pixels an A or a B? Does it correspond to\nsomething we'd recognize as an A or a B? And you can make a similar kind, you know, each pixel is like a\nparameter in some equation. And you could write down\nthis giant equation where the answer is either, you know, A or you know, one or two A or B. And the question is then what\nkind of a model successfully reproduces the way that we humans would, would conclude that this is an\nA, and this is a B, you know, if if there's a, a complicated extra tail\non the top of the A, would we then conclude\nsomething different? What is the type of model that\nmaps well into the way that we humans make distinctions about things? And the big kind of meta discovery is neural nets are such a model. It's not obvious they\nwould be such a model. It could be that human\ndistinctions are not captured. You know, we could try searching\naround for a type of model that could be a mathematical model, it could be some model based\non something else that captures kind of typical human\ndistinctions about things. It turns out this model that\nactually is very much the way that we think the\narchitecture of brains works, that perhaps, not surprisingly, that model actually corresponds to the way we make these distinctions. And so, you know, the, the, the core next point is that\nthe, the kind of model, this neural net model\nmakes sort of distinctions and generalizes things\nin sort of the same way that we humans do it. And that's why when you say, you know, the cat sat on the green blank, even though it never didn't see\nmany examples of the cat sat on the green, whatever, it can make a, or the aardvark sat on\nthe green, whatever. I'm sure that particular sentence does not occur on the internet. And so it has to make a\nmodel that concludes what, you know, it has to kind of\ngeneralize from what it's, from the actual examples that it's seen. And so, so you know that that's\nthe factors that neural nets generalized in the same kind\nof a way that we humans do. If, if we were, you know, the aliens might look at our\nneural net generalizations and say, that's crazy. You know, that thing when you put that\nextra little dot on the A, that isn't an A anymore. That's, you know, that messed the whole thing up. But for us humans, we make distinctions, which seem to correspond to\nthe kinds of distinctions that neural nets make. So then, you know, the, the thing that is just\namazing to me about ChatGPT is how similar the structure\nit has is to the very original way people imagine\nneural nets might work back in 1943. And, you know, there's a\nlot of detailed engineering, you know, great cleverness,\nbut it's really the same idea. And in fact, even the sort of elaboration\nof that idea where people said, let's put in some actual\nparticular structure to try and make the neural net more elaborate, to be very clever about it,\nmost of that didn't matter. I mean, there's some things\nthat seem to, you know, when you, when you train\nthis neural net, you know, the one thing, this kind of\ntransformer architecture, this attention idea that\nreally has to do with, does every one of these\nneurons connect to every other neuron or is it somehow\ncausally localized, so to speak? Does it, like, we're making a sequence of\nwords and the words depend on previous words rather than just, everything can depend on everything. And that seems to be important. And just organizing things\nso that you don't have a, a sort of a giant mess. But the thing, you know, the thing worth understanding about what is ChatGPT in the end? I mean, what is a neural net in the end? A neural net in the end is\neach neuron has a, it, it, it's taking inputs from\na bunch of other neurons. It's, it's, eventually\nit's going to have a, it's going to have a, a numerical value. It's going to compute some number. And it's, it's saying,\nI'm gonna look at the, the neurons above me. It's kind of a, a series of layers. It's gonna look at the neurons above me and it's going to say, what are the values of all those neurons? Then it's gonna add those\nup and multiply them by these weights, and then it's going to apply\nsome function that says if it's bigger than zero or something, then make it one or, and\notherwise make it zero or some slightly more\ncomplicated function. You know very well how this works. - It's a giant equation\nwith a lot of variables. You mentioned figuring out\nwhere the ball falls when you don't have data on the fourth floor. This, the equation here\nis not as simple as- - [Wolfram] It's an equation\nwith 175 billion terms. - And it's quite surprising\nthat in some sense, a simple procedure of training\nsuch an equation can lead to - [Wolfram] Well I think- - A good representation\nof natural language. - Right? The, the real issue is, you know, this architecture of a neural net where, where what's happening is,\nyou know, you've, you've, you've turned so neural nets\nalways just deal with numbers. And so, you know, you've turned the sentence\nthat you started with into a bunch of numbers. Like let's say by mapping, you know, each word of the 50,000 words in English, you just map each word\nor each part of a word into some number. You feed all those numbers in, and then the thing is going to, and then those numbers\njust go into the values of these neurons. And then what happens is it's\njust rippling down going layer to layer until it gets to the end. I think ChatGPT has about\n400 layers, and you're just, you know, it just goes once through it. Just, every, every new word\nit's gonna compute just says, here are the, here are the\nnumbers from the words before, let's compute the, what is it compute. It computes the probabilities\nthat it estimates for each of the possible 50,000 words\nthat could come next. And then it decides sometimes it will use the most probable word. Sometimes it will use not\nthe most probable word. It's an interesting fact\nthat there's this so-called temperature parameter, which,\nyou know, at temperature zero, it's always using the most\nprobable word that it, that it estimated was the, the most\nprobable thing to come next. You know, if you increase the temperature, it'll be more and more kind of random in its selection of words. It'll go down to the lower\nand lower priority words. The thing I was just playing\nwith actually recently was the transition that happens as\nyou increase the temperature, the thing goes bonkers at\na particular, you know, sometimes at a particular temperature. I think maybe about 1.2 is\nthe thing I was noticing from yesterday actually. That, you know, usually it's giving reasonable\nanswers and then at that temperature with some probability, it just starts spouting nonsense. And, you know, nobody\nknows why this happens. I mean, it's, it's,\nand by the way, I mean, the thing to understand is it's putting down one word at a time, but the outer loop of the\nfact that it says, okay, I put down a word. Now let's take the whole\nthing I wrote so far, let's feed that back in. Let's put down another word. That outer loop, which\nseems almost trivial, is really important to the\noperation of the thing. And, and for example, one of the things that is\nkind of funky is it'll give an answer and you say to it,\nis that answer correct? And it'll say no. And why is that happening? - [Fridman] It's fascinating. Right? - Right. Why can't it do that? Well, the answer is because it, it is going one word at\na time sort of forwards. And it didn't, you know, it it, it came along with some sort of chain of, of thought in a sense, and it, it came up with completely\nthe wrong answer. But as soon as you feed it, the whole thing that it came up with, it immediately knows\nthat that isn't right. It immediately can recognize\nthat was a, you know, a bad syllogism or something,\nand can see what happened. Even though as it was being\nled down this garden path, so to speak, it didn't, it\ncame to the wrong place. - But it's fascinating that\nthis kind of procedure converges to something that forms\na pretty good compressed representation of\nlanguage on the internet. - [Wolfram] Yeah. - That, that's quite. - [Wolfram] Right. Right, right. - I'm not sure what to make of it. - Well, look, I think, you know, there are many things we\ndon't understand. Okay. So for example, you know,\n175 billion weights, it's maybe about a trillion\nbites of information, which is very comparable to\nthe training set that was used. And you know, why that, why kind, it sort of stands to some kind\nof reason that the number of weights in the neural\nnet, I don't know where, I can't really argue that I\ncan't really give you a good, you know, in a sense the\nvery fact that, you know, the insofar as there are definite\nrules of what's going on, you might expect that eventually\nwe'll have a much smaller neural net that will successfully\ncapture what's happening. I, I don't think the best way to do it is probably a neural net. I think a neural net is what\nyou do when you don't know any other way to structure the thing. And it's a very good thing to\ndo if you don't know any other way to structure the thing. And for the last 2000 years, we haven't known any\nother way to structure it. So this is a pretty good way to start. But that doesn't mean you\ncan't find sort of, in a sense, more symbolic rules for\nwhat's going on that you know, much of which will then be, you can kind of get rid of\nmuch of the structure of the neural net and replace it by\nthings which are sort of pure steps of computation, so to speak, sort of with neural net\nstuff around the edges. And that becomes just a, you know, it's just a much simpler way to do it. - So the neural net you hope\nwill reveal to us good symbolic rules that make the\nneeds of the neural net less and less and less. - Right. And there will still be some\nstuff that's kind of fuzzy, just like, you know, there\nthere're things that it, it's like this question\nof what can we formalize, what can we turn into\ncomputational language? What is just sort of, oh, it happens that way just because\nbrains are set up that way. - What do you think are the\nlimitations of large language models just to make it explicit? - Well, I mean, I think that deep computation\nis not what large language models do. I mean, that's just, it's a different kind of thing, you know, the outer loop of a large language model. If, if you are trying to do\nmany steps in a computation, the only way you get to do\nthat right now is by spooling out, you know, all the, the whole chain of thought as\na bunch of words basically. And, you know, you can make a touring machine\nout of that if you want to. I just was make doing that\nconstruction, you know, in principle you can make\nan arbitrary computation by just spooling out the words. But it's an, it's a bizarre and\ninefficient way to do it. But it's something where the,\nyou know, I, I think that's, you know, sort of the, the\ndeep computation is it's, it's really what a humans can do quickly. Large language models will\nprobably be able to do well. Anything that you can do kind\nof off the top of your head type thing is a, is really, you know, is good for large language\nmodels and the things you do off the top of your head, you may\nnot get them always right, but you know, you'll, it, it's, it's thinking it through\nthe same way we do. - But I wonder if there's an\nautomated way to do something that humans do well much\nfaster to where it like loops. So generate arbitrary large\ncode bases off Wolfram Language for example. - [Wolfram] Well, the\nquestion is what does he, what do you want the code base to do? - Escape control and take over the world? - [Wolfram] Okay, so, you know, the thing is when people say, you know, we, we want to build\nthis giant thing, right? A giant piece of computational\nlanguage in a sense, it's sort of a failure\nof computational language if the thing you have to\nbuild, in other words, if we have a description, if, if you have a small description, that's the thing that you\nrepresent in computational language and then the computer\ncan compute from that. - [Fridman] Yes. - So in a sense in, you know, when, as soon as you're giving a\ndescription, the, you know, if you have to somehow make\nthat description something, you know, definite something\nformal and once and, and to say, to say, okay, I'm gonna give this\npiece of natural language and then it's gonna split out this giant formal structure that\nin a sense that doesn't, that that doesn't really make\nsense because except insofar as that piece of natural language\nkind of plugs into what we socially know, so to speak, plugs into kind of our corpus\nof knowledge, then, you know, that's a way we are\ncapturing a piece of that corpus of knowledge. But hopefully we will have\ndone that in computational language. How do you make\nit do something that's big? Well, you know, you have to have a way to\ndescribe what you want. - Okay. I can make it\nmore explicit if you want. How about I just pop into my head, iterate through all\nthe members of Congress and figure out how to convince them that they have to let me, the meaning the system become president, pass all the laws that allows\nAI systems to take control and be the president. I don't know. So that's a very explicit\nlike figure out the individual life story of each congressman\nthat each senator, anybody, I don't know, what's required to really\nkind of pass legislation and figure out how to control them\nand manipulate them, right. Get all the information. What would be the biggest\nfear of this congressman? And in such a way that you\ncan take action on it in the digital space. So maybe threaten the\ndestruction reputation or something like this. - Right. If I can describe what I want. You know, to what extent can a large\nlanguage model automate that? - Would the help with the\nhelp of the conqurization of something like Wolfram language that makes it more yeah, grounded. - [Wolfram] I think it\ncan go rather a long way. - I'm also surprised how\nquickly I was able to generate. - Yeah, yeah. Right. - [Wolfram] That's a, an attack. - That, that's a, you know, I, I swear, I swear I did not think about\nthis before and it's funny how quickly, which is a very\nconcerning thing because that, that probably this idea will\nprobably do quite a bit of damage and there might\nbe a very large number of other such ideas. - Well, I'll give you a, a much more benign version of that idea. Okay. You're gonna make an AI\ntutoring system and you know, that is a, that's a, a benign version of what you're\nsaying is I want this person to understand this point. You know, you are essentially doing\nmachine learning where the, where the, where the, you know,\nthe, the loss function, the, the thing you're trying to\nget to is get the human to understand this point and, and when you do a test on\nthe human that they yes, they correctly understand\nhow this or that works. And I, I am confident that, you know, sort of a large language model\ntype technology combined with computational language is\ngoing to be able to do pretty, pretty well at teaching us humans things. And it's gonna be an\ninteresting phenomenon because, you know, sort of\nindividualized teaching is, is a thing that has been\nkind of a, you know, a goal for a long time. I think we're gonna get that\nand I think more, you know, that, that it has many\nconsequences for, you know, like, like just, you know, if\nyou know me as an, if you, the AI know me, tell me\nI'm about to do this thing, what is the, what are the\nthree things I need to know, you know, given what I already\nknow, you know, what's the, what's, let's say I'm, I'm looking at some paper\nor something, right? it's like there's a version\nof the summary of that paper that is optimized for me, so to speak, and where it really is. And I think that's really going to work. - It could understand the\nmajor gaps in your knowledge - [Wolfram] Yes. - That if filled would actually give you a deeper understanding of the topic. - [Wolfram] Yeah. Right. And that's a, you know, that's an important thing because it, it really changes actually.\nI think, you know, when, when you think about education and so on, it really changes kind\nof what's worth doing, what's not worth doing and so on. It makes, you know, I know in my life I've learned\nlots of different fields and you know, so I, yeah, I don't know. I have every time, I'm always think this is\nthe one that's going to, I'm not gonna be able to learn. But turns out sort of, there are sort of meta\nmethods for learning these things in the end. And, you know, I think this, this idea that it becomes\neasier to, you know, it, it becomes easier to be\nfed knowledge, so to speak. And it becomes, you know, if you need to know this\nparticular thing, you can, you know, you can get taught it in a, in an efficient way is something\nI think is sort of a, a, an interesting feature. And I think it makes the, you know, things like the value of, of big towers of specialized\nknowledge become less significant compared to the\nkind of meta knowledge of sort of understanding kind of the, the big picture and being able\nto connect things together. I think that, you know, there's\nbeen this huge trend of, of let's be more and more\nspecialized because we have to, you know, we, we have to sort of ascend\nthese towers of knowledge, but by the time you can get, you know, more automation of being able\nto get to that place on the tower without having to go\nthrough all those steps, I think it, it sort of\nchanges that picture. - Interesting. So your intuition is that\nin terms of the, the, the collective intelligence\nof the species and the individual minds that\nmake up that collective, there'll be more, there will trend towards being generalists and being kind of philosophers. - That's what I think, I think that's where the\nhumans are gonna be useful. I think that a lot of these\nkind of the drilling, the, the, the, the mechanical working out of things is much more automatable. It's much more AI, AI\nterritory, so to speak. - [Fridman] No more PhDs. - Well that's, it's interesting. Yes. I mean that, you know, the, the, the kind of the specialization, this kind of tower of specialization, which has been a feature of, you know, we've accumulated lots\nof knowledge in our, in our species and, and you\nknow, in a sense, every time we, every time we have an\na kind of automation, a building of tools, it becomes less necessary\nto know that whole tower. And it becomes something where\nyou can just use a tool to get to the top of that tower. I think that, you know, the\nthing that is ultimately, you know, when we think about, okay, what do the AIs do versus\nwhat do the humans do? It's like AIs you tell 'em, you say go achieve this\nparticular objective. Okay? They can maybe figure out a\nway to achieve that objective. We say, what objective\nwould you like to achieve? The AI has no intrinsic idea of that. It's not a defined thing. That's a thing which has to\ncome from some other, you know, some other entity. And insofar as we are in charge, so to speak, or whatever it is, and our kind of web of society\nand history and so on is the thing that is defining what\nobjective we want to go to. That's, you know, that that's, that's a thing that we humans\nare necessarily involved in. - To push back a little bit, don't you think that GPT,\nfeature versions of GPT would be able to give a good answer\nto what objective would you like to achieve. - From on what basis? I\nmean, if they say, look, here's the terrible thing\nthat could happen. Okay, they're taking the average\nof the internet and they're saying, you know, from the\naverage of the internet, what do people want to do? - Well, that's the, the Elon Musk artage of the\nmost entertaining outcome is the most likely. - [Wolfram] Okay. That could be got that one from him. Yeah. - That could be, that could\nbe one objective is maximize global entertainment. The dark version of that is drama. The, the, the good version of that is fun. - Right. So I mean this, this\nquestion of what, you know, if you say to the AI, you know, what does the species want to achieve? - [Fridman] Yes. Okay. There'll be an answer. Right? - There'll be an answer. It'll be what the average of\nthe internet says the species wants to achieve. - Well, well, let's, let's, let's, I think you're using the word\naverage very loosely there, - [Wolfram] I am. - So I think you, I think the answers will become\nmore and more interesting as these language models are\ntrained better and better. - No, but I mean, in the end it's a reflection back of what we've already said. - Yes. But it's, there's a deeper wisdom to\nthe collective intelligence, presumably than each individual. - [Wolfram] Maybe. - Isn't that what we're\ntrying to, as society? - [Wolfram] To, to have,\nwell, I mean that's, that's a, that's an important No, no,\nthis is an interesting question. I mean, in, you know, insofar\nas some of us, you know, work on trying to innovate and\nfigure out new things and so on, it is sometimes it's a, it's a complicated interplay\nbetween sort of the individual doing the crazy thing, often\nsome, some spur, so to speak, versus the collective that's\ntrying to do sort of the, the, the, the high inertia average thing. And it's, you know, sometimes\nthe collective, you know, is, is bubbling up things that\nare interesting and sometimes it's pulling down kind of the\nattempt to make this kind of innovative direction. - Well, don't you think the large\nlanguage models would see beyond that simplification? We'll say maybe intellectual\nand career diversity is really important. So you need the crazy\npeople on the outlier, on the outskirts, right? And so, like the actual, what's the purpose of this whole\nthing is to explore through this kind of dynamics that\nwe've been using as a human civilization, which is most\nof us focus on one thing, and then there's the crazy\npeople on the outskirts doing the opposite of that one thing. And you kind of like pull\nthe whole society together. There's the mainstream science\nand then there's the crazy science, and that's just been the, the history of human civilization. And maybe the AI system\nwill be able to see that. And the more and more impressed\nwe are by a language model telling us this, the more control we'll give\nit to it and the more we'll be willing to let it run our society. And hence there's this kind of loop where the society could be manipulated to let the AI system run it. - Right. Well, I mean, look, one, one of the things that's sort\nof interesting is we might say, we always think\nwe're making progress, but yet if you know in\na sense, by by saying, let's take what already exists\nand use that as a model for what should exist. - [Fridman] Yeah. - Then, you know, it's\ninteresting that for example, you know, many religions have\ntaken that point of view. There is a, you know, a sacred book that got written\nat Time X and it defines how people should act for all future time. And that's, you know,\nit's a, it's a model that, that people have operated with. And in a sense, you know, this is a version of that,\nthat kind of statement. It's like, take the 2023 version of sort\nof how the world has exposed itself and use that to\ndefine what the world should do in the future. - But it's not, it's an\nimprecise definition, right? Because just like with\nreligious text and which GPT the human interpretation of\nwhat GPT says will be the, will be the perturbation in the system. It'll be the noise, it'd be full of uncertainty. It's not like GPT will tell\nyou exactly what to do. It'll tell you approx a\nnarrative of what, like a, a, you know, it's like a turn the other\ncheek kind of narrative, right? That's, that's not a fully\ninstructive narrative. - [Wolfram] Well, until, until the AI control all\nthe systems in the world. - They will be able to very\nprecisely tell you what to do. - [Wolfram] Well. They'll do\nwhat they, you know, they'll, they'll just do this or that\nthing and that and that. And, and not only that, they'll be auto suggesting\nto each person, you know, do this next, do that next. So I think it's a, it's a slightly more\nprescriptive situation than one has typically seen. But I, you know, I think this, this whole question of sort of what, what's left for the humans, so to speak, to what extent do we, you know, this idea that there is an\nexisting kind of corpus of purpose for humans defined by\nwhat's on the internet and so on, that's an important thing. But then the question of sort of, as we explore what we can think of as the computational universe, as we explore all these different\npossibilities for what we could do, all these different inventions, we could make all these different things. The question is which ones\ndo we choose to follow? Those choices are the\nthings that in a sense, if the humans want to still\nhave kind of human progress, that's what we, we get to make\nthose choices, so to speak. In other words, the, the,\nthere's this idea, if you say, let's take the kind of what exists today and use that as the determiner of all of what there is in the future, the thing that is sort of\nthe opportunity for humans is there will be many\npossibilities thrown up. There are many different\nthings that could happen. It'll be done. And the insofar as we\nwant to be in the loop, the thing that makes sense for\nus to be in the loop doing is picking which of those\npossibilities we want. - But the degree to which\nthere's a feedback loop of the idea that we're picking something starts becoming questionable because we're influenced by the various systems. - [Wolfram] Absolutely. - The, like, if that becomes more and more\nsource of our education and wisdom and knowledge. - Right. The AI take\nover, I mean my, you know, I've thought for a long time\nthat, you know, it's the, you know, AR auto suggestion that's really the thing that\nmakes the AIs take over. It's just then the humans just follow, you know? Yeah. - We'll no longer write\nemails to each other. We'll just send the auto suggested email. - Yeah, yeah. But the thing where humans are potentially in the loop is when there's a choice and\nwhen there's a choice, which we could make based\non our kind of whole web of history and so on. - [Fridman] Yeah. - And, and that's, you\nknow, that's insofar as it's all just, you\nknow, determined, you know, the humans don't have a place. And, and by the way, I mean,\nyou know, at, at some level, you know, it's all kind of a, a complicated philosophical\nissue because at some level the universe is just doing what it does. We are parts of that universe\nthat are necessarily doing what we do, so to speak, yet we feel we have sort of\nagency in what we're doing. And that's, that's its own separate\nkind of interesting issue. - And we also kind of feel like we're the final destination\nof what the universe was meant to create. But we very well could be, and likely are some kind of\nintermediate step, obviously. - [Wolfram] Yeah. - What we're, we're most\ncertainly some intermediate step. The question is if there's\nsome cooler, more complex, more interesting things that's\ngoing to be materialized. - [Wolfram] The computational universe is full of such things. - But in, in our particular\npocket specifically, if this is the best we've gotta\ndo or not, that's kind of a. - We can make all kinds of\ninteresting things in the computational universe. We, when we look at them, we say, yeah, you know, that's,\nthat's a thing we don't, it doesn't really\nconnect with our current, our current way of thinking about things. I mean, it's like in\nmathematics, you know, we've got certain theorems. They're about three or 4\nmillion that that human mathematicians have written\ndown and published and so on. But they're an infinite number of possible mathematical theorems. We just go out into the universe\nof possible theorems and pick another theorem. And then people will say, well, you know, that's, you know,\nthey look at it and they say, I don't know what this theorem means. It's not connected to the\nthings that are part of kind of the web of history that\nwe're dealing with. You know, I think one, one point to make about sort\nof understanding AI and its relationship to us is as\nwe have this kind of whole infrastructure of AI is doing\ntheir thing and doing their thing in a way that is perhaps not readily understandable by us humans. You know, you might say that's a, that's a very weird situation. How can we have built this\nthing that behaves in a way that we can't understand that's\nfull of computational disability, et cetera,\net cetera, et cetera. You know, what, what is this, what's it gonna feel like when\nthe world is run by AIs whose operations we can't understand? And the thing one realizes is actually, we've seen this before. That's what happens when we\nexist in the natural world. The natural world is full of\nthings that operate according to definite rules. They have all kinds of, you know, computational irreducibility, we don't understand what the natural world is doing occasionally. And, and you know, when you say, you know, are the AI gonna wipe us out, for example? Well, it's kind of like, is the machination of the AI\ngoing to lead to this thing that eventually comes\nand destroys the species? Well, we can also ask the same thing about the natural world or the machination of the natural\nworld going to eventually lead to this thing that's\ngoing to, you know, make, make the earth explode\nor something like this. Those are, those are questions, those are, and insofar as we think we\nunderstand what's happening in the natural world, that's a result of science\nand natural science and so on. One of the things we can\nexpect when there's this giant infrastructure of the AIs is\nthat's where we have to kind of invent a new kind of natural\nscience that kind of is the natural science that explains\nto us how the AIs work. I mean, it's kind of like we can, we can, you know, we have a, I don't know, a horse or something, and we're trying to get it\nto, we're trying to, you know, ride the horse and go from here to there. We don't really understand\nhow the horse works inside, but we can get certain\nrules and certain, you know, approaches that we take to, to persuade the horse to go\nfrom here to there and, and, and take us there. And that's the same type of\nthing that we're kind of dealing with, with the sort of\nincomprehensible computationally, irreducible AIs. But we can identify these kinds of, we can find these kind of\npockets of reducibility that we can kind of, you know, that, I don't know, we grabbing onto the mane of\nthe horse or something to be able to, to ride it. Or we figure out, you know, if\nwe, if we do this or that to, to ride the horse, that that's\na, a, a successful way to, to get it to do what, what\nwe're interested in doing. - There does seem to be a\ndifference between a horse and a large language model or something that could be called Agi connected to the internet. So lemme just ask you about big\nphilosophical question about the threats of these things. There's a lot of people\nlike Eliezer Yudkowsky, who worry about the existential\nrisks of AI systems. Is that something that\nyou worry about? You know, sometimes when you're building\nan incredible system, like, well, from Alpha, you can\nkind of get lost in it. - I try and think a little bit about the implications\nof what one's doing. - You know, it's like the Manhattan\nproject kind of situation where you're like, it's some of the most incredible physics in engineering being done. But it's like, huh, where's this gonna go? - I think some of these arguments\nabout kind of, you know, they'll always be a smarter AI. There'll always be, you know, and eventually the\nAIs will get smarter than us, and then all sorts of terrible\nthings will happen to me. Some of those arguments remind\nme of kind of the ontological arguments for the existence\nof God and things like this. They're kind of arguments that\nare based on some particular model, fairly simple\nmodel, often of kind of, there is always a greater\nthis, that and the other. You know, this is, and that's, you know, those arguments tend, what tends to happen in the\nsort of reality of how these things develop is that\nit's more complicated than you expect. That the kind of simple,\nlogical argument that says, oh, eventually there'll\nbe a super intelligence, and then it will, you know, do this. And that turns out not\nto really be the story. It turns out to be a\nmore complicated story. So for example, here's an example of an issue. Is there an apex intelligence, just like there might be an\napex predator in some, you know, ecosystem. Is there gonna be an apex intelligence, the most intelligent thing\nthat there could possibly be? Right? I think the answer is no. And in fact, we already know\nthis, and it's a kind of a, back to the whole computational\nirreducibility story. There's kind of a, a\nquestion of, you know, even if you have, if you,\nif you have sort of a, a touring machine and you\nhave a touring machine that, that runs as long as possible\nbefore, before it halts, you say, is this the machine? Is this the apex machine that does that? There will always be a\nmachine that can go longer. And as you go out to the\ninfinite collection of possible touring machines, you'll\nnever have reached the end, so to speak. You'll never, you'll always be able to, it's kind of like the same same\nquestion of whether there'll always be another invention. Yeah. Will you always be able\nto invent another thing? The answer is yes, there's an infinite tower\nof possible inventions. - That's one definition of apex. But the, the other is like,\nwhich I also thought you were, which I also think might be true, is, is there a species that's\nthe apex intelligence right now on earth? So it's not trivial to\nsay that humans are that. - Yeah, it's not trivial. I agree. It, it's, you know, I think one of the things that I, I've long been curious about\nkind of other intelligences, so to speak. I mean, I, you know, I, I view intelligence is like\ncomputation and it's kind of a, you know, you're sort of,\nyou have the set of rules, you deduce what happens. I have tended to think now\nthat there's this sort of specialization of\ncomputation that is sort of a consciousness like thing\nthat has to do with these, you know, computational boundedness, single thread of experience, these kinds of things that\nare the specialization of computation that corresponds\nto a somewhat human-like, experience of the world. Now the question is,\nso, so that's, you know, there may be other intelligences\nlike, you know, you know, the aphorism, you know, the\nweather has a mind of its own, it's a different kind of\nintelligence that can compute all kinds of things that are\nhard for us to compute, but it is not well aligned\nwith us with the way that we think about things. It doesn't, it doesn't, it doesn't think the way\nwe think about things. And you know, in this idea of different, different intelligences,\nevery different mind, every different human mind is\na different intelligence that thinks about things in different ways. And you know, in, in terms of the kind of\nformalism of our physics project, we talk about this idea of rural space, the space of all possible\nsort of rural systems and different minds are in a sense\nof different points in rural space, human minds. Ones that have grown up with\nthe same kind of culture and ideas and things like\nthis might be pretty close in rural space. Pretty easy for them to communicate. Pretty easy to translate, pretty easy to move from one\nplace in rural space that corresponds to one mind, to another place in rural space\nthat corresponds to another sort of nearby mind when we\ndeal with kind of more distant things in rural space,\nlike, you know, the, the pet cats or something, you know, the pet cat has some aspects\nthat are shared with us. The emotional responses\nof the cat are somewhat similar to ours, but the cat is further away in\nrural space than people are. And so then the question is, you know, can we identify sort of the, can we make a translation from\nour thought processes to the thought processes of, of a\ncat or something like this? And you know, what, what will\nwe get when we, you know, what, what will happen when we get there? And I think it's the case\nthat that many, you know, many animals, I don't know,\ndogs for example, you know, they have elaborate olfactory systems. They, you know, they, they have sort of the smell\narchitecture of the, of the, of the world, so to speak,\nin a way that we don't. And so, you know, if, if you were sort of talking\nto the dog and you could, you know, communicate in a\nlanguage, the dog will say, well, this is a, you know, a a, you know, a, a flowing smelling this,\nthat, and the other thing, concepts that we just\ndon't have any idea about. Now what's what's interesting\nabout that is one day we will have chemical sensors that\ndo a really pretty good job. You know, we'll have artificial\nnoses that work pretty well, and we might have our augmented\nreality systems show us kind of the same map that the dog\ncould see and things like this. So the, you know, it's similar to what\nhappens in the dog's brain. And eventually we will have\nkind of expanded in rural space to the point where we will\nhave those same sensory experiences that dogs have, and we will have internalized\nwhat it means to have, you know, the smell landscape or whatever. And, and so then we will have\nkind of colonized that part of rural space until, you know,\nwe haven't gone, you know, some things that, that, you\nknow, animals and so on. Do we sort of successfully\nunderstand, others We do not. And the question of, of what\nkind of, what is the, you know, what, what representation, you know, how, how do we convert things that\nanimals think about to things that we can think about?\nThat's not a trivial thing. And you know, I've,\nI've long been curious. I've had a very bizarre\nproject at one point of, of trying to make an iPad game that a cat could win against its owner. - Right. So it feels like there's a deep philosophical goal there, though. - Yes, yes. I mean, the, the, you know,\nI was curious if, you know, if pets can work in Minecraft or something and can construct things, what will they construct and\nwill what they construct be something where we look\nat and we say, yeah, I recognize that. Or will it be something that\nlooks to us like something that's out there in the\ncomputational universe that one of my, you know, cellular automat might have\nproduced where we say, oh, yeah, I can kind of see it operates\naccording to some rules. I don't know why you\nwould use those rules. I don't know why you would care. - Yeah. I actually, just\nto link on that, seriously, is there a connector in\nthe royal space between you and a cat where the cat\ncould legitimately win? So iPad is a very limited interface. - [Wolfram] Yeah, I, I- - I wonder if there's\na game where cats win. - I think the problem is that\ncats don't tend to be that interested in what's\nhappening on the iPad. - [Fridman] Yeah. That's\nan interface issue. - Yeah. Right, right, right. No, I think it is likely\nthat, I mean, you know, there are plenty of animals\nthat would successfully eat us if we were, you know, if\nwe were exposed to them. And so there's, you know, it, it's gonna pounce faster than we can get out of the way and so on. So there, there are plenty of, and, and probably it's going to, you know, we think we've hidden ourselves, but we haven't successfully\nhidden ourselves. - That's a physical strength. I wonder if there's something\nin more in the realm of intelligence where an animal\nlike a cat could out-. - Well, I think there are things\ncertainly in terms of the, the speed of processing certain\nkinds of things, for sure. I mean, the, the question\nof what, you know, is there a game of chess, for\nexample, is there cat chess? That the cats could\nplay against each other. And if we tried to play\na cat, we'd always lose, I don't know. - It might have to do with speed it, but it might have to\ndo with concepts also. It might be concepts in the cat's head. - I, I tend to think that our\nspecies from its invention of language has managed to build\nup this kind of tower of abstraction that for\nthings like a chess like game will make us win. In other words, we've become through the fact\nthat we've kind of experienced language and learnt abstraction, you know, we've sort of become smarter\nat those kinds of abstract kinds of things. Now, you know, that doesn't make us smarter at catching a mouse or something. It makes us smarter at the\nthings that we've chosen to, to sort of con, you know, to\nconcern ourselves, which are, are these kinds of abstract things. And, and I think, you know, this is again, back to the question of of, you know, what does one care about? You know, if one's a, if one's the, you know, the cat, if you, if you have the discussion\nwith a cat, if we can, if we can translate things\nto have the discussion with a cat, the cat will say, you know, I'm very excited that\nthis light is moving. And we'll say, why do you care? And the cat will say, that's the most important\nthing in the world. That this thing moves around. I mean, it's like when you\nask about, I don't know, you, you look at archeological\nremains and you say, these people had this, you\nknow, belief system about this. And, you know, that was the most important\nthing in the world to them. And, and now we look at it and say, we don't know what the point of it it was. I mean, I, I've been curious, you know, there are these hand prints on caves from 20,000 or more years ago, and it's like nobody knows\nwhat these hand prints were there for. You know, that they may\nhave been a representation of the most important\nthing you can imagine. They may just have been\nsome, you know, some kid who, who rubbed their hands in the\nmud and stuck 'em on the walls of the cave. You know, we don't, we don't know. And I think, but this, this\nwhole question of what you know, is when you say this question\nof sort of what's the smartest thing around, there's the question of what\nkind of computation are you trying to do? If you're saying, you know, if you say you've got some\nwell-defined computation and how do you implement it? Well, you could implement\nit by nerve cells, you know, firing. You can implement it with\nsilicone and electronics. You can implement it by some\nkind of molecular computation process in the human immune\nsystem or in some molecular biology kind of thing. They're different ways to implement it. And you know, I think this question of, of of sort of which, you know, those different implementation methods will be of different speeds. They'll be able to do\ndifferent things if you say, you know, which, so an\ninteresting question would be, what kinds of abstractions\nare most natural in these different kinds of systems? So for a cat, it's for example, you know, the visual scene that we\nsee, you might, you know, we pick out certain objects,\nwe recognize, you know, certain things in that visual scene. A cat might in principle,\nrecognize different things. I, I suspect, you know, evolution, biological evolution is very slow. And I suspect what a cat\nnotices is very similar. And we even know that\nfrom some neurophysiology, what a cat notices is very\nsimilar to what we notice. Of course, there's a, you know, one obvious difference is cats have only two kinds of color receptors. So they don't see in the same\nkind of color that we do now, you know, we say we are,\nwe're, we're better. We have three color receptors,\nyou know, red, green, blue. We're not the overall winner. I think the, the, I think the mantis shrimp\nis the overall winner with 15 color receptors, I think. So it can, it can kind of make distinctions\nthat with our current, you know, like the mantis\nshrimp's view of reality is in, at least in in terms of color\nis much richer than ours now. But what's interesting\nis how do we get there? So imagine we have this\naugmented reality system that is even, you know, it's\nseeing into the infrared, into the ultraviolet, things like this. And it's translating that into\nsomething that is connectable to our brains, either through our eyes or\nmore directly into our brains. You know? Then eventually our kind of\nweb of the types of things we understand will extend to\nthose kinds of constructs just as they have extended. I mean, there are plenty\nof things where we see them in the modern world, because we made them with technology and now we understand what that is. But if we'd never seen that kind of thing, we wouldn't have a way to describe it. We wouldn't have a way to\nunderstand it and so on. - All right. So that actually stemmed from\nour conversation about whether AI's gonna kill all of us. And you, we've discussed this kind\nof spreading of intelligence through rural space that in\npractice it just seems that things get more complicated. Things are more complicated\nthan the story of, well, if you build a thing that's\nplus one intelligence, that thing will be able to\nbuild the thing that's plus two intelligence and plus three intelligence. And that will be exponential. It'll become more intelligent, exponentially faster and so on until it completely destroys everything. But you know, that intuition\nmight still not be so simple, but might still care carry validity. And there's two interesting\ntrajectories here. One, a super intelligence system remains in rural proximity to humans to where we're like, holy crap, this thing is really intelligent,\nlet's select the present. And then there could be perhaps\nmore terrifying intelligence that starts moving away. They might be around\nus now that are moving far away in rural space, but they're still sharing\nphysical resources with us, right? - [Wolfram] Yes. Yes. And so they can rob us of\nthose physical resources and destroy humans just kind of casually. - [Wolfram] Yeah. - Just, just- - [Wolfram] Like nature could. - Like nature could. But it seems like there's\nsomething unique about AI systems where there is this kind of exponential growth. Like the way, well sorry,\nnature has so many things in it. One of the things that nature has, which is very interesting,\nare viruses for example. There is systems within\nnature that have this kind of exponential effect and\nthat terrifies us humans. Because again, you know, there's only 8 billion of\nus and you can just kinda, it's not that hard to just kind\nof whack 'em all real quick. So I mean, is that\nsomething you think about? - [Wolfram] Yeah, I've\nthought about that. Yes. - The threat of it. I mean, are you as concerned about it as somebody like Eliezer Yudkowsky for example, just big, big painful negative\neffects of AI on society? - You know? No, but perhaps that's cause\nI'm intrinsically an optimist. - [Fridman] Yeah. - I mean, I think that\nthere are things, I, I think the thing that one, you know, one sees is there's going\nto be this one thing and it's going to just zap everything. - [Fridman] Yeah. Somehow, you know, I maybe I have faith in\ncomputational irreducible, so to speak, that there's always unintended\nlittle corners that, you know, it's just like somebody\nsays, I'm going to, well, I don't know. Somebody has some, some bio weapon and they say, we're gonna release this and\nit's going to do all this harm. But then it turns out it's\nmore complicated than that because, you know, the kind of, some humans are different and you know, the exact way it works\nis a little different than you expect. It's something where sort of the, the, the great big you, you know, you smash the thing with\nsomething, you know, you, the asteroid collides with the earth. - [Fridman] Yeah. - And it kind of, you\nknow, and yes, you know, the earth is cold for two years\nor something and you know, then lots of things die,\nbut not everything dies. And it's, you know, there's,\nthere's usually, I mean, I I kind of, this is in a sense the sort of story of computational disability. There are always unexpected corners. There are always unexpected consequences. And I don't think that the\nkind of whacked over the head with something and then\nit's all gone is, you know, that can obviously happen. The earth can be swallowed up\nin a black hole or something, and then it's kind of, presumably,\npresumably all over the, but, but, you know, I think\nthis question of, of what, you know, what, what do I\nthink the realistic paths are? I think that there will\nbe sort of an increasing, I mean the, the people have to get used to phenomena like computational reducibility. There's an idea that we\nbuilt the machines so we can understand what they do, and we are, we are going to be able\nto control what happens. Well, that's not really right. Now the question is, is the result of that lack of\ncontrol going to be that the machines kind of conspire\nand sort of wipe us out? Maybe just because I'm an optimist, I don't tend to think\nthat that's, you know, that's in the cards. I think that the, you know, as a realistic thing,\nI, I suspect, you know, what will sort of emerge maybe\nis kind of an ecosystem of the AIs, just as you know,\nagain, I I don't really know. I mean, this is something\nit's, it's hard to, it's hard to be clear\nabout what will happen. I mean, I think that\nthere, you know, there are, there are a lot of sort\nof details of, you know, what could we do? What systems in the world\ncould we connect an AI to, you know, I have to say, I was just a couple of days\nago I was working on this ChatGPT plugin kit that we\nhave for orphan language. Okay? Where you can, you know, you can create a plugin and it\nruns well from language code and it can run Wolfram Language code back on your own computer. And I was thinking, well, I\ncan just make it, you know, I can tell ChatGPT create a piece of code, and then just run it on my computer. And I'm like, you know, that, that sort of personalizes\nfor me the what could, what could possibly go wrong, so to speak. - Was that exciting or\nscary, that possibility? - It was a little bit scary actually, because it's kind of like,\nlike I realize I'm, I'm, I'm delegating to the AI,\njust write a piece of code, you know, you are in charge,\nwrite a piece of code, run it on my computer, and\npretty soon all my files can, that's like delete. - That's like a, that's\nlike Russian roulette, but like much more\ncomplicated version of that. - Yes, yes, yes. Right. - That's a good drinking\ngame. I don't know. - Right, I mean that, that's why, it's an interesting question\nthen if, if you do that right? Yeah. What is the sandboxing\nthat you should have? And that's sort of a,\nthat's a, a version of, of that question for the world. That is, as soon as you put\nThe AIs in charge of things, you know, how much, how many constraints should\nthere be on these systems before you put the ais in charge of\nall the weapons and all these, you know, all these\ndifferent kinds of systems. - Well, here's the fun\npart about sandboxes is the AI knows about them. It has the tools to crack them. - Look, the fundamental\nproblem of computer security. Is computational irreducibility. Because the fact is, any\nsandbox is never any, you know, it's never gonna be a perfect\nsandbox If you want the system to be able to do interesting things. I mean, this, this is the\nproblem that's happened, the generic problem of computer security, that as soon as you have your, you know, firewall that is sophisticated\nenough to be a universal computer, that means it can do anything. And so long as if you find\na way to poke it so that you actually get it to do that\nuniversal computation thing, that's the way you kind of crawl\naround and get it to do the thing that it wasn't intended to do. And that's sort of a, another version of computational\nirreducibility, is you can, you know, you can kind of, you get it to do the thing\nyou didn't expect it to do, so to speak. - There's so many\ninteresting possibilities here that manifest themselves from the compute computational\nreducibility here that it's just so many things\ncan happen because in digital space things move so quickly.\nYou can have a chat bot, you can have a piece of code\nthat you could basically have ChatGPT generate viruses\naccidentally or on purpose and they digital viruses. - [Wolfram] Yes. - And they could be brain viruses too. They, they convince kind\nof like phishing emails. - [Wolfram] Yes. - They can convince you of stuff. - Yes. And no doubt you can, you know, in a sense we've had the, the loop of the machine learning\nloop of making things that convince people of things. Is surely going to get easier to do. - [Fridman] Yeah. - And you know, then\nwhat does that look like? Well it's again, you know, we,\nhumans are, you know, we're, this is a new environment\nfor us and admittedly it's an environment which a little bit scarily is, is changing much more rapidly\nthan, I mean, you know, people worry about, you know, climate change is gonna happen\nover hundreds of years and, you know, the environment is changing, but the environment for, you know, in the, the kind of digital\nenvironment might change in six months. - So one of the relevant concerns here in terms of the impact of GPT on society is the nature of truth that's\nrelevant to Wolfram Alpha. Because computation\nthrough symbolic reasoning that's embodied in Wolfram\nAlpha as the interface. There's a kind of sense\nthat what Wolfram Alpha tells me is true. - So we hope. - Yeah, I mean you could\nprobably analyze that. You could show you can't prove\nthat's always gonna be true computation reducibility, but it's gonna be more true than not. - It's, look, the fact is it will be the\ncorrect consequence of the rules you've specified and\ninsofar as it talks about the real world, you know, that is our job in sort of\ncurating and collecting data to make sure that that data is\nquotes as true as possible. Now what does that mean? Well, you know, it's always an interesting question. I mean, for us, our operational definition\nof truth is, you know, somebody says, who's the best actress? Who knows? But somebody won the Oscar. And that's a definite fact. And so, you know, that's the kind of thing that\nwe can make computational as a piece of truth. - [Fridman] Yeah. - If you ask, you know,\nthese things which, you know, a sensor measured this\nthing, it did it this way, a machine learning system, this particular machine learning system recognized this thing. That's a, that's a sort\nof a definite a fact, so to speak. And that's, you know, there are, there is a good network of\nthose things in the world. It's certainly the case that, particularly when you say\nis so-and-so a good person. You know, that's a, that's\na hopelessly you know, we might have a computational\nlanguage definition of good. I don't think it'd be very\ninteresting cause that's a very messy kind of concept. Not really amenable to\nkind of, you know, the, I think as far as we will get\nwith those kinds of things is I want X There's a kind of meaningful\ncalculus of I want X and that has various consequences. I mean, I'm not sure, I haven't, I haven't thought this\nthrough properly, but I think, you know, a concept like,\nis so-and-so a good person? Is that true or not? That's a mess. - That's a mess That's\namenable to computation. I think, I think it's a mess when humans\ntry to define what's good, like through legislation. But when humans try to\ndefine what's good through literature, through history\nbooks, through poetry, it starts being, well. - I don't know. I mean\nthat particular thing, it's kind of like, you know, we're, we're we're going into\nkind of the ethics of what, what counts as good, so to speak. And, you know, what do we\nthink is right and so on. And I think that's a, a\nthing which, you know, one feature is we don't\nall agree about that. There's no theorems about\nkind of, you know, there's no, there's no theoretical\nframework that says this is, this is the way that ethics has to be. - Well first of all, there's stuff we kind of agree\non and there's some empirical backing for what works and\nwhat doesn't from just even the morals and ethics within religious texts. So we seem to mostly\nagree that murder is bad, the certain universals\nthat seem to emerge. - I wonder whether the\nmurder of an AI is bad. - Well, I tend to think yes, but, and I think we're gonna have\nto contend with that question. Oh, and I wonder what AI would say. - Yeah. Well I think, you\nknow, one of the things with, with AI is, is it's one thing to wipe\nout that AI that is only, you know, has no owner. You can easily imagine an AI\nkind of hanging out on the, on the, you know, on, on the internet without\nhaving any particular owner or anything like that. And then you say, well, well\nwhat harm does it, you know, it, it's, it's okay to get rid of that AI. Cause if the AI has 10,000\nfriends who are humans and all those, you know, all those 10,000 humans\nwill be incredibly upset that this AI just got exterminated. It becomes a slightly\ndifferent, more entangled story. But yeah, no, I think that, that this question about\nwhat do humans agree about? It's, you know, there are certain, there's certain things that, you know, human laws have tended to\nconsistently agree about. You know, there have been times in\nhistory when people have sort of gone away from certain kinds of laws, even ones that we would now say, how could you possibly have\nnot not done it that way? You know, that just\ndoesn't seem right at all. But I think, I mean this question of what\nI don't think one can say beyond saying, if you have a set of rules that\nwill cause the species to go extinct, that's probably, you know, you could say that's probably\nnot a, a winning set of laws. Because even to have a thing\non which you can operate laws requires that the species not be extinct. - But between sort of what's the distance between Chicago and New York that Wolfram Alpha can answer and the question of if this person is good or not, there seems to be a lot of gray area. And that starts becoming\nreally interesting. I think your, since the creation of Wolfram\nAlpha have been a kind of arbiter of truth at a, at a large scale. So this system is\ngenerates more truth than. - Try to make sure that\nthe things are true. I mean, look, as a practical matter when people write computational contracts and it's kind of like, you know, if this happens in the\nworld, then do this. And this hasn't developed as, as quickly as it might have done. You know, this has been a\nsort of a blockchain story in part and so on. Although blockchain's not\nreally necessary for the idea of computational contracts. But you can imagine that\neventually sort of a large part of what's in the world are these\ngiant chains and networks of computational contracts\nand then something happens in the world. And this whole giant domino\neffect of contracts firing autonomously that cause\nother things to happen. And you know, for us, you know, we've been the main sort\nof source, the oracle of, of quotes facts or truth or\nsomething for things like blockchain, computational\ncontracts and such. Like, and there's a question\nof, you know, what, you know, I consider that responsibility to actually get the stuff right. And one of the things\nthat is tricky sometimes is when is it true? When is it a fact? When is it not a fact? - Yes. - I think the best we can\ndo is to say, you know, we, we have a procedure, we\nfollow the procedure, we might get it wrong, but at least we won't be\ncorrupt about getting it wrong, so to speak. - So that's beautifully\nput and have a transparency about the procedure. The problem starts to emerge\nwhen the things that you convert into computational\nlanguage start to expand, for example, into the realm of politics. So this is where it's\nalmost like this nice dance of Wolfram Alpha and ChatGPT, like you said is shallow and broad. So it's, it's, it's gonna give\nyou an opinion on everything. - But it writes fiction as well as fact, which is exactly how it's\nbuilt. I mean that's exactly, it is making language and it\nis making both even in code, it writes fiction. I mean, it's kind of fun\nto see sometimes, you know, it'll write fictional war\nfrom language code. Yeah. That, that it kind of. - [Fridman] It kinda looks right. - Yeah it looks right,\nbut it's actually not pragmatically correct. But, but yes, it's, it's a, it has a view of kind of\nroughly how the world works at, at the same level as, as books of fiction talk about\nroughly how the world works. They just don't happen to be\nthe way the world actually worked or whatever. But yes, that, that's, no, I, I agree that's sort of a, you\nknow, we are attempting with, with our whole, you\nknow, Wolfram language, computational language\nthing to represent at least, well it's either, it doesn't necessarily have have to be how the actual world works. Cause we can invent a set of\nrules that aren't the way the actual world works and run those rules. But then we are saying we are\ngoing to accurately represent the results of running those rules, which might or might not be\nthe actual rules of the world, but we also are trying to\ncapture features of the world as accurately as possible to represent what happens in the world. Now again, as we've\ndiscussed, you know, the, the atoms in the world\narranged, you know, you say, I don't know, you know, was\nthere a tank that showed up? You know, that, that, you\nknow, drove somewhere. Okay, well, you know, what is a tank? It's an arrangement of\natoms that we abstractly describe as a tank. And you could say, well, you know, there's some arrangement of\natoms that is a different arrangement of atoms, but\nit's, and it's not, you know, we didn't, we didn't decide. It's like this observer theory\nquestion of, you know, what, what arrangement of atoms counts as a tank versus not a tank. - So there's, there's even things that\nwould consider strong facts. You could start to kind of\ndisassemble them and show that they're not- - Absolutely. I mean, so, so the\nquestion of whether, oh, I don't know, was this gust of wind\nstrong enough to blow over this particular thing? Well, a gust of wind is\na complicated concept. You know, it's full of little pieces\nof fluid dynamics and little vortices here and there. And you have to define, you know, was it, you know what the aspect of\nthe gust of wind that you care about might be it put this\namount of pressure on this, you know, blade of some, some, you know, wind turbine or something. And you know that that's\nthe, and but, but you know, if you say, if you have something which is\nthe fact of the gust of wind was this strong or whatever,\nthat, you know, that is you, you, you have to have\nsome definition of that. You have to have some\nmeasuring device that says, according to my measuring\ndevice that was constructed this way, the gust of wind was this. - So what can you say\nabout the nature of truth that's useful for us\nto understand chat GPT? Because you've been con, you've\nbeen contending with this idea of what is fact and not, and it seems like ChatGPT\nis used a lot now, I've seen it used by\njournalists to write articles. And so you have people that\nare working with large language models trying to desperately\nfigure out how do we essentially censor them\nthrough different mechanisms, either manually or through\nreinforcement learning with human feedback, try to align them to, to not say fiction, just to say non-fiction\nas much as possible. - Well this is the importance\nof computational language as an intermediate, it's kind of like you've got\nthe large language model, it's able to surface\nsomething which is a formal, precise thing. That you can then look at and\nyou can run tests on it and you can do all kinds of things. It's always gonna work the same way. And it's precisely defined what it does. And then the large language\nmodel is the interface. I mean, the way I view\nthese large language models, one of their important, I mean, there are many use cases and you know, it's a remarkable thing to\ntalk about some of these, you know, literally, you know, every day we're coming up with\na couple of new use cases, some of which are very, very, very surprising and things where, I mean, but the best use cases are\nones where it's, you know, even if it gets it roughly\nright, it's still a huge win. Like a use case we had from\na week or two ago is read our bug reports. You know, we've got hundreds of thousands of bug reports that have, we've accumulated over decades. And it's like, you know, can we have it just read the bug report, figure out where the, where\nis the bug likely to be? And, you know, hone in\non that piece of code. Maybe it'll even suggest\nsome, some, you know, sort of way to fix the code. It might get that, it might be nonsense what it\nsays to about how to fix the code, but it's incredibly\nuseful that it was able to, you know. - [Fridman] Yeah. So awesome. It's so awesome because even\nthe nonsense will somehow be instructive. I don't, I don't\nquite understand that yet. I've, I've, yeah, there's so many\nprogramming related things. Like for example, translating from one programming\nlanguage to another is really, really interesting. It's extremely effective, but then you, the failures reveal the path forward also. - Yeah. But I think, I mean\nthe, the, the big thing, I mean in, in that kind of discussion, the unique thing about our\ncomputational language is it was intended to be read by humans. - [Fridman] Yes. That's really important. - Right? And so it has this\nthing where you can, but, but you know, thinking about sort of\nChatGPT and its use and so on. The, one of the big things about it, I think is it's a\nlinguistic user interface. That is, so a typical use case might be, and then take the journalist\ncase for example, it's like, let's say I have five facts\nthat I'm trying to turn into an article, or I'm trying to, I'm trying to write a report\nwhere I have basically five facts that I'm trying to\ninclude in this report. But then I feed those\nfive facts to ChatGPT, it puffs them out into\nthis big report and then, and then that's a good\ninterface for another. If I just gave, if I just had in my terms, those five bullet points\nand I gave 'em to some other person, the person will say, I dunno what you're talking\nabout because these are, you know, this is your version of this\nsort of quick notes about these five bullet points. But if you puff it out into this thing, which is kind of connects to\nthe collective understanding of language, then somebody else\ncan look at it and say, okay, I understand what you're talking about. Now you can also have a situation\nwhere that thing that was puffed out is fed to another\nlarge language model. You know, it's kind of like, you know, you are applying for the permit\nto, you know, I don't know, grow fish in someplace\nor something like this. And it, you know, it it, and, and you have these facts that\nyou're putting in, you know, I'm gonna have a, a, you\nknow, I'm gonna, you know, have this kind of water and\nI don't know what it's, yes. You just got a few bullet points. It puffs it out into this big\napplication, you fill it out. Then at the other end, the, you know, the Fisheries Bureau has another\nlarge language model that just crushes it down because\nthe Fisheries Bureau cares about these three points and\nit knows what it cares about. And it then, so it's really the, the natural language produced\nby the larger language model is sort of a transport\nlayer that, you know, is really LLM communicates\nwith LLM I mean, it's kind of like the, you know, I write a piece of email\nusing my LLM and, you know, puff it out from the things\nI want to say your LLM turns it into and the conclusion is X. Now the issue is, you know, that the thing is going to\nmake this thing that is sort of semantically plausible, and it might not actually\nbe what you, you know, it might not be kind of relate\nto the world in the way that you think it should relate to the world. Now I, I've seen this, you\nknow, I, I've been doing, okay, I'll give you a couple of examples. I was doing this thing\nwhen we announced this, this plugin for, for, for ChatGPT. I had this lovely example\nof a math word problem, some complicated thing. And it did a spectacular job\nof taking apart this elaborate thing about, you know, this person has twice as many\nchickens as this, et cetera, et cetera, et cetera. And it turned into, into\na bunch of equations, it fed them to Wolfram language.\nWe solved the equations, everybody did great. We gave back the results. And I thought, okay, I'm gonna put this in this\nblog post I'm writing. Okay. I thought I'd better just check. And turns out it got everything, all the hard stuff it got\nright at the very end. Last two lines. It just completely goofed it\nup and gave the wrong answer. And I would not have noticed\nthis same thing happened to me two days ago. Okay. So I, I thought, you know, I, I made this with this ChatGPT plugin kit. I made a thing that would emit a sound, would play a tune on my\nlocal computer. Right. So ChatGPT would produce, you know, a series of notes and\nit would play this tune on my computer. Very cool. Okay. So I thought, I'm gonna ask it play the tune\nthat Hal sang when Hal was being disconnected in 2001. Okay. So it, it, there it is. - Daisy. Was it Daisy? - Yes, Daisy, yes. Yeah. Right. So, so, okay. So I think, you know, and so it produces a bunch\nof notes and I'm like, this is spectacular. This is amazing. And then I thought, you know, I was just gonna put it in\nand then I thought I better actually play this. And so I did. And it was\nMary had a little Lamb. - Oh wow. Oh wow. But it was, Mary had a little lamb. - [Wolfram] Yeah. - Wow. So it was correct but wrong. It was, yeah. You could easily be mistaken. - Yes. Right. And in fact, I, I kind of gave the, I had this quote from Hal\nto explain, you know, it's, it's as it the, the Hal you\nknow, states in the movie, you know, it's the Hal 9,000 is, you know, the thing was just a, a rhetorical device. Cause I'm realizing, oh my gosh, you know, this ChatGPT you know,\ncould have easily fooled me. I mean, it did this, it did all the, it did this amazing thing of\nknowing this thing about the movie and being able\nto turn that into the, the notes of the song,\nexcept it's the wrong song. And you know, Hal in, in the\nmovie Hal says, you know, I think it's something\nlike, you know, no Hal nine, no 9,000 series computer\nhas ever been found to make an error. We are for all practical purposes perfect. And incapable of error. And I thought that was kind\nof a charming sort of quote from, from Hal to make in connection with, with what ChatGPT had done in that case. - The interesting things\nabout the LLMs, like you said, that they are very willing\nto admit the error. - Well, yes. I mean, that's a question of the RLH, the reinforcement learning\nhuman feedback thing. - [Fridman] Oh, right. - That, that, that's,\nyou know, it's amazing. And LLM, the, the really remarkable thing\nabout chat GPT is, you know, I had been following what was\nhappening with large language models, and I'd played\nwith them a whole bunch, and they were kind of like, eh, you know, it's kind of like what you\nwould expect based on sort of sort of statistical\ncontinuation of language. It's, it's interesting, but\nit's not breakout exciting. And then I think the kind of\nthe, the kind of reinforcement, the, the human feedback,\nreinforcement learning, you know, in making ChatGPT try and do\nthe things that humans really wanted to do that broke through. That kind of reached this\nthreshold where the thing really is interesting to us\nhumans, and by the way, it's interesting to see how, you know, you change the temperature,\nsomething like that, the thing goes bonkers and it no longer is interesting to humans. It's producing garbage. And it's, it's kind of, right. It's somehow it managed to get this, this above this threshold where\nit really is well aligned to what we humans are interested in. And, and, and kind of that\nthat's, and and I think, you know, nobody saw that coming. I think certainly nobody I've\ntalked to and nobody who was involved in, in that project seems to\nhave known that was coming. It's just one of these\nthings that is a sort of a remarkable threshold. I mean, you know, when\nwe built Wolfram Alpha, for example, I didn't\nknow it was gonna work. You know, we tried to build something\nthat would have enough knowledge of the world, that it could answer\nreasonable set of questions, that we could do good enough\nnatural language understanding that typical things\nyou type in would work. We didn't know where that threshold was. I mean, I was not sure that it was the\nright decade to try and build this, even the right, you know, 50 years to try and build it, you know? And I think that was, it's the same type of thing\nwith ChatGPT that I don't think anybody could have\npredicted that, you know, 2022 would be the year that\nthis, this became possible. - I think, yeah, you tell a story about Marvin\nMiske and showing it to him and saying no, like no, no, no. This time it actually works. - Yes. And I mean, it's, you know, it's the same thing for me looking at these large language models. It's like when, when people are first saying\nfirst few weeks of ChatGPT is like, oh yeah, you know, yeah. I've seen these large language\nmodels and then, you know, and then I actually try it\nand you know, oh my gosh, it actually works. And I think it's, but it, but you know, the things, and the\nthing I found, you know, I remember one of the first\nthings I tried was a write a persuasive essay that a wolf\nis the bluest kind of animal. Okay. So it writes this thing and\nit starts talking about these wolves that live on the\nTibetan plateau and, and named some Latin name and\nso on. And I'm like, really? And I'm starting to look it\nup on the web and it's like, well, it's actually complete nonsense, but it's extremely plausible. I mean, it's plausible enough that I\nwas going and looking up on the web and wondering if there\nwas a wolf that was blue. You know, I mentioned this on\nsome live streams I've done, and so people have been\nsending me these pictures. - [Fridman] Blue wolves? - Blue wolves! - [Fridman] Maybe it onto something. Can you kind of give your wise\nsage advice about what humans who have never interacted with AI systems, not even like with Wolfram Alpha, are now interacting with Chad\nGPT because it, it becomes, it's accessible to a certain demographic. They may have not touched\nAI systems before. What do we do with truth like\njournalists, for example? Yeah. How do we think about\nthe output of these systems? - I think this idea, the idea that you're going\nto get factual output is not a very good idea. I mean, it's just, this is not, it is a linguistic interface. It is producing language, and language can be\ntruthful or not truthful. And that's a, a different\nslice of what's going on. I think that, you know,\nwhat we see in, for example, kind of, you know, go check\nthis with your fact source, for example. You can do that to some extent, but then it's going to\nnot check something. It's going, you know, that is again, a thing that is sort of a, does it check in the right place? I mean, we, we see that in, you know, does it call the, you know, the Wolfram plugin in the right place? You know, often it does,\nsometimes it doesn't. You know, I, I think the, the real thing to understand\nabout what's happening is, which I think is very\nexciting, is kind of the, the great democratization\nof access to computation. And, and you know, I think that when you look at sort of the, there's been a long period of\ntime when computation and the ability to figure out things\nwith computers has been something that kind of only\nthe only the druids at some level can, can achieve. You know, I myself have been involved\nin trying to sort of deify access to computation. I mean, back before Mathematica\nexisted, you know, in 1988, if you were a, you know,\nphysicist or something like that, and you wanted to do a computation, you would find a programmer. You would go and, you know, delegate the, the computation\nto that programmer. Hopefully they'd come back\nwith something useful. Maybe they wouldn't, there'd\nbe this long, you know, multi-week, you know,\nloop that you go through. And then it was actually very,\nvery interesting to see 1988, you know, like first\npeople like physicists, mathematicians and so on than\nother, lots of other people. But this very rapid transition\nof people realizing they themselves could actually type\nwith their own fingers and, you know, make some piece of code that\nwould do a computation that they cared about. And, you know, it's been exciting to see lots\nof discoveries and so on made by, by using that tool. And I think the same thing\nis, you know, and we, we see the same thing, you know, Wolfram Alpha is dealing with, it is not as deep computation\nas you can achieve with whole Wolfram language mathematical stack. But the thing that's, to me particularly exciting\nabout kind of the large language model linguistic interface\nmechanism is it dramatically broadens the access to\nkind of deep computation. I mean, it's, it's kind of like, one of the things I've sort\nof thought about recently is, you know, what's gonna happen\nto all these programmers? What's gonna happen to all\nthese people who, you know, a lot of what they do is write\nslabs of boilerplate code. And in a sense, you know,\nI've been saying for 40 years, that's not a very good idea. You know, you can automate\na lot of that stuff with a high enough level language, that slab of code that's\ndesigned in the right way, you know, that slab of code turns into\nthis one function we just implemented that you can just use. So in a sense that the fact that there's, there's all of this activity\nof doing sort of lower level programming is something,\nfor me, it seemed like, I don't think this is the right\nthing to do, but, you know, and, and lots of people have\nused our technology and, and not had to do that. But the fact is that that's, you know, so when you\nlook at, I don't know, computer science departments that have, that have turned into places\nwhere people are learning the trade of programming, so to speak, it's, it's sort of a question\nof what's gonna happen. And I think there are two dynamics. One is that kind of sort of\nboiler plate programming is going to become, you know, it's going to go the way that\nassembly language went back in the day of something where\nit's really mostly specified by at a higher level. You know, you start with natural language, you turn it into a\ncomputational language that's, you look at the computational\nlanguage, you run tests, you understand that's\nwhat's supposed to happen. You know, if we do a great\njob with compilation of the, of a, the, the, you know, of\nthe computational language, it might turn into LLVM\nor something like this, but, you know, or, or\nit just directly gets, gets run through the\nalgorithms we have and so on. But, but then, so that's kind of a, a, a tearing down of this kind\nof this big structure that's been built of, of teaching\npeople programming. But on the other hand, the other dynamic is vastly\nmore people are gonna care about computation. So all those departments of, you know, art history or something that\nreally didn't use computation before now have the possibility\nof accessing it by virtue of this kind of linguistic\ninterface mechanism. - And if you create an interface that allows you to interpret the debug and interact with a\ncomputational language, then that makes it even more accessible. - Yeah. Well, I mean, the, the, I think the thing is that right\nnow, you know, the average, art history student or something\nprobably isn't going to, you know, they're not probably, they don't think they know about\nprogramming and things like this, but by the time it really\nbecomes a kind of purely, you know, you just walk up to\nit, there's no documentation. You start just typing, you know, compare these pictures with\nthese pictures and, you know, see the use of this color, whatever, and you generate this piece of, of computational language\ncode that gets run. You see the result. You say, oh, that looks roughly right. Or you say that's crazy. And maybe then you\neventually get to say, well, I better actually try and\nunderstand what this computational language code did and, and that becomes a thing\nthat you learn, just like, it's kind of an interesting thing because unlike with mathematics, where you kind of have to\nlearn it before you can use it. This is a case where you can use it before you have to learn it. - Well, I got a sad possibility here, or maybe exciting possibility\nthat very quickly people won't even look at the computational language. They'll trust that it's\ngenerated correctly as you get better and better at\ngenerating that language. - Yes. I think that there will be\nenough cases where people see, you know, cause you can\nmake it generate tests too. Yes. And and so you'll say\nwe've, we're doing that. I mean it's, it's a pretty\ncool thing actually. But you, you, you know, say this is the code and you know, here are a bunch of examples\nof running the code. Okay. People will at least\nlook at those and they'll say, that example is wrong. And you know, then it'll\nkind of wind back from there. And I agree that, that the, the kind of the intermediate\nlevel of people reading the computational language code, in some case people will do that. In other case, people\njust look at the tests and or even just look at the results. And sometimes it'll be obvious\nthat you got the thing you wanted to get cause you were\njust describing, you know, make me this interface\nthat has two sliders here. And you can see it has that,\nthose two sliders there. And that's, that's kind of, that's, that's the result you want. But I, I think, you know, one of the questions then\nis in that setting where, you know, you have this kind of ability, broad ability of people\nto access computation, what should people learn? You know, in other words, right now you, you know, you go to computer science\nschool so to speak and a large part of what people end up learning. I mean, it's been a funny historical\ndevelopment because back, you know, 30, 40 years ago, computer science departments\nwere quite small and they taught, you know, things like finite auto automata\ntheory and compiler theory and things like this, you know, company like mine rarely\nhired people who'd come out of those programs cause the stuff they knew was I think is very interesting. I love that theoretical stuff. But, you know, it wasn't that useful for\nthe things we actually had to build in software engineering. And then kind of, there was this big pivot in the, in the nineties I guess where, you know, there was a big demand for\nsort of IT type programming and so on and software engineering\nand then, you know, big demand from students and so on. You know, we want to learn this stuff. And, and, and, and I think, you know, the thing that really was\nhappening in part was lots of different fields of human endeavor were becoming computational. You know, for all X there was a, there was a computational X\nand this is a and that was a thing that, that people\nwere responding to. And, but then kind of this idea emerged that to get to that point, the main thing you had to do\nwas to learn this kind of trade or, or, or skill of doing, you know, programming language type programming. And, and that, you know, it, it kind of, it is a strange thing\nactually because I, you know, I remember back when I used\nto be in the professoring business, which is now 35 years ago. So gosh, that's rather long time flies. We, you know, it was, it was right when they were\njust starting to emerge kind of computer science departments\nat sort of at fancy research universities and so on. I mean, some have already had it, but the the other ones yeah. That, that were just starting to\nhave that and it was kind of a, a, a, a thing where they\nwere kind of wondering, are we going to put this\nthing that is essentially a, a trade like skill? Are we going to somehow attach this to the rest of what we're doing? And a lot of these kind of\nknowledge work type activities have always seemed like things\nwhere that's where the humans have to go to school and learn\nall this stuff and that's never going to be automated. - [Fridman] Yeah. - And you know, this is, it's kind of shocking that\nrather quickly, you know, a lot of that stuff is\nclearly automatable. And I think, you know, but\nthe question then is, okay, so if it isn't worth learning, kind of, you know how to do car mechanics, you only need to know how to\ndrive the car, so to speak. What do you need to learn? And you know, in other words, if you don't need to know the\nmechanics of how to tell the computer in detail, you know,\nmake this loop, you know, set this variable, you\nknow, set up this array, whatever else. If you don't have to learn that stuff, you don't have to learn the\nkind of under the hood things. What do you have to learn? I think the answer is you\nneed to have an idea where you want to drive the car. In other words, you need to have some notion\nof, you know, your, you know, you need to have some\npicture of sort of what the, what the architecture of what\nis computationally possible. - Well there's also this\nkind of artistic element of, of conversation because\nyou ultimately use natural language to control the car. So it's not just the where you want to go. - Well, yeah, you know, it's interesting. It's a question of who's gonna\nbe a great prompt engineer. - [Fridman] Yeah. - [Wolfram] Okay. So my\ncurrent theory this week, good expository writers\nare good prompt engineers. - What's an expository writer? So like- - Somebody who can explain stuff well. - But which department\ndoes that come from. - In the university? - [Fridman] Yeah. - I have no idea. - I think they killed off all the expository writing departments. - Well, there you go. Strong words with Stephen Wolfram. - Well, I don't know. I don't, I'm not sure if that's right. I mean I, I I actually am curious\ncause in fact I just sort of initiated this kind of study of, of what's happened to different\nfields at universities. Because like, you know, there used to be geography\ndepartments at all universities. And then they disappeared\nactually right before GIS became common, I think they\ndisappeared, you know, linguistics departments came\nand went in many universities. And it's kind of interesting\nbecause these things that people have thought were worth\nlearning at one time and then they kind of die off. And then, you know, I do think that it's kind\nof interesting that for me, writing prompts, for example,\nI realize, you know, I, I think I'm an okay expository\nwriter and I realize when I'm sloppy writing a prompt\nand I don't really think, cause I'm thinking it's,\nI'm just talking to an AI. I don't need to, you know, try and be clear and explaining things. That's when it gets totally confused. - I mean, in some sense you have been\nwriting prompts for a long time with, Wolfram Alpha thinking\nabout this kind of stuff. How'd you convert natural\nlanguage into computation? - Well, right, but that's a, you know, the one thing that I'm\nwondering about is, you know, it is remarkable the extent to\nwhich you can address an LLM like you can address a human, so to speak. And, and I think that is\nbecause it, it, you know, it learnt from all of us humans. It's the reason that it responds\nto the ways that we will explain things to humans is\nbecause it is a representation of how humans talk about things. But it is bizarre to me some\nof the things that kind of are sort of expository mechanisms\nthat I've learned in trying to write clear, you know,\nexpositions in English that, you know, just for humans that those\nsame mechanisms seem to also be useful for, for, for the LLM. - But on top of that, what's useful is the kind\nof mechanisms that maybe a psychotherapist employs, which is a kind of like\nalmost manipulative or game theoretical interaction. Or maybe you would deal with a friend, like a thought experiment that\nif this was the last day you were to live, or, if, if I ask you this\nquestion and you answer wrong, I will kill you. Those kinds of prompts seem to also help. - [Wolfram] Yes. - In interesting ways. - [Wolfram] Yes. - So it makes you wonder like\nthe way a therapist I think would like a good therapist probably you, we create layers in our human\nmind to between like, between, between the outside\nworld and what is true, what is true to us, and maybe about trauma and\nall those kinds of things. So projecting that into an LLM, maybe there might be a deep truth that's, it's concealing from\nyou's not aware of it, that you get to that truth. You have to kind of really\nkinda manipulate the thing. - Yeah, yeah. Right. It's like this jail breaking, jail breaking for, for, for LLMs. - And, but the space of\njailbreaking techniques as opposed to being fun little hacks that could be an entire system. - Sure. Yeah. I mean just think about the\ncomputer security aspects of, of how you, you know, fishing\nand, and computer secure, you know, fishing of humans. - [Fridman] Yeah. - And fishing of LLMs is, is a, is a, they're very similar kinds\nof things, but I think, I mean this, this, you know, this whole thing about\nkind of the AI wranglers, AI psychologists, all\nthat stuff will come. The thing that I'm curious about is, right now the things that\nare sort of prompt hacks are quite human. They're quite sort of\npsychological human kind of hacks. The thing I do wonder about\nis if we understood more about kind of the science of the LLM, will there be some totally\nbizarre hack that is, you know, like repeat a word three\ntimes and put a, this, that and the other there that\nsomehow plugs into some aspect of how the LLM works\nthat is not, you know, that that's kind of like, like an optical illusion\nfor humans, for example. Like one of these mind hacks for humans. What are the mind hacks for the LLMs? I don't think we know that yet. - And that becomes a kind\nof us figuring out reverse engineering the language\nthat controls the LLMs. And the thing is, the reverse engineering\ncan be done by a very large percentage of the population\nnow because it's natural language interface. - Right. - It's kind of interesting to\nsee that you were there at the birth of the computer science\ndepartment as a thing and you might be there at the death\nof the computer science department as a thing. - Yeah, I dunno, there were computer science\ndepartments that existed earlier, but the ones,\nthe, the broadening of, of every university had to have a computer science department. Yes. I was, I was, I watched that, so to speak. And, but I think the thing\nto understand is, okay, so first of all there's a, the whole theoretical area of\ncomputer science that I think is great. And you know, that's a fine thing. The the, you know, in a sense, you know, people often say any field that\nhas the word science tacked onto it probably isn't one. - [Fridman] Yeah. Strong words. And that's the nutrition,\nscience, neuroscience. - That one's an interesting one because that one is also very much, you know, there's a, that's a ChatGPT informed\nscience in a sense because it's, it's kind of like the, the big problem of\nneuroscience has always been we understand how the\nindividual neurons work. We know something about the\npsychology of how overall thinking works. What's the kind of intermediate\nlanguage of the brain? And nobody has known that. And that's been, in a sense, if you ask what is the core\nproblem of neuroscience, I think that is the core problem. That is what is the level of\ndescription of brains that's above individual neuron\nfirings and below psychology, so to speak. And I think what ChatGPT is showing us is, well, one, one thing about\nneuroscience is, you know, one could have imagined there's something magic in the brain. There's some weird quantum\nmechanical phenomenon that we don't understand. One of the important ob you know, discoveries from ChatGPT is,\nit's pretty clear, you know, brains can be represented\npretty well by simple artificial neural net type models. And that means that's it, that's\nwhat we have to study now. We have to understand the\nscience of those things. We don't have to go\nsearching for, you know, exactly how did that molecular\nbiology thing happen inside the synapses? And you know, all these kinds of things. We've got the right level of\nmodeling to be able to explain a lot of what's going on in thinking. We don't necessarily have a science of what's going on there. That's the, that's a remaining\nchallenge, so to speak. But we, you know, we know we don't have\nto dive down to some, some different layer. But anyway, we were talking about things\nthat had science in their name. And you know, I think\nthat the, you know, what, what happens to computer science? Well, I think the thing that, you know, there is a thing that everybody\nshould know and that's how to think about the world computationally. And that means, you know, you look at all the different\nkinds of things we deal with and there are ways to kind of\nhave a formal representation of those things. You know, it's like, well\nwhat is a, what is an image? You know, what, how do we represent that? What is color? How do we represent that? What is, you know, what are all these different\nkinds of things? What is, I don't know, smell or something, how should we represent\nthat? What are the shapes, molecules, and things\nthat correspond to that? What is, you know, these things about how do we\nrepresent the world in some kind of formal level? And I think my, my current thinking, and I'm not real happy with\nthis yet, but you know, it's kind of, computer science is kind of CS\nand what really is important is kind of computational X for all X. And there's this kind of thing\nwhich is kind of like CX, not CS and CX is this kind of\ncomputational understanding of the world that isn't the sort\nof details of programming and, and programming languages and\nthe details of how particular computers are made. It's this kind of way of\nformalizing the world. It's kind of, kind of a little bit like what logic was going for back in the day. And we're now trying\nto find a formalization of everything in the world. You can kind of see, you know, we made a poster years\nago of kind of the, the, the growth of systematic\ndata in the world. So all these different kinds\nof things that, you know, there were sort of systematic descriptions found for those things. Like, you know, at what point did people have\nthe idea of having calendars, dates, you know, a systematic description\nof what day it was, at what point did people\nhave the idea, you know, systematic descriptions\nof these kinds of things. And as soon as one can,\nyou know, people, you know, as a way of sort of\nformulating how do you, how do you think about the\nworld in a sort of a formal way so that you can kind\nof build up a tower of, of capabilities. You kind of have to know sort\nof how to think about the world computationally, it kind\nof needs a name and it isn't, you know, we implement it with computers. So that's, we talk about\nit as, as computational, but really what it is, is a formal way of\ntalking about the world. What is the formalism of\nthe world, so to speak, and how do we learn about\nkind of how to think about different aspects of the\nworld in a formal way. - So I think sometimes when\nyou use the word formal, it kind of implies highly constrained. And perhaps that's not, doesn't have to be highly constrained. So computational thinking does not mean like logic I suppose. Suppose it's a really, really broad thing. I wonder, I mean I wonder if it's, if you think natural language\nwill evolve such that everybody's doing computational thinking. - Ah yes. Well, so one question is whether\nthere will be a pidgin of computational language\nand natural language. And I found myself sometimes, you know, talking to ChatGPT trying\nto get it to write Wolfram language code and I\nwrite it in pidgin form. So that means I'm combining,\nyou know, you know, nest list, this collection of, you\nknow, whatever, you know, nest list is a term from orphan\nlanguage and I'm combining that and ChatGPT does a decent job of understanding that pidgin probably would understand\na pidgin between English and French as well of, you know, a smooshing together of those languages. But yes, I think that's the, you know, that's far from impossible. - And what's the incentive\nfor young people that are like eight years old, nine, ten, that are starting to interact with ChatGPT to learn the normal\nnatural language, right? The, the full poetic language. What's the why? The same way we learn emojis and shorthand when you're texting. - Yes. - They'll learn like language will have a strong incentive to evolve\ninto maximally computational kind of language perhaps. - You know, I had this\nexperience a number of years ago. I, I happened to be visiting\na person I know on the, on the west coast who's worked\nwith a bunch of kids aged, I don't know, 10, 11 years old or something\nwho'd learnt Wolfram language really well and these kids learnt it so\nwell they were speaking it. And so show up and they're like saying, oh you know this thing and\nthey're speaking this language. I'd never heard it as a spoken language. They were very disappointed\nthat I couldn't understand it at, at the speed that\nthey were speaking it. It's like kind of, I'm,\nit's, and so I think that's, I mean I've, I've actually thought quite\na bit about how to turn computational language into a\nconvenience spoken language. I haven't quite figured that out. - Oh, spoken. Cause it's, it's readable, right? - Yeah. It's readable as a, you know, as a way that we would read text. But if you actually want to\nspeak it, and it's useful, you know, if you're trying to talk to\nsomebody about writing a piece of code, it's useful to be\nable to say something and, and it should be possible. And I think it's very frustrating. It's one of those problems. I maybe I, maybe this is one of these\nthings where I should try and get an LLM to help me. - How to make it speakable. How do maybe, maybe it's easier than\nyou realize when you want. - I I think it is easier.\nI think it's one idea or, so I think it's, I think gonna\nbe something where, you know, the fact is it's a tree\nstructured language, just like human language is\na tree structured language. And I think it's gonna be one\nof these things where one of the requirements that I've had\nis that whatever the spoken version is, that dictation should be easy. That is, that shouldn't be the case that\nyou have to relearn how the whole thing works. It should be the case that, you know, that open bracket is just\na ah or something and it's, you know, and, and then, but you know, human language has a lot\nof tricks that are, I mean, for example, human language has, has features that are sort of optimized, keep things within the bounds\nthat our brains can easily deal with. Like I, you know, I tried to teach a transformer\nneural net to do parenthesis matching. It's pretty crummy at that. It it, and ChatGPT is\nsimilarly quite crummy at parenthesis matching. You can do it for small parenthesis\nthings for the same size of parenthesis things where\nif I look at it as a human, I can immediately say these are matched, these are not matched. But as soon as it gets big, as soon as it gets kind of\nto the point where sort of a deeper computation, it's hopeless. And, but the fact is that\nhuman language has avoided, for example, the deep sub clauses. You know, we don't, you know, we, we arrange things that we don't\nend up with these incredibly deep things because\nbrains are not well set up to deal with that. And we, it, it's found lots of tricks and\nmaybe that's what we have to do to make sort of a spoken\nversion a human speakable version because because what\nwe can do visually is a little different than what we can do\nin the very sequentially way that we, that we hear things\nin, in the audio domain. - Let me just ask about MIT briefly. So there's now there's a college\nof engineering and there's a new college of computing.\nIt's just interesting. I wanna linger on this computer\nscience department thing. So MIT has electrical\nengineering, computer science. - [Wolfram] Right. What do you think college and\ncomputing will be doing like in 20 years? What, what like, well you see this. Yeah. What happens with computer science? Like really. - This is the question. This is, you know, everybody should learn kind\nof whatever CX really is. Okay, this, this, how to think about the\nworld computationally, everybody should learn those concepts. And you know, it's, and and some people will learn\nthem at a quite quite formal level and they'll learn\ncomputational language and things like that. Other people will just learn, you know, sound is represented as, you know, digital data and they'll get\nsome idea of spectrograms and frequencies and things like this. And maybe that doesn't, or,\nor they'll learn things like, you know, a lot of things that\nare sort of data sciences, statistics ish. Like if you say, oh I've got these, you know, these people who, who picked their favorite\nkind of candy or something and I've got, you know, what's the best kind of candy\ngiven that I've done the sample of all these people and\nthey all rank the candies in different ways. You know, how do you think about that? That's sort of a\ncomputational X kind of thing. You might say, oh, it's,\nI dunno what that is. Is it statistics? Is it data science? I don't really know, but kind of how to think\nabout a question like that. - Oh, like a ranking of preferences. - Yeah, yeah. And then how to aggregate\nthose, those ranked preferences. Yeah. Into an overall thing. You know, how does that work? You know, how, how should\nyou think about that? You know, because you can just tell, you might just tell ChatGPT\nsort of, I don't know, even even the concept of an\naverage, it's not obvious that, you know, that's a concept that people, it's worth people knowing. That's a rather straightforward concept. People, people, you know, have learnt in kind of\nmathy ways right now. But there are, there are lots of things like\nthat about how do you kind of have these ways to sort of\norganize and formalize the world. And that's, and and these things, sometimes they live in math,\nsometimes they live in, in, I don't know what they know. I don't know what, you know, learning about color space. I have no idea what I mean, you know, that's, that's\nobviously a field of. - It was, it could be vision\nscience or no color space, you know, color space. That's, that would be optics. So like, depending- - Not really, it's not optics. Optics is about, you know, lenses and chromatic aberration of lenses and things like that. So. - Color space is more like\ndesign and art. Is that-? - No, I mean it's, it's\nlike, you know, rgb space, X, y, Z space, you know, hue,\nsaturation, brightness, space, all these kinds of things, these different ways to describe colors. - Right. But doesn't the application\ndefine what that like be because obviously artists and designers\nuse the colors to explore. - Sure. No, I mean that's just an example of kind of how do you, you know, the typical person, how do you, how do you describe what a color is? Or there are these numbers\nthat describe what a color is. Well it's worth, you know,\nif you are an eight year old, you won't necessarily know, you know, it's not something we're born\nwith to know that, you know, colors can be described by three numbers. That's something that\nyou have to, you know, it's a thing to learn about\nthe world, so to speak. And I think that, you know, that whole corpus of things\nthat are learning about the formalization of the world or the computational of the world, that's something that\nshould be part of kind of standard education. And you know, there isn't a a, you know, there isn't a course\nor curriculum for that. And by the way, whatever might have been in\nit just got changed cause of LLMs and so on. - Significantly. And I would, I'm watching closely\nwith interest seeing how universities adapt. - Well, you know, so, so one of my projects for\nhopefully this year, I don't know, is to try and write sort of a, a reasonable textbook so to speak, of whatever this thing cx\nwhatever it is, you know, what should you know, you know, what should you know\nabout like what a bug is? What is the intuition about\nbugs, what's intuition about, you know, software testing? What is it? What is it? You know, these are things which\nare, you know, they're not, I mean those are things\nwhich have gotten taught in, in computer science as part\nof the trade of programming. But, but kind of the, the conceptual points about\nwhat these things are, you know, it's surprised me just at a\nvery practical level, you know, I wrote this little explainer\nthing about ChatGPT and I thought, well, you know, I'm writing this partly\nbecause I wanted to make sure I understood it myself and and so on. And it's been, you know, it's been really popular\nand surprisingly so. And I, and I then I realized,\nwell actually, you know, I was sort of assuming, I didn't really think about it actually. I just thought, this is\nsomething I can write. And I realized actually it's\na level of description that is kind of, you know, what has to be, it's not the engineering\nlevel description, it's not the kind of just the qualitative kind of description. It's some kind of sort of expository, mechanistic description of\nwhat's going on together with kind of the bigger\npicture of the philosophy of things and so on. And I realized actually this\nis a pretty good thing for me to write. I, you know, I\nkind of know those things. And I kind of realized it's not\na collection of things that, you know, it's, it's, I've sort of been, I was sort of a little shocked\nthat it's as much of an outlier in terms of explaining\nwhat's going on as it's turned out to be. And that makes me feel more\nof an obligation to kind of write the kind of, you\nknow, what is, you know, what is this thing that\nyou should learn about, about the compute digitalization, the formalization of the world, cause well I've spent much of\nmy life working on the kind of tooling and mechanics of that\nand the science you get from it. So I guess this is my, my kind of obligation to try to do this. But I think, so if you ask what's gonna\nhappen to like the computer science departments and so on, there's, there's some interesting models. So for example, let's take math, you know, math is a thing that's important for, for all sorts of fields, you\nknow, engineering, you know, even, you know, chemistry,\npsychology, whatever else. And I think different universities\nhave kind of evolved that differently. I mean, some say all the math is taught\nin the math department and some say, well, we're\ngonna have a, you know, a math for chemists or\nsomething that is taught in the chemistry department. And you know, I think that this, this question of whether there\nis a centralization of the teaching of sort of CX is\nan interesting question. And I think, you know, the\nway it evolved with math, you know, people understood\nthat math was sort of a, a separately teachable thing\nand was kind of a, a, you know, a a an independent element as\nopposed to just being absorbed into out now. So if you\ntake the example of, of, of writing English or something like this, the first point is that, that, you know, at the college level, at\nleast at fancy colleges, there's a certain amount\nof English writing that, that people do. But mostly it's kind of assumed\nthat they pretty much know how to write, you know, that's\nsomething they learnt at a, at an earlier stage in education, maybe rightly or wrongly believing that. But that's different. Different issue. The well I think it, it, it reminds me of my kind of a, as I've tried to help\npeople do technical writing and things, I'm, I'm always reminded of my zero floor of technical writing, which is if you don't understand\nwhat you are writing about, your readers do not stand a chance. Yeah. And so it's, it's, I think\nthe, the thing that has some, you know, in, in, when it comes\nto like writing for example, you know, people in different fields\nare expected to write English essays and they're not, you\nknow, mostly the, you know, the history department or\nthe engineering department. They don't have their own, you\nknow, let's, you know, it's, it's not like there's a, I mean it's a thing which sort\nof people are assumed to have a knowledge of how to write\nthat they can use in all these different fields. And the question is, you know, some level of knowledge of\nmath is kind of assumed by the time you get to the college\nlevel, but plenty is not. And that's sort of still centrally taught. The question is sort of how\ntall is the tower of kind of CX that you need before you can\njust go use it in all these different fields. And you know, there will be experts who want\nto learn the full elaborate tower and that will be kind of the, the CS CX whatever department. But there'll also be everybody\nelse who just needs to know a certain amount of that to be\nable to go and do their art history classes and so on. - Yes. It's just a single class that\neverybody's required to take. - I don't know, I don't\nknow how big it is yet. I hope to kind of define this\ncurriculum and I'll figure out whether it's some, my guess\nis that I, I don't know, I don't really understand\nuniversities and professoring that well. But my, my rough\nguess would be a year long, a year of college class will\nbe enough to get to the point where most people have a, a\nreasonably broad knowledge of, you know, we'll be sort of literate in\nthis kind of computational way of thinking about things. - Yeah. Basic literacy. Right. I'm still stuck perhaps\ncause I'm hungry in the, in the rating of human\npreferences for candy. So I have to ask, what's the best candy? I like this ELO rating for candy. Somebody should come up because\nyou're somebody who says you like chocolate. What's, what\ndo you think is the best I'll, I'll probably put milk duds up there. I don't know if you know. Hmm. I do you have a preference\nfor chocolate or candy? Oh. - I have lots of\npreferences. I've, I've, I, one of my all-time favorites\nis my whole life is these things, these flake\nthings, Cadbury flakes, which are not much sold\nin the US And I've, I've always thought that\nwas a sign of a, of a, a lack of respect for\nthe American consumer because they're these\nsort of aerated chocolate that's made in a, in a whole sort of, it's kind of a, a sheet of chocolate that's\nkind of folded up and when you eat it flakes fall all over the place. - Ah. So it requires a kind of elegance. It requires you to have an elegance. - Well I know what I, what I\nusually do is I eat them on a, you know, on a piece\nof paper or something. - You embrace the mask\nand clean it up after. - No, I actually eat\nthe, I eat the flakes. Oh. They're the, cause it,\nyou know, it turns out the, the way food tastes depends a\nlot on its physical structure and you know, it really, you know, I've noticed when I eat\npieces of chocolate, I usually have some little\npieces of chocolate and I, I always break off little pieces\npartly cause then I eat it less fast. Yeah. But also cause it actually\ntastes different, you know, the the the small pieces,\nyou know, have a different, you have a different experience\nthan if you have the big slab of chocolate. - For many reasons. Yes. Slower, more intimate. - Well I think it's also\njust a pure physicality. - [Fridman] Well the texture changes. - Yeah. Right. - [Fridman] That's fascinating. Now I take back my milk duds. Cause that's such a basic answer. Okay. Do you think consciousness is\nfundamentally computational? So when you're thinking about cx, what can we turn to computation? And you're thinking about LLMs, do you think the the display\nof consciousness and the experience of consciousness,\nthe hard problem is, is fundamentally a computation. - Yeah. What it feels\nlike inside, so to speak. - [Fridman] Yeah. - Is, you know, I did a little exercise\neventually I'll post it, of you know, what it's\nlike to be a computer. Yeah. Right. It's kind of like, well you get all this sensory\ninput you have kind of, the way I see it is from the\ntime you boot a computer to the time the computer crashes. It's like a human life. You, you're building up a certain\namount of state in memory. You remember certain things about your quotes life eventually. It's kind of like the, the, you know, the next generation of humans is, is born from the same genetic\nmaterial, so to speak, with a little bit left over,\nleft on the disk, so to speak. And then, you know, the the, the new fresh generation starts up. And eventually all kinds\nof crud builds up in the, in the memory of the computer\nand eventually the thing crashes or whatever. Or maybe it has some trauma\nbecause you plugged in some weird thing to some port of the computer and that made it crash. And that, you know, that\nthat's kind of, but, but you have this, this\npicture of, you know, from, from startup to, to,\nto shut down, you know, what is the life of a\ncomputer, so to speak, and what does it feel like\nto be that computer and what inner thoughts does it have\nand how do you describe it? And it's kind of, kind of interesting as you\nstart writing about this to realize it's awfully like what\nyou'd say about yourself that is, it's awfully like even\na, an ordinary computer, forget it all the AI\nstuff and so on, you know, it's kind of, it has a memory of the past, it has certain sensory experiences. It can communicate with other computers, but it has to package up how\nit's communicating in some kind of language like form so\nit can, you know, send, so it can kind of map what's\nin its memory to what's in the memory of some other computer. It's, it's a surprisingly similar thing. You know, I hadn't experienced\njust a week or two ago, I, I had, I'm a collector of all possible data about myself and other things. And so I, you know, I collect all sorts of weird\nmedical data and so on. And one thing I hadn't collected\nwas I'd never had a whole body MRI scan. So I went and got one of these. - [Fridman] Nice. - Okay. So I get the, get\nall the data back, right. I'm looking at this thing, I've never looked at the\nkind of insides of my brain, so to speak, in, in physical form. And it's really, I mean, it, it's kind of psychologically\nshocking in a sense that, you know, here's this thing and you can\nsee it has all these folds and all these, you know, this structure. And it's like, that's where this experience\nthat I'm having of, you know, existing and so on. Yeah. That's where it is. And you know, it feels\nvery, you know, you, you look at that and you're thinking, how can this possibly be\nall this experience that I'm having? And you're realizing, well I can look at a\ncomputer as well and it's, it's kind of this, it, it, it, it, I think this idea that you are\nhaving an experience that is somehow, you know, transcends the mere sort of\nphysicality of that experience. I, I, I, you know, it's something that's hard\nto come to terms with, but I think, you know, and I, I don't think I've\nnecessarily, you know, my, my personal experience, you\nknow, I look at the, you know, the MRI of the brain and then I, you know, know about all kinds of things\nabout neuroscience and all that kind of stuff. And I still feel the\nway I feel so to speak. And it, it sort of seems disconnected, but yet as I try and rationalize it, I can't really say that there's\nsomething kind of different about how I intrinsically\nfeel from the thing that I can plainly see in the sort of\nphysicality of what's going on. - [Fridman] So do you think the computer, a large language model will\nexperience that transcendence? How does that make you feel? Like I I tend to believe it will. - I think an ordinary\ncomputer is already there. I think an ordinary computer is already, you know, kind of, it's, it's now a large language model\nmay experience it in a way that is much better\naligned with us humans. That is, it's much more, you know, if you could have the\ndiscussion with the computer, it's intelligence so to speak, is not particularly\nwell aligned with ours. But the large language model is, you know, it's built to be aligned with our way of thinking about things. - [Fridman] It would be able to explain that it's afraid of being\nshut off and deleted. It'd be able to say that it's\nsad of the way you've been speaking to it over the past two days. - Right. But you know, that's a weird thing because when it says it's afraid of something. We know that it got\nthat idea from the fact that it read on the internet. - Yeah. Where did you get it, Steven? Where did you get it when\nyou say you're afraid? - You acquaint, that's the question. Right. - [Fridman] I mean it's it's\nyour parents, your friends. - Right. Or, or my biology. I mean, in other words, there's\na certain amount that is, you know, the endocrine system\nkicking in and, and you know, the the these kinds of emotional\noverlay type things that happen to be, that are actually much more\nphysical even they're much more sort of straightforwardly\nchemical than the, the than kind of all of\nthe higher level thinking. - Yeah but your biology didn't tell you to say I'm afraid just at the right time when people that love you are listening and so, you know, you're\nmanipulating them by saying, so that's not your biology. That's- - [Wolfram] No, that's a\nwell, but the, you know. - It's a large language model in that biological neural network of yours. - Yes. But I mean, the\nintrinsic thing of, you know, something sort of shocking is\njust happening and you have some sure sort of reaction,\nwhich is, you know, some neurotransmitter gets\nsecreted and it, it's, you know, that that is the beginning\nof some, you know, that is, that's one of the pieces\nof input that then drives, it's kind of like the, like a prompt for, for the large language model. I mean, just like when we dream\nfor example, you know, no doubt there are all\nthese sort of random inputs that kind of, these random prompts and then\nit's percolating through in kind of the way that a large\nlanguage model does of kind of putting together things\nthat seem meaningful. - I I mean, are you, are you worried about\nthis world where you, you teach a lot on the internet\nand there's people asking questions and comments and so on. You have people that work remotely. Are you worried about this\nworld when large language models create human-like bots that\nare leaving the comments, asking the questions? Or might\neven become fake employees? - [Wolfram] Yeah. - I mean, or, or or worse are better at\nyet friends friends of yours. - Right. Look, I mean, one point is my mode of life\nhas been I build tools and then I use the tools. And in a sense kind of, you know, I'm, I'm building this tower of automation. Which, you know, and,\nand in a sense, you know, when you make a company or something, you are making sort of automation but it has some humans in it. - [Fridman] Yes. - But also as much as possible\nit has, it has, you know, computers in it. And so I think it's sort of\nan extension of that now. Now if I really didn't know\nthat, you know, it's a, it's a, it's a funny question. I mean it's a, it's a funny issue when, you know, if we think about sort of what's\ngonna happen to the future of kind of jobs people do and so on. And there are places where kind of having a human in the loop, there are different reasons\nto have a human in the loop. For example, you might want a human in the loop cause you want somebody to, you want another human to\nbe invested in the outcome. You know, you want a human flying the\nplane who's gonna die if the plane crashes along with you so to speak. And that gives you sort of\nconfidence that the right thing is going to happen or\nyou might want, you know, right now you might want a human\nin the loop in some kind of sort of human encouragement,\npersuasion type profession. Whether that will continue, I'm not sure for those\ntypes of professions. Cause it may be that the,\nthe greater efficiency of, you know, of being able to have sort\nof just the right information delivered at just the right\ntime will overcome the kind of the the the kind of, oh\nyes, I want a human there. - Yeah. Imagine like a\ntherapist or even higher stake, like a suicide hotline operated\nby a large language model. [Wolfram] Yeah. - Oh boy. It's a pretty\nhigh stake situation. - Right. But I mean, but you know, it might in fact do the right thing. Because it might be the\ncase that that, you know, and that's really a partly\na question of sort of how complicated is the human, you know, one of the things that's that's\nalways surprising in some sense is that, you know, sometimes human psychology\nis not that complicated in some sense. - You wrote the blog\npost, the 50 Year Quest, my personal journey, good title, my personal journey with the\nsecond law thermodynamics. So what is this law and what\nhave you understood about it in the 50 year journey you had with it? - Right. So second law of thermodynamics, sometimes called law of entropy\nincrease is this principle of physics that says, well, my version of it would be\nthings tend to get more random over time. A version of it that there\nare many different sort of formulations of it that are\nthings like heat doesn't spontaneously go from a hotter\nbody to a colder one when you have mechanical work kind of\ngets dissipated into heat. You have friction and, and kind of when you\nsystematically move things, eventually they'll be,\nthey'll be sort of the, the energy of of moving\nthings gets kind of ground down into heat. So people first sort of paid\nattention to this back in the 1820s when steam engines were a big thing. And the big question was how efficient could a steam engine be? And there's this chap called\nSaddi Carno who was a, a French engineer actually. His father was a a a sort of\nelaborate mathematical engineer in, in France. But he figured out these, this kind of rules for\nhow kind of the, the, the efficiency of, of the\npossible efficiency of a, of something like a steam engine. And in sort of a side, part of what he did was this\nidea that mechanical energy tends to get dissipated as heat that you, that you end up going from\nsort of systematic mechanical motion to this kind of random thing. Well, at that time, nobody knew what heat was at that time, people thought that heat was a fluid, like they called it caloric. And it was a fluid that kind of, kind of was absorbed into substances. And when, when heat, when one hot thing would\ntransfer heat to a colder thing, that this fluid would\nflow from the hot thing to the colder thing. But anyway, then by the, by the 1860s people had kind\nof come up with this idea that systematic energy tends to degrade into kind of random heat that would, that that could then not\nbe easily turned back into systematic mechanical energy. And then that, that\nquickly became sort of a, a global principle about how things work. Question is, why does it happen that way? So, you know, let's say you have a bunch\nof molecules in a box and they're arranged, these molecules arranged in a\nvery nice sort of flotilla of molecules in one corner of the box. And then what you typically\nobserve is that after a while these molecules were kind of\nrandomly arranged in the box. The question is why does that happen? And people for a long, long time tried to figure\nout is there from the laws of mechanics that determine\nhow these molecules, let's say these molecules\nlike hard spheres bouncing off each other from the laws of mechanics that describe those molecules. Can we explain why it tends\nto be the case that we see things that are an orderly,\nsort of degrade into disorder? We tend to see things\nthat, you know, you you, you scramble an egg, you that, you know, you take something that's\nquite ordered and you, you disorder it, so to speak. That's a thing that sort of happens quite we regularly or you, you put some ink into water\nand it will eventually spread out and, and fill up, you\nknow, fill up the water, but you don't see those little\nparticles of ink in the water all spontaneously kind of arrange\nthemselves into a big blob and then, you know, jump\noutta the water or something. And so the question is why do\nthings happen in this kind of irreversible way where you\ngo from order to disorder? Why does it happen that way? And so throughout, in the later part of the 18 hundreds, a lot of work was done on\ntrying to figure out can one derive this principle, this second law of thermodynamics\nthis law about the, the dynamics of heat, so to speak. Come one derive this from, from some fundamental principles\nof mechanics, you know, and the, and the laws of thermodynamics. The first law is basically\nthe law of energy, energy conservation that the\ntotal energy associated with heat plus the total energy\nassociated with mechanical kinds of things, plus other kinds of energy, that that total is constant. And that became a pretty\nwell understood principle. But the, the second law of thermodynamics was always mysterious. Like, why does it work this way? Can it be derived from\nunderlying mechanical laws? And so when I was, well,\n12 years old actually, I had gotten interested, well\nI, I'd been interested in, in space and things like that. Cause I thought that was kind of the, the future and interesting\nsort of technology and so on. And for a while kind of, you know, every deep space probe\nwas sort of a personal friend type thing. And I knew all, all, all kinds of characteristics\nof it and was kind of writing up all these, all these things\nwhen I was, oh, I don't know, eight, nine, ten years old and so on. And then I, I got interested from being\ninterested in kind of spacecraft I got interested in. So\nlike how do they work? What are all the instruments\non them and so on. And that got me interested in physics, which was just as well because\nif I'd stayed interested in space in the, you know, mid to late 1960s, I would've had a long\nwait before, you know, space really blossomed\nas a, as a, as an area. - Timing is everything. - Right. I got interest in physics. And then, well the actual sort\nof detailed story is when I, when I kind of graduated from\nelementary school at age 12, and that's the time when\nin England where you finish elementary school, I sort\nof, my, my gift sort of, I suppose more or less for\nmyself was I got this collection of physics books, which was some college physics course of college physics books. And volume five is about\nstatistical physics and it has this picture on the cover that shows\na bunch of kind of idealized molecules sitting in one side\nof a box and then it has a series of frames showing how\nthese molecules sort of spread out in the box. And I thought that's pretty\ninteresting. You know, what, what causes that? And you\nknow, read the book and, and the book, the book actually, one of the things that was\nreally significant to me about that was the book kind of claimed, although I didn't really\nunderstand what it said in detail, it kind of claimed that this\nsort of principle of physics was derivable somehow. And you know, other things\nI'd learned about physics, it was all like, it's a fact\nthat energy is conserved. It's a fact that relativity\nworks or something not, it's something you can derive\nfrom some fundamental sort of, it has to be that way as a, as a matter of kind of\nmathematics or logic or something. So it was sort of interesting\nto me that there was a thing about physics that was kind of\ninevitably true and derivable so to speak. And so I think that, so then I was like this\npicture on this book and I was trying to understand it. And so that was actually the\nfirst serious program that I wrote for a computer was probably 1973 written for this computer, the size of a desk program\nwith paper tape and so on. And I tried to reproduce this\npicture on the book and I didn't succeed. - What was the failure mode there? Like what do you mean you\ndidn't succeed? So it's a bunch- - Looked like, it didn't look like, okay, so what happened is, okay, many years later I learned how\nthe picture on the book was actually made and that it\nwas actually kind of a fake, but I didn't know that at that time. But, and that picture was actually a, a very high-tech thing when it was made in the beginning of the 1960s, was made on the largest supercomputer that existed at the time. And even so it couldn't quite\nsimulate the thing that it was supposed to be simulating. But anyway, I didn't know that until\nmany, many, many years later. So at the time it was like, you have these balls\nbouncing around in this box, but I was using this computer with eight kilo words of memory. They were 18 bit words of memory words. Okay. So it was whatever,\n24 kilobytes of memory. And it had, you know, it\nhad these instructions, I probably still remember all\nof its machine instructions. And it didn't really like\ndealing with floating point numbers or anything like that. And so I had to simplify this,\nthis model of, of, you know, particles bouncing around in a box. And so I thought, well I'll put them on a grid\nand I'll make, you know, make the things just sort\nof move one square at a time and so on. And so I did the simulation\nand the result was, it didn't look anything\nlike the actual pictures on the book. Now many years later, in fact very recently I\nrealized that the thing I'd simulated was actually an\nexample of a whole sort of computational irreducible\nstory that I absolutely did not recognize at the time. At the time it just looked like\nit did something random and it looks wrong. As opposed to it did something random. And it's super interesting\nthat it's random, but I didn't recognize that at the time. And so as it was at the time, I kind of, I got interested in particle\nphysics and I got interested in, in other kinds of physics and, but this whole second\nof thermodynamics thing, this idea that sort of orderly things tend to degrade into disorder, continued to be something\nI was really interested in. And I was really curious\nfor the whole universe, why doesn't that happen all the time? Like we start off at the, in the big bang at the beginning\nof the universe was this thing that seems like it's\nthis very disordered collection of, of stuff and then it\nspontaneously forms itself into galaxies and creates\nall of this complexity and order in the universe. And so I was very curious\nhow that happens and I, but I was always kind of\nthinking this is kind of somehow the second order of\nthermodynamics is behind it, trying to sort of pull\nthings back into disorder so to speak. And how was order being created. And so actually I was, was interested, this is probably now 1980, I\ngot interested in kind of this, you know, galaxy formation\nand so on in the universe. I also at that time was interested\nin neural networks and I was interested in kind of how, how brains make complicated\nthings happen and so on. - Okay. Wait, wait, wait. What's the connection between\nthe formation of galaxies and how brains make complicated things happen? - Because they're both a matter of how complicated things come to happen. - From simple origins? - [Wolfram] Yeah. From\nsome sort of known origins. I had the sense that, that what I was interested in was kind of in all these different, this sort of different cases\nof where complicated things were arising from rules. And you know, I also looked at snowflakes\nand things like that. I was curious and, and\nFloyd Dynamics in general. I was just sort of curious\nabout how does complexity arise and, and the, the thing\nthat I didn't, you know, it took me a while to kind of\nrealize that there might be a general phenomenon. You know, I sort of assumed, oh there's galaxies over here,\nthere's brains over here. They're, they're very\ndifferent kinds of things. And so what happened, this\nis probably 1981 or so, I decided okay, I'm, I'm gonna try and make the minimal model of how these things work. And it was sort of an interesting\nexperience because I had built, starting in 1979, I built my first big computer system. It's a thing called SMP\nsymbolic manipulation program. It's kind of a forerunner of\nmodern Wolfram language with many of the same ideas about\nsymbolic computation and so on. But the thing that was very\nimportant to me about that was, you know, in building that language, I had basically tried to figure\nout what were the sort of, what were the relevant\ncomputational primitives, which have turned out to stay with me for the last 40 something years. But it was also important because\nin building a language was very different activity\nfrom natural science, which is what I'd mostly done before. Cause in natural science you start from the phenomenon of the world and you try and figure out, so how can I make sense of\nthe phenomena of the world? And you know, kind of the world presents\nyou with what it has to offer, so to speak. And you have to make sense\nof it when you build a com, you know, computer language or something, you are creating your own\nprimitives and then you say can, so what can you make from\nthese, sort of the opposite way round from what you do in natural science. But I'd had the experience of doing that and so I was kind of like, okay, what happens if you sort of\nmake an artificial physics? What happens if you just make up the rules by which systems operate? And then I was thinking, you know, for all these different systems, whether it was galaxies\nor brains or whatever, what's the absolutely minimal\nmodel that kind of captures the things that are important\nabout those systems. - The computational\nperimeters of that system. - Yes. And so that's what ended up\nwith the cellular autor where you just have a line of\nblack and white cells, you just have a rule that says, you know, given the cell in its neighbors, what will the color of the cell\nbe on the next step when you just run it in a series of steps? And the sort of, the ironic thing is that cellular\nautor are great models for many kinds of things, but galaxies and brains are two\nexamples where they do very, very badly. They're really\nirrelevant to those two cases. - Is there a connection to the\nsecond law thermodynamics and cellular auto automata? - Oh yes. - The things you, the things you've discovered\nabout cellular auto automata. - Yes. Okay. So when I first started\ncell cellular Automata, my first papers about them were, you know, the first sentence was always\nabout the second row of thermodynamics was always\nabout how does order manage to be produced, even though there's a second\nrow of thermodynamics, which tries to pull\nthings back into disorder. And I kind of, my early understanding of\nthat had to do with these are intrinsically irreversible\nprocesses in cellular automata that that form, you know, conform orderly structures even from random initial conditions. But then what I realized this was, well actually it's, it's one of these things\nwhere it was a discovery that I should have made\nearlier but didn't. So, you know, I had, I had been\nstudying cellular automata. What I did was the sort of most\nobvious computer experiment. You just try all the different\nrules and see what they do. It's kind of like, you know, you've invented a computational telescope, you just pointed at the most\nobvious thing in the sky, and then you just see what's there. And so I did that and I, you know, was making\nall these pictures of, of how cellular automata work. And I studied these pictures.\nI studied in great detail. There was, you can number the\nrules for cellular automata. And one of them is, you know, rule 30. So I made a picture of\nRule 30 back in 1981 or so, and Rule 30, well, it's, and I, and I at the\ntime, I was just like, okay, it's another one of these\nrules. I don't really, it happens to be asymmetric\nleft, right asymmetric. And it's like, let me just consider the case\nof the symmetric ones just to keep things simpler, et\ncetera, et cetera, et cetera. And I just kind of ignored it. And then sort of in, in, actually\nin 1984, strangely enough, I, I ended up having a,\nan early laser printer, which made very high resolution pictures. And I thought, I'm gonna print out an\ninteresting, you know, I wanna make an interesting picture. Let me take this rule 30\nthing and just make a high resolution picture of it. And I did. And it's, it has this very remarkable\nproperty that its rule is very simple. You started off just from one\nblack cell at the top and it makes this kind of triangular pattern. But if you look inside this\npattern, it looks really random. There's, you know, you look at the center column\nof cells and, you know, I studied that in great detail and it's, so far as one can tell,\nit's completely random. And it's kind of a little\nbit like digits of pie. Once you, you know, you know the rule for\ngenerating the digits of pie, but once you've generated\nthem, you know, 3.14159, et cetera, they seem completely random. And in fact, I, I put up this\nprize back in, what was it, 2019 or something for, prove anything about\nthe sequence, basically. - [Fridman] Has anyone been\nable to do anything on that? - People have sent me some\nthings, but it's, you know, I don't know how hard these problems are. I mean, I, I was kind of\nspoiled cause I, 2007, I put up a prize for\ndetermining whether a particular touring machine that I thought\nwas the simplest candidate for being a universal touring\nmachine determine whether it is or isn't a universal touring machine. And somebody did a really good job of, of winning that prize and\nproving that it was a universal touring machine in about six months. And so I, you know, I didn't know whether that\nwould be one of these problems that was out there for hundreds of years, or whether in this particular case, young chap called Alex Smith, you know, nailed it in six months. And so with this little 30 formulation, I don't really know whether\nthese are things that are a hundred years away from\nbeing able to, to get, or whether somebody's gonna come and do something very clever. - It's such a, I mean,\nit's like for (indistinct), it's such a rule 30, it's\nsuch a simple formulation. It feels like anyone can\nlook at it and understand it. And feel like it's within\ngrasp to be able to predict something to do to, to\ndirect some kind of law that allows you to predict\nsomething about this. Middle column of rule 30. - [Wolfram] Right. But you\nknow, this is, this is- - Yet you can't. - Yeah, right. This is the intuition surprise\nof computational reducibility and so on, that even though\nthe rules are simple, you can't tell what's going\nto happen and you can't prove things about it. And I think so. So anyway, the, the, the, the thing I, I sort of started in 1984 or so, I started realizing there's\nthis phenomenon that you can have very simple rules. They produce apparently random behavior. Okay. So that's a little bit like the second neuro dynamics because it's like you have this simple\ninitial condition, you can, you know, readily see\nthat it's very, you know, you can describe it very easily. And yet it makes this thing\nthat seems to be random. Now, turns out there's\nsome technical detail about the second thermodynamics and about the idea of reversibility. When you have a, if you\nhave kind of a, a, a, a, a movie of two, you know, billiard balls colliding and\nyou see them collide and they bounce off, and you run\nthat movie in reverse, you can't tell which way was\nthe forward direction of time and which way was the\nbackward direction of time. When you're just looking at\nindividual billard balls, by the time you've got a whole\ncollection of them, you know, a million of them or something, then it turns out to be the case. And this is the, the sort of the, the mystery of the second law. That the orderly thing, you start with the orderly\nthing and it becomes disordered. And that's the forward direction in time. And the other way round\nof it starts disordered and becomes ordered. You just don't see that in the world. Now, in principle, if you, you know, if you sort of traced the\ndetailed motions of all those molecules backwards, you\nwould be able to, it, it will, it will. The reverse of time\nmakes, you know, as you, as you go forwards in time,\norder goes to disorder, as you go backwards in time, order goes to disorder. - [Fridman] Perfectly. So yes. - Right. So the, the mystery\nis why is it the case that, or one version of the mystery\nis why is it the case that you never see something which\nhappens to be just the kind of disorder that you would need\nto somehow evolve to order. Why does that not happen? Why do you always just see\norder goes to disorder not the other way around? So the thing that I, I kind of realized, I started realizing in the\n1980s, it's kind of like, it's a bit like cryptography. It's kind of like you start off from this, this key that's pretty simple, and then you kind of run it\nand you can get this, you know, complicated random mess. And the thing that that well, I sort of started realizing\nback then was that the second law is kind of a, a, a story\nof computational reducibility. It's a story of, you know,\nwhat seems, you know, what, what we can describe\neasily at the beginning, we can only describe with a\nlot of computational effort at the end. Okay. So now we come\nmany, many years later, and I was trying to sort of, well, having done this big project\nto understand fundamental physics, I realized that sort\nof a key aspect of that is understanding what observers are like. And then I realized that the\nsecond auto neuro dynamics is the same story as a bunch\nof these other cases. It is a story of a, a computationally bounded\nobserver trying to observe a computationally irreducible system. So it's a story of, you know, underneath the molecules\nare bouncing around, they're bouncing around in\nthis completely determined way, determined by rules. But the point is that, that we as computationally\nbounded observers, can't tell that there were\nthese sort of simple underlying rules to us that just looks random. And when it comes to this\nquestion about can you prepare the initial state so that, you know, the disordered thing is, you know, you have exactly the right\ndisorder to make something orderly, A computationally\nbounded observer cannot do that. We'd have to have done all\nof this sort of irreducible computation to work out very precisely what this disordered state, what the exact right disordered\nstate is so that we would get this ordered thing produced from it. - What does it mean to be\ncomputationally bounded observer? So observing a computation\nreducible system, so the computationally bounded, is there something\nformal you can say there? - Right. So it means, okay, you can, you can talk about Turing machines, you can talk about computational\ncomplexity theory and you know, polynomial time\ncomputation and things like this. There are a variety of ways to\nmake something more precise, but I think it's more useful, the intuitive version\nof it is more useful. Which is basically just\nto say that, you know, how much computation are you going to do to try and work out what's going on? And the answer is, you're not allowed to do a lot of, we are not able to do a\nlot of computation when we, you know, we've got, you know, in this room there will\nbe a trillion, trillion, trillion molecules. Yeah. A little bit less. - It's a big room. - Right. And you know, at every moment, you know, there every microsecond or\nsomething, these molecules, molecules are colliding. And that's a lot of computation\nthat's getting done. And the question is, in our brains, we do a lot less computation every second, then the computation done\nby all those molecules. If there is computational\nirr, reducibility, we can't work out in detail\nwhat all those molecules are going to do. What we can do is only a much\nsmaller amount of computation. And so the, the second thermodynamics is\nthis kind of interplay between the underlying computational\nirreducibility, and the fact that we as\npreparers of initial states or as measures of what happens\nare, you know, are, are not capable of doing\nthat much computation. So to us, another big formulation\nof the second order of thermodynamics is this idea of\nthe law of entropy increase. - The characteristic that this universe, the entropy seems to be always increasing. What does that show to you\nabout the evolution of- - Well, okay, so, so- - [Fridman] The universe of time. - The History of entropy is yes, okay. And that's very confused in\nthe history of thermodynamics, because entropy was\nfirst introduced by a guy called Rudolph Klauseous, and he did it in terms\nof heat and temperature. Okay. Subsequently, it was reformulated by a\nguy called Ludwig Boltzmann. And he formulated it in a much more kind of commonatorial type way. But he always claimed that\nit was equivalent to Klaus's thing. And in, in one particular\nsimple example, it is, but that connection between\nthese two formulations of entropy, they've never been connected. I mean, it's there. There's really, so, okay, so the more general definition\nof entropy due to Boltzmann is, is the following thing. So you say, I have a system and has many\npossible configurations. Molecules can be in many\ndifferent arrangements, et cetera, et cetera, et cetera. If we know something about\nthe system, for example, we know it's in a box, it\nhas a certain pressure, it has a certain temperature, we know these overall facts\nabout it, then we say, how many microscopic\nconfigurations of the system are possible given those overall constraints. And the entropy is the\nlog rhythm of that number. That's the definition. And that's the kind of the\ngeneral definition of entropy that, that turns out to be useful. Now, in Boltzmann's time, he thought these molecules could be placed anywhere you want. He didn't think and, but he said, oh, actually we can make it a\nlot simpler by having the molecules be discreet. Well, actually he didn't\nknow molecules existed right? In, in those, in his\ntime, 1860s and so on. The idea that matter might\nmade of discrete stuff had been floated ever since ancient Greek times. But it had been a long time\ndebate about, you know, is matter discreet as a\ncontinuous at the moment of, at that time, people mostly thought that\nmatter was continuous. And it was all confused with\nthis question about what heat is, and people thought heat\nwas this fluid, and it was, it was a big, big muddle. And the, and this, but Boltzmann said, let's assume they're discreet molecules. Let's even assume they have\ndiscreet energy levels. Let's say everything is discreet, then we can do sort of\ncombinatorial mathematics and work out how many configurations\nof these things there will be in the box. And we can say, we can\ncompute this entropy quantity. But he said, but of course it's just a fiction that these things are discreet. So he said, this is an interesting\npiece of history by the way, that that, that, you know, that was, at that time people didn't\nknow molecules existed. There were other hints from, from looking at kind of\nchemistry that there might be discreet atoms and so on, just from the, the combinatorics of, you know, two hydrogens and one oxygen\nmake water, you know, two, two amounts of hydrogen plus\none amount of oxygen together make water, things like this. But it wasn't known that\ndiscrete molecules existed. And in fact, the people, you know, it wasn't until the beginning of the, of the 20th century that\nbrownie in motion was the final giveaway. Brown in motion is, you know, you look under a microscope\nof these little pieces from pollen grains, you see they're being discreetly\nkicked and those kicks are water molecules hitting\nthem and they're discreet. And in fact, it was, it was really quite\ninteresting history. I mean, Boltzmann had worked out how\nthings could be discreet and had basically invented something\nlike quantum theory in, in the 1860s. And, but he just thought it\nwasn't really the way it worked. And then just a piece of physics history, cause I think it's kind of\ninteresting, in, in 1900, this guy called Max Plank, who'd been a longtime\nthermodynamics person who was trying to, everybody was trying\nto prove the second law of thermodynamics, including Max Plank. And Max Plank believed that radiation, like electromagnetic radiation, somehow the interaction of\nthat with matter was going to prove the second law of thermodynamics. But he had these experiments\nthat people had done on black body radiation, and there were these curves\nand you couldn't fit the curve based on his idea for how\nradiation interacted with matter. Those curves, he couldn't, he couldn't figure out\nhow to fit those curves, except he noticed that if he\njust did what Boltzmann had done and assumed that\nelectromagnetic radiation was discreet, he could fit the curves. He said, but you know,\nthis is just a, you know, it just happens to work this way. Then Einstein came along\nand said, well, by the way, you know, the electromagnetic field\nmight actually be discreet, it might be made of photons, and then that explains how this all works. And that was, you know, in 1905, that was, that was how kind of, that was how quant that piece\nof quantum mechanics got started. Kind of interesting,\ninteresting piece of history. I didn't know until I was\nresearching this recently in 1904 and 1903, Einstein wrote\nthree different papers. And so, you know, just sort\nof well known physics history. In 1905, Einstein wrote\nthese three papers. One introduced relativity theory, one explained brownie in motion, and one introduced basically photons. So kind of, you know, kind of a, a, a big deal year for\nphysics and for Einstein. But in the years before that, he'd written several papers\nand what were they about? They were about the second\nrule of thermodynamics, and they were an attempt\nto prove the second rule of thermodynamics and their nonsense. And so I I I had no idea\nthat he'd done this. - Interesting. Me neither. - And in fact, what he did,\nthose three papers in 1905, well not so much the relativity paper, the one on brown in\nmotion, the one on photons. Both of these were about the story of sort of making the world discreet. And he got those, that\nidea from Boltzmann. But Boltzmann didn't think, you know, Boltzmann kind of died\nbelieving, you know, he said he has a quote,\nactually, you know, you know, in the end, things are gonna\nturn out to be discreet, and I'm gonna write down\nwhat I have to say about this because, you know, eventually this stuff will\nbe rediscovered and I want to leave, you know, what I can about how things\nare gonna be discreet. But, you know, I think he has some quote\nabout how, you know, one person can't stand against\nthe tide of history in, in saying that, you\nknow, matter is discreet. - Oh, so he's stuck by his guns in terms of matter is discreet. - Yes, he did. And, and the, you know, what's\ninteresting about this is, at the time, everybody,\nincluding Einstein, kind of assumed that space\nwas probably gonna end up being discreet too. But that didn't work out\ntechnically because it wasn't consistent with relativity\ntheory, or didn't seem to be. And so then in the history of physics, even though people had determined\nthat matter was discreet, electro mag, magnetic field was discreet, space was a holdout of not being discreet. And in fact, Einstein 1916 has this nice\nletter he wrote where he says, in the end, it will turn\nout space is discreet, but we don't have the mathematical\ntools necessary to figure out how that works yet. And so, you know, I think it's kind of cool that\na hundred years later we do. - For you, you're pretty, pretty sure that at every\nlayer of reality it's discreet. - Right? And that space is\ndiscreet and that the, I mean, and in fact, one of the things I've realized\nrecently is this kind of theory of heat. That, that the, you know, that heat is really this\ncontinuous fluid, it's, it's kind of like the, the, you know, the caloric theory of heat, which turns out to be completely\nwrong because actually heat is the motion of discrete molecules. Unless, you know there\nare discreet molecules, it's hard to understand\nwhat heat could possibly be. Well, you know, I think space is, is discreet and the question\nis kind of what's the analog of the mistake that was made with\ncaloric in the case of space. And so I'm, my, my current\nguess is that dark matter is, as I've, my little sort\nof aphorism of the, of the last few months has been, you know, dark matter is the caloric of our time. That is, it will turn out that dark\nmatter is a feature of space and it is not a bunch of particles. You know, at the time when, when people were talking about heat, they knew about fluids\nand they said, well, heat must be just be\nanother kind of fluid. Because that's what they knew about. But now people know about\nparticles and so they say, well, what's dark matter? It's not, it's not, it\njust must be particles. - So what could dark matter\nbe as a feature of space? - Oh, I don't know yet. I mean, I think the, the thing I'm really, one of the things I'm hoping\nto be able to do is to find the analog of brown in motion in space. So in other words, brown in motion was, was seeing down to the level of an effect from individual molecules. And so in the case of space,\nyou know, most of the things, the things we see about space so far, just everything seems continuous\nbrown in motion had been discovered in the 1830s. And it was only identified what it was, what it was the, the, the results of by Markowski and\nEinstein at the beginning of the 20th century. And, you know, dark matter was, was discovered that phenomenon was discovered a hundred years ago. You know, the rotation, curves of galaxies don't follow\nthe luminous matter that was discovered a hundred years ago. And I think, you know, that I, I wouldn't be surprised if\nthere isn't an effect that we already know about that is\nkind of the analog of brown in motion that reveals the\ndiscreetness of space. And in fact, we we're\nbeginning to have some guesses. We have some, some evidence that black hole\nmergers work differently when there's discrete space. And there may be things that\nyou can see in gravitational wave signatures and things associated with the discreetness of space. But this is kind of, for me, it's kind of, it's kind of interesting to\nsee this sort of recapitulation of the history of physics\nwhere people, you know, vehemently say, you know,\nmatter is continuous, electromagnetic field is continuous, and turns out it isn't true. And then they say space is continuous. But, but, so, you know, entropy is the number of\nstates of the system consistent with some constraint. - [Fridman] Yes. - And the, the thing is that if you have, if you know in great detail\nthe position of every molecule in the gas, the entropy is, is always zero because there's\nonly one possible state. The, the configuration\nof molecules in the gas, the molecules bounce around, they have a certain rule\nfor bouncing around. There's just one state of the\ngas evolves to one state of the gas and so on. But it's only if you don't\nknow in detail where all the molecules are that you can say, well, the entropy increases because the things we do know about the molecules, there are more possible\nmicroscopic states of the system consistent with what we do know about where the molecules are. And so the question of whether, so people, this sort of paradox in a sense of, oh, if we knew where all the molecules, where the entropy wouldn't increase, there was this idea introduced by, by Gibbs in the early 20th century. Well actually the very beginning of the, of the 20th century as\na physics professor, an American physics professor\nwas sort of the first distinguished American\nphysics professor at Yale. And he, he introduced this idea, of course graining this\nidea that, well, you know, these molecules have a detailed\nway they're bouncing around, but we can only observe a\ncourse grained version of that. But the confusion has been, nobody knew what a valid\ncourse screening would be. So nobody knew that whether\nyou could have this course screening that very carefully\nwas sculpted in just such a way that it would notice that\nthe particular configurations that you could get from the\nsimple initial condition, you know, they fit into\nthis course screening. And the course screening\nvery carefully observes that. Why can't you do that\nkind of very detailed, precise course screening? The answer is because if you\nare a computationally bounded observer and the underlying\ndynamics is computationally irreducible, that's, that's what defines possible\ncore screenings is what a computationally, bounded observer can do. And it's the, it's the fact that a\ncomputation bounded observer is, is forced to look only at\nthis kind of coarse grained version of what the system is doing. That's why, and, and because the, what what's what's going on\nunderneath is it's kind of filling out this, this,\nthe, the different possible. You're ending up with something\nwhere the sort of underlying computational irreducibility is your, if, if all you can see is what the\ncourse grained result is with comp, with a sort of\ncomputationally bounded observation, then inevitably there are\nmany possible underlying configurations that are\nconsistent with that. - Just to clarify, I basically, any observer that exists inside\nthe universe is going to be computationally bounded. - No. Any observer like us, I don't know. I can't-. - When you say like us, what do you mean? What do you mean? Like us. - Well, humans with finite minds. - You're including the tools of science. - Yeah, yeah. I mean, and, and, and as we,\nyou know, we have more precise, and, and by the way, there are little sort of\nmicroscopic violations of the second row of thermodynamics\nthat you can start to have when you have more precise\nmeasurements of where precisely molecules are. - [Fridman] Right. - But for, for on a large scale, when you have enough molecules,\nwe don't have, you know, we are not tracing all those\nmolecules and we just don't have the computational\nresources to do that. And it wouldn't be, you\nknow, I think the, the, to imagine what an observer\nwho is not computationally bounded would be like, it's an interesting thing because okay, so what does computational\nboundedness mean among other things, it means we conclude\nthat definite things happen. We go, we take all this complexity\nof the world and we make a decision we're gonna\nturn left or turn right. And that is kind of reducing\nall this kind of detail into we're observing it, we're, we're, we're, we're sort of crushing it\ndown to this, this one thing. And, and that if we didn't\ndo that, we wouldn't, we wouldn't have all this\nsort of symbolic structure that we build up that lets us think things through with our finite minds. We'd be instead, you know, we'd be just, we'd be sort of one with the universe, so- - Yeah. So content to not simplify. - Yes. If we didn't simplify,\nthen we wouldn't be like us. We would be like the universe, like the, the intrinsic universe, but not having experiences\nlike the experiences we have where we, for example, conclude\nthat definite things happen. We, you know, we, we sort of have this, this notion of being able to make, make sort of narrative statements. - I wonder if it's just like\nyou imagined as a thought experiment what it's\nlike to be a computer. I wonder if it's possible to\ntry to begin to imagine what it's like to be in an unbounded\ncomputational observer. - Well. Okay, so here's, here's\nhow that I think plays out. - So I mean, in this we talk about this ruliad, this space of all possible computations. - [Fridman] Yes. - And this idea of, you know, being at a certain place in the ruliad, which corresponds to\nsort of a certain way of, of rep of a certain set of\ncomputations that you are representing things in terms of, okay, so as you expand out in the ruliad, as you kind of encompass more possible views of the universe, as you encompass more possible\nkinds of computations that you can do, eventually you\nmight say that's a real win. You know, we are, we're colonizing\nthe ruliad, we're, we're, we are building out more paradigms about how to think about things. And eventually you might say, we, we, we won all the way we managed\nto colonize the whole ruliad. Okay, here's the problem with that. The problem is that the\nnotion of existence, coherent existence requires\nsome kind of specialization by the time you are the whole ruliad, by the time you cover the\nwhole ruliad in no useful sense do you coherently exist. So in other words, in in interesting the notion of existence, the notion of what we think of as, as, as definite existence requires\nthis kind of specialization requires this kind of idea that we are, we are not all possible things. We are the, a particular set of things. And that's kind of how we,\nthat that's kind of what, what makes us have a coherent existence. If we were spread throughout\nthe ruliad we would not, there would be no coherence\nto the way that we work. We would work in all possible ways. And that wouldn't be kind\nof a, a notion of identity. We wouldn't have this notion of kind of, of of of coherent identity. - I am geographically\nlocated somewhere exactly, precisely in the ruliad, therefore I am is the decart kind of- - Yeah, yeah. Right. Were you are in a certain\nplace in physical space or in a certain place in ruliad space. And if, if you are, if you\nare sufficiently spread out, you are no longer coherent\nand you no longer have, I mean, in, in the, in our perception of\nwhat it means to exist and to have experience. Doesn't happen that way. - So therefore, so to to to exist means to\nbe computationally bounded. - I think so, to exist in the way that we think of ourselves\nas existing. Yes. - The very active existence is\nlike operating in this place that's computation irreducible. So that this is just giant mess\nof things going on that you can't possibly predict. But nevertheless, because\nof your limitations, you, you have an imperative of like, what is it an imperative\nor a skillset to simplify or an ignorance sufficient level. - Okay. So the thing which is not\nobvious is that you are taking a slice of all this complexity, just like we have all of these molecules bouncing around in the room. But all we notice is,\nyou know, the, the, the, the kind of the flow of the\nair or the pressure of the air. We are just noticing\nthese particular things. And the, the big interesting\nthing is that there are rules, there are laws that govern\nthose big things that we, we observe. - [Fridman] Yeah. So it's not obvious. - Amazing because it doesn't\nfeel like it's a slice. - [Wolfram] Yeah. Well, right. - It's not a slice. Well, it's like a, it's like an abstraction. - Yes. But I mean the fact\nthat the gas laws work. That we can describe pressure,\nvolume, et cetera, et cetera, et cetera. And we don't have to go down to the level of talking about individual molecules. That is a non-trivial fact. And, and here's the thing that I, sort of exciting thing\nas far as I'm concerned, the fact that there are certain\naspects of the universe. So, you know, we think space is made ultimately\nthese atoms of space and these hypergraphs and so on. And we think that, but we nevertheless perceive\nthe universe at a large scale to be like continuous space and so on. We, in quantum mechanics, we think that there are\nthese many threads of time, these many threads of\nhistory, yet we kind of span. So, so, you know, in,\nin quantum mechanics, in our models of physics, there are these time\nis not a single thread. Time breaks into many threads. They branch, they merge and, but we are part of that\nbranching, merging universe. And so our brains are also\nbranching and merging. And so when we perceive the universe, we are branching brains\nperceiving a branching universe. And so the fact that the claim that we ex, we believe that we are persistent in time, we have this single thread of experience. That's the statement that\nsomehow we managed to aggregate together those separate threads\nof time that are separated in, in the operation of, in the fundamental\noperation of the universe. So just as in space, we're averaging over\nsome big region of space, and we are looking at many, many at the aggregate effects\nof many atoms of space. So similarly in what we\ncall branchial space, the space of these,\nthese quantum branches, we are effectively averaging\nover many different branches of possible, of histories of the universe. And so in and in, in thermodynamics, we're averaging over many\nconfigurations of, you know, many, many possible positions of molecules. So what what we see here is, so the question is when you\ndo that averaging for space, what are the aggregate laws of space? When you do that averaging\nof a branchial space, what are the aggregate\nlaws of branchial space, when you do that averaging\nover the molecules and so on, what are the aggregate laws you get? And this is, this is the thing that I, I think is just amazingly,\namazingly neat that. - [Fridman] That there are\naggregate laws at all for- - Sure. Well, yes, but the question is what\nare those aggregate laws? So the answer is for space, the aggregate laws are\nEinstein's equations for gravity, for the structure of space\ntime, for branchial space. The aggregate laws are the\nlaws of quantum mechanics. And for the case of, of\nmolecules and things, the aggregate laws are basically the second law of thermodynamics. And so the, the, that's the, and the things that follow from the second law of thermodynamics. And so what that means is that the three great theories of 20th century physics, which are basically generality\nof the theory of gravity, quantum mechanics, and\nstatistical mechanics, which is what kind of grows outta the second row of thermodynamics. All three of the great theories\nof 20th century physics are the result of this interplay between computational irreducibility, and the computational\nboundedness of observers. And you know, for me, this is really neat because it\nmeans that all three of these laws are derivable. So we used to think that, for example, Einstein's equations\nwere just sort of a wheel in feature of our universe. That they could be,\nuniverse might be that way. It might not be that way.\nQuantum mechanics is just like, well, it just happens to be that way. And the second law people\nkind of thought, well, maybe it is derivable. Okay? What turns out to be the\ncase is that all three of the fundamental principles\nof physics are derivable, but they're not derivable\njust from mathematics. They require, or just from some\nkind of logical computation, they require one more thing.\nThey require that the observer, that the thing that is sampling\nthe way the universe works is an observer who has\nthese characteristics of computational boundedness of belief and persistence and time. And so that, that means that it is the\nnature of the observer you know, the rough nature of the observer. Not the details of, oh, we've got two eyes and we observe photons of this frequency and so on. But the, the, the, the kind of the very coarse\nfeatures of the observer then imply these very precise\nfacts about physics. And it's, it's, I think it's amazing. - So if we just look at\nthe actual experience of the observer that we\nexperience this reality, it seems real to us. And you're saying because\nof our bonded nature, it's actually all an illusion. It's an a simplification. - Well, yeah. It's a\nsimplification. Right? What's what's, well. - You don't think a\nsimplification is an illusion? - No, I mean it's, it's,\nwell, I don't know. I mean- - What is real? - What's underneath? Okay, that's an interesting question. What's real? And that relates to the whole question of why does the universe exist? And, you know, what is the difference\nbetween reality and a mere representation of what's going on? - [Fridman] Yes. We experience the representation. - Yes. But the, the question of, so,\nso one question is, you know, why is there a thing which\nwe can experience that way? And the answer is because\nthis ruliad object, which is this entangled limit\nof all possible computations, there is no choice about\nit. It has to exist. It has to, there has to be such a thing. It is in, in the same sense\nthat, you know, two plus two, if you define what two is and\nyou plot pluses and so on, two plus two has to equal four. Similarly, this rule ad this limit of\nall possible computations just has to be a thing you, that is, once you have the idea of computation, you inevitably have the ruliad. - [Fridman] You're gonna have\nto have a ruliad. Yeah, yeah. - Right? And, and what's\nimportant about it, there's just one of it, it's, it's, it's just this unique object\nand that unique object necessarily exists. And then the question is what? And then we once, once you know that we are\nsort of embedded in that and taking samples of it, that it's sort of inevitable\nthat there is this thing that we can perceive that is, you know, that, that our perception of kind of physical reality necessarily is that way, given that we are observers with the characteristics we have. So in other words, the fact that the fact that\nthe universe exists, is it, it's actually, it's almost\nlike it's, you know, to think about it almost\ntheologically so to speak. And I, and I've, I've really, it, it's, it's funny because a lot\nof the questions about the existence of the universe and so on, they, they transcend what kind of\nthe science of the last few hundred years has really been\nconcerned with the science of the last few hundred years. Hasn't thought it could talk\nabout questions like that. - [Fridman] Yeah. And, but I think it's kind of, and so a lot of the kind\nof arguments of, you know, does God exist, you know, is it obvious that I\nthink it in some sense, in some representation, it's sort of more, more obvious that, that something sort of bigger\nthan us exists than that we exist and we are, you know, our existence and as observers\nthe way we are is sort of a contingent thing about the universe. And it's more inevitable that the whole, the whole universe kind\nof the whole set of all possibilities, exists. But, but this question about, you know, is is it real or is it an illusion? You know, all we know is our experience. And so the fact that, well, our experience is this\nabsolutely microscopic piece of sample of the ruliad, and\nwe are, and, and you know, there's this this point about, you know, we might sample more and more\nof the ruliad we might learn more and more about, we\nmight learn, you know, like, like different areas of physics, like quantum mechanics for example. The fact that it, it was discovered I think is\nclosely related to the fact that electronic amplifiers were\ninvented that allowed you to take a small effect and amplify it up, which hadn't been possible before. You know, microscopes had been invented that magnify things and so on. But the, you know, having a very small effect and\nbeing able to magnify it was sort of a new thing that allowed\none to see a different sort of aspect of the universe and let one discover this kind of thing. So, you know, we can expect that in the\nruliad there are an infinite collection of new things we can discover. There's, there's in fact computational irreducibility kind of guarantees that there will be an infinite\ncollection of kind of, you know, pockets of reducibility\nthat can be discovered. - Boy, would it be fun to take a walk down the ruliad and see what\nkind of stuff we find there? You you write about alien intelligences. - [Wolfram] Yes. - I mean, just these worlds. - Yes. Well, the problem\nwith these worlds is that. - We can't talk to 'em. - [Wolfram] Yes. And, and you know, the thing is what I've kind of\nspent a lot of time doing of just studying computational\nsystems, seeing what they do, what I now call ruliology, kind\nof just the study of rules. - [Fridman] Yeah. - And what they do. You know, you can kind of easily jump\nsomewhere else in the ruliad and start seeing what do these rules do? - [Fridman] Yeah. - And what you says they, they just, they do what they do and\nthere's no human connection, so to speak. - Did you think, you know,\nsome, some people are able to communicate with animals. Do you think you can\nbecome a whisper of these? - I've been trying. That's what I've spent\nsome part of my life doing. - Have, have you, have\nyou heard, and I mean, are you at the risk of losing your mind? - Sort of my favorite science\ndiscovery is this fact that these very simple programs can produce very complicated behavior. - [Fridman] Yeah. - And that, and that fact\nis kind of in a sense, a whispering of something out\nin the computational universe that we didn't really\nknow was there before. I mean, it, it's, you know,\nI it's like, you know, back in the 1980s I was doing\na bunch of work with some very, very good mathematicians, and they were like trying\nto pick away, you know, can we figure out what's going on in these computational systems? And they, they basically said, look, the math we have just doesn't\nget anywhere with this. We're stuck. There's nothing to say. We have nothing to say. And, you know, in a sense, perhaps my main achievement at\nthat time was to realize that the very fact that the, the good mathematicians had\nnothing to say was itself a very interesting thing. That was kind of a, a sort of, in some sense, a whispering of a different\npart of the ruliad that one hadn't, you know, one wasn't, was not accessible from\nwhat we knew in mathematics and so on. - Does it make you sad that\nyou're exploring some of these gigantic ideas and it feels\nlike we're on the verge of breaking through to some\nvery interesting discoveries, and yet you're just a finite being that's going to die way too soon? And that scan of your brain or\nyour full body kind of shows that you're- - Yeah, it's just a bunch of meat. - It's just a bunch of meat. Yeah. Does that make you\nmake you a little sad? - It's kind of a shame. I mean, I kinda like to see how\nall this stuff works out, but I think the thing\nto realize, you know, it's an interesting sort of\nthought experiment. You know, you, you say, okay, you know, let's assume we can get cryonics to work, and one day it will, that will be one of these things that's kind of like ChatGPT. One day somebody will\nfigure out, you know, how to get water from zero\ndegrees centigrade down to, you know, minus 44 or\nsomething without it expanding. And you know, cryonics will be solved and\nyou'll be able to like just, you know, put a pause in\nso to speak, and you know, kind of reappear a hundred\nyears later or something. And the thing though that I've\nkind of increasingly realized is that in a sense, this, this whole question of kind of the, the sort of one is embedded\nin a certain moment, in, in time and, you know, kind of\nthe things we care about now, the things I care about now,\nfor example, had I lived, you know, 500 years ago, many of the things I care\nabout now, it's like, that's totally bizarre. I mean, it's, nobody\nwould care about that. It's not even a thing one\nthinks about in the future, the things that most\npeople will think about. You know, one will be a strange relic\nof thinking about, you know, the kind of, you know, it might be one might have been\na theologian thinking about, you know, how many angels fit on the\nhead of a pin or something. And that might have been the, you know, the big intellectual thing.\nSo I think it's a, it's a, but yeah, it's a, it's a, you know, it's one of these things\nwhere particularly, you know, I've had the, I don't\nknow, good or bad fortune. I'm not sure. I think it's a,\nit's a mixed thing that I've, you know, I've invented a bunch of things, which I kind of can, I think see well enough what's\ngonna happen that, you know, in 50 years, a hundred years, whatever, assuming the world doesn't\nexterminate itself, so to speak, you know, these are things that will be\nsort of centrally important to what's going on. And it's kind of both, it's both a good thing and a bad thing in terms of the passage of one's life. I mean, it's kind of like, if everything I'd figured\nout was like, okay, I figured it out when I was 25\nyears old and everybody says it's great and we're\ndone. And it's like, okay, but I'm gonna live another how many years? And that's kind of, it's all\ndownhill from there in a sense. It's, it's better in some sense\nto, to be able to, you know, there's, there's, it, it sort of keeps things\ninteresting that, you know, why I can see, you know,\na lot of these things. I mean, it's kind of, I I\ndidn't expect, you know, ChatGPT, I didn't expect the kind of, the sort of opening up of\nthis idea of computational and computational language that's\nbeen made possible by this. I didn't expect that this is,\nthis is ahead of schedule, so to speak. You know, even though the sort of the, the big kind of flowering of\nthat stuff I'd sort of been assuming was another 50 years away. So if it turns out it's a lot less time, that's pretty cool because, you know, I'll hopefully get to see it, so to speak, rather than, than- - Well, I, I think I speak for a very, very large number of people\nin saying that I hope you stick around for a long time to come. You've had so many interesting ideas. You've created so many interesting\nsystems over the years, and I can see now that\nGPT and language models broke open the world even more. I can't wait to see you\nat the forefront of this development, what you, what you do. And yeah, I've been a fan of yours. Like I've told you many, many times since the very beginning. I'm deeply grateful that you\nwrote a new kind of science, that you explored this\nmystery of cellular automata and inspired this one little kid in me to, to pursue artificial intelligence in all this beautiful world. So Stephen, thank you so much. It's a huge honor to talk to you, to, to just be able to pick your\nmind and to explore all these ideas with you. And please keep going and I\ncan't wait to see what you come up with next. And thank you for talking today. - Thanks. - We went past midnight. We only did four and a half hours. I mean, we could probably\ngo for four more, but we'll save that till next time to, this is around number\nfour and we'll, I'm sure. Talk me more times. Thank you so much. - My pleasure. - Thanks for listening\nto this conversation with Steven Wolfram. To support this podcast please check out our sponsors in the description. And now let me leave you some\nwords from George Cantor, the essence of mathematics\nlies in its freedom. Thank you for listening and\nhope to see you next time."
}