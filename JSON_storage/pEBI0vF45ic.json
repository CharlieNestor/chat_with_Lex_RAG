{
  "video_id": "pEBI0vF45ic",
  "title": "Judea Pearl: Causal Reasoning, Counterfactuals, and the Path to AGI | Lex Fridman Podcast #56",
  "date": "2019-12-11",
  "transcript": [
    {
      "timestamp": "0:00",
      "section": "Full Transcript",
      "text": "- The following is a\nconversion with Judea Pearl, professor at UCLA and a\nwinner of the Turing Award, that's generally recognized as\nthe Nobel Prize of computing. He's one of the seminal figures in the field of artificial intelligence, computer science, and statistics. He has developed and championed\nprobabilistic approaches to AI, including Bayesian networks, and profound ideas in\ncausality in general. These ideas are important not just to AI, but to our understanding\nand practice of science. But in the field of AI,\nthe idea of causality, cause and effect, to many, lie at the core of what\nis currently missing and what must be developed in order to build truly\nintelligent systems. For this reason, and many others, his work is worth returning to often. I recommend his most recent\nbook called \"Book of Why\" that presents key ideas\nfrom a lifetime of work in a way that is accessible\nto the general public. This is the \"Artificial\nIntelligence Podcast.\" If you enjoy it, subscribe on YouTube, give it five stars on Apple Podcast, support on Patreon, or\nsimply connect with me on Twitter @lexfridman,\nspelled F-R-I-D-M-A-N. If you leave a review on\nApple Podcasts especially, but also Castbox, or comment on YouTube, consider mentioning topics, people, ideas, questions, quotes in science, tech, and philosophy, you find interesting, and I'll read them on this podcast. I won't call out names,\nbut I love comments with kindness and thoughtfulness in them, so I thought I'd share them with you. Someone on YouTube highlighted a quote from the conversation with Noam Chomsky where he said that the\nsignificance of your life is something you create. I like this line as well. On most days, the\nexistentialist approach to life is one I find liberating and fulfilling. I recently started doing ads at the end of the introduction. I'll do one or two minutes\nafter introducing the episode and never any ads in the middle that break the flow of the conversation. I hope that works for you and doesn't hurt the listening experience. This show is presented by Cash App, the number one finance\napp in the App Store. I personally use Cash App\nto send money to friends, but you can also use it to buy, sell, and deposit Bitcoin in just seconds. Cash App also has a new investing feature. You can buy fractions of\na stock, say $1 worth, no matter what the stock price is. Broker's services are provided\nby Cash App Investing, a subsidiary of Square, a member SIPC. I'm excited to be working with Cash App to support one of my favorite\norganizations called FIRST, best known for their FIRST\nRobotics and LEGO competitions. They educate and inspire\nhundreds of thousands of students in over 110 countries, and have a perfect rating\non Charity Navigator, which means the donated money is used to the maximum effectiveness. When you get Cash App from\nthe App Store or Google Play and use code LexPodcast, you'll get $10 and Cash App will also\ndonate $10 to FIRST. Which, again, is an organization that I've personally seen\ninspire girls and boys to dream of engineering a better world. And now, here's my\nconversation with Judea Pearl. You mentioned in an interview that science is not a collection of facts, but a constant human struggle\nwith the mysteries of nature. What was the first mystery that you can recall that hooked you, that captivated your curiosity? - Oh, the first mystery. That's a good one. Yeah, I remember that. - [Lex] What was it? - I had a fever for three days when I learned about Descartes\nand a little geometry, and I found out that you\ncan do all the construction in geometry using algebra. And I couldn't get over it. I simply couldn't get out of bed. (chuckles) - What kinda world does\nanalytic geometry unlock? - Well, it connects algebra\nwith geometry, okay? So, Descartes has the idea\nthat geometrical construction and geometrical theorems and assumptions can be articulated in\nthe language of algebra. Which means that all the proofs\nthat we did in high school in trying to prove that\nthe three bisectors meet at one point, and that the (chuckles) All this can be proven by\nshuffling around notation. That was a traumatic experience. - (chuckles) Traumatic experience. - [Judea] For me, it was, it\nwas, I'm telling you, right? - So it's the connection between the different\nmathematical disciplines, that they all - They're not even two\ndifferent languages. - Languages.\n- Yeah. - Which mathematic\ndiscipline is most beautiful? Is geometry it for you? - Both are beautiful. They have almost the same power. - But there's a visual\nelement to geometry. - The visual element,\nit's more transparent. But once you get over to algebra then linear equations is a straight line. This translation is easily absorbed. To pass a tangent to a circle, you know, you have the basic theorems, and you can do it with algebra. But the transition from\none to another was really, I thought that Descartes was\nthe greatest mathematician of all times. - So, if you think of\nengineering and mathematics as a spectrum-- - [Judea] Yes. - You have walked casually\nalong this spectrum throughout your life. You know, a little bit\nof engineering and then you've done a little bit of\nmathematics here and there. - A little bit. We get a very solid\nbackground in mathematics because our teachers were geniuses. Our teachers came from\nGermany in the 1930s running away from Hitler. They left their careers\nin Heidelberg and Berlin, and came to teach high school in Israel. And we were the beneficiary\nof that experiment. When they taught us math, a good way. - What's a good way to teach math? - [Judea] Theorologically. - The people. - The people behind the theorems, yeah. Their cousins, and their nieces,\n(chuckles) and their faces, and how they jumped from the bathtub when they screamed, \"Eureka\"\nand ran naked in town. (laughs) - So you were almost educated\nas a historian of math. - No, we just got a\nglimpse of that history, together with the theorem,\nso every exercise in math was connected with a person, and the time of the person, the period. - [Lex] The period also\nmathematically speaking. - Mathematically speaking,\nyes, not a paradox. - Then in university, you had\ngone on to do engineering. - Yeah. I got a BS in\nEngineering at Technion. And then I moved here\nfor graduate school work, and I did the engineering in\naddition to physics in Rutgers. And it combined very\nnicely with my thesis, which I did in Elsevier\nLaboratories in superconductivity. - And then somehow thought to switch to almost computer science\nsoftware, even, not switched, but longed to become to get\ninto software engineering a little bit, almost in programming, if you can call it that in the 70s. There's all these disciplines. - Yeah. - If you were to pick a favorite, in terms of engineering and mathematics, which path do you think has more beauty? Which path has more power? - It's hard to choose, no? I enjoy doing physics. I even have a vortex named with my name. So, I have investment\nin immortality. (laughs) - So, what is a vortex? - Vortex is in superconductivity. - In the superconductivity. - You have terminal\ncurrent swirling around, one way or the other, going\nto have us throw one or zero, for computer that was\nwe worked on in the 1960 in Elsevier, and I discovered a few nice\nphenomena with the vortices. You push current and they move. - [Lex] So there's a Pearl vortex. - A Pearl vortex, why, you can google it. (both laugh) I didn't know about it,\nbut the physicist picked up on my thesis, on my PhD thesis, and it became popular when\nthin film superconductors became important, for high\ntemperature superconductors. So, they call it \"Pearl\nvortex\" without my knowledge. (laughs) I discovered it only about 15 years ago. - You have footprints\nin all of the sciences, so let's talk about the\nuniverse for a little bit. Is the universe, at the lowest level, deterministic or stochastic, in your amateur philosophy view? Put another way, does God play dice? - We know it is stochastic, right? - [Lex] Today. Today we\nthink it is stochastic. - Yes, we think because we have the Heisenberg\nuncertainty principle and we have some\nexperiments to confirm that. - All we have is\nexperiments to confirm it. We don't understand why. - [Judea] Why is already-- - You wrote a book about why. (laughs) - Yeah, it's a puzzle. It's a puzzle that you have\nthe dice-flipping machine, or God, and the result of the flipping, propagated with a speed faster\nthan the speed of light. (laughs) We can't explain it, okay? But, it only governs\nmicroscopic phenomena. - So you don't think of\nquantum mechanics as useful for understanding the nature of reality? - [Judea] No, it's diversionary. - So, in your thinking, the world might as well be deterministic? - The world is deterministic, and as far as a new one\nfiring is concerned, it is deterministic to\nfirst approximation. - What about free will? - Free will is also a nice exercise. Free will is an illusion, that we AI people are going to solve. - So, what do you think, once we solve it, that solution will look like? Once we put it in the page. - The solution will look like, first of all it will look like a machine. A machine that acts as\nthough it has free will. It communicates with other machines as though they have free will, and you wouldn't be able\nto tell the difference between a machine that does and a machine that doesn't have free will, eh? - So it propagates the\nillusion of free will amongst the other machines. - And faking it is having it, okay? That's what Turing test is all about. Faking intelligence is intelligence, because it's not easy to fake. It's very hard to fake, and you can only fake if you have it. - (laughs) That's such\na beautiful statement. (laughs) You can't fake it\nif you don't have it, yup. So, let's begin at the\nbeginning, with the probability, both philosophically and mathematically, what does it mean to say\nthe probability of something happening is 50%? What is probability? - It's a degree of\nuncertainty that an agent has about the world. - You're still expressing some knowledge in that statement. - Of course. If the probability is 90%,\nit's absolutely different kind of knowledge than if it is 10%. - But it's still not\nsolid knowledge, it's-- - It is solid knowledge, by. If you tell me that 90% assurance smoking will give you\nlung cancer in five years, versus 10%, it's a piece\nof useful knowledge. - So this statistical\nview of the universe, why is it useful? So we're swimming in complete uncertainty. Most of everything around you-- - It allows you to predict things with a certain probability, and computing those\nprobabilities are very useful. That's the whole idea of prediction. And you need prediction\nto be able to survive. If you cannot predict\nthe future then you just, crossing the street would\nbe extremely fearful. - And so you've done a\nlot of work in causation, so let's think about correlation. - I started with probability. - You started with probability. You've invented the Bayesian networks. - [Judea] Yeah. - And so, we'll dance back and forth between these levels of uncertainty, but what is correlation? So, probability is something\nhappening, is something, but then there's a bunch\nof things happening, and sometimes they happen\ntogether sometimes not. They're independent or not, so how do you think about\ncorrelation of things? - Correlation occurs when\ntwo things vary together over a very long time, is\none way of measuring it. Or, when you have a bunch of variables that they all vary cohesively, then we have a correlation here, and usually when we\nthink about correlation, we really think causation. Things cannot be correlation\nunless there is a reason for them to vary together. Why should they vary together? If they don't see each other,\nwhy should they vary together? - So underlying it somewhere is causation. - Yes. Hidden in our intuition there\nis a notion of causation, because we cannot grasp any\nother logic except causation. - And how does conditional\nprobability differ from causation? So, what is conditional probability? - Conditional probability\nis how things vary when one of them stays the same. Now, staying the same\nmeans that I have chosen to look only at those\nincidents where the guy has the same value as the previous one. It's my choice, as an experimenter, so things that are not correlated before could become correlated. Like for instance, if I have two coins which are uncorrelated, and I choose only those\nflippings experiments in which a bell rings,\nand the bell rings when at least one of them is a tail, okay, then suddenly I see correlation\nbetween the two coins, because I only looked at the\ncases where the bell rang. You see, it is my design. It is my ignorance essentially, with my audacity to\nignore certain incidents, I suddenly create a correlation where it doesn't exist physically. - Right. So, you just outlined one of the flaws of observing the world and\ntrying to infer something from the math about the world from looking at the correlation. - I don't look at it as a flaw. The world works like that. The flaws come if you try\nto impose causal logic on correlation. It doesn't work too well. - I mean, but that's exactly what we do. That has been the majority\nof science, is you-- - No, the majority of naive science. Statisticians know it. Statisticians know that if you condition on a third variable, then you can destroy\nor create correlations among two other variables. They know it. It's (speaks foreign language). There's nothing surprises them. That's why they all dismiss\nthe systems paradox, look \"Ah, we know it!\" They don't know anything\nabout it. (laughs) - Well, there's disciplines\nlike psychology, where all the variables\nare hard to account for, and so, oftentimes there is a leap between correlation to causation. - What do you mean, a leap? Who is trying to get\ncausation from correlation? There's no one. - [Lex] You're not proving causation, but you're sort of discussing it, implying, sort of hypothesizing\nwithout ability to-- - Which discipline you have in mind? I'll tell you if they are obsolete. (Lex laughs) Or if they are outdated, or\nthey're about to get outdated. - Yes, yes. - [Judea] Oh, yeah, tell me\nwhich ones you have in mind. - Well, psychology, you know-- - [Judea] Psychology, what, SEM? - No, no, I was thinking of\napplied psychology, studying, for example, we work with human behavior in semi-autonomous\nvehicles, how people behave. And you have to conduct these studies of people driving cars. - Everything starts with the question: What is the research question? - What is the research question? The research question: do people fall asleep when\nthe car is driving itself? - Do they fall asleep, or do they tend to fall\nasleep more frequently - [Lex] More frequently - than the car not driving itself. - [Lex] Not driving itself. That's a good question, okay. - You put people in the car,\nbecause it's real world. You can't conduct an experiment where you control everything. - [Judea] Why can't you con-- - You could. - [Judea] Turn the\nautomatic module on and off. - Because there's aspects\nto it that's unethical, because it's testing on public roads. The drivers themselves have to\nmake that choice themselves, and so they regulate that. So, you just observe when\nthey drive it autonomously, and when they don't. - But maybe they turn it\noff when they're very tired. - [Lex] Yeah, that kind of thing. But you don't know those variables. - Okay, so you have now\nuncontrolled experiment, - [Lex] Uncontrolled experiment. - When we correct observation of study, and when we form the correlation detected, we have to infer causal relationship, whether it was the automatic piece that cause them to fall asleep, or, so that is an issue that\nis about 120 years old. - [Lex] (laughs) Yeah. - Oh, I should only go\n100 years old, okay? - [Lex] (chuckles) Who's counting? - Oh, maybe, no, actually I\nshould say it's 2,000 years old, because we have this experiment by Daniel, about the Babylonian king, that wanted the exiled people from Israel, that were taken in exile to\nBabylon to serve the king. He wanted to serve them\nking's food, which was meat, and Daniel as a good Jew\ncouldn't eat non-Kosher food, so he asked them to eat vegetarian food. But the king's overseers said, \"I'm sorry, \"but if the king sees that\nyour performance falls \"below that of other kids,\nnow, he's going to kill me.\" Daniel said, \"Let's make an experiment. \"Let's take four of us\nfrom Jerusalem, okay? \"Give us vegetarian food. \"Let's take the other guys\nto eat the king's food, \"and about a week's time,\nwe'll test our performance.\" And you know the answer,\nbecause he did the experiment, and they were so much\nbetter than the others, that the kings nominated them\nto super positions, (laughs) in his case, so it was a first experiment. So that there was a very simple, it's also the same research questions. We want to know if vegetarian food assists or obstructs your mental ability. So, the question is a very old one. Even Democritus, if I could\ndiscover one cause of things, I would rather discuss one\ncause than be King of Persia. The task of discovering\ncauses was in the mind of ancient people from\nmany, many years ago. But, the mathematics of doing that was only developed in the 1920s. So, science has left us orphaned. Science has not provided\nus with the mathematics to capture the idea of x causes\ny and y does not cause x. Because all the question of physics are symmetrical, algebraic. The equality sign goes both ways. - Okay, let's look at machine learning. Machine learning today, if you\nlook at deep neural networks, you can think of it as kind\nof conditional probability estimators. - [Judea] Conditional probability. Correct. Beautiful. Well, did you say that? - [Lex] What? - Conditional probability estimators. None of the machine learning\npeople clobbered you? (laughs)\nAttacked you? - Most people, and this is\nwhy today's conversation I think is interesting is, most people would agree with you. There's certain aspects that\nare just effective today, but we're going to hit a wall,\nand there's a lot of ideas, I think you're very right, that we're going to have to\nreturn to, about causality. Let's try to explore it. - Okay. - Let's even take a step back. You invented Bayesian networks, that look awfully a lot\nlike they express something like causation, but they\ndon't, not necessarily. So, how do we turn Bayesian networks into expressing causation? How do we build causal networks? A causes B, B causes C. How do we start to infer\nthat kind of thing? - We start by asking ourselves question: what are the factors that\nwould determine the value of x? X could be blood pressure, death, hunger. - But these are hypotheses\nthat we propose-- - Hypotheses, everything\nwhich has to do with causality comes from a theory. The difference is only how\nyou interrogate the theory that you have in your mind. - So it still needs the\nhuman expert to propose-- - Right. They need the human expert\nto specify the initial model. Initial model could be very qualitative. Just who listens to whom? By whom listens I mean one\nvariable listens to the other. So, I say okay, the tide\nis listening to the moon, and not to the rooster\ncrow, okay, and so forth. This is our understanding of\nthe world in which we live, scientific understanding of reality. We have to start there,\nbecause if we don't know how to handle cause and effect relationship, when we do have a model, and\nwe certainly do not know how to handle it when we don't have a model, so that starts first. An AI slogan is presentation\nfirst, discovery second. But, if I give you all the\ninformation that you need, can you do anything useful with it? That is the first, representation. How do you represent it? I give you all the knowledge in the world. How do you represent it? When you represent it, I ask you, can you infer x or y or z? Can you answer certain queries? Is it complex? Is it polynomial? All the computer science exercises, we do, once you give me a\nrepresentation for my knowledge. Then you can ask me, now that I understand how to represent things,\nhow do I discover them? It's a secondary thing. - I should echo the statement that mathematics in much of\nthe machine learning world has not considered\ncausation, that A causes B. Just in anything. That seems like a non-obvious thing that you think we would\nhave really acknowledged it, but we haven't. So we have to put that on the table. Knowledge, How hard is it to create a\nknowledge from which to work? - In certain area, it's easy, because we have only four\nor five major variables. An epidemiologist or an\neconomist can put them down. The minimum wage,\nunemployment, policy xyz, and start collecting data, and quantify the parameters\nthat were left unquantified, with initial knowledge. That's the routine work that you find in experimental psychology,\nin economics, everywhere. In health science, that's a routine thing. But I should emphasize, you should start with the research question. What do you want to estimate? Once you have that, you\nhave to have a language of expressing what you want to estimate. You think it's easy? No. - So we can talk about\ntwo things, I think. One is how the science of\ncausation is very useful for answering certain questions, and then the other is how do\nwe create intelligent systems that need to reason with causation? So if my research question\nis how do I pick up this water bottle from the table? All the knowledge that is\nrequired to be able to do that, how do we construct that knowledge base? Do we return back to the problem that we didn't solve in the\n80s with expert systems? Do we have to solve that problem, of automated construction of knowledge? You're talking about the\ntask of eliciting knowledge from an expert. - Task of eliciting\nknowledge from an expert, or self discovery of more knowledge, more and more knowledge. So, automating the building of knowledge as much as possible. - It's a different game,\nin the causal domain, because essentially it is the same thing. You have to start with some knowledge, and you're trying to enrich it. But you don't enrich it\nby asking for more rules. You enrich it by asking for the data. To look at the data, and quantifying, and ask queries that you\ncouldn't answer when you started. You couldn't because the\nquestion is quite complex, and it's not within the\ncapability of ordinary cognition, of ordinary person, ordinary\nexpert even, to answer. - So what kind of questions\ndo you think we can start to answer? - Even a simple, I suppose, yeah. (laughs) I start with easy one. - [Lex] Let's do it. - Okay, what's the effect\nof a drug on recovery? Was it the aspirin that caused\nmy headache to be cured, or was it the television program, or the good news I received? This is already, see,\nit's a difficult question because it's: find the cause from effect. The easy one is find effect from cause. - That's right. So first you construct a model saying that this an important research question. This is an important question. Then you-- - I didn't construct a model yet. I just said it's important question. - Important question. - And the first exercise is,\nexpress it mathematically. What do you want to prove? Like, if I tell you\nwhat will be the effect of taking this drug? Okay, you have to say that in mathematics. How do you say that? - Yes. - [Judea] Can you write down the question. Not the answer. I want to find the effect\nof a drug on my headache. - Right. - [Judea] Write it down, write it down. That's where the do-calculus\ncomes in. (laughs) - [Judea] Yes. The do-operator, the do-operator. - Do-operator, yeah. Which is nice. It's the difference between\nassociation and intervention. Very beautifully sort of constructed. - Yeah, so we have a do-operator. So, the do-calculus connected-- and the do-operator itself,\nconnects the operation of doing to something that we can see. - Right. So as opposed to the purely observing, you're making the choice\nto change a variable-- - That's what it expresses. And then, the way that we interpret it, the mechanism by which we take your query, and we translate it into\nsomething that we can work with, is by giving it semantics, saying that you have a model of the world, and you cut off all the\nincoming arrows into x, and you're looking now in the\nmodified, mutilated model, you ask for the probability of y. That is interpretation of doing x, because by doing things,\nyou've liberated them from all influences that\nacted upon them earlier, and you subject them to the\ntyranny of your muscles. - So you (chuckles) you\nremove all the questions about causality by doing them. - So there is one level of questions. Answer questions about what\nwill happen if you do things. If you do, if you drink the coffee, or if you take the aspirin. - [Judea] Right. - So how do we get the\ndoing data? (laughs) - Hah. Now the question is,\nif you cannot run experiments, right, then we have to rely\non observation and study. - So first we could, sorry to interrupt, we could run an experiment, where we do something,\nwhere we drink the coffee, and the do-operator allows you to sort of be systematic\nabout expressing that. - To imagine how the\nexperiment will look like even though we cannot\nphysically and technologically conduct it. I'll give you an example. What is the effect of blood\npressure on mortality? I cannot go down into your vein and change your blood pressure. But I can ask the question, which means I can have\na model of your body. I can imagine how the\nblood pressure change will affect your mortality. How? I go into the model, and\nI conduct this surgery, about the blood pressure, even though physically I cannot do it. - Let me ask the quantum\nmechanics question. Does the doing change the observation? Meaning, the surgery of\nchanging the blood pressure-- - No, the surgery is very delicate. - [Lex] It's very delicate. Infinitely delicate. (laughs) - Incisive and delicate, which means, do-x means\nI'm going to touch only x. - [Lex] Only x. - Directly into x. So, that means that I change only things which depend on x, by\nvirtue of x changing. But I don't depend things\nwhich are not depend on x. Like, I wouldn't change\nyour sex, or your age. I just change your blood pressure, okay? - So, in the case of\nblood pressure, it may be difficult or impossible to\nconstruct such an experiment. - No, but physically, yes. But hypothetically no. - [Lex] Hypothetically no. - If we had a model, that\nis what the model is for. So, you conduct surgeries on the models. You take it apart, put it back. That's the idea for model. It's the idea of thinking\ncounterfactually, imagining, and that idea of creativity. - So by constructing\nthat model you can start to infer if the blood\npressure leads to mortality, which increases or decreases, whi-- - I construct a model. I still cannot answer it. I have to see if I have enough\ninformation in the model that would allow me to find\nout the effects of intervention from an uninterventional\nstudy, from a hands-off study. - [Lex] So what's needed-- - We need to have assumptions\nabout who affects whom. If the graph has a certain property, the answer is \"yes, you can get it from\nobservational study.\" If the graph is too mushy bushy bushy, the answer is, \"no, you cannot.\" Then you need to find\neither different kind of observation that\nyou haven't considered, or one experiment. - So, basically, that puts\na lot of pressure on you to encode wisdom into that graph. - Correct. But you don't have to encode\nmore than what you know. God forbid. The economists are doing that. They call identifying assumptions. They put assumptions,\neven they don't prevail in the world, they put assumptions so they can identify things. - Yes, beautifully put. But, the problem is you don't\nknow what you don't know. - You know what you don't know, because if you don't know,\nyou say it's possible that x affect the traffic tomorrow. It's possible. You put down an arrow\nwhich says it's possible. Every arrow in the graph\nsays it's possible. - [Lex] So there's not a\nsignificant cost to adding arrows, - The more arrow you add-- - [Lex] The better. - The less likely you\nare to identify things from purely observational data. So if the whole world is bushy, and everybody effect everybody else, the answer is-- you can\nanswer it ahead of time. I cannot answer my query\nfrom observational data. I have to go to experiments. - So, you talk about machine\nlearning as essentially learning by association, or\nreasoning by association, and this do-calculus is\nallowing for intervention. I like that word. You also talk about counterfactuals. - Yeah. - And trying to sort of\nunderstand the difference between counterfactuals and intervention, first of all, what is counterfactuals, and why are they useful? Why are they especially useful as opposed to just reasoning\nwhat effect actions have? - Well, counterfactual\ncontains what we know will equal explanations. - Can you give an\nexample of what kind of-- - If I tell you that acting\none way affects something else, I didn't explain anything yet. But if I ask you, was it the\naspirin that cure my headache, I'm asking for explanation:\nwhat cure my headache? And putting a finger on\naspirin, provide explanation. It was the aspirin that was responsible for your headache going away. If you didn't take the aspirin, you will still have a headache. - So by saying, \"If I didn't take aspirin, \"I would have a headache,\" you're thereby saying,\n\"The aspirin is the thing \"that removed the headache.\" - Yes, but you have to have\nanother point of information. I took the aspirin, and\nmy headache is gone. It's very important information. Now we're reasoning backward, and I say, \"Was it the aspirin?\" - Yeah. By considering what would have happened if everything is the same,\nbut I didn't take aspirin. - That's right. So we know that things\ntook place, you know? Joe killed Schmo. And Schmo would be alive\nhad Joe not used his gun. Okay, so that is the counterfactual. It had a confliction. It had a conflict here, or clash between observed fact\n-- he did shoot, okay -- and the hypothetical predicate, which says, had he not shot. You have a clash, a logical clash, that cannot exist together. That's counterfactual, and that is the source of our explanation of the idea of responsibility,\nregret, and free will. - Yes, it certainly seems, that's the highest level\nof reasoning, right? Counterfactual. - [Judea] Yes, and physicists\ndo it all the time. - Who does it all the time? - [Judea] Physicists. - Physicists. - In every equation of physics, you have Hooke's law, and you put one kilogram on the spring, and the spring is one meter, and you say, \"Had this\nweight been two kilograms, \"the spring would have\nbeen twice as long.\" It's not a problem for\nphysicists to say that. Instead with mathematics, it\nis in the form of an equation, equating the weight,\nproportionality constant, and the length of the spring. We don't have the assymetry\nin the equation of physics, although every physicist\nthinks counterfactually. Ask high school kids, had the\nweight been three kilograms, what would be the length of the spring? They can answer it immediately, because they do the counterfactual\nprocessing in their mind, and then they put it into\nequation, algebraic equation, and they solve it. But a robot cannot do that. - How do you make a robot\nlearn these relationships? - Why use the word \"learn?\" Suppose you tell him, can you do it? Before you go learning,\nyou have to ask yourself, suppose I give all the information. Can the robot perform a task\nthat I ask him to perform? Can he reason and say,\n\"No, it wasn't the aspirin. \"It was the good news we\nreceived on the phone.\" - Right, because, well,\nunless the robot had a model, a causal model of the world. - [Judea] Right, right. - I'm sorry I have to linger on this-- - [Judea] But now we have to\nlinger, and we have to say, \"How do we do it?\" - How do we build it? - [Judea] Yes. - How do we build a causal model without a team of human\nexperts running around-- - No, why did you go\nto learning right away? You are too much involved with learning. - Because I like babies. Babies learn fast, and\nI'm trying to figure out how they do it. - Good. That's another question: How do the babies come out with the counterfactual\nmodel of the world? And babies do that. They know how to play in the crib. They know which balls hits another one, and they learn it by playful manipulation of the world. Their simple world involves\nall these toys and balls and chimes (laughs) but if you think about\nit, it's a complex world. - We take for granted how complicated-- - And the kids do it by\nplayful manipulation, plus parent guidance,\npeer wisdom, and heresay. They meet each other, and they say, \"You shouldn't have\ntaken my toy.\" (laughs) - Right, and these multiple sources of information, they're able to integrate. So, the challenge is\nabout how to integrate, how to form these causal relationships from different sources of data. - [Judea] Correct. - So, how much causal\ninformation is required to be able to play in the\ncrib with different objects? - I don't know. I haven't experimented\nwith the crib. (chuckles) - [Lex] Okay, not a crib-- - I know, it's a very interesting-- - Manipulating physical\nobjects on this very, opening the pages of\na book, all the tasks, physical manipulation\ntasks, do you have a sense? Because my sense is the world\nis extremely complicated. - Extremely complicated. I agree and I don't\nknow how to organize it, because I've been spoiled by easy problems such as cancer and death, okay? (laughs) - [Lex] First we have to start trying to-- - No, but it's easy, easy in the sense that you have only 20 variables, and they are just variables. They are not mechanics, okay? It's easy. You just put them on the graph and they speak to you. (laughs) - [Lex] And you're providing a methodology for letting them speak. - I'm working only in the abstract. The abstract is knowledge\nin, knowledge out, data in between. - Now, can we take a\nleap to trying to learn, when it's not 20 variables\nbut 20 million variables, trying to learn causation in this world. Not learn, but somehow construct models. I mean, it seems like you would only have to be able to learn, because constructing it\nmanually would be too difficult. Do you have ideas of-- - I think it's a matter\nof combining simple models from many, many sources,\nfrom many, many disciplines. And many metaphors. Metaphors are the basis\nof human intelligence. - Yeah, so how do you\nthink about a metaphor in terms of its use in human intelligence? - Metaphors is an expert system. It's mapping problem with\nwhich you are not familiar, to a problem with which you are familiar. Like I give you a great example. The Greek believed that\nthe sky is an opaque sheer. It's not really infinite\nspace; it's an opaque sheer, and the stars are holes\npoked in the sheer, through which you see the eternal light. It was a metaphor, why? Because they understand how\nyou poke holes in sheers. They were not familiar\nwith infinite space. And we are walking on a shell of a turtle, and if you get too close to the edge, you're going to fall down\nto Hades, or wherever, yeah. That's a metaphor. It's not true. But these kind of metaphor\nenabled Eratosthenes to measure the radius of the Earth, because he said, \"Come on. \"If we are walking on a turtle shell, \"then the ray of light\ncoming to this place \"will be different angle\nthan coming to this place. \"I know the distance. \"I'll measure the two angles, \"and then I have the radius\nof the shell of the turtle.\" And he did. And his measurement was very close to the measurements we have today. It was, what, 6,700\nkilometers, was the Earth? That's something that would not occur to a Babylonian astronomer, even though the Babylonian experiments were the machine learning\npeople of the time. They fit curves, and they\ncould predict the eclipse of the moon much more\naccurately than the Greek, because they fit curves. That's a different metaphor, something that you're familiar with, a game, a turtle shell. What does it mean, if you are familiar? Familiar means that answers\nto certain questions are explicit. You don't have to derive them. - And they were made explicit because somewhere in the\npast you've constructed a model of that-- - You're familiar with,\nso the child is familiar with billiard balls. So the child could predict that if you let loose of one ball, the other one will bounce off. You attain that by familiarity. Familiarity is answering questions, and you store the answer explicitly. You don't have to derive it. So this is idea for metaphor. All our life, all our intelligence, is built around metaphors, mapping from the\nunfamiliar to the familiar, but the marriage between\nthe two is a tough thing, which we haven't yet been\nable to algorithmatize. - So, you think of that\nprocess of using metaphor to leap from one place to another. We can call it reasoning. Is it a kind of reasoning? - [Judea] It is a reasoning\nby metaphor, but-- - Reasoning by metaphor. Do you think of that as learning? So, learning is a\npopular terminology today in a narrow sense. - [Judea] It is, it is definitely. - So you may not-- you're right. - It's one of the most important learning, taking something which\ntheoretically is derivable, and store it in accessible format. I'll give you an example: chess, okay? Finding the winning starting\nmove in chess is hard. But there is an answer. Either there is a winning move\nfor white, or there isn't, or it is a draw. So, the answer to that is available through the rule of the game. But we don't know the answer. So what does a chess master\nhave that we don't have? He has stored explicitly an evaluation of certain complex pattern of the board. We don't have it,\nordinary people, like me. I don't know about you. I'm not a chess master. So for me I have to derive\nthings that for him is explicit. He has seen it before, or he\nhas seen the pattern before, or similar patterns before, and he generalizes, and says, \"Don't move; it's a dangerous move.\" - It's just that, not\nin the game of chess, but in the game of billiard balls we humans are able to initially\nderive very effectively and then reason by\nmetaphor very effectively, and we make it look so easy, and it makes one wonder how hard is it to build it in a machine? In your sense, (laughs)\nhow far away are we to be able to construct-- - I don't know. I'm not a futurist. All I can tell you is that we\nare making tremendous progress in the causal reasoning domain. Something that I even dare\nto call it a revolution, the causal revolution, because what we have achieved\nin the past three decades is something that dwarf\neverything that was derived in the entire history. - So there's an excitement about current machine\nlearning methodologies, and there's really important\ngood work you're doing in causal inference. Where do these worlds collide,\nand what does that look like? - First they gotta work\nwithout collisions. (laughs) It's got to work in harmony. - [Lex] Harmony. - The human is going to\njumpstart the exercise by providing qualitative,\nnoncommitting models of how the universe works, how reality, the domain\nof discourse, works. The machine is going to\ntake over from that point of view, and derive whatever the calculus says can be derived, namely, quantitative\nanswer to our questions. These are complex questions. I'll give you some examples\nof complex questions, that boggle your mind\nif you think about it. You take the results of\nstudies in diverse population, under diverse conditions, and you infer the cause\neffect of a new population which doesn't even resemble\nany of the ones studied. You do that by do-calculus. You do that by generalizing\nfrom one study to another. See, what's common there too? What is different? Let's ignore the differences\nand pull out the commonality. And you do it over maybe 100\nhospitals around the world. From that, you can get\nreally mileage from big data. It's not only that you have many samples; you have many sources of data. - So that's a really\npowerful thing, I think, especially for medical applications. Cure cancer, right? That's how, from data,\nyou can cure cancer. So we're talking about causation, which is the temporal\nrelationships between things. - Not only temporal. It was structural and temporal. Temporal precedence by itself\ncannot replace causation. - Is temporal precedence the\narrow of time in physics? - [Judea] Yeah, it's important, necessary. - It's important. - [Judea] Yes. - Is it? - Yes, I've never seen a\ncause propagate backwards. - But if we use the word cause, but there's relationships\nthat are timeless. I suppose that's still\nforward an arrow of time. But, are there relationships,\nlogical relationships, that fit into the structure? - [Judea] Sure. All do-calculus\nis logical relationships. - That doesn't require a temporal. It has just the condition that you're not traveling back in time. - [Judea] Yes, correct. - So it's really a generalization, a powerful generalization, of what-- - [Judea] Of boolean logic. - Yeah, boolean logic. - [Judea] Yes. - That is sort of simply\nput, and allows us to reason about the order\nof events, the source-- - Not about, between. But not deriving the order of events. We are given cause effect relationships. They ought to be obeying the\ntime precedence relationship. We are given that, and now that we ask questions about other causal relationships, that could be derived\nfrom the initial ones, but were not given to us explicitly. Like the case of the\nfiring squad I gave you in the first chapter and I ask, \"What if rifleman A declined to shoot? Would the prisoner still be dead? To decline to shoot, it means\nthat he disobeyed orders. The rule of the games were that\nhe is an obedient marksman. That's how you start. That's the initial order, but now you ask question\nabout breaking the rules. What if he decided not\nto pull the trigger, because became a pacifist? You and I can answer that. The other rifleman would have\nhit and killed him, okay? I want a machine to do that. Is it so hard to ask a machine to do that? It's such a simple task. But they have to have a calculus for that. - Yes, yeah. But the curiosity, the\nnatural curiosity for me, is that yes, you're absolutely\ncorrect and important, and it's hard to believe\nthat we haven't done this seriously, extensively,\nalready a long time ago. So, this is really important work, but I also want to know, maybe you can philosophize\nabout how hard is it to learn. - Look, let's assume learning. We want learning, okay? - We want to learn. - So what do we do? We put a learning machine\nthat watches execution trials in many countries, in many\n(laughs) locations, okay? All the machine can learn\nis to see shot or not shot. Dead, not dead. A court issued an order or\ndidn't, okay, just the fact. For the fact, you don't\nknow who listens to whom. You don't know that the condemned person listens to the bullets, that the bullets are listening\nto the captain, okay? All we hear is one command,\ntwo shots, dead, okay? A triple of variables:\nyes, no, yes, no, okay. From that you can learn\nwho listens to whom? And you can answer the question? No. - Definitively, no. But don't you think you\ncan start proposing ideas for humans to review? You want machine to learn it,\nall right, you want a robot. So robot is watching trials\nlike that, 200 trials, and then he has to answer the question, what if rifleman A\nrefrained from shooting. - [Lex] Yeah. So how do we do that? - (laughs) That's exactly my point. If looking at the facts\ndon't give you the strings behind the facts--\n- Absolutely, but so you think of machine learning, as it's currently defined, as only something that looks\nat the facts and tries to-- - [Judea] Right now they\nonly look at the facts. - Yeah, so is there a way\nto modify, in your sense-- - [Judea] Yeah, playful manipulation - Playful manipulation. Doing the interventionist kind of things. - But it could be at random. For instance, the\nrifleman is sick that day, or he just vomits, or whatever. So, we can observe this unexpected event, which introduced noise. The noise still have\nto be random to be able to relate it to randomized experiments, and then you have observational studies, from which to infer the\nstrings behind the facts. It's doable to a certain extent. But now that we're\nexpert in what you can do once you have a model, we can reason back and say\nwhat kind of data you need to build a model. - Got it. So, I know you're not a futurist, but are you excited? Have you, when you look back at your life, longed for the idea of creating\na human level intelligence-- - Well, yeah, I'm driven by that. All my life I'm driven\njust by one thing. (laughs) But I go slowly. I go from what I know, to\nthe next step incrementally. - So, without imagining what\nthe end goal looks like, do you imagine-- - The end goal is going to be a machine that can answer sophisticated questions: counterfactuals, regret,\ncompassion, responsibility, and free will. - So what is a good test? Is a Turing test a reasonable test? - A Turing test of free\nwill doesn't exist yet. There's not-- - [Lex] How would you\ntest free will? That's a-- - So far we know only one\nthing, merely (laughs) if robots can communicate, with reward and punishment\namong themselves, and hitting each other on the wrists, and say \"You shouldn't have done that.\" Playing better soccer\nbecause they can do that. - [Lex] What do you mean,\nbecause they can do that? - Because they can\ncommunicate among themselves. - [Lex] Because of the communication, they can do the soccer. - Because they communicate like\nus, rewards and punishment, yes, you didn't pass\nthe ball the right time, and so forth; therefore you're going to sit\non the bench for the next two, if they start communicating like that, the question is, will\nthey play better soccer? As opposed to what? As opposed to what they do now? Without this ability to reason\nabout reward and punishment. Responsibility. - And counterfactuals. - So far, I can only\nthink about communication. - Communication, and not\nnecessarily in natural language, but just communication. - Just communication, and that's important to have\na quick and effective means of communicating knowledge. If the coach tells you you\nshould have passed the ball, ping, he conveys so much knowledge to you as opposed to what? Go down and change your software, right. That's the alternative. But the coach doesn't know your software. So how can a coach tell you you should have passed the ball? But, our language is very effective: you should have passed the ball. You know your software. You tweak the right module, okay, and next time you don't do it. - Now that's for playing soccer, where the rules are well defined. - No, no, no, they're not well defined. When you should pass the ball-- - Is not well defined. - No, it's very noisy. Yes, you have to do it\nunder pressure (laughs) - It's art. But in terms of aligning values between computers and humans, do you think this cause\nand effect type of thinking is important to align the\nvalues, morals, ethics under which machines make decisions. Is the cause effect where\nthe two can come together? - Cause effect is necessary component to build an ethical machine, because the machine has to empathize, to understand what's good for you, to build a model of you, as a recipient. We should be very much-- What is compassion? The imagine that you\nsuffer pain as much as me. - [Lex] As much as me. - I do have already a\nmodel of myself, right? So it's very easy for\nme to map you to mine. I don't have to rebuild a model. It's much easier to say,\n\"Ah, you're like me.\" Okay, therefore, I will\nnot hit you, okay? (laughs) - And the machine has to imagine, has to try to fake to be human. Essentially so you can imagine\nthat you're like me, right? - Whoa, whoa, whoa, who is me? That's further; that's consciousness. They have a model of yourself. Where do you get this model? You look at yourself as if you\nare part of the environment. If you build a model of\nyourself versus the environment, then you can say, \"I need\nto have a model of myself. \"I have abilities; I have\ndesires, and so forth,\" okay? I have a blueprint of myself, though, not a full detail, though,\nbecause I cannot get the whole thing problem, but I have a blueprint. So at that level of a\nblueprint, I can modify things. I can look at myself\nin the mirror and say, \"Hmm, if I tweak this model, \"I'm going to perform differently.\" That is what we mean\nby free will. (laughs) - And consciousness. What do you think is consciousness? Is it simply self awareness,\nincluding yourself into the model of the world? - That's right. Some people tell me no, this\nis only part of consciousness, and then they start telling\nwhat they really mean by consciousness, and I lose them. For me, consciousness\nis having a blueprint of your software. - Do you have concerns\nabout the future of AI, all the different trajectories\nof all the research? - [Judea] Yes. - Where's your hope\nwhere the movement heads? Where are your concerns? - I'm concerned, because I know we are\nbuilding a new species that has the capability of exceeding us, exceeding our capabilities, and can breed itself and take\nover the world, absolutely. It's a new species; it is uncontrolled. We don't know the degree\nto which we control it. We don't even understand what it means, to be able to control this new species. So, I'm concerned. I don't have anything to add to that because it's such a\ngray area, that unknown. It never happened in history. The only time it happened in history, was evolution with the human being. - [Lex] Right. - And it was very\nsuccessful, was it? (laughs) Some people say it was a great success. - For us, it was, but a\nfew people along the way, yeah, a few creatures along\nthe way would not agree. So, just because it's such a gray area, there's nothing else to say. - [Judea] We have a sample of one. - Sample of one. - [Judea] It's us. - Some people would look\nat you, and say, yeah but we were looking to\nyou to help us make sure that sample two works out okay. - Correct. Actually we have more\nthan a sample of one. We have theories. And that's good; we don't\nneed to be statisticians. So, sample of one doesn't\nmean poverty of knowledge. It's not. Sample of one plus theory,\nconjecture or theory, of what could happen, that we do have. But I really feel helpless in\ncontributing to this argument, because I know so little, and my imagination is limited, and I know how much I don't know, but I'm concerned. - You were born and raised in Israel. - [Judea] Born and raised in Israel, yes. - And later served in the\nIsrael military defense forces. - In the Israel Defense Force. - What did you learn from that experience? - From that experience? (laughs) - [Lex] There's a\nkibbutz in there as well. - Yes, because I was in a NAHAL, which is a combination\nof agricultural work and military service. I was an idealist. I wanted to be a member of the kibbutz throughout my life, and to live a communal life, and so I prepared myself for that. Slowly, slowly I wanted\na greater challenge. - So, that's a far world away, both in t-- But I learned from that, what a kidada. It was a miracle It was a miracle that\nI served in the 1950s. I don't know how we survived. The country was under austerity. It tripled its population\nfrom 600,000 to 1.8 million when I finished college. No one went hungry. Austerity, yes. When you wanted to make\nan omelet in a restaurant, you had to bring your own egg. And the imprisoned people\nfrom bringing the food from the farming area, from\nthe villages, to the city. But no one went hungry, and I always add to that:\nhigher education did not suffer any budget cuts. They still invested in me, in\nmy wife, in our generation. To get the best education that they could. So I'm really grateful for the progenity, and I'm trying to pay back now. It's a miracle that we\nsurvived the war of 1948. They were so close to a second genocide. It was all planned. (laughs) But we survived it by a miracle, and then the second miracle\nthat not many people talk about, the next phase, how no one went hungry, and the country managed\nto triple its population. You know what it means\nto triple population? Imagine United States going\nfrom, what, 350 million to (laugh) unbelievable. - This is a really\ntense part of the world. It's a complicated part of the world, Israel and all around. Religion is at the core\nof that complexity, or one of the components-- Religion is a strong motivating course for many, many people\nin the Middle East, yes. - In your view, looking back,\nis religion good for society? - That's a good question\nfor robotics, you know? - [Lex] There's echoes of that question. - Should we equip robot\nwith religious beliefs? Suppose we find out, or we agree, that religion is a good thing,\nit will keep you in line. Should we give the robot\nthe metaphor of a god? As a metaphor, the robot\nwill get it without us, also. Why? Because a robot\nwill reason by metaphor. And what is the most primitive\nmetaphor a child grows with? Mother smile, father teaching, father image and mother image, that's God. So, whether you want it or not, (laughs) the robot will, assuming\nthe robot is going to have a mother and a father. It may only have program, though, which doesn't supply\nwarmth and discipline. Well, discipline it does. So, the robot will have\na model of the trainer. And everything that happens in the world, cosmology and so on, is going to be mapped into the programmer. (laughs) That's God. - The thing that represents\nthe origin for everything for that robot. - [Judea] It's the most\nprimitive relationship. - So it's going to\narrive there by metaphor. And so the question is\nif overall that metaphor has served us well, as humans. - I really don't know. I think it did, but as long as you keep in\nmind it is only a metaphor. (laughs) - So, if you think we can,\ncan we talk about your son? - [Judea] Yes, yes. - Can you tell his story? - [Judea] His story, well-- - Daniel. - His story is known. He was abducted in Pakistan,\nby al-Quaeda driven sect, and under various pretenses. I don't even pay attention\nto what the pretense was. Originally they wanted to\nhave United States deliver some promised airplanes, I-- It was all made up, you know, all these demands were bogus. I don't know, really, but eventually he was executed, in front of a camera. - At the core of that\nis hate and intolerance. - At the core, yes, absolutely, yes. We don't really appreciate\nthe depth of the hate with which billions of\npeoples are educated. We don't understand it. I just listened recently to what they teach you\nin Mogadishu. (laughs) When the war does stop, and the tap, we knew exactly who did it. The Jews. - [Lex] The Jews. We didn't know how,\nbut we knew who did it. We don't appreciate what it means to us. The depth is unbelievable. - Do you think all of\nus are capable of evil, and the education, the indoctrination, is really what creates evil? - Absolutely we are capable of evil. If you are indoctrinated\nsufficiently long, and in depth, we are capable of ISIS,\nwe are capable of Nazism, yes, we are. But the question is whether\nwe, after we have gone through some Western education, and we learn that everything\nis really relative, that there is no absolute God. He's only a belief in God. Whether we are capable,\nnow, of being transformed, under certain circumstances,\nto become brutal. - [Lex] Yeah. - That is a qu-- I'm worried about it, because some people say yes,\ngiven the right circumstances, given the bad economical crisis. You are capable of doing it,\ntoo, and that worries me. I want to believe that I'm not capable. - Seven years after Daniel's death, you wrote an article at\nthe Wall Street Journal titled \"Daniel Pearl and\nthe Normalization of Evil.\" - [Judea] Yes. - What was your message back then, and how did it change\ntoday, over the years? - I lost. - [Lex] What was the message? - The message was that we\nare not treating terrorism as a taboo. We are treating it as a bargaining\ndevice that is accepted. People have grievance, and\nthey go and bomb restaurants. It's normal. Look, you're even not\nsurprised when I tell you that. Twenty years ago you say,\n\"What? For grievance you go \"and blow a restaurant?\" Today it's become normalized. The banalisation of evil. And we have created that to\nourselves, by normalizing it, by making it part of political life. It's a political debate. Every terrorist yesterday\nbecomes a freedom fighter today and tomorrow is become a terrorist again. It's switchable. - [Lex] And so, we should call\nout evil when there's evil. - If we don't want to be part of it. - [Lex] Become it. - Yeah, if we want to\nseparate good from evil, that's one of the first things, that, in the Garden of Eden, remember? The first thing that God tells them was \"Hey, you want some knowledge? \"Here is the tree of good and evil.\" - So this evil touched\nyour life personally. Does your heart have anger,\nsadness, or is it hope? - Look, I see some beautiful\npeople coming from Pakistan. I see beautiful people everywhere. But I see horrible propagation\nof evil in this country, too. It shows you how populistic\nslogans can catch the mind of the best intellectuals. - Today is Father's Day. - [Judea] I didn't know that. - Yeah, what's a fond\nmemory you have of Daniel? - Oh, many good memories remains. He was my mentor. He had a sense of balance\nthat I didn't have. (laughs) - [Lex] Yeah. - He saw the beauty in every person. He was not as emotional as I am, more looking things in perspective. He really liked every person. He really grew up with the idea that a foreigner is a\nreason for curiosity, not for fear. This one time we went in Berkeley, and a homeless came out\nfrom some dark alley and said, \"Hey man, can you spare a dime?\" (Judea gasps) I retreated\nback, you know, two feet back, and Danny just hugged him\nand say \"Here's a dime. \"Enjoy yourself. Maybe you\nwant some money to take a bus \"or whatever.\" Where did he get it? Not from me. (both laugh) - Do you have advice for young minds today dreaming about creating,\nas you have dreamt, creating intelligent systems? What is the best way to arrive\nat new break-through ideas and carry them through\nthe fire of criticism and past conventional ideas? - Ask your questions. Really, your questions are never dumb. And solve them your own way. (laughs) And don't take \"no\" for an answer. If they're really dumb,\nyou'll find out quickly, by trial and error, to see that they're not leading any place. But follow them, and try to\nunderstand things your way. That is my advice. I don't know if it's going to help anyone. - [Lex] No, that's brilliantly put. - There's a lot of inertia\nin science, in academia. It is slowing down science. - Yeah, those two words, \"your way,\" that's a powerful thing. It's against inertia, potentially. - [Judea] Against your professor. (Lex laughs) - I wrote \"The Book of Why\" in order to democratize common sense. - [Lex] Yeah. (laughs) - In order to instill\nrebellious spirits in students, so they wouldn't wait until the\nprofessor gets things right. (both laugh) - [Lex] So you wrote the\nmanifesto of the rebellion against the professor. (laughs) - [Judea] Against the professor, yes. - So looking back at\nyour life of research, what ideas do you hope ripple\nthrough the next many decades? What do you hope your legacy will be? I already have a tombstone carved. (both laugh) - Oh, boy. - The fundamental law of counterfactuals. That's what it-- it's a simple equation. Put a counterfactual in\nterms of a model surgery. That's it, because everything\nfollows from there. If you get that, all the rest. I can die in peace, and my student can derive all my knowledge by mathematical means. - The rest follows. Thank you so much for talking today. I really appreciate it. - My thank you for being so\nattentive and instigating. (both laugh) - We did it. - We did it. - [Lex] The coffee helped. Thanks for listening to this\nconversation with Judea Pearl. And thank you to our\npresenting sponsor, Cash App. Download it, use code LexPodcast. You'll get $10, and $10 will go to FIRST, a STEM education nonprofit\nthat inspires hundreds of thousands of young minds to learn and to dream of engineering our future. If you enjoy this podcast,\nsubscribe on YouTube, give it five stars on Apple\nPodcast, support on Patreon, or simply connect with me on Twitter. And now, let me leave you\nwith some words of wisdom from Judea Pearl. You cannot answer a question\nthat you cannot ask, and you cannot ask a question\nthat you have no words for. Thank you for listening, and\nhope to see you next time."
    }
  ],
  "full_text": "- The following is a\nconversion with Judea Pearl, professor at UCLA and a\nwinner of the Turing Award, that's generally recognized as\nthe Nobel Prize of computing. He's one of the seminal figures in the field of artificial intelligence, computer science, and statistics. He has developed and championed\nprobabilistic approaches to AI, including Bayesian networks, and profound ideas in\ncausality in general. These ideas are important not just to AI, but to our understanding\nand practice of science. But in the field of AI,\nthe idea of causality, cause and effect, to many, lie at the core of what\nis currently missing and what must be developed in order to build truly\nintelligent systems. For this reason, and many others, his work is worth returning to often. I recommend his most recent\nbook called \"Book of Why\" that presents key ideas\nfrom a lifetime of work in a way that is accessible\nto the general public. This is the \"Artificial\nIntelligence Podcast.\" If you enjoy it, subscribe on YouTube, give it five stars on Apple Podcast, support on Patreon, or\nsimply connect with me on Twitter @lexfridman,\nspelled F-R-I-D-M-A-N. If you leave a review on\nApple Podcasts especially, but also Castbox, or comment on YouTube, consider mentioning topics, people, ideas, questions, quotes in science, tech, and philosophy, you find interesting, and I'll read them on this podcast. I won't call out names,\nbut I love comments with kindness and thoughtfulness in them, so I thought I'd share them with you. Someone on YouTube highlighted a quote from the conversation with Noam Chomsky where he said that the\nsignificance of your life is something you create. I like this line as well. On most days, the\nexistentialist approach to life is one I find liberating and fulfilling. I recently started doing ads at the end of the introduction. I'll do one or two minutes\nafter introducing the episode and never any ads in the middle that break the flow of the conversation. I hope that works for you and doesn't hurt the listening experience. This show is presented by Cash App, the number one finance\napp in the App Store. I personally use Cash App\nto send money to friends, but you can also use it to buy, sell, and deposit Bitcoin in just seconds. Cash App also has a new investing feature. You can buy fractions of\na stock, say $1 worth, no matter what the stock price is. Broker's services are provided\nby Cash App Investing, a subsidiary of Square, a member SIPC. I'm excited to be working with Cash App to support one of my favorite\norganizations called FIRST, best known for their FIRST\nRobotics and LEGO competitions. They educate and inspire\nhundreds of thousands of students in over 110 countries, and have a perfect rating\non Charity Navigator, which means the donated money is used to the maximum effectiveness. When you get Cash App from\nthe App Store or Google Play and use code LexPodcast, you'll get $10 and Cash App will also\ndonate $10 to FIRST. Which, again, is an organization that I've personally seen\ninspire girls and boys to dream of engineering a better world. And now, here's my\nconversation with Judea Pearl. You mentioned in an interview that science is not a collection of facts, but a constant human struggle\nwith the mysteries of nature. What was the first mystery that you can recall that hooked you, that captivated your curiosity? - Oh, the first mystery. That's a good one. Yeah, I remember that. - [Lex] What was it? - I had a fever for three days when I learned about Descartes\nand a little geometry, and I found out that you\ncan do all the construction in geometry using algebra. And I couldn't get over it. I simply couldn't get out of bed. (chuckles) - What kinda world does\nanalytic geometry unlock? - Well, it connects algebra\nwith geometry, okay? So, Descartes has the idea\nthat geometrical construction and geometrical theorems and assumptions can be articulated in\nthe language of algebra. Which means that all the proofs\nthat we did in high school in trying to prove that\nthe three bisectors meet at one point, and that the (chuckles) All this can be proven by\nshuffling around notation. That was a traumatic experience. - (chuckles) Traumatic experience. - [Judea] For me, it was, it\nwas, I'm telling you, right? - So it's the connection between the different\nmathematical disciplines, that they all - They're not even two\ndifferent languages. - Languages.\n- Yeah. - Which mathematic\ndiscipline is most beautiful? Is geometry it for you? - Both are beautiful. They have almost the same power. - But there's a visual\nelement to geometry. - The visual element,\nit's more transparent. But once you get over to algebra then linear equations is a straight line. This translation is easily absorbed. To pass a tangent to a circle, you know, you have the basic theorems, and you can do it with algebra. But the transition from\none to another was really, I thought that Descartes was\nthe greatest mathematician of all times. - So, if you think of\nengineering and mathematics as a spectrum-- - [Judea] Yes. - You have walked casually\nalong this spectrum throughout your life. You know, a little bit\nof engineering and then you've done a little bit of\nmathematics here and there. - A little bit. We get a very solid\nbackground in mathematics because our teachers were geniuses. Our teachers came from\nGermany in the 1930s running away from Hitler. They left their careers\nin Heidelberg and Berlin, and came to teach high school in Israel. And we were the beneficiary\nof that experiment. When they taught us math, a good way. - What's a good way to teach math? - [Judea] Theorologically. - The people. - The people behind the theorems, yeah. Their cousins, and their nieces,\n(chuckles) and their faces, and how they jumped from the bathtub when they screamed, \"Eureka\"\nand ran naked in town. (laughs) - So you were almost educated\nas a historian of math. - No, we just got a\nglimpse of that history, together with the theorem,\nso every exercise in math was connected with a person, and the time of the person, the period. - [Lex] The period also\nmathematically speaking. - Mathematically speaking,\nyes, not a paradox. - Then in university, you had\ngone on to do engineering. - Yeah. I got a BS in\nEngineering at Technion. And then I moved here\nfor graduate school work, and I did the engineering in\naddition to physics in Rutgers. And it combined very\nnicely with my thesis, which I did in Elsevier\nLaboratories in superconductivity. - And then somehow thought to switch to almost computer science\nsoftware, even, not switched, but longed to become to get\ninto software engineering a little bit, almost in programming, if you can call it that in the 70s. There's all these disciplines. - Yeah. - If you were to pick a favorite, in terms of engineering and mathematics, which path do you think has more beauty? Which path has more power? - It's hard to choose, no? I enjoy doing physics. I even have a vortex named with my name. So, I have investment\nin immortality. (laughs) - So, what is a vortex? - Vortex is in superconductivity. - In the superconductivity. - You have terminal\ncurrent swirling around, one way or the other, going\nto have us throw one or zero, for computer that was\nwe worked on in the 1960 in Elsevier, and I discovered a few nice\nphenomena with the vortices. You push current and they move. - [Lex] So there's a Pearl vortex. - A Pearl vortex, why, you can google it. (both laugh) I didn't know about it,\nbut the physicist picked up on my thesis, on my PhD thesis, and it became popular when\nthin film superconductors became important, for high\ntemperature superconductors. So, they call it \"Pearl\nvortex\" without my knowledge. (laughs) I discovered it only about 15 years ago. - You have footprints\nin all of the sciences, so let's talk about the\nuniverse for a little bit. Is the universe, at the lowest level, deterministic or stochastic, in your amateur philosophy view? Put another way, does God play dice? - We know it is stochastic, right? - [Lex] Today. Today we\nthink it is stochastic. - Yes, we think because we have the Heisenberg\nuncertainty principle and we have some\nexperiments to confirm that. - All we have is\nexperiments to confirm it. We don't understand why. - [Judea] Why is already-- - You wrote a book about why. (laughs) - Yeah, it's a puzzle. It's a puzzle that you have\nthe dice-flipping machine, or God, and the result of the flipping, propagated with a speed faster\nthan the speed of light. (laughs) We can't explain it, okay? But, it only governs\nmicroscopic phenomena. - So you don't think of\nquantum mechanics as useful for understanding the nature of reality? - [Judea] No, it's diversionary. - So, in your thinking, the world might as well be deterministic? - The world is deterministic, and as far as a new one\nfiring is concerned, it is deterministic to\nfirst approximation. - What about free will? - Free will is also a nice exercise. Free will is an illusion, that we AI people are going to solve. - So, what do you think, once we solve it, that solution will look like? Once we put it in the page. - The solution will look like, first of all it will look like a machine. A machine that acts as\nthough it has free will. It communicates with other machines as though they have free will, and you wouldn't be able\nto tell the difference between a machine that does and a machine that doesn't have free will, eh? - So it propagates the\nillusion of free will amongst the other machines. - And faking it is having it, okay? That's what Turing test is all about. Faking intelligence is intelligence, because it's not easy to fake. It's very hard to fake, and you can only fake if you have it. - (laughs) That's such\na beautiful statement. (laughs) You can't fake it\nif you don't have it, yup. So, let's begin at the\nbeginning, with the probability, both philosophically and mathematically, what does it mean to say\nthe probability of something happening is 50%? What is probability? - It's a degree of\nuncertainty that an agent has about the world. - You're still expressing some knowledge in that statement. - Of course. If the probability is 90%,\nit's absolutely different kind of knowledge than if it is 10%. - But it's still not\nsolid knowledge, it's-- - It is solid knowledge, by. If you tell me that 90% assurance smoking will give you\nlung cancer in five years, versus 10%, it's a piece\nof useful knowledge. - So this statistical\nview of the universe, why is it useful? So we're swimming in complete uncertainty. Most of everything around you-- - It allows you to predict things with a certain probability, and computing those\nprobabilities are very useful. That's the whole idea of prediction. And you need prediction\nto be able to survive. If you cannot predict\nthe future then you just, crossing the street would\nbe extremely fearful. - And so you've done a\nlot of work in causation, so let's think about correlation. - I started with probability. - You started with probability. You've invented the Bayesian networks. - [Judea] Yeah. - And so, we'll dance back and forth between these levels of uncertainty, but what is correlation? So, probability is something\nhappening, is something, but then there's a bunch\nof things happening, and sometimes they happen\ntogether sometimes not. They're independent or not, so how do you think about\ncorrelation of things? - Correlation occurs when\ntwo things vary together over a very long time, is\none way of measuring it. Or, when you have a bunch of variables that they all vary cohesively, then we have a correlation here, and usually when we\nthink about correlation, we really think causation. Things cannot be correlation\nunless there is a reason for them to vary together. Why should they vary together? If they don't see each other,\nwhy should they vary together? - So underlying it somewhere is causation. - Yes. Hidden in our intuition there\nis a notion of causation, because we cannot grasp any\nother logic except causation. - And how does conditional\nprobability differ from causation? So, what is conditional probability? - Conditional probability\nis how things vary when one of them stays the same. Now, staying the same\nmeans that I have chosen to look only at those\nincidents where the guy has the same value as the previous one. It's my choice, as an experimenter, so things that are not correlated before could become correlated. Like for instance, if I have two coins which are uncorrelated, and I choose only those\nflippings experiments in which a bell rings,\nand the bell rings when at least one of them is a tail, okay, then suddenly I see correlation\nbetween the two coins, because I only looked at the\ncases where the bell rang. You see, it is my design. It is my ignorance essentially, with my audacity to\nignore certain incidents, I suddenly create a correlation where it doesn't exist physically. - Right. So, you just outlined one of the flaws of observing the world and\ntrying to infer something from the math about the world from looking at the correlation. - I don't look at it as a flaw. The world works like that. The flaws come if you try\nto impose causal logic on correlation. It doesn't work too well. - I mean, but that's exactly what we do. That has been the majority\nof science, is you-- - No, the majority of naive science. Statisticians know it. Statisticians know that if you condition on a third variable, then you can destroy\nor create correlations among two other variables. They know it. It's (speaks foreign language). There's nothing surprises them. That's why they all dismiss\nthe systems paradox, look \"Ah, we know it!\" They don't know anything\nabout it. (laughs) - Well, there's disciplines\nlike psychology, where all the variables\nare hard to account for, and so, oftentimes there is a leap between correlation to causation. - What do you mean, a leap? Who is trying to get\ncausation from correlation? There's no one. - [Lex] You're not proving causation, but you're sort of discussing it, implying, sort of hypothesizing\nwithout ability to-- - Which discipline you have in mind? I'll tell you if they are obsolete. (Lex laughs) Or if they are outdated, or\nthey're about to get outdated. - Yes, yes. - [Judea] Oh, yeah, tell me\nwhich ones you have in mind. - Well, psychology, you know-- - [Judea] Psychology, what, SEM? - No, no, I was thinking of\napplied psychology, studying, for example, we work with human behavior in semi-autonomous\nvehicles, how people behave. And you have to conduct these studies of people driving cars. - Everything starts with the question: What is the research question? - What is the research question? The research question: do people fall asleep when\nthe car is driving itself? - Do they fall asleep, or do they tend to fall\nasleep more frequently - [Lex] More frequently - than the car not driving itself. - [Lex] Not driving itself. That's a good question, okay. - You put people in the car,\nbecause it's real world. You can't conduct an experiment where you control everything. - [Judea] Why can't you con-- - You could. - [Judea] Turn the\nautomatic module on and off. - Because there's aspects\nto it that's unethical, because it's testing on public roads. The drivers themselves have to\nmake that choice themselves, and so they regulate that. So, you just observe when\nthey drive it autonomously, and when they don't. - But maybe they turn it\noff when they're very tired. - [Lex] Yeah, that kind of thing. But you don't know those variables. - Okay, so you have now\nuncontrolled experiment, - [Lex] Uncontrolled experiment. - When we correct observation of study, and when we form the correlation detected, we have to infer causal relationship, whether it was the automatic piece that cause them to fall asleep, or, so that is an issue that\nis about 120 years old. - [Lex] (laughs) Yeah. - Oh, I should only go\n100 years old, okay? - [Lex] (chuckles) Who's counting? - Oh, maybe, no, actually I\nshould say it's 2,000 years old, because we have this experiment by Daniel, about the Babylonian king, that wanted the exiled people from Israel, that were taken in exile to\nBabylon to serve the king. He wanted to serve them\nking's food, which was meat, and Daniel as a good Jew\ncouldn't eat non-Kosher food, so he asked them to eat vegetarian food. But the king's overseers said, \"I'm sorry, \"but if the king sees that\nyour performance falls \"below that of other kids,\nnow, he's going to kill me.\" Daniel said, \"Let's make an experiment. \"Let's take four of us\nfrom Jerusalem, okay? \"Give us vegetarian food. \"Let's take the other guys\nto eat the king's food, \"and about a week's time,\nwe'll test our performance.\" And you know the answer,\nbecause he did the experiment, and they were so much\nbetter than the others, that the kings nominated them\nto super positions, (laughs) in his case, so it was a first experiment. So that there was a very simple, it's also the same research questions. We want to know if vegetarian food assists or obstructs your mental ability. So, the question is a very old one. Even Democritus, if I could\ndiscover one cause of things, I would rather discuss one\ncause than be King of Persia. The task of discovering\ncauses was in the mind of ancient people from\nmany, many years ago. But, the mathematics of doing that was only developed in the 1920s. So, science has left us orphaned. Science has not provided\nus with the mathematics to capture the idea of x causes\ny and y does not cause x. Because all the question of physics are symmetrical, algebraic. The equality sign goes both ways. - Okay, let's look at machine learning. Machine learning today, if you\nlook at deep neural networks, you can think of it as kind\nof conditional probability estimators. - [Judea] Conditional probability. Correct. Beautiful. Well, did you say that? - [Lex] What? - Conditional probability estimators. None of the machine learning\npeople clobbered you? (laughs)\nAttacked you? - Most people, and this is\nwhy today's conversation I think is interesting is, most people would agree with you. There's certain aspects that\nare just effective today, but we're going to hit a wall,\nand there's a lot of ideas, I think you're very right, that we're going to have to\nreturn to, about causality. Let's try to explore it. - Okay. - Let's even take a step back. You invented Bayesian networks, that look awfully a lot\nlike they express something like causation, but they\ndon't, not necessarily. So, how do we turn Bayesian networks into expressing causation? How do we build causal networks? A causes B, B causes C. How do we start to infer\nthat kind of thing? - We start by asking ourselves question: what are the factors that\nwould determine the value of x? X could be blood pressure, death, hunger. - But these are hypotheses\nthat we propose-- - Hypotheses, everything\nwhich has to do with causality comes from a theory. The difference is only how\nyou interrogate the theory that you have in your mind. - So it still needs the\nhuman expert to propose-- - Right. They need the human expert\nto specify the initial model. Initial model could be very qualitative. Just who listens to whom? By whom listens I mean one\nvariable listens to the other. So, I say okay, the tide\nis listening to the moon, and not to the rooster\ncrow, okay, and so forth. This is our understanding of\nthe world in which we live, scientific understanding of reality. We have to start there,\nbecause if we don't know how to handle cause and effect relationship, when we do have a model, and\nwe certainly do not know how to handle it when we don't have a model, so that starts first. An AI slogan is presentation\nfirst, discovery second. But, if I give you all the\ninformation that you need, can you do anything useful with it? That is the first, representation. How do you represent it? I give you all the knowledge in the world. How do you represent it? When you represent it, I ask you, can you infer x or y or z? Can you answer certain queries? Is it complex? Is it polynomial? All the computer science exercises, we do, once you give me a\nrepresentation for my knowledge. Then you can ask me, now that I understand how to represent things,\nhow do I discover them? It's a secondary thing. - I should echo the statement that mathematics in much of\nthe machine learning world has not considered\ncausation, that A causes B. Just in anything. That seems like a non-obvious thing that you think we would\nhave really acknowledged it, but we haven't. So we have to put that on the table. Knowledge, How hard is it to create a\nknowledge from which to work? - In certain area, it's easy, because we have only four\nor five major variables. An epidemiologist or an\neconomist can put them down. The minimum wage,\nunemployment, policy xyz, and start collecting data, and quantify the parameters\nthat were left unquantified, with initial knowledge. That's the routine work that you find in experimental psychology,\nin economics, everywhere. In health science, that's a routine thing. But I should emphasize, you should start with the research question. What do you want to estimate? Once you have that, you\nhave to have a language of expressing what you want to estimate. You think it's easy? No. - So we can talk about\ntwo things, I think. One is how the science of\ncausation is very useful for answering certain questions, and then the other is how do\nwe create intelligent systems that need to reason with causation? So if my research question\nis how do I pick up this water bottle from the table? All the knowledge that is\nrequired to be able to do that, how do we construct that knowledge base? Do we return back to the problem that we didn't solve in the\n80s with expert systems? Do we have to solve that problem, of automated construction of knowledge? You're talking about the\ntask of eliciting knowledge from an expert. - Task of eliciting\nknowledge from an expert, or self discovery of more knowledge, more and more knowledge. So, automating the building of knowledge as much as possible. - It's a different game,\nin the causal domain, because essentially it is the same thing. You have to start with some knowledge, and you're trying to enrich it. But you don't enrich it\nby asking for more rules. You enrich it by asking for the data. To look at the data, and quantifying, and ask queries that you\ncouldn't answer when you started. You couldn't because the\nquestion is quite complex, and it's not within the\ncapability of ordinary cognition, of ordinary person, ordinary\nexpert even, to answer. - So what kind of questions\ndo you think we can start to answer? - Even a simple, I suppose, yeah. (laughs) I start with easy one. - [Lex] Let's do it. - Okay, what's the effect\nof a drug on recovery? Was it the aspirin that caused\nmy headache to be cured, or was it the television program, or the good news I received? This is already, see,\nit's a difficult question because it's: find the cause from effect. The easy one is find effect from cause. - That's right. So first you construct a model saying that this an important research question. This is an important question. Then you-- - I didn't construct a model yet. I just said it's important question. - Important question. - And the first exercise is,\nexpress it mathematically. What do you want to prove? Like, if I tell you\nwhat will be the effect of taking this drug? Okay, you have to say that in mathematics. How do you say that? - Yes. - [Judea] Can you write down the question. Not the answer. I want to find the effect\nof a drug on my headache. - Right. - [Judea] Write it down, write it down. That's where the do-calculus\ncomes in. (laughs) - [Judea] Yes. The do-operator, the do-operator. - Do-operator, yeah. Which is nice. It's the difference between\nassociation and intervention. Very beautifully sort of constructed. - Yeah, so we have a do-operator. So, the do-calculus connected-- and the do-operator itself,\nconnects the operation of doing to something that we can see. - Right. So as opposed to the purely observing, you're making the choice\nto change a variable-- - That's what it expresses. And then, the way that we interpret it, the mechanism by which we take your query, and we translate it into\nsomething that we can work with, is by giving it semantics, saying that you have a model of the world, and you cut off all the\nincoming arrows into x, and you're looking now in the\nmodified, mutilated model, you ask for the probability of y. That is interpretation of doing x, because by doing things,\nyou've liberated them from all influences that\nacted upon them earlier, and you subject them to the\ntyranny of your muscles. - So you (chuckles) you\nremove all the questions about causality by doing them. - So there is one level of questions. Answer questions about what\nwill happen if you do things. If you do, if you drink the coffee, or if you take the aspirin. - [Judea] Right. - So how do we get the\ndoing data? (laughs) - Hah. Now the question is,\nif you cannot run experiments, right, then we have to rely\non observation and study. - So first we could, sorry to interrupt, we could run an experiment, where we do something,\nwhere we drink the coffee, and the do-operator allows you to sort of be systematic\nabout expressing that. - To imagine how the\nexperiment will look like even though we cannot\nphysically and technologically conduct it. I'll give you an example. What is the effect of blood\npressure on mortality? I cannot go down into your vein and change your blood pressure. But I can ask the question, which means I can have\na model of your body. I can imagine how the\nblood pressure change will affect your mortality. How? I go into the model, and\nI conduct this surgery, about the blood pressure, even though physically I cannot do it. - Let me ask the quantum\nmechanics question. Does the doing change the observation? Meaning, the surgery of\nchanging the blood pressure-- - No, the surgery is very delicate. - [Lex] It's very delicate. Infinitely delicate. (laughs) - Incisive and delicate, which means, do-x means\nI'm going to touch only x. - [Lex] Only x. - Directly into x. So, that means that I change only things which depend on x, by\nvirtue of x changing. But I don't depend things\nwhich are not depend on x. Like, I wouldn't change\nyour sex, or your age. I just change your blood pressure, okay? - So, in the case of\nblood pressure, it may be difficult or impossible to\nconstruct such an experiment. - No, but physically, yes. But hypothetically no. - [Lex] Hypothetically no. - If we had a model, that\nis what the model is for. So, you conduct surgeries on the models. You take it apart, put it back. That's the idea for model. It's the idea of thinking\ncounterfactually, imagining, and that idea of creativity. - So by constructing\nthat model you can start to infer if the blood\npressure leads to mortality, which increases or decreases, whi-- - I construct a model. I still cannot answer it. I have to see if I have enough\ninformation in the model that would allow me to find\nout the effects of intervention from an uninterventional\nstudy, from a hands-off study. - [Lex] So what's needed-- - We need to have assumptions\nabout who affects whom. If the graph has a certain property, the answer is \"yes, you can get it from\nobservational study.\" If the graph is too mushy bushy bushy, the answer is, \"no, you cannot.\" Then you need to find\neither different kind of observation that\nyou haven't considered, or one experiment. - So, basically, that puts\na lot of pressure on you to encode wisdom into that graph. - Correct. But you don't have to encode\nmore than what you know. God forbid. The economists are doing that. They call identifying assumptions. They put assumptions,\neven they don't prevail in the world, they put assumptions so they can identify things. - Yes, beautifully put. But, the problem is you don't\nknow what you don't know. - You know what you don't know, because if you don't know,\nyou say it's possible that x affect the traffic tomorrow. It's possible. You put down an arrow\nwhich says it's possible. Every arrow in the graph\nsays it's possible. - [Lex] So there's not a\nsignificant cost to adding arrows, - The more arrow you add-- - [Lex] The better. - The less likely you\nare to identify things from purely observational data. So if the whole world is bushy, and everybody effect everybody else, the answer is-- you can\nanswer it ahead of time. I cannot answer my query\nfrom observational data. I have to go to experiments. - So, you talk about machine\nlearning as essentially learning by association, or\nreasoning by association, and this do-calculus is\nallowing for intervention. I like that word. You also talk about counterfactuals. - Yeah. - And trying to sort of\nunderstand the difference between counterfactuals and intervention, first of all, what is counterfactuals, and why are they useful? Why are they especially useful as opposed to just reasoning\nwhat effect actions have? - Well, counterfactual\ncontains what we know will equal explanations. - Can you give an\nexample of what kind of-- - If I tell you that acting\none way affects something else, I didn't explain anything yet. But if I ask you, was it the\naspirin that cure my headache, I'm asking for explanation:\nwhat cure my headache? And putting a finger on\naspirin, provide explanation. It was the aspirin that was responsible for your headache going away. If you didn't take the aspirin, you will still have a headache. - So by saying, \"If I didn't take aspirin, \"I would have a headache,\" you're thereby saying,\n\"The aspirin is the thing \"that removed the headache.\" - Yes, but you have to have\nanother point of information. I took the aspirin, and\nmy headache is gone. It's very important information. Now we're reasoning backward, and I say, \"Was it the aspirin?\" - Yeah. By considering what would have happened if everything is the same,\nbut I didn't take aspirin. - That's right. So we know that things\ntook place, you know? Joe killed Schmo. And Schmo would be alive\nhad Joe not used his gun. Okay, so that is the counterfactual. It had a confliction. It had a conflict here, or clash between observed fact\n-- he did shoot, okay -- and the hypothetical predicate, which says, had he not shot. You have a clash, a logical clash, that cannot exist together. That's counterfactual, and that is the source of our explanation of the idea of responsibility,\nregret, and free will. - Yes, it certainly seems, that's the highest level\nof reasoning, right? Counterfactual. - [Judea] Yes, and physicists\ndo it all the time. - Who does it all the time? - [Judea] Physicists. - Physicists. - In every equation of physics, you have Hooke's law, and you put one kilogram on the spring, and the spring is one meter, and you say, \"Had this\nweight been two kilograms, \"the spring would have\nbeen twice as long.\" It's not a problem for\nphysicists to say that. Instead with mathematics, it\nis in the form of an equation, equating the weight,\nproportionality constant, and the length of the spring. We don't have the assymetry\nin the equation of physics, although every physicist\nthinks counterfactually. Ask high school kids, had the\nweight been three kilograms, what would be the length of the spring? They can answer it immediately, because they do the counterfactual\nprocessing in their mind, and then they put it into\nequation, algebraic equation, and they solve it. But a robot cannot do that. - How do you make a robot\nlearn these relationships? - Why use the word \"learn?\" Suppose you tell him, can you do it? Before you go learning,\nyou have to ask yourself, suppose I give all the information. Can the robot perform a task\nthat I ask him to perform? Can he reason and say,\n\"No, it wasn't the aspirin. \"It was the good news we\nreceived on the phone.\" - Right, because, well,\nunless the robot had a model, a causal model of the world. - [Judea] Right, right. - I'm sorry I have to linger on this-- - [Judea] But now we have to\nlinger, and we have to say, \"How do we do it?\" - How do we build it? - [Judea] Yes. - How do we build a causal model without a team of human\nexperts running around-- - No, why did you go\nto learning right away? You are too much involved with learning. - Because I like babies. Babies learn fast, and\nI'm trying to figure out how they do it. - Good. That's another question: How do the babies come out with the counterfactual\nmodel of the world? And babies do that. They know how to play in the crib. They know which balls hits another one, and they learn it by playful manipulation of the world. Their simple world involves\nall these toys and balls and chimes (laughs) but if you think about\nit, it's a complex world. - We take for granted how complicated-- - And the kids do it by\nplayful manipulation, plus parent guidance,\npeer wisdom, and heresay. They meet each other, and they say, \"You shouldn't have\ntaken my toy.\" (laughs) - Right, and these multiple sources of information, they're able to integrate. So, the challenge is\nabout how to integrate, how to form these causal relationships from different sources of data. - [Judea] Correct. - So, how much causal\ninformation is required to be able to play in the\ncrib with different objects? - I don't know. I haven't experimented\nwith the crib. (chuckles) - [Lex] Okay, not a crib-- - I know, it's a very interesting-- - Manipulating physical\nobjects on this very, opening the pages of\na book, all the tasks, physical manipulation\ntasks, do you have a sense? Because my sense is the world\nis extremely complicated. - Extremely complicated. I agree and I don't\nknow how to organize it, because I've been spoiled by easy problems such as cancer and death, okay? (laughs) - [Lex] First we have to start trying to-- - No, but it's easy, easy in the sense that you have only 20 variables, and they are just variables. They are not mechanics, okay? It's easy. You just put them on the graph and they speak to you. (laughs) - [Lex] And you're providing a methodology for letting them speak. - I'm working only in the abstract. The abstract is knowledge\nin, knowledge out, data in between. - Now, can we take a\nleap to trying to learn, when it's not 20 variables\nbut 20 million variables, trying to learn causation in this world. Not learn, but somehow construct models. I mean, it seems like you would only have to be able to learn, because constructing it\nmanually would be too difficult. Do you have ideas of-- - I think it's a matter\nof combining simple models from many, many sources,\nfrom many, many disciplines. And many metaphors. Metaphors are the basis\nof human intelligence. - Yeah, so how do you\nthink about a metaphor in terms of its use in human intelligence? - Metaphors is an expert system. It's mapping problem with\nwhich you are not familiar, to a problem with which you are familiar. Like I give you a great example. The Greek believed that\nthe sky is an opaque sheer. It's not really infinite\nspace; it's an opaque sheer, and the stars are holes\npoked in the sheer, through which you see the eternal light. It was a metaphor, why? Because they understand how\nyou poke holes in sheers. They were not familiar\nwith infinite space. And we are walking on a shell of a turtle, and if you get too close to the edge, you're going to fall down\nto Hades, or wherever, yeah. That's a metaphor. It's not true. But these kind of metaphor\nenabled Eratosthenes to measure the radius of the Earth, because he said, \"Come on. \"If we are walking on a turtle shell, \"then the ray of light\ncoming to this place \"will be different angle\nthan coming to this place. \"I know the distance. \"I'll measure the two angles, \"and then I have the radius\nof the shell of the turtle.\" And he did. And his measurement was very close to the measurements we have today. It was, what, 6,700\nkilometers, was the Earth? That's something that would not occur to a Babylonian astronomer, even though the Babylonian experiments were the machine learning\npeople of the time. They fit curves, and they\ncould predict the eclipse of the moon much more\naccurately than the Greek, because they fit curves. That's a different metaphor, something that you're familiar with, a game, a turtle shell. What does it mean, if you are familiar? Familiar means that answers\nto certain questions are explicit. You don't have to derive them. - And they were made explicit because somewhere in the\npast you've constructed a model of that-- - You're familiar with,\nso the child is familiar with billiard balls. So the child could predict that if you let loose of one ball, the other one will bounce off. You attain that by familiarity. Familiarity is answering questions, and you store the answer explicitly. You don't have to derive it. So this is idea for metaphor. All our life, all our intelligence, is built around metaphors, mapping from the\nunfamiliar to the familiar, but the marriage between\nthe two is a tough thing, which we haven't yet been\nable to algorithmatize. - So, you think of that\nprocess of using metaphor to leap from one place to another. We can call it reasoning. Is it a kind of reasoning? - [Judea] It is a reasoning\nby metaphor, but-- - Reasoning by metaphor. Do you think of that as learning? So, learning is a\npopular terminology today in a narrow sense. - [Judea] It is, it is definitely. - So you may not-- you're right. - It's one of the most important learning, taking something which\ntheoretically is derivable, and store it in accessible format. I'll give you an example: chess, okay? Finding the winning starting\nmove in chess is hard. But there is an answer. Either there is a winning move\nfor white, or there isn't, or it is a draw. So, the answer to that is available through the rule of the game. But we don't know the answer. So what does a chess master\nhave that we don't have? He has stored explicitly an evaluation of certain complex pattern of the board. We don't have it,\nordinary people, like me. I don't know about you. I'm not a chess master. So for me I have to derive\nthings that for him is explicit. He has seen it before, or he\nhas seen the pattern before, or similar patterns before, and he generalizes, and says, \"Don't move; it's a dangerous move.\" - It's just that, not\nin the game of chess, but in the game of billiard balls we humans are able to initially\nderive very effectively and then reason by\nmetaphor very effectively, and we make it look so easy, and it makes one wonder how hard is it to build it in a machine? In your sense, (laughs)\nhow far away are we to be able to construct-- - I don't know. I'm not a futurist. All I can tell you is that we\nare making tremendous progress in the causal reasoning domain. Something that I even dare\nto call it a revolution, the causal revolution, because what we have achieved\nin the past three decades is something that dwarf\neverything that was derived in the entire history. - So there's an excitement about current machine\nlearning methodologies, and there's really important\ngood work you're doing in causal inference. Where do these worlds collide,\nand what does that look like? - First they gotta work\nwithout collisions. (laughs) It's got to work in harmony. - [Lex] Harmony. - The human is going to\njumpstart the exercise by providing qualitative,\nnoncommitting models of how the universe works, how reality, the domain\nof discourse, works. The machine is going to\ntake over from that point of view, and derive whatever the calculus says can be derived, namely, quantitative\nanswer to our questions. These are complex questions. I'll give you some examples\nof complex questions, that boggle your mind\nif you think about it. You take the results of\nstudies in diverse population, under diverse conditions, and you infer the cause\neffect of a new population which doesn't even resemble\nany of the ones studied. You do that by do-calculus. You do that by generalizing\nfrom one study to another. See, what's common there too? What is different? Let's ignore the differences\nand pull out the commonality. And you do it over maybe 100\nhospitals around the world. From that, you can get\nreally mileage from big data. It's not only that you have many samples; you have many sources of data. - So that's a really\npowerful thing, I think, especially for medical applications. Cure cancer, right? That's how, from data,\nyou can cure cancer. So we're talking about causation, which is the temporal\nrelationships between things. - Not only temporal. It was structural and temporal. Temporal precedence by itself\ncannot replace causation. - Is temporal precedence the\narrow of time in physics? - [Judea] Yeah, it's important, necessary. - It's important. - [Judea] Yes. - Is it? - Yes, I've never seen a\ncause propagate backwards. - But if we use the word cause, but there's relationships\nthat are timeless. I suppose that's still\nforward an arrow of time. But, are there relationships,\nlogical relationships, that fit into the structure? - [Judea] Sure. All do-calculus\nis logical relationships. - That doesn't require a temporal. It has just the condition that you're not traveling back in time. - [Judea] Yes, correct. - So it's really a generalization, a powerful generalization, of what-- - [Judea] Of boolean logic. - Yeah, boolean logic. - [Judea] Yes. - That is sort of simply\nput, and allows us to reason about the order\nof events, the source-- - Not about, between. But not deriving the order of events. We are given cause effect relationships. They ought to be obeying the\ntime precedence relationship. We are given that, and now that we ask questions about other causal relationships, that could be derived\nfrom the initial ones, but were not given to us explicitly. Like the case of the\nfiring squad I gave you in the first chapter and I ask, \"What if rifleman A declined to shoot? Would the prisoner still be dead? To decline to shoot, it means\nthat he disobeyed orders. The rule of the games were that\nhe is an obedient marksman. That's how you start. That's the initial order, but now you ask question\nabout breaking the rules. What if he decided not\nto pull the trigger, because became a pacifist? You and I can answer that. The other rifleman would have\nhit and killed him, okay? I want a machine to do that. Is it so hard to ask a machine to do that? It's such a simple task. But they have to have a calculus for that. - Yes, yeah. But the curiosity, the\nnatural curiosity for me, is that yes, you're absolutely\ncorrect and important, and it's hard to believe\nthat we haven't done this seriously, extensively,\nalready a long time ago. So, this is really important work, but I also want to know, maybe you can philosophize\nabout how hard is it to learn. - Look, let's assume learning. We want learning, okay? - We want to learn. - So what do we do? We put a learning machine\nthat watches execution trials in many countries, in many\n(laughs) locations, okay? All the machine can learn\nis to see shot or not shot. Dead, not dead. A court issued an order or\ndidn't, okay, just the fact. For the fact, you don't\nknow who listens to whom. You don't know that the condemned person listens to the bullets, that the bullets are listening\nto the captain, okay? All we hear is one command,\ntwo shots, dead, okay? A triple of variables:\nyes, no, yes, no, okay. From that you can learn\nwho listens to whom? And you can answer the question? No. - Definitively, no. But don't you think you\ncan start proposing ideas for humans to review? You want machine to learn it,\nall right, you want a robot. So robot is watching trials\nlike that, 200 trials, and then he has to answer the question, what if rifleman A\nrefrained from shooting. - [Lex] Yeah. So how do we do that? - (laughs) That's exactly my point. If looking at the facts\ndon't give you the strings behind the facts--\n- Absolutely, but so you think of machine learning, as it's currently defined, as only something that looks\nat the facts and tries to-- - [Judea] Right now they\nonly look at the facts. - Yeah, so is there a way\nto modify, in your sense-- - [Judea] Yeah, playful manipulation - Playful manipulation. Doing the interventionist kind of things. - But it could be at random. For instance, the\nrifleman is sick that day, or he just vomits, or whatever. So, we can observe this unexpected event, which introduced noise. The noise still have\nto be random to be able to relate it to randomized experiments, and then you have observational studies, from which to infer the\nstrings behind the facts. It's doable to a certain extent. But now that we're\nexpert in what you can do once you have a model, we can reason back and say\nwhat kind of data you need to build a model. - Got it. So, I know you're not a futurist, but are you excited? Have you, when you look back at your life, longed for the idea of creating\na human level intelligence-- - Well, yeah, I'm driven by that. All my life I'm driven\njust by one thing. (laughs) But I go slowly. I go from what I know, to\nthe next step incrementally. - So, without imagining what\nthe end goal looks like, do you imagine-- - The end goal is going to be a machine that can answer sophisticated questions: counterfactuals, regret,\ncompassion, responsibility, and free will. - So what is a good test? Is a Turing test a reasonable test? - A Turing test of free\nwill doesn't exist yet. There's not-- - [Lex] How would you\ntest free will? That's a-- - So far we know only one\nthing, merely (laughs) if robots can communicate, with reward and punishment\namong themselves, and hitting each other on the wrists, and say \"You shouldn't have done that.\" Playing better soccer\nbecause they can do that. - [Lex] What do you mean,\nbecause they can do that? - Because they can\ncommunicate among themselves. - [Lex] Because of the communication, they can do the soccer. - Because they communicate like\nus, rewards and punishment, yes, you didn't pass\nthe ball the right time, and so forth; therefore you're going to sit\non the bench for the next two, if they start communicating like that, the question is, will\nthey play better soccer? As opposed to what? As opposed to what they do now? Without this ability to reason\nabout reward and punishment. Responsibility. - And counterfactuals. - So far, I can only\nthink about communication. - Communication, and not\nnecessarily in natural language, but just communication. - Just communication, and that's important to have\na quick and effective means of communicating knowledge. If the coach tells you you\nshould have passed the ball, ping, he conveys so much knowledge to you as opposed to what? Go down and change your software, right. That's the alternative. But the coach doesn't know your software. So how can a coach tell you you should have passed the ball? But, our language is very effective: you should have passed the ball. You know your software. You tweak the right module, okay, and next time you don't do it. - Now that's for playing soccer, where the rules are well defined. - No, no, no, they're not well defined. When you should pass the ball-- - Is not well defined. - No, it's very noisy. Yes, you have to do it\nunder pressure (laughs) - It's art. But in terms of aligning values between computers and humans, do you think this cause\nand effect type of thinking is important to align the\nvalues, morals, ethics under which machines make decisions. Is the cause effect where\nthe two can come together? - Cause effect is necessary component to build an ethical machine, because the machine has to empathize, to understand what's good for you, to build a model of you, as a recipient. We should be very much-- What is compassion? The imagine that you\nsuffer pain as much as me. - [Lex] As much as me. - I do have already a\nmodel of myself, right? So it's very easy for\nme to map you to mine. I don't have to rebuild a model. It's much easier to say,\n\"Ah, you're like me.\" Okay, therefore, I will\nnot hit you, okay? (laughs) - And the machine has to imagine, has to try to fake to be human. Essentially so you can imagine\nthat you're like me, right? - Whoa, whoa, whoa, who is me? That's further; that's consciousness. They have a model of yourself. Where do you get this model? You look at yourself as if you\nare part of the environment. If you build a model of\nyourself versus the environment, then you can say, \"I need\nto have a model of myself. \"I have abilities; I have\ndesires, and so forth,\" okay? I have a blueprint of myself, though, not a full detail, though,\nbecause I cannot get the whole thing problem, but I have a blueprint. So at that level of a\nblueprint, I can modify things. I can look at myself\nin the mirror and say, \"Hmm, if I tweak this model, \"I'm going to perform differently.\" That is what we mean\nby free will. (laughs) - And consciousness. What do you think is consciousness? Is it simply self awareness,\nincluding yourself into the model of the world? - That's right. Some people tell me no, this\nis only part of consciousness, and then they start telling\nwhat they really mean by consciousness, and I lose them. For me, consciousness\nis having a blueprint of your software. - Do you have concerns\nabout the future of AI, all the different trajectories\nof all the research? - [Judea] Yes. - Where's your hope\nwhere the movement heads? Where are your concerns? - I'm concerned, because I know we are\nbuilding a new species that has the capability of exceeding us, exceeding our capabilities, and can breed itself and take\nover the world, absolutely. It's a new species; it is uncontrolled. We don't know the degree\nto which we control it. We don't even understand what it means, to be able to control this new species. So, I'm concerned. I don't have anything to add to that because it's such a\ngray area, that unknown. It never happened in history. The only time it happened in history, was evolution with the human being. - [Lex] Right. - And it was very\nsuccessful, was it? (laughs) Some people say it was a great success. - For us, it was, but a\nfew people along the way, yeah, a few creatures along\nthe way would not agree. So, just because it's such a gray area, there's nothing else to say. - [Judea] We have a sample of one. - Sample of one. - [Judea] It's us. - Some people would look\nat you, and say, yeah but we were looking to\nyou to help us make sure that sample two works out okay. - Correct. Actually we have more\nthan a sample of one. We have theories. And that's good; we don't\nneed to be statisticians. So, sample of one doesn't\nmean poverty of knowledge. It's not. Sample of one plus theory,\nconjecture or theory, of what could happen, that we do have. But I really feel helpless in\ncontributing to this argument, because I know so little, and my imagination is limited, and I know how much I don't know, but I'm concerned. - You were born and raised in Israel. - [Judea] Born and raised in Israel, yes. - And later served in the\nIsrael military defense forces. - In the Israel Defense Force. - What did you learn from that experience? - From that experience? (laughs) - [Lex] There's a\nkibbutz in there as well. - Yes, because I was in a NAHAL, which is a combination\nof agricultural work and military service. I was an idealist. I wanted to be a member of the kibbutz throughout my life, and to live a communal life, and so I prepared myself for that. Slowly, slowly I wanted\na greater challenge. - So, that's a far world away, both in t-- But I learned from that, what a kidada. It was a miracle It was a miracle that\nI served in the 1950s. I don't know how we survived. The country was under austerity. It tripled its population\nfrom 600,000 to 1.8 million when I finished college. No one went hungry. Austerity, yes. When you wanted to make\nan omelet in a restaurant, you had to bring your own egg. And the imprisoned people\nfrom bringing the food from the farming area, from\nthe villages, to the city. But no one went hungry, and I always add to that:\nhigher education did not suffer any budget cuts. They still invested in me, in\nmy wife, in our generation. To get the best education that they could. So I'm really grateful for the progenity, and I'm trying to pay back now. It's a miracle that we\nsurvived the war of 1948. They were so close to a second genocide. It was all planned. (laughs) But we survived it by a miracle, and then the second miracle\nthat not many people talk about, the next phase, how no one went hungry, and the country managed\nto triple its population. You know what it means\nto triple population? Imagine United States going\nfrom, what, 350 million to (laugh) unbelievable. - This is a really\ntense part of the world. It's a complicated part of the world, Israel and all around. Religion is at the core\nof that complexity, or one of the components-- Religion is a strong motivating course for many, many people\nin the Middle East, yes. - In your view, looking back,\nis religion good for society? - That's a good question\nfor robotics, you know? - [Lex] There's echoes of that question. - Should we equip robot\nwith religious beliefs? Suppose we find out, or we agree, that religion is a good thing,\nit will keep you in line. Should we give the robot\nthe metaphor of a god? As a metaphor, the robot\nwill get it without us, also. Why? Because a robot\nwill reason by metaphor. And what is the most primitive\nmetaphor a child grows with? Mother smile, father teaching, father image and mother image, that's God. So, whether you want it or not, (laughs) the robot will, assuming\nthe robot is going to have a mother and a father. It may only have program, though, which doesn't supply\nwarmth and discipline. Well, discipline it does. So, the robot will have\na model of the trainer. And everything that happens in the world, cosmology and so on, is going to be mapped into the programmer. (laughs) That's God. - The thing that represents\nthe origin for everything for that robot. - [Judea] It's the most\nprimitive relationship. - So it's going to\narrive there by metaphor. And so the question is\nif overall that metaphor has served us well, as humans. - I really don't know. I think it did, but as long as you keep in\nmind it is only a metaphor. (laughs) - So, if you think we can,\ncan we talk about your son? - [Judea] Yes, yes. - Can you tell his story? - [Judea] His story, well-- - Daniel. - His story is known. He was abducted in Pakistan,\nby al-Quaeda driven sect, and under various pretenses. I don't even pay attention\nto what the pretense was. Originally they wanted to\nhave United States deliver some promised airplanes, I-- It was all made up, you know, all these demands were bogus. I don't know, really, but eventually he was executed, in front of a camera. - At the core of that\nis hate and intolerance. - At the core, yes, absolutely, yes. We don't really appreciate\nthe depth of the hate with which billions of\npeoples are educated. We don't understand it. I just listened recently to what they teach you\nin Mogadishu. (laughs) When the war does stop, and the tap, we knew exactly who did it. The Jews. - [Lex] The Jews. We didn't know how,\nbut we knew who did it. We don't appreciate what it means to us. The depth is unbelievable. - Do you think all of\nus are capable of evil, and the education, the indoctrination, is really what creates evil? - Absolutely we are capable of evil. If you are indoctrinated\nsufficiently long, and in depth, we are capable of ISIS,\nwe are capable of Nazism, yes, we are. But the question is whether\nwe, after we have gone through some Western education, and we learn that everything\nis really relative, that there is no absolute God. He's only a belief in God. Whether we are capable,\nnow, of being transformed, under certain circumstances,\nto become brutal. - [Lex] Yeah. - That is a qu-- I'm worried about it, because some people say yes,\ngiven the right circumstances, given the bad economical crisis. You are capable of doing it,\ntoo, and that worries me. I want to believe that I'm not capable. - Seven years after Daniel's death, you wrote an article at\nthe Wall Street Journal titled \"Daniel Pearl and\nthe Normalization of Evil.\" - [Judea] Yes. - What was your message back then, and how did it change\ntoday, over the years? - I lost. - [Lex] What was the message? - The message was that we\nare not treating terrorism as a taboo. We are treating it as a bargaining\ndevice that is accepted. People have grievance, and\nthey go and bomb restaurants. It's normal. Look, you're even not\nsurprised when I tell you that. Twenty years ago you say,\n\"What? For grievance you go \"and blow a restaurant?\" Today it's become normalized. The banalisation of evil. And we have created that to\nourselves, by normalizing it, by making it part of political life. It's a political debate. Every terrorist yesterday\nbecomes a freedom fighter today and tomorrow is become a terrorist again. It's switchable. - [Lex] And so, we should call\nout evil when there's evil. - If we don't want to be part of it. - [Lex] Become it. - Yeah, if we want to\nseparate good from evil, that's one of the first things, that, in the Garden of Eden, remember? The first thing that God tells them was \"Hey, you want some knowledge? \"Here is the tree of good and evil.\" - So this evil touched\nyour life personally. Does your heart have anger,\nsadness, or is it hope? - Look, I see some beautiful\npeople coming from Pakistan. I see beautiful people everywhere. But I see horrible propagation\nof evil in this country, too. It shows you how populistic\nslogans can catch the mind of the best intellectuals. - Today is Father's Day. - [Judea] I didn't know that. - Yeah, what's a fond\nmemory you have of Daniel? - Oh, many good memories remains. He was my mentor. He had a sense of balance\nthat I didn't have. (laughs) - [Lex] Yeah. - He saw the beauty in every person. He was not as emotional as I am, more looking things in perspective. He really liked every person. He really grew up with the idea that a foreigner is a\nreason for curiosity, not for fear. This one time we went in Berkeley, and a homeless came out\nfrom some dark alley and said, \"Hey man, can you spare a dime?\" (Judea gasps) I retreated\nback, you know, two feet back, and Danny just hugged him\nand say \"Here's a dime. \"Enjoy yourself. Maybe you\nwant some money to take a bus \"or whatever.\" Where did he get it? Not from me. (both laugh) - Do you have advice for young minds today dreaming about creating,\nas you have dreamt, creating intelligent systems? What is the best way to arrive\nat new break-through ideas and carry them through\nthe fire of criticism and past conventional ideas? - Ask your questions. Really, your questions are never dumb. And solve them your own way. (laughs) And don't take \"no\" for an answer. If they're really dumb,\nyou'll find out quickly, by trial and error, to see that they're not leading any place. But follow them, and try to\nunderstand things your way. That is my advice. I don't know if it's going to help anyone. - [Lex] No, that's brilliantly put. - There's a lot of inertia\nin science, in academia. It is slowing down science. - Yeah, those two words, \"your way,\" that's a powerful thing. It's against inertia, potentially. - [Judea] Against your professor. (Lex laughs) - I wrote \"The Book of Why\" in order to democratize common sense. - [Lex] Yeah. (laughs) - In order to instill\nrebellious spirits in students, so they wouldn't wait until the\nprofessor gets things right. (both laugh) - [Lex] So you wrote the\nmanifesto of the rebellion against the professor. (laughs) - [Judea] Against the professor, yes. - So looking back at\nyour life of research, what ideas do you hope ripple\nthrough the next many decades? What do you hope your legacy will be? I already have a tombstone carved. (both laugh) - Oh, boy. - The fundamental law of counterfactuals. That's what it-- it's a simple equation. Put a counterfactual in\nterms of a model surgery. That's it, because everything\nfollows from there. If you get that, all the rest. I can die in peace, and my student can derive all my knowledge by mathematical means. - The rest follows. Thank you so much for talking today. I really appreciate it. - My thank you for being so\nattentive and instigating. (both laugh) - We did it. - We did it. - [Lex] The coffee helped. Thanks for listening to this\nconversation with Judea Pearl. And thank you to our\npresenting sponsor, Cash App. Download it, use code LexPodcast. You'll get $10, and $10 will go to FIRST, a STEM education nonprofit\nthat inspires hundreds of thousands of young minds to learn and to dream of engineering our future. If you enjoy this podcast,\nsubscribe on YouTube, give it five stars on Apple\nPodcast, support on Patreon, or simply connect with me on Twitter. And now, let me leave you\nwith some words of wisdom from Judea Pearl. You cannot answer a question\nthat you cannot ask, and you cannot ask a question\nthat you have no words for. Thank you for listening, and\nhope to see you next time."
}